<div id=toc></div>

# Table of Contents

- [q-bio.NC](#q-bio.NC) [Total: 3]
- [cs.CL](#cs.CL) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [1] [A Pre-trained Framework for Multilingual Brain Decoding Using Non-invasive Recordings](https://arxiv.org/abs/2506.03214)
*Yi Guo,Yihang Dong,Michael Kwok-Po Ng,Shuqiang Wang*

Main category: q-bio.NC

TL;DR: 提出了一种多语言、多被试和多模态的联合解码框架，通过预训练多语言模型统一语义空间，提升了脑机接口的解码性能和语言公平性。


<details>
  <summary>Details</summary>
Motivation: 当前脑机接口的解码方法局限于单语言、单被试和单模态，限制了其临床应用和泛化能力。

Method: 将多样化的脑记录映射到预训练多语言模型定义的统一语义空间，实现跨语言、跨被试和多模态的解码。

Result: 在159名参与者的非侵入性脑记录上验证，表现出强大的跨语言、跨被试和多模态泛化能力，并提升了少数语言的解码性能。

Conclusion: 该框架为脑解码提供了新范式，拓宽了脑机接口的应用范围，并促进了语言公平性。

Abstract: Brain-computer interfaces (BCIs) with speech decoding from brain recordings
have broad application potential in fields such as clinical rehabilitation and
cognitive neuroscience. However, current decoding methods remain limited to
single-language, single-subject, and single neuroimaging modality settings,
restricting their clinical applicability and generalizability. Here we propose
a joint multilingual, multi-subject and multimodal decoding framework. It maps
diverse brain recordings into a unified semantic space defined by a pre-trained
multilingual model (PMM), enabling decoding across multiple languages, multiple
subjects and multiple neuroimaging modalities. The proposed framework is
validated using non-invasive brain recordings from 159 participants across four
languages. Experimental results show that it exhibits strong generalization
across multilingual, multi-subject, and multimodal settings. More importantly,
the proposed framework can promote linguistic fairness, which is vital for
underrepresented languages in BCI applications. The unified semantic space
enables cross-lingual mapping enhancement, allowing the framework to boost the
decoding performance of underrepresented languages, thereby promoting
linguistic fairness. Overall, the proposed framework establishes a new
potential paradigm for brain decoding, opening new paths for broader
applications of BCI.

</details>


### [2] [Learning to cluster neuronal function](https://arxiv.org/abs/2506.03293)
*Nina S. Nellen,Polina Turishcheva,Michaela Vystrčilová,Shashwat Sridhar,Tim Gollisch,Andreas S. Tolias,Alexander S. Ecker*

Main category: q-bio.NC

TL;DR: DECEMber通过引入辅助损失函数和改进聚类方法，提升了神经元嵌入的聚类效果，同时保持预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型生成的神经元嵌入缺乏清晰的聚类模式，无法有效映射功能景观或识别细胞类型，DECEMber旨在解决这一问题。

Method: DECEMber通过联合优化神经元特征嵌入和聚类参数，利用EM算法更新聚类中心和尺度矩阵，增强聚类结构。

Result: DECEMber提高了聚类一致性，保持了高预测性能，并在稳定性上优于标准聚类方法，且适用于不同物种和视觉区域。

Conclusion: DECEMber为神经元功能组织研究提供了更有效的工具，适用于广泛的神经科学研究场景。

Abstract: Deep neural networks trained to predict neural activity from visual input and
behaviour have shown great potential to serve as digital twins of the visual
cortex. Per-neuron embeddings derived from these models could potentially be
used to map the functional landscape or identify cell types. However,
state-of-the-art predictive models of mouse V1 do not generate functional
embeddings that exhibit clear clustering patterns which would correspond to
cell types. This raises the question whether the lack of clustered structure is
due to limitations of current models or a true feature of the functional
organization of mouse V1. In this work, we introduce DECEMber -- Deep Embedding
Clustering via Expectation Maximization-based refinement -- an explicit
inductive bias into predictive models that enhances clustering by adding an
auxiliary $t$-distribution-inspired loss function that enforces structured
organization among per-neuron embeddings. We jointly optimize both neuronal
feature embeddings and clustering parameters, updating cluster centers and
scale matrices using the EM-algorithm. We demonstrate that these modifications
improve cluster consistency while preserving high predictive performance and
surpassing standard clustering methods in terms of stability. Moreover,
DECEMber generalizes well across species (mice, primates) and visual areas
(retina, V1, V4). The code is available at
https://github.com/Nisone2000/sensorium/tree/neuroips_version.

</details>


### [3] [Robust Scaling in Human Brain Dynamics Despite Latent Variables and Limited Sampling Distortions](https://arxiv.org/abs/2506.03640)
*Rubén Calvo,Carles Martorell,Adrián Roig,Miguel A. Muñoz*

Main category: q-bio.NC

TL;DR: 论文探讨了信息处理系统是否因临界性而提升计算性能，并分析了外部信号对临界性特征的影响。通过理论分析和实验验证，发现非临界系统在特定条件下会表现出临界性特征，并提出了一种框架来区分真实临界性。最终揭示静息态大脑活动接近临界状态。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决信息处理系统是否因临界性而优化性能的问题，并探讨外部信号对临界性特征的影响。

Method: 方法包括理论分析简单神经模型中的自相关输入和时间分辨率对临界性特征的影响，以及开发一个框架来区分真实临界性。

Result: 结果显示非临界系统在特定条件下会表现出临界性特征，而静息态大脑活动在群体水平上接近临界状态。

Conclusion: 结论是大脑活动接近临界状态，且这种状态可能由网络活动驱动，对信息处理和人工智能有潜在意义。

Abstract: The idea that information-processing systems operate near criticality to
enhance computational performance is supported by scaling signatures in brain
activity. However, external signals raise the question of whether this behavior
is intrinsic or input-driven. We show that autocorrelated inputs and temporal
resolution influence observed scaling exponents in simple neural models. We
also demonstrate analytically that under subsampling, non-critical systems
driven by independent autocorrelated signals can exhibit strong signatures of
apparent criticality. To address these pitfalls, we develop a robust framework
and apply it to pooled neural data, revealing resting-state brain activity at
the population level is slightly sub-critical yet near-critical. Notably, the
extracted critical exponents closely match predictions from a simple recurrent
firing-rate model, supporting the emergence of near-critical dynamics from
reverberant network activity, with potential implications for information
processing and artificial intelligence.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [4] [Brain-tuned Speech Models Better Reflect Speech Processing Stages in the Brain](https://arxiv.org/abs/2506.03832)
*Omer Moussa,Mariya Toneva*

Main category: cs.CL

TL;DR: 脑调优的语音模型在语义理解上优于预训练模型，且能更好地反映人脑语音处理的层次结构。


<details>
  <summary>Details</summary>
Motivation: 研究脑调优模型是否能更准确地反映人脑语音处理的中间阶段。

Method: 通过脑调优（使用人脑记录微调模型）改进语音模型，并分析其层次结构。

Result: 脑调优模型的后期层在语义区域对齐上显著提升，层次结构更清晰（早期层处理声学特征，后期层处理高级语义任务）。

Conclusion: 脑调优模型不仅性能更好，还能更准确地模拟人脑语音处理的层次结构，成为更好的研究工具。

Abstract: Pretrained self-supervised speech models excel in speech tasks but do not
reflect the hierarchy of human speech processing, as they encode rich semantics
in middle layers and poor semantics in late layers. Recent work showed that
brain-tuning (fine-tuning models using human brain recordings) improves speech
models' semantic understanding. Here, we examine how well brain-tuned models
further reflect the brain's intermediate stages of speech processing. We find
that late layers of brain-tuned models substantially improve over pretrained
models in their alignment with semantic language regions. Further layer-wise
probing reveals that early layers remain dedicated to low-level acoustic
features, while late layers become the best at complex high-level tasks. These
findings show that brain-tuned models not only perform better but also exhibit
a well-defined hierarchical processing going from acoustic to semantic
representations, making them better model organisms for human speech
processing.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [5] [Sub-Scalp EEG for Sensorimotor Brain-Computer Interface](https://arxiv.org/abs/2506.03423)
*Timothy B Mahoney,David B Grayden,Sam E John*

Main category: eess.SP

TL;DR: 研究证明皮下脑电图（EEG）在记录和分类感觉运动神经活动方面有效，支持其作为慢性脑机接口（BCI）应用的可行选择。


<details>
  <summary>Details</summary>
Motivation: 探讨皮下EEG在BCI应用中的潜力，尤其是长期使用场景，以替代更具侵入性的记录方法（如ECoG和血管内阵列）。

Method: 通过两项实验：1）在羊模型中分析体感诱发电位，验证皮下EEG的高空间分辨率；2）在行为实验中分类运动执行数据。

Result: 成功记录羊模型的感觉运动节律，识别信号的空间、时间和频谱特征，运动执行分类性能优于随机水平，结果与ECoG和血管内阵列相当。

Conclusion: 皮下EEG的信号质量接近侵入性方法，适合慢性BCI应用。

Abstract: Objective: To establish sub-scalp electroencephalography (EEG) as a viable
option for brain-computer interface (BCI) applications, particularly for
chronic use, by demonstrating its effectiveness in recording and classifying
sensorimotor neural activity. Approach: Two experiments were conducted in this
study. The first aim was to demonstrate the high spatial resolution of
sub-scalp EEG through analysis of somatosensory evoked potentials in sheep
models. The second focused on the practical application of sub-scalp EEG,
classifying motor execution using data collected during a sheep behavioural
experiment. Main Results: We successfully demonstrated the recording of
sensorimotor rhythms using sub-scalp EEG in sheep models. Important spatial,
temporal, and spectral features of these signals were identified, and we were
able to classify motor execution with above-chance performance. These results
are comparable to previous work that investigated signal quality and motor
execution classification using ECoG and endovascular arrays in sheep models.
Significance: These results suggest that sub-scalp EEG may provide signal
quality that approaches that of more invasive neural recording methods such as
ECoG and endovascular arrays, and support the use of sub-scalp EEG for chronic
BCI applications.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [6] [From Spikes to Speech: NeuroVoc -- A Biologically Plausible Vocoder Framework for Auditory Perception and Cochlear Implant Simulation](https://arxiv.org/abs/2506.03959)
*Jacob de Nobel,Jeroen J. Briaire,Thomas H. W. Baeck,Anna V. Kononova,Johan H. M. Frijns*

Main category: cs.SD

TL;DR: NeuroVoc是一个灵活的、与模型无关的声码器框架，通过逆傅里叶变换从模拟的神经活动模式重建声波。它支持模块化设计，便于比较正常听力与电听力模型，并验证了其在噪声中的语音可懂度。


<details>
  <summary>Details</summary>
Motivation: 解决传统声码器在模拟人工耳蜗用户听觉感知时需针对特定语音编码策略的问题，提供一种通用且灵活的框架。

Method: 利用逆傅里叶变换处理神经图谱表示，模块化设计允许替换或修改底层听觉模型。

Result: NH和EH模型的声码器在噪声测试中分别增加了2.4 dB和7.1 dB的信噪比阈值，与临床数据一致。

Conclusion: NeuroVoc能有效重建可懂语音，准确反映人工耳蜗用户在噪声中的语音感知性能下降。

Abstract: We present NeuroVoc, a flexible model-agnostic vocoder framework that
reconstructs acoustic waveforms from simulated neural activity patterns using
an inverse Fourier transform. The system applies straightforward signal
processing to neurogram representations, time-frequency binned outputs from
auditory nerve fiber models. Crucially, the model architecture is modular,
allowing for easy substitution or modification of the underlying auditory
models. This flexibility eliminates the need for
speech-coding-strategy-specific vocoder implementations when simulating
auditory perception in cochlear implant (CI) users. It also allows direct
comparisons between normal hearing (NH) and electrical hearing (EH) models, as
demonstrated in this study. The vocoder preserves distinctive features of each
model; for example, the NH model retains harmonic structure more faithfully
than the EH model. We evaluated perceptual intelligibility in noise using an
online Digits-in-Noise (DIN) test, where participants completed three test
conditions: one with standard speech, and two with vocoded speech using the NH
and EH models. Both the standard DIN test and the EH-vocoded groups were
statistically equivalent to clinically reported data for NH and CI listeners.
On average, the NH and EH vocoded groups increased SRT compared to the standard
test by 2.4 dB and 7.1 dB, respectively. These findings show that, although
some degradation occurs, the vocoder can reconstruct intelligible speech under
both hearing models and accurately reflects the reduced speech-in-noise
performance experienced by CI users.

</details>
