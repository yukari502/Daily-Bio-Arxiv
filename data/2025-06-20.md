<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 2]
- [q-bio.QM](#q-bio.QM) [Total: 2]
- [q-bio.MN](#q-bio.MN) [Total: 2]
- [math.DS](#math.DS) [Total: 2]
- [cs.LG](#cs.LG) [Total: 6]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [BMFM-RNA: An Open Framework for Building and Evaluating Transcriptomic Foundation Models](https://arxiv.org/abs/2506.14861)
*Bharath Dandala,Michael M. Danziger,Ella Barkan,Tanwi Biswas,Viatcheslav Gurev,Jianying Hu,Matthew Madgwick,Akira Koseki,Tal Kozlovski,Michal Rosen-Zvi,Yishai Shimoni,Ching-Huei Tsou*

Main category: q-bio.GN

TL;DR: BMFM-RNA是一个开源模块化软件包，统一了转录组基础模型（TFM）的预训练和微调目标，并引入了新的训练目标WCED，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前TFM模型的多样性和训练策略差异导致难以评估设计选择和协同效应，限制了最佳实践的确定和研究的可重复性。

Method: 开发了BMFM-RNA框架，支持多种输入表示和训练目标，包括新的WCED目标，并评估了四种预训练模型。

Result: WCED模型在零样本和微调任务中表现优于或匹配现有方法（如scGPT）。

Conclusion: BMFM-RNA为系统基准测试和社区驱动的TFM训练策略探索提供了可重复的基础，推动了细胞生物学AI工具的进步。

Abstract: Transcriptomic foundation models (TFMs) have recently emerged as powerful
tools for analyzing gene expression in cells and tissues, supporting key tasks
such as cell-type annotation, batch correction, and perturbation prediction.
However, the diversity of model implementations and training strategies across
recent TFMs, though promising, makes it challenging to isolate the contribution
of individual design choices or evaluate their potential synergies. This
hinders the field's ability to converge on best practices and limits the
reproducibility of insights across studies. We present BMFM-RNA, an
open-source, modular software package that unifies diverse TFM pretraining and
fine-tuning objectives within a single framework. Leveraging this capability,
we introduce a novel training objective, whole cell expression decoder (WCED),
which captures global expression patterns using an autoencoder-like CLS
bottleneck representation. In this paper, we describe the framework, supported
input representations, and training objectives. We evaluated four model
checkpoints pretrained on CELLxGENE using combinations of masked language
modeling (MLM), WCED and multitask learning. Using the benchmarking
capabilities of BMFM-RNA, we show that WCED-based models achieve performance
that matches or exceeds state-of-the-art approaches like scGPT across more than
a dozen datasets in both zero-shot and fine-tuning tasks. BMFM-RNA, available
as part of the biomed-multi-omics project (
https://github.com/BiomedSciAI/biomed-multi-omic ), offers a reproducible
foundation for systematic benchmarking and community-driven exploration of
optimal TFM training strategies, enabling the development of more effective
tools to leverage the latest advances in AI for understanding cell biology.

</details>


### [2] [BMFM-RNA: An Open Framework for Building and Evaluating Transcriptomic Foundation Models](https://arxiv.org/abs/2506.14861)
*Bharath Dandala,Michael M. Danziger,Ella Barkan,Tanwi Biswas,Viatcheslav Gurev,Jianying Hu,Matthew Madgwick,Akira Koseki,Tal Kozlovski,Michal Rosen-Zvi,Yishai Shimoni,Ching-Huei Tsou*

Main category: q-bio.GN

TL;DR: 论文介绍了BMFM-RNA，一个开源、模块化的转录组基础模型（TFM）软件包，统一了多种预训练和微调目标，并引入新的训练目标WCED，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前TFM模型的多样性和训练策略差异导致难以评估设计选择的影响和协同效应，阻碍了领域内最佳实践的确定和研究的可重复性。

Method: 开发了BMFM-RNA框架，支持多种输入表示和训练目标，包括新提出的WCED目标，并在CELLxGENE数据集上预训练了四个模型检查点。

Result: WCED模型在零样本和微调任务中性能优于或匹配现有方法（如scGPT），并在多个数据集中验证。

Conclusion: BMFM-RNA为系统化基准测试和社区驱动的TFM训练策略探索提供了可重复的基础，有助于开发更有效的工具以理解细胞生物学。

Abstract: Transcriptomic foundation models (TFMs) have recently emerged as powerful
tools for analyzing gene expression in cells and tissues, supporting key tasks
such as cell-type annotation, batch correction, and perturbation prediction.
However, the diversity of model implementations and training strategies across
recent TFMs, though promising, makes it challenging to isolate the contribution
of individual design choices or evaluate their potential synergies. This
hinders the field's ability to converge on best practices and limits the
reproducibility of insights across studies. We present BMFM-RNA, an
open-source, modular software package that unifies diverse TFM pretraining and
fine-tuning objectives within a single framework. Leveraging this capability,
we introduce a novel training objective, whole cell expression decoder (WCED),
which captures global expression patterns using an autoencoder-like CLS
bottleneck representation. In this paper, we describe the framework, supported
input representations, and training objectives. We evaluated four model
checkpoints pretrained on CELLxGENE using combinations of masked language
modeling (MLM), WCED and multitask learning. Using the benchmarking
capabilities of BMFM-RNA, we show that WCED-based models achieve performance
that matches or exceeds state-of-the-art approaches like scGPT across more than
a dozen datasets in both zero-shot and fine-tuning tasks. BMFM-RNA, available
as part of the biomed-multi-omics project (
https://github.com/BiomedSciAI/biomed-multi-omic ), offers a reproducible
foundation for systematic benchmarking and community-driven exploration of
optimal TFM training strategies, enabling the development of more effective
tools to leverage the latest advances in AI for understanding cell biology.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [3] [DisProtEdit: Exploring Disentangled Representations for Multi-Attribute Protein Editing](https://arxiv.org/abs/2506.14853)
*Max Ku,Sun Sun,Hongyu Guo,Wenhu Chen*

Main category: q-bio.QM

TL;DR: DisProtEdit是一个可控的蛋白质编辑框架，通过双通道自然语言监督学习解耦的结构和功能表示。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于联合整体嵌入，缺乏模块化和可解释性。DisProtEdit旨在明确分离语义因素，实现更可控的蛋白质编辑。

Method: 构建多模态数据集SwissProtDis，利用对齐和均匀性目标对齐蛋白质和文本嵌入，并通过解耦损失促进结构和功能语义的独立性。

Result: 在蛋白质编辑和表示学习基准测试中表现优异，多属性编辑基准测试的成功率达到61.7%。

Conclusion: DisProtEdit在保持竞争力的同时，提供了更高的可解释性和可控性。

Abstract: We introduce DisProtEdit, a controllable protein editing framework that
leverages dual-channel natural language supervision to learn disentangled
representations of structural and functional properties. Unlike prior
approaches that rely on joint holistic embeddings, DisProtEdit explicitly
separates semantic factors, enabling modular and interpretable control. To
support this, we construct SwissProtDis, a large-scale multimodal dataset where
each protein sequence is paired with two textual descriptions, one for
structure and one for function, automatically decomposed using a large language
model. DisProtEdit aligns protein and text embeddings using alignment and
uniformity objectives, while a disentanglement loss promotes independence
between structural and functional semantics. At inference time, protein editing
is performed by modifying one or both text inputs and decoding from the updated
latent representation. Experiments on protein editing and representation
learning benchmarks demonstrate that DisProtEdit performs competitively with
existing methods while providing improved interpretability and controllability.
On a newly constructed multi-attribute editing benchmark, the model achieves a
both-hit success rate of up to 61.7%, highlighting its effectiveness in
coordinating simultaneous structural and functional edits.

</details>


### [4] [DisProtEdit: Exploring Disentangled Representations for Multi-Attribute Protein Editing](https://arxiv.org/abs/2506.14853)
*Max Ku,Sun Sun,Hongyu Guo,Wenhu Chen*

Main category: q-bio.QM

TL;DR: DisProtEdit是一个可控的蛋白质编辑框架，利用双通道自然语言监督学习解耦的结构和功能表示，提供模块化和可解释的控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖联合整体嵌入，缺乏对结构和功能语义的明确分离，限制了可控性和可解释性。

Method: 构建SwissProtDis数据集，使用对齐和均匀性目标对齐蛋白质和文本嵌入，并通过解耦损失促进语义独立性。

Result: 在蛋白质编辑和表示学习基准测试中表现优异，多属性编辑成功率高达61.7%。

Conclusion: DisProtEdit在保持性能的同时显著提升了可控性和可解释性。

Abstract: We introduce DisProtEdit, a controllable protein editing framework that
leverages dual-channel natural language supervision to learn disentangled
representations of structural and functional properties. Unlike prior
approaches that rely on joint holistic embeddings, DisProtEdit explicitly
separates semantic factors, enabling modular and interpretable control. To
support this, we construct SwissProtDis, a large-scale multimodal dataset where
each protein sequence is paired with two textual descriptions, one for
structure and one for function, automatically decomposed using a large language
model. DisProtEdit aligns protein and text embeddings using alignment and
uniformity objectives, while a disentanglement loss promotes independence
between structural and functional semantics. At inference time, protein editing
is performed by modifying one or both text inputs and decoding from the updated
latent representation. Experiments on protein editing and representation
learning benchmarks demonstrate that DisProtEdit performs competitively with
existing methods while providing improved interpretability and controllability.
On a newly constructed multi-attribute editing benchmark, the model achieves a
both-hit success rate of up to 61.7%, highlighting its effectiveness in
coordinating simultaneous structural and functional edits.

</details>


<div id='q-bio.MN'></div>

# q-bio.MN [[Back]](#toc)

### [5] [Attractor Stability of Boolean networks under noise](https://arxiv.org/abs/2506.15581)
*Byungjoon Min,Jeehye Choi,Reinhard Laubenbacher*

Main category: q-bio.MN

TL;DR: 研究了噪声对布尔网络中吸引子动力学的影响，提出了量化吸引子稳定性的框架，发现吸引子稳定性高于预期，且噪声类型影响主导吸引子的选择。


<details>
  <summary>Details</summary>
Motivation: 探索噪声环境下布尔网络中吸引子的稳定性和动态行为，以理解其在实际应用中的鲁棒性。

Method: 通过单节点扰动构建吸引子矩阵，量化吸引子稳定性并识别主导吸引子。

Result: 吸引子稳定性高于基于吸引盆大小的预测；全局扰动下吸引盆大小决定长期行为，局部噪声下主导吸引子由噪声诱导的过渡模式决定。

Conclusion: 随机扰动诱导的过渡动力学为噪声下布尔网络的吸引子稳定性和动态提供了高效的定量描述。

Abstract: We study the impact of noise on attractor dynamics in Boolean networks,
focusing on their stability and transition behaviors. By constructing attractor
matrices based on single-node perturbations, we propose a framework to quantify
attractor stability and identify dominant attractors. We find that attractors
are more stable than predicted by basin sizes, showing the importance of
dynamical structure in noisy environments. In addition, under global
perturbations, basin sizes dictate long-term behavior; under local noise,
however, attractor dominance is determined by noise-induced transition patterns
rather than basin sizes. Our results show that transition dynamics induced by
stochastic perturbations provide an efficient and quantitative description for
the attractor stability and dynamics in Boolean networks under noise.

</details>


### [6] [Attractor Stability of Boolean networks under noise](https://arxiv.org/abs/2506.15581)
*Byungjoon Min,Jeehye Choi,Reinhard Laubenbacher*

Main category: q-bio.MN

TL;DR: 研究了噪声对布尔网络中吸引子动力学的影响，提出了一种量化吸引子稳定性的框架，发现吸引子比预测更稳定，且噪声类型影响吸引子主导性。


<details>
  <summary>Details</summary>
Motivation: 探索噪声环境下布尔网络中吸引子的稳定性和动态行为，以理解其在实际应用中的表现。

Method: 通过单节点扰动构建吸引子矩阵，量化吸引子稳定性并识别主导吸引子。

Result: 吸引子比基于盆地大小的预测更稳定；全局扰动下盆地大小决定长期行为，局部噪声下吸引子主导性由噪声诱导的过渡模式决定。

Conclusion: 随机扰动诱导的过渡动力学为噪声下布尔网络中吸引子稳定性和动态提供了高效定量描述。

Abstract: We study the impact of noise on attractor dynamics in Boolean networks,
focusing on their stability and transition behaviors. By constructing attractor
matrices based on single-node perturbations, we propose a framework to quantify
attractor stability and identify dominant attractors. We find that attractors
are more stable than predicted by basin sizes, showing the importance of
dynamical structure in noisy environments. In addition, under global
perturbations, basin sizes dictate long-term behavior; under local noise,
however, attractor dominance is determined by noise-induced transition patterns
rather than basin sizes. Our results show that transition dynamics induced by
stochastic perturbations provide an efficient and quantitative description for
the attractor stability and dynamics in Boolean networks under noise.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [7] [Automatic computation of the glycemic index: data driven analysis of the glucose standard](https://arxiv.org/abs/2506.15471)
*Fabio Credali,Maria Teresa Venuti,Daniele Boffi,Paola Rossi*

Main category: math.DS

TL;DR: 研究通过数学模型模拟葡萄糖摄入后的血糖反应，揭示血糖响应与葡萄糖吸收参数的直接相关性，并基于血糖峰值时间将受试者分为三组。


<details>
  <summary>Details</summary>
Motivation: 为糖尿病预防和管理提供工具，通过血糖指数（GI）分类碳水化合物。

Method: 应用数学模型进行数据驱动的血糖响应模拟。

Result: 发现血糖响应与葡萄糖吸收参数直接相关，并将受试者按血糖峰值时间分为三组。

Conclusion: 结果可用于血糖指数模拟和糖尿病生物学研究。

Abstract: The Glycemic Index (GI) is a tool for classifying carbohydrates based on
their impact on postprandial glycemia, useful for diabetes prevention and
management. This study applies a mathematical model for a data driven
simulation of the glycemic response following glucose ingestion. The analysis
reveals a direct correlation between glucose response profiles and parameters
describing glucose absorption, enabling the classification of subjects into
three groups based on the timing of their glycemic peak. Our results offer
potential applications for both glycemic index simulation and advancing
biological studies on diabetes.

</details>


### [8] [Automatic computation of the glycemic index: data driven analysis of the glucose standard](https://arxiv.org/abs/2506.15471)
*Fabio Credali,Maria Teresa Venuti,Daniele Boffi,Paola Rossi*

Main category: math.DS

TL;DR: 研究通过数学模型模拟葡萄糖摄入后的血糖反应，揭示了血糖响应曲线与葡萄糖吸收参数的直接相关性，并将受试者分为三类。


<details>
  <summary>Details</summary>
Motivation: 血糖指数（GI）是糖尿病预防和管理的重要工具，但需要更深入的数据驱动模拟来理解血糖反应。

Method: 应用数学模型对葡萄糖摄入后的血糖反应进行数据驱动模拟。

Result: 分析显示血糖响应曲线与葡萄糖吸收参数直接相关，受试者可根据血糖峰值时间分为三类。

Conclusion: 研究结果对血糖指数模拟和糖尿病生物学研究具有潜在应用价值。

Abstract: The Glycemic Index (GI) is a tool for classifying carbohydrates based on
their impact on postprandial glycemia, useful for diabetes prevention and
management. This study applies a mathematical model for a data driven
simulation of the glycemic response following glucose ingestion. The analysis
reveals a direct correlation between glucose response profiles and parameters
describing glucose absorption, enabling the classification of subjects into
three groups based on the timing of their glycemic peak. Our results offer
potential applications for both glycemic index simulation and advancing
biological studies on diabetes.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [9] [Integrating Dynamical Systems Learning with Foundational Models: A Meta-Evolutionary AI Framework for Clinical Trials](https://arxiv.org/abs/2506.14782)
*Joseph Geraci,Bessi Qorri,Christian Cumbaa,Mike Tsay,Paul Leonczyk,Luca Pani*

Main category: cs.LG

TL;DR: 论文分析了两种AI方法：DeepSeek-V3（大规模通用模型）和NetraAI（针对小临床数据集设计的稳定可解释框架）。NetraAI结合动态系统、信息几何和进化算法，发现高效应子群体，并通过LLM策略师优化变量选择。


<details>
  <summary>Details</summary>
Motivation: 解决小临床数据集的稳定性和可解释性问题，同时结合动态系统和进化算法提升预测能力。

Method: NetraAI结合收缩映射、信息几何和进化算法，通过伪时间嵌入和长程记忆探索高阶特征交互，并利用进化循环选择简洁可解释的特征组合。LLM策略师作为元进化层优化变量选择和知识注入。

Result: 在精神分裂症、抑郁症和胰腺癌案例中，NetraAI将弱基线模型（AUC 0.50-0.68）提升为近乎完美的分类器，仅使用少量特征。

Conclusion: NetraAI为临床发现提供了一种自适应、可解释的AI方法，结合动态系统、信息几何和进化学习，符合新兴的概念级推理范式。

Abstract: Artificial intelligence (AI) has evolved into an ecosystem of specialized
"species," each with unique strengths. We analyze two: DeepSeek-V3, a
671-billion-parameter Mixture of Experts large language model (LLM)
exemplifying scale-driven generality, and NetraAI, a dynamical system-based
framework engineered for stability and interpretability on small clinical trial
datasets. We formalize NetraAI's foundations, combining contraction mappings,
information geometry, and evolutionary algorithms to identify predictive
patient cohorts. Features are embedded in a metric space and iteratively
contracted toward stable attractors that define latent subgroups. A
pseudo-temporal embedding and long-range memory enable exploration of
higher-order feature interactions, while an internal evolutionary loop selects
compact, explainable 2-4-variable bundles ("Personas").
  To guide discovery, we introduce an LLM Strategist as a meta-evolutionary
layer that observes Persona outputs, prioritizes promising variables, injects
domain knowledge, and assesses robustness. This two-tier architecture mirrors
the human scientific process: NetraAI as experimentalist, the LLM as theorist,
forming a self-improving loop.
  In case studies (schizophrenia, depression, pancreatic cancer), NetraAI
uncovered small, high-effect-size subpopulations that transformed weak baseline
models (AUC ~0.50-0.68) into near-perfect classifiers using only a few
features. We position NetraAI at the intersection of dynamical systems,
information geometry, and evolutionary learning, aligned with emerging
concept-level reasoning paradigms such as LeCun's Joint Embedding Predictive
Architecture (JEPA). By prioritizing reliable, explainable knowledge, NetraAI
offers a new generation of adaptive, self-reflective AI to accelerate clinical
discovery.

</details>


### [10] [AZT1D: A Real-World Dataset for Type 1 Diabetes](https://arxiv.org/abs/2506.14789)
*Saman Khamesian,Asiful Arefeen,Bithika M. Thompson,Maria Adela Grando,Hassan Ghasemzadeh*

Main category: cs.LG

TL;DR: AZT1D是一个高质量的真实世界数据集，包含25名使用自动胰岛素输送系统的1型糖尿病患者的详细数据，填补了现有数据集的空白。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏公开的详细患者数据集，1型糖尿病管理领域的数据驱动方法进展受限。

Method: 收集了25名患者的连续血糖监测、胰岛素泵数据、碳水化合物摄入和设备模式等数据，持续6至8周。

Result: AZT1D提供了罕见的详细胰岛素输送数据，支持多种人工智能和机器学习应用。

Conclusion: AZT1D数据集有助于改善1型糖尿病的临床决策和个性化护理。

Abstract: High quality real world datasets are essential for advancing data driven
approaches in type 1 diabetes (T1D) management, including personalized therapy
design, digital twin systems, and glucose prediction models. However, progress
in this area has been limited by the scarcity of publicly available datasets
that offer detailed and comprehensive patient data. To address this gap, we
present AZT1D, a dataset containing data collected from 25 individuals with T1D
on automated insulin delivery (AID) systems. AZT1D includes continuous glucose
monitoring (CGM) data, insulin pump and insulin administration data,
carbohydrate intake, and device mode (regular, sleep, and exercise) obtained
over 6 to 8 weeks for each patient. Notably, the dataset provides granular
details on bolus insulin delivery (i.e., total dose, bolus type, correction
specific amounts) features that are rarely found in existing datasets. By
offering rich, naturalistic data, AZT1D supports a wide range of artificial
intelligence and machine learning applications aimed at improving clinical
decision making and individualized care in T1D.

</details>


### [11] [Universal Laboratory Model: prognosis of abnormal clinical outcomes based on routine tests](https://arxiv.org/abs/2506.15330)
*Pavel Karpov,Ilya Petrenkov,Ruslan Raiman*

Main category: cs.LG

TL;DR: 通过将常规生化检测与血常规（CBC）结合，提出一种基于集合翻译的表格建模方法，用于预测未检测项目的异常值，无需填补缺失值，并在临床数据上取得了最高8%的AUC提升。


<details>
  <summary>Details</summary>
Motivation: 临床实验室结果在诊断中普遍存在，但未检测项目的异常值预测对早期诊断具有重要意义。血常规（CBC）作为最常用的检测，结合生化检测数据，形成具有缺失值的表格数据。

Method: 将表格建模问题转化为集合翻译问题，源集合包含标签列嵌入及其对应值，目标集合仅包含相同类型的嵌入。该方法无需隐式填补缺失值，并连接了大型语言模型与表格领域。

Result: 在预测高尿酸、高血糖、高胆固醇和低铁蛋白水平的联合任务中，AUC最高提升了8%。

Conclusion: 提出的方法有效处理了临床实验室数据中的缺失值问题，并显著提升了预测性能，为早期诊断提供了新思路。

Abstract: Clinical laboratory results are ubiquitous in any diagnosis making.
Predicting abnormal values of not prescribed tests based on the results of
performed tests looks intriguing, as it would be possible to make early
diagnosis available to everyone. The special place is taken by the Common Blood
Count (CBC) test, as it is the most widely used clinical procedure. Combining
routine biochemical panels with CBC presents a set of test-value pairs that
varies from patient to patient, or, in common settings, a table with missing
values. Here we formulate a tabular modeling problem as a set translation
problem where the source set comprises pairs of GPT-like label column embedding
and its corresponding value while the target set consists of the same type
embeddings only. The proposed approach can effectively deal with missing values
without implicitly estimating them and bridges the world of LLM with the
tabular domain. Applying this method to clinical laboratory data, we achieve an
improvement up to 8% AUC for joint predictions of high uric acid, glucose,
cholesterol, and low ferritin levels.

</details>


### [12] [Integrating Dynamical Systems Learning with Foundational Models: A Meta-Evolutionary AI Framework for Clinical Trials](https://arxiv.org/abs/2506.14782)
*Joseph Geraci,Bessi Qorri,Christian Cumbaa,Mike Tsay,Paul Leonczyk,Luca Pani*

Main category: cs.LG

TL;DR: 论文分析了两种AI模型：DeepSeek-V3（大规模通用LLM）和NetraAI（基于动态系统的小数据集稳定可解释框架），后者通过结合收缩映射、信息几何和进化算法，在临床数据中发现高效应子群。


<details>
  <summary>Details</summary>
Motivation: 解决小数据集临床研究中模型稳定性和可解释性问题，同时结合动态系统和进化学习以发现高效应子群。

Method: NetraAI结合收缩映射、信息几何和进化算法，通过伪时间嵌入和长程记忆探索高阶特征交互，并利用LLM作为元进化层指导发现。

Result: 在精神分裂症、抑郁症和胰腺癌案例中，NetraAI将弱基线模型（AUC 0.50-0.68）提升为近乎完美的分类器。

Conclusion: NetraAI为临床研究提供了稳定、可解释的AI新范式，结合动态系统和信息几何，加速知识发现。

Abstract: Artificial intelligence (AI) has evolved into an ecosystem of specialized
"species," each with unique strengths. We analyze two: DeepSeek-V3, a
671-billion-parameter Mixture of Experts large language model (LLM)
exemplifying scale-driven generality, and NetraAI, a dynamical system-based
framework engineered for stability and interpretability on small clinical trial
datasets. We formalize NetraAI's foundations, combining contraction mappings,
information geometry, and evolutionary algorithms to identify predictive
patient cohorts. Features are embedded in a metric space and iteratively
contracted toward stable attractors that define latent subgroups. A
pseudo-temporal embedding and long-range memory enable exploration of
higher-order feature interactions, while an internal evolutionary loop selects
compact, explainable 2-4-variable bundles ("Personas").
  To guide discovery, we introduce an LLM Strategist as a meta-evolutionary
layer that observes Persona outputs, prioritizes promising variables, injects
domain knowledge, and assesses robustness. This two-tier architecture mirrors
the human scientific process: NetraAI as experimentalist, the LLM as theorist,
forming a self-improving loop.
  In case studies (schizophrenia, depression, pancreatic cancer), NetraAI
uncovered small, high-effect-size subpopulations that transformed weak baseline
models (AUC ~0.50-0.68) into near-perfect classifiers using only a few
features. We position NetraAI at the intersection of dynamical systems,
information geometry, and evolutionary learning, aligned with emerging
concept-level reasoning paradigms such as LeCun's Joint Embedding Predictive
Architecture (JEPA). By prioritizing reliable, explainable knowledge, NetraAI
offers a new generation of adaptive, self-reflective AI to accelerate clinical
discovery.

</details>


### [13] [AZT1D: A Real-World Dataset for Type 1 Diabetes](https://arxiv.org/abs/2506.14789)
*Saman Khamesian,Asiful Arefeen,Bithika M. Thompson,Maria Adela Grando,Hassan Ghasemzadeh*

Main category: cs.LG

TL;DR: AZT1D是一个高质量的1型糖尿病（T1D）数据集，包含25名使用自动胰岛素输送（AID）系统的患者的详细数据，填补了公开数据集稀缺的空白。


<details>
  <summary>Details</summary>
Motivation: 现有公开数据集缺乏详细和全面的1型糖尿病患者数据，限制了数据驱动方法在T1D管理中的应用。

Method: 收集了25名T1D患者6至8周的连续血糖监测（CGM）、胰岛素泵数据、碳水化合物摄入和设备模式等详细数据。

Result: AZT1D提供了丰富的自然数据，支持人工智能和机器学习在T1D临床决策和个性化护理中的应用。

Conclusion: AZT1D填补了公开数据集的空白，为T1D管理的研究和应用提供了重要资源。

Abstract: High quality real world datasets are essential for advancing data driven
approaches in type 1 diabetes (T1D) management, including personalized therapy
design, digital twin systems, and glucose prediction models. However, progress
in this area has been limited by the scarcity of publicly available datasets
that offer detailed and comprehensive patient data. To address this gap, we
present AZT1D, a dataset containing data collected from 25 individuals with T1D
on automated insulin delivery (AID) systems. AZT1D includes continuous glucose
monitoring (CGM) data, insulin pump and insulin administration data,
carbohydrate intake, and device mode (regular, sleep, and exercise) obtained
over 6 to 8 weeks for each patient. Notably, the dataset provides granular
details on bolus insulin delivery (i.e., total dose, bolus type, correction
specific amounts) features that are rarely found in existing datasets. By
offering rich, naturalistic data, AZT1D supports a wide range of artificial
intelligence and machine learning applications aimed at improving clinical
decision making and individualized care in T1D.

</details>


### [14] [Universal Laboratory Model: prognosis of abnormal clinical outcomes based on routine tests](https://arxiv.org/abs/2506.15330)
*Pavel Karpov,Ilya Petrenkov,Ruslan Raiman*

Main category: cs.LG

TL;DR: 论文提出了一种基于表格数据的异常值预测方法，通过将表格建模问题转化为集合翻译问题，结合CBC和生化检测数据，实现了对未检测项目的异常值预测，AUC提升达8%。


<details>
  <summary>Details</summary>
Motivation: 临床实验室数据在诊断中普遍存在，但未检测项目的异常值预测具有挑战性。通过结合常规检测数据（如CBC）预测未检测项目的异常值，有望实现早期诊断。

Method: 将表格建模问题转化为集合翻译问题，利用GPT式标签列嵌入及其对应值作为源集，目标集为相同类型的嵌入。该方法无需隐式估计缺失值，并连接了LLM与表格数据领域。

Result: 在临床实验室数据中应用该方法，对高尿酸、高血糖、高胆固醇和低铁蛋白水平的联合预测，AUC提升高达8%。

Conclusion: 该方法有效解决了表格数据中的缺失值问题，为临床实验室数据的异常值预测提供了新思路。

Abstract: Clinical laboratory results are ubiquitous in any diagnosis making.
Predicting abnormal values of not prescribed tests based on the results of
performed tests looks intriguing, as it would be possible to make early
diagnosis available to everyone. The special place is taken by the Common Blood
Count (CBC) test, as it is the most widely used clinical procedure. Combining
routine biochemical panels with CBC presents a set of test-value pairs that
varies from patient to patient, or, in common settings, a table with missing
values. Here we formulate a tabular modeling problem as a set translation
problem where the source set comprises pairs of GPT-like label column embedding
and its corresponding value while the target set consists of the same type
embeddings only. The proposed approach can effectively deal with missing values
without implicitly estimating them and bridges the world of LLM with the
tabular domain. Applying this method to clinical laboratory data, we achieve an
improvement up to 8% AUC for joint predictions of high uric acid, glucose,
cholesterol, and low ferritin levels.

</details>
