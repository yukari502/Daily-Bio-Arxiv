<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [q-bio.MN](#q-bio.MN) [Total: 1]
- [math.DS](#math.DS) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [BMFM-RNA: An Open Framework for Building and Evaluating Transcriptomic Foundation Models](https://arxiv.org/abs/2506.14861)
*Bharath Dandala,Michael M. Danziger,Ella Barkan,Tanwi Biswas,Viatcheslav Gurev,Jianying Hu,Matthew Madgwick,Akira Koseki,Tal Kozlovski,Michal Rosen-Zvi,Yishai Shimoni,Ching-Huei Tsou*

Main category: q-bio.GN

TL;DR: BMFM-RNA是一个开源、模块化的转录组基础模型框架，统一了多种预训练和微调目标，并引入新的训练目标WCED，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 转录组基础模型（TFMs）的实现和训练策略多样，难以评估设计选择或协同效应，阻碍了最佳实践的确定和研究的可重复性。

Method: 提出BMFM-RNA框架，支持多种输入表示和训练目标，包括新的WCED目标，并在CELLxGENE数据集上预训练模型。

Result: WCED模型在零样本和微调任务中性能优于scGPT等现有方法。

Conclusion: BMFM-RNA为系统评估和优化TFM训练策略提供了可重复的基础，有助于开发更有效的工具理解细胞生物学。

Abstract: Transcriptomic foundation models (TFMs) have recently emerged as powerful
tools for analyzing gene expression in cells and tissues, supporting key tasks
such as cell-type annotation, batch correction, and perturbation prediction.
However, the diversity of model implementations and training strategies across
recent TFMs, though promising, makes it challenging to isolate the contribution
of individual design choices or evaluate their potential synergies. This
hinders the field's ability to converge on best practices and limits the
reproducibility of insights across studies. We present BMFM-RNA, an
open-source, modular software package that unifies diverse TFM pretraining and
fine-tuning objectives within a single framework. Leveraging this capability,
we introduce a novel training objective, whole cell expression decoder (WCED),
which captures global expression patterns using an autoencoder-like CLS
bottleneck representation. In this paper, we describe the framework, supported
input representations, and training objectives. We evaluated four model
checkpoints pretrained on CELLxGENE using combinations of masked language
modeling (MLM), WCED and multitask learning. Using the benchmarking
capabilities of BMFM-RNA, we show that WCED-based models achieve performance
that matches or exceeds state-of-the-art approaches like scGPT across more than
a dozen datasets in both zero-shot and fine-tuning tasks. BMFM-RNA, available
as part of the biomed-multi-omics project (
https://github.com/BiomedSciAI/biomed-multi-omic ), offers a reproducible
foundation for systematic benchmarking and community-driven exploration of
optimal TFM training strategies, enabling the development of more effective
tools to leverage the latest advances in AI for understanding cell biology.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [2] [DisProtEdit: Exploring Disentangled Representations for Multi-Attribute Protein Editing](https://arxiv.org/abs/2506.14853)
*Max Ku,Sun Sun,Hongyu Guo,Wenhu Chen*

Main category: q-bio.QM

TL;DR: DisProtEdit是一个可控的蛋白质编辑框架，通过双通道自然语言监督学习解耦的结构和功能表示。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖联合整体嵌入，缺乏模块化和可解释性。DisProtEdit旨在通过解耦语义因素实现更可控的蛋白质编辑。

Method: 构建SwissProtDis数据集，利用大语言模型自动分解结构和功能描述。通过对齐和解耦损失学习蛋白质和文本嵌入。

Result: 在蛋白质编辑和表示学习基准测试中表现优异，多属性编辑成功率高达61.7%。

Conclusion: DisProtEdit在保持性能的同时提高了可解释性和可控性。

Abstract: We introduce DisProtEdit, a controllable protein editing framework that
leverages dual-channel natural language supervision to learn disentangled
representations of structural and functional properties. Unlike prior
approaches that rely on joint holistic embeddings, DisProtEdit explicitly
separates semantic factors, enabling modular and interpretable control. To
support this, we construct SwissProtDis, a large-scale multimodal dataset where
each protein sequence is paired with two textual descriptions, one for
structure and one for function, automatically decomposed using a large language
model. DisProtEdit aligns protein and text embeddings using alignment and
uniformity objectives, while a disentanglement loss promotes independence
between structural and functional semantics. At inference time, protein editing
is performed by modifying one or both text inputs and decoding from the updated
latent representation. Experiments on protein editing and representation
learning benchmarks demonstrate that DisProtEdit performs competitively with
existing methods while providing improved interpretability and controllability.
On a newly constructed multi-attribute editing benchmark, the model achieves a
both-hit success rate of up to 61.7%, highlighting its effectiveness in
coordinating simultaneous structural and functional edits.

</details>


<div id='q-bio.MN'></div>

# q-bio.MN [[Back]](#toc)

### [3] [Attractor Stability of Boolean networks under noise](https://arxiv.org/abs/2506.15581)
*Byungjoon Min,Jeehye Choi,Reinhard Laubenbacher*

Main category: q-bio.MN

TL;DR: 研究了噪声对布尔网络吸引子动力学的影响，提出了量化吸引子稳定性的框架，发现吸引子稳定性高于预期，且噪声类型影响长期行为。


<details>
  <summary>Details</summary>
Motivation: 探讨噪声环境下布尔网络吸引子的稳定性和动态行为，以理解其在实际系统中的表现。

Method: 通过单节点扰动构建吸引子矩阵，量化稳定性并识别主导吸引子。

Result: 吸引子稳定性高于预期，全局噪声下盆地大小决定行为，局部噪声下过渡模式主导。

Conclusion: 随机扰动诱导的过渡动力学为噪声下布尔网络吸引子稳定性提供了高效定量描述。

Abstract: We study the impact of noise on attractor dynamics in Boolean networks,
focusing on their stability and transition behaviors. By constructing attractor
matrices based on single-node perturbations, we propose a framework to quantify
attractor stability and identify dominant attractors. We find that attractors
are more stable than predicted by basin sizes, showing the importance of
dynamical structure in noisy environments. In addition, under global
perturbations, basin sizes dictate long-term behavior; under local noise,
however, attractor dominance is determined by noise-induced transition patterns
rather than basin sizes. Our results show that transition dynamics induced by
stochastic perturbations provide an efficient and quantitative description for
the attractor stability and dynamics in Boolean networks under noise.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [4] [Automatic computation of the glycemic index: data driven analysis of the glucose standard](https://arxiv.org/abs/2506.15471)
*Fabio Credali,Maria Teresa Venuti,Daniele Boffi,Paola Rossi*

Main category: math.DS

TL;DR: 研究通过数学模型模拟葡萄糖摄入后的血糖反应，发现血糖反应曲线与葡萄糖吸收参数直接相关，可将受试者分为三组，为血糖指数模拟和糖尿病研究提供新视角。


<details>
  <summary>Details</summary>
Motivation: 血糖指数（GI）是预防和管理糖尿病的重要工具，研究旨在通过数据驱动模拟更深入地理解血糖反应。

Method: 应用数学模型对葡萄糖摄入后的血糖反应进行数据驱动模拟。

Result: 分析显示血糖反应曲线与葡萄糖吸收参数直接相关，受试者可根据血糖峰值时间分为三组。

Conclusion: 研究结果为血糖指数模拟和糖尿病生物学研究提供了潜在应用价值。

Abstract: The Glycemic Index (GI) is a tool for classifying carbohydrates based on
their impact on postprandial glycemia, useful for diabetes prevention and
management. This study applies a mathematical model for a data driven
simulation of the glycemic response following glucose ingestion. The analysis
reveals a direct correlation between glucose response profiles and parameters
describing glucose absorption, enabling the classification of subjects into
three groups based on the timing of their glycemic peak. Our results offer
potential applications for both glycemic index simulation and advancing
biological studies on diabetes.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Integrating Dynamical Systems Learning with Foundational Models: A Meta-Evolutionary AI Framework for Clinical Trials](https://arxiv.org/abs/2506.14782)
*Joseph Geraci,Bessi Qorri,Christian Cumbaa,Mike Tsay,Paul Leonczyk,Luca Pani*

Main category: cs.LG

TL;DR: 论文分析了两种AI方法：DeepSeek-V3（大规模通用LLM）和NetraAI（基于动态系统的小数据集稳定框架）。NetraAI通过结合收缩映射、信息几何和进化算法，识别预测性患者群体，并通过LLM Strategist优化发现过程。在案例研究中，NetraAI显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 探索AI在临床数据中的稳定性和可解释性，尤其是在小数据集上识别高效应子群体。

Method: NetraAI结合收缩映射、信息几何和进化算法，嵌入特征到度量空间并迭代收缩到稳定吸引子。LLM Strategist作为元进化层优化变量选择和知识注入。

Result: NetraAI在精神分裂症、抑郁和胰腺癌案例中，将弱基线模型（AUC ~0.50-0.68）提升为近乎完美分类器。

Conclusion: NetraAI为动态系统、信息几何和进化学习的交叉点提供了可靠、可解释的临床AI解决方案，符合新兴概念级推理范式。

Abstract: Artificial intelligence (AI) has evolved into an ecosystem of specialized
"species," each with unique strengths. We analyze two: DeepSeek-V3, a
671-billion-parameter Mixture of Experts large language model (LLM)
exemplifying scale-driven generality, and NetraAI, a dynamical system-based
framework engineered for stability and interpretability on small clinical trial
datasets. We formalize NetraAI's foundations, combining contraction mappings,
information geometry, and evolutionary algorithms to identify predictive
patient cohorts. Features are embedded in a metric space and iteratively
contracted toward stable attractors that define latent subgroups. A
pseudo-temporal embedding and long-range memory enable exploration of
higher-order feature interactions, while an internal evolutionary loop selects
compact, explainable 2-4-variable bundles ("Personas").
  To guide discovery, we introduce an LLM Strategist as a meta-evolutionary
layer that observes Persona outputs, prioritizes promising variables, injects
domain knowledge, and assesses robustness. This two-tier architecture mirrors
the human scientific process: NetraAI as experimentalist, the LLM as theorist,
forming a self-improving loop.
  In case studies (schizophrenia, depression, pancreatic cancer), NetraAI
uncovered small, high-effect-size subpopulations that transformed weak baseline
models (AUC ~0.50-0.68) into near-perfect classifiers using only a few
features. We position NetraAI at the intersection of dynamical systems,
information geometry, and evolutionary learning, aligned with emerging
concept-level reasoning paradigms such as LeCun's Joint Embedding Predictive
Architecture (JEPA). By prioritizing reliable, explainable knowledge, NetraAI
offers a new generation of adaptive, self-reflective AI to accelerate clinical
discovery.

</details>


### [6] [AZT1D: A Real-World Dataset for Type 1 Diabetes](https://arxiv.org/abs/2506.14789)
*Saman Khamesian,Asiful Arefeen,Bithika M. Thompson,Maria Adela Grando,Hassan Ghasemzadeh*

Main category: cs.LG

TL;DR: AZT1D是一个高质量的真实世界数据集，包含25名使用自动胰岛素输送系统的1型糖尿病患者的详细数据，填补了现有数据集的不足。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏公开的详细患者数据，限制了数据驱动方法在1型糖尿病管理中的应用。

Method: 收集了25名患者的连续血糖监测、胰岛素泵数据、碳水化合物摄入和设备模式等数据，持续6至8周。

Result: AZT1D提供了丰富的自然数据，支持人工智能和机器学习在1型糖尿病管理中的应用。

Conclusion: AZT1D数据集为改进1型糖尿病的临床决策和个性化护理提供了重要支持。

Abstract: High quality real world datasets are essential for advancing data driven
approaches in type 1 diabetes (T1D) management, including personalized therapy
design, digital twin systems, and glucose prediction models. However, progress
in this area has been limited by the scarcity of publicly available datasets
that offer detailed and comprehensive patient data. To address this gap, we
present AZT1D, a dataset containing data collected from 25 individuals with T1D
on automated insulin delivery (AID) systems. AZT1D includes continuous glucose
monitoring (CGM) data, insulin pump and insulin administration data,
carbohydrate intake, and device mode (regular, sleep, and exercise) obtained
over 6 to 8 weeks for each patient. Notably, the dataset provides granular
details on bolus insulin delivery (i.e., total dose, bolus type, correction
specific amounts) features that are rarely found in existing datasets. By
offering rich, naturalistic data, AZT1D supports a wide range of artificial
intelligence and machine learning applications aimed at improving clinical
decision making and individualized care in T1D.

</details>


### [7] [Universal Laboratory Model: prognosis of abnormal clinical outcomes based on routine tests](https://arxiv.org/abs/2506.15330)
*Pavel Karpov,Ilya Petrenkov,Ruslan Raiman*

Main category: cs.LG

TL;DR: 该论文提出了一种基于表格数据的建模方法，通过将表格数据转化为集合翻译问题，预测未检测项目的异常值，尤其在血液常规检测（CBC）中表现优异，AUC提升达8%。


<details>
  <summary>Details</summary>
Motivation: 临床实验室结果在诊断中普遍存在，预测未检测项目的异常值有助于早期诊断。CBC是最常用的检测项目，结合生化检测数据，形成具有缺失值的表格数据，需要一种有效的方法处理。

Method: 将表格建模问题转化为集合翻译问题，源集合包含标签列嵌入及其对应值，目标集合仅包含相同类型的嵌入。该方法无需隐式估计缺失值，并连接了LLM与表格数据领域。

Result: 在临床实验室数据中应用该方法，对高尿酸、高血糖、高胆固醇和低铁蛋白水平的联合预测，AUC提升高达8%。

Conclusion: 该方法有效处理缺失值，提升了临床实验室数据的预测性能，为早期诊断提供了新思路。

Abstract: Clinical laboratory results are ubiquitous in any diagnosis making.
Predicting abnormal values of not prescribed tests based on the results of
performed tests looks intriguing, as it would be possible to make early
diagnosis available to everyone. The special place is taken by the Common Blood
Count (CBC) test, as it is the most widely used clinical procedure. Combining
routine biochemical panels with CBC presents a set of test-value pairs that
varies from patient to patient, or, in common settings, a table with missing
values. Here we formulate a tabular modeling problem as a set translation
problem where the source set comprises pairs of GPT-like label column embedding
and its corresponding value while the target set consists of the same type
embeddings only. The proposed approach can effectively deal with missing values
without implicitly estimating them and bridges the world of LLM with the
tabular domain. Applying this method to clinical laboratory data, we achieve an
improvement up to 8% AUC for joint predictions of high uric acid, glucose,
cholesterol, and low ferritin levels.

</details>
