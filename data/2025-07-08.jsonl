{"id": "2507.02877", "pdf": "https://arxiv.org/pdf/2507.02877", "abs": "https://arxiv.org/abs/2507.02877", "authors": ["Chi Zhang", "Yu Dong", "Yang Wang", "Yuetong Han", "Guihua Shan", "Bixia Tang"], "title": "AuraGenome: An LLM-Powered Framework for On-the-Fly Reusable and Scalable Circular Genome Visualizations", "categories": ["q-bio.GN", "cs.AI", "cs.GR", "cs.HC"], "comment": null, "summary": "Circular genome visualizations are essential for exploring structural\nvariants and gene regulation. However, existing tools often require complex\nscripting and manual configuration, making the process time-consuming,\nerror-prone, and difficult to learn. To address these challenges, we introduce\nAuraGenome, an LLM-powered framework for rapid, reusable, and scalable\ngeneration of multi-layered circular genome visualizations. AuraGenome combines\na semantic-driven multi-agent workflow with an interactive visual analytics\nsystem. The workflow employs seven specialized LLM-driven agents, each assigned\ndistinct roles such as intent recognition, layout planning, and code\ngeneration, to transform raw genomic data into tailored visualizations. The\nsystem supports multiple coordinated views tailored for genomic data, offering\nring, radial, and chord-based layouts to represent multi-layered circular\ngenome visualizations. In addition to enabling interactions and configuration\nreuse, the system supports real-time refinement and high-quality report export.\nWe validate its effectiveness through two case studies and a comprehensive user\nstudy. AuraGenome is available at: https://github.com/Darius18/AuraGenome."}
{"id": "2507.02980", "pdf": "https://arxiv.org/pdf/2507.02980", "abs": "https://arxiv.org/abs/2507.02980", "authors": ["Kalyan Ramakrishnan", "Jonathan G. Hedley", "Sisi Qu", "Puneet K. Dokania", "Philip H. S. Torr", "Cesar A. Prada-Medina", "Julien Fauqueur", "Kaspar Martens"], "title": "Modeling Gene Expression Distributional Shifts for Unseen Genetic Perturbations", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "We train a neural network to predict distributional responses in gene\nexpression following genetic perturbations. This is an essential task in\nearly-stage drug discovery, where such responses can offer insights into gene\nfunction and inform target identification. Existing methods only predict\nchanges in the mean expression, overlooking stochasticity inherent in\nsingle-cell data. In contrast, we offer a more realistic view of cellular\nresponses by modeling expression distributions. Our model predicts gene-level\nhistograms conditioned on perturbations and outperforms baselines in capturing\nhigher-order statistics, such as variance, skewness, and kurtosis, at a\nfraction of the training cost. To generalize to unseen perturbations, we\nincorporate prior knowledge via gene embeddings from large language models\n(LLMs). While modeling a richer output space, the method remains competitive in\npredicting mean expression changes. This work offers a practical step towards\nmore expressive and biologically informative models of perturbation effects."}
{"id": "2507.03718", "pdf": "https://arxiv.org/pdf/2507.03718", "abs": "https://arxiv.org/abs/2507.03718", "authors": ["Heng Li"], "title": "Finding easy regions for short-read variant calling from pangenome data", "categories": ["q-bio.GN"], "comment": null, "summary": "Background: While benchmarks on short-read variant calling suggest low error\nrate below 0.5%, they are only applicable to predefined confident regions. For\na human sample without such regions, the error rate could be 10 times higher.\nAlthough multiple sets of easy regions have been identified to alleviate the\nissue, they fail to consider non-reference samples or are biased towards\nexisting short-read data or aligners.\n  Results: Here, using hundreds of high-quality human assemblies, we derived a\nset of sample-agnostic easy regions where short-read variant calling reaches\nhigh accuracy. These regions cover 87.9% of GRCh38, 92.7% of coding regions and\n96.4% of ClinVar pathogenic variants. They achieve a good balance between\ncoverage and easiness and can be generated for other human assemblies or\nspecies with multiple well assembled genomes.\n  Conclusion: This resource provides a convient and powerful way to filter\nspurious variant calls for clinical or research human samples."}
{"id": "2507.04125", "pdf": "https://arxiv.org/pdf/2507.04125", "abs": "https://arxiv.org/abs/2507.04125", "authors": ["Jiaxin Qi", "Yan Cui", "Jinli Ou", "Jianqiang Huang", "Gaogang Xie"], "title": "Graph Neural Networks as a Substitute for Transformers in Single-Cell Transcriptomics", "categories": ["cs.LG", "q-bio.GN"], "comment": "9 pages, 5 figures", "summary": "Graph Neural Networks (GNNs) and Transformers share significant similarities\nin their encoding strategies for interacting with features from nodes of\ninterest, where Transformers use query-key scores and GNNs use edges. Compared\nto GNNs, which are unable to encode relative positions, Transformers leverage\ndynamic attention capabilities to better represent relative relationships,\nthereby becoming the standard backbones in large-scale sequential pre-training.\nHowever, the subtle difference prompts us to consider: if positions are no\nlonger crucial, could we substitute Transformers with Graph Neural Networks in\nsome fields such as Single-Cell Transcriptomics? In this paper, we first\nexplore the similarities and differences between GNNs and Transformers,\nspecifically in terms of relative positions. Additionally, we design a\nsynthetic example to illustrate their equivalence where there are no relative\npositions between tokens in the sample. Finally, we conduct extensive\nexperiments on a large-scale position-agnostic dataset-single-cell\ntranscriptomics-finding that GNNs achieve competitive performance compared to\nTransformers while consuming fewer computation resources. These findings\nprovide novel insights for researchers in the field of single-cell\ntranscriptomics, challenging the prevailing notion that the Transformer is\nalways the optimum choice."}
{"id": "2507.03720", "pdf": "https://arxiv.org/pdf/2507.03720", "abs": "https://arxiv.org/abs/2507.03720", "authors": ["Tarek Tohme", "Massimo Vergassola", "Thierry Mora", "Aleksandra M. Walczak"], "title": "Fast decisions with biophysically constrained gene promoter architectures", "categories": ["q-bio.MN", "q-bio.SC"], "comment": null, "summary": "Cells integrate signals and make decisions about their future state in short\namounts of time. A lot of theoretical effort has gone into asking how to best\ndesign gene regulatory circuits that fulfill a given function, yet little is\nknown about the constraints that performing that function in a small amount of\ntime imposes on circuit architectures. Using an optimization framework, we\nexplore the properties of a class of promoter architectures that distinguish\nsmall differences in transcription factor concentrations under time\nconstraints. We show that the full temporal trajectory of gene activity allows\nfor faster decisions than its integrated activity represented by the total\nnumber of transcribed mRNA. The topology of promoter architectures that allow\nfor rapidly distinguishing low transcription factor concentrations result in a\nlow, shallow, and non cooperative response, while at high concentrations, the\nresponse is high and cooperative. In the presence of non-cognate ligands,\nnetworks with fast and accurate decision times need not be optimally selective,\nespecially if discrimination is difficult. While optimal networks are\ngenerically out of equilibrium, the energy associated with that irreversibility\nis only modest, and negligible at small concentrations. Instead, our results\nhighlight the crucial role of rate-limiting steps imposed by biophysical\nconstraints."}
{"id": "2507.03023", "pdf": "https://arxiv.org/pdf/2507.03023", "abs": "https://arxiv.org/abs/2507.03023", "authors": ["Rana Raza Mehdi", "Sukanya Sahoo", "Sunder Neelakantan", "Emilio A. Mendiola", "Kyle Myers", "Sakthivel Sadayappan", "Reza Avazmohammadi"], "title": "Human-Guided Feature Selection for Accurate Cardiomyocyte Dysfunction Classification", "categories": ["q-bio.QM", "q-bio.CB"], "comment": "Accepted in 47th Annual International Conference of the IEEE\n  Engineering in Medicine and Biology Society (EMBC)", "summary": "Early identification of cardiomyocyte dysfunction is a critical challenge for\nthe prognosis of diastolic heart failure (DHF) exhibiting impaired left\nventricular relaxation (ILVR). Myocardial relaxation relies strongly on\nefficient intracellular calcium (${\\text{Ca}}^{2+}$) handling. During diastole,\na sluggish removal of ${\\text{Ca}}^{2+}$ from cardiomyocytes disrupts sarcomere\nrelaxation, leading to ILVR \\textit{at the organ level}. Characterizing\nmyocardial relaxation \\textit{at the cellular level} requires analyzing both\nsarcomere length (SL) transients and intracellular calcium kinetics (CK).\nHowever, due to the complexity and redundancy in SL and CK data, identifying\nthe most informative features for accurate classification is challenging. To\naddress this, we developed a robust feature selection pipeline involving\nstatistical significance testing (p-values), hierarchical clustering, and\nfeature importance evaluation using random forest (RF) classification to select\nthe most informative features from SL and CK data. SL and CK transients were\nobtained from prior studies involving a transgenic phospho-ablated mouse model\nexhibiting ILVR (AAA mice) and wild-type as non-transgenic control mice (NTG).\nBy iteratively refining the feature set, we trained a RF classifier using the\nselected reduced features. For comparison, we evaluated the performance of the\nclassifier using the full set of original features as well as a dimensionally\nreduced set derived through principal component analysis (PCA). The confusion\nmatrices demonstrated that the reduced feature set achieved comparable\nperformance to the full feature set and outperformed the PCA-based approach,\nwhile offering better interpretability by retaining biologically relevant\nfeatures. These findings suggest that a small, carefully chosen set of\nbiological features can effectively detect early signs of cardiomyocyte\ndysfunction."}
{"id": "2507.04981", "pdf": "https://arxiv.org/pdf/2507.04981", "abs": "https://arxiv.org/abs/2507.04981", "authors": ["Ruihao Zhang", "Fei Ye", "Dandan Meng", "Yixuan Huang", "Maochen", "Xiao Liu"], "title": "Classification of autoimmune diseases from Peripheral blood TCR repertoires by multimodal multi-instance learning", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": "7 figures, 4 tabels", "summary": "T cell receptor (TCR) repertoires encode critical immunological signatures\nfor autoimmune diseases, yet their clinical application remains limited by\nsequence sparsity and low witness rates. We developed EAMil, a multi-instance\ndeep learning framework that leverages TCR sequencing data to diagnose systemic\nlupus erythematosus (SLE) and rheumatoid arthritis (RA) with exceptional\naccuracy. By integrating PrimeSeq feature extraction with ESMonehot encoding\nand enhanced gate attention mechanisms, our model achieved state-of-the-art\nperformance with AUCs of 98.95% for SLE and 97.76% for RA. EAMil successfully\nidentified disease-associated genes with over 90% concordance with established\ndifferential analyses and effectively distinguished disease-specific TCR genes.\nThe model demonstrated robustness in classifying multiple disease categories,\nutilizing the SLEDAI score to stratify SLE patients by disease severity as well\nas to diagnose the site of damage in SLE patients, and effectively controlling\nfor confounding factors such as age and gender. This interpretable framework\nfor immune receptor analysis provides new insights for autoimmune disease\ndetection and classification with broad potential clinical applications across\nimmune-mediated conditions."}
{"id": "2507.04432", "pdf": "https://arxiv.org/pdf/2507.04432", "abs": "https://arxiv.org/abs/2507.04432", "authors": ["Pranta Saha", "Joyce Reimer", "Brook Byrns", "Connor Burbridge", "Neeraj Dhar", "Jeffrey Chen", "Steven Rayan", "Gordon Broderick"], "title": "Reconstructing Biological Pathways by Applying Selective Incremental Learning to (Very) Small Language Models", "categories": ["q-bio.MN", "cs.CL", "cs.IT", "cs.LG", "cs.PF", "math.IT"], "comment": "9 pages, 6 figures, 3 tables + 28 pages of supplemental tables;\n  submitted to 16th ACM Conference on Bioinformatics, Computational Biology,\n  and Health Informatics (ACM BCB 2025) as submission no. 76", "summary": "The use of generative artificial intelligence (AI) models is becoming\nubiquitous in many fields. Though progress continues to be made, general\npurpose large language AI models (LLM) show a tendency to deliver creative\nanswers, often called \"hallucinations\", which have slowed their application in\nthe medical and biomedical fields where accuracy is paramount. We propose that\nthe design and use of much smaller, domain and even task-specific LM may be a\nmore rational and appropriate use of this technology in biomedical research. In\nthis work we apply a very small LM by today's standards to the specialized task\nof predicting regulatory interactions between molecular components to fill gaps\nin our current understanding of intracellular pathways. Toward this we attempt\nto correctly posit known pathway-informed interactions recovered from manually\ncurated pathway databases by selecting and using only the most informative\nexamples as part of an active learning scheme. With this example we show that a\nsmall (~110 million parameters) LM based on a Bidirectional Encoder\nRepresentations from Transformers (BERT) architecture can propose molecular\ninteractions relevant to tuberculosis persistence and transmission with over\n80% accuracy using less than 25% of the ~520 regulatory relationships in\nquestion. Using information entropy as a metric for the iterative selection of\nnew tuning examples, we also find that increased accuracy is driven by favoring\nthe use of the incorrectly assigned statements with the highest certainty\n(lowest entropy). In contrast, the concurrent use of correct but least certain\nexamples contributed little and may have even been detrimental to the learning\nrate."}
{"id": "2507.03039", "pdf": "https://arxiv.org/pdf/2507.03039", "abs": "https://arxiv.org/abs/2507.03039", "authors": ["Jonathan Karin", "Zoe Piran", "Mor Nitzan"], "title": "Enhancing Swarms Durability to Threats via Graph Signal Processing and GNN-based Generative Modeling", "categories": ["q-bio.QM", "cs.LG", "physics.bio-ph"], "comment": null, "summary": "Swarms, such as schools of fish or drone formations, are prevalent in both\nnatural and engineered systems. While previous works have focused on the social\ninteractions within swarms, the role of external perturbations--such as\nenvironmental changes, predators, or communication breakdowns--in affecting\nswarm stability is not fully understood. Our study addresses this gap by\nmodeling swarms as graphs and applying graph signal processing techniques to\nanalyze perturbations as signals on these graphs. By examining predation, we\nuncover a \"detectability-durability trade-off\", demonstrating a tension between\na swarm's ability to evade detection and its resilience to predation, once\ndetected. We provide theoretical and empirical evidence for this trade-off,\nexplicitly tying it to properties of the swarm's spatial configuration. Toward\ntask-specific optimized swarms, we introduce SwaGen, a graph neural\nnetwork-based generative model. We apply SwaGen to resilient swarm generation\nby defining a task-specific loss function, optimizing the contradicting\ntrade-off terms simultaneously.With this, SwaGen reveals novel spatial\nconfigurations, optimizing the trade-off at both ends. Applying the model can\nguide the design of robust artificial swarms and deepen our understanding of\nnatural swarm dynamics."}
{"id": "2507.05183", "pdf": "https://arxiv.org/pdf/2507.05183", "abs": "https://arxiv.org/abs/2507.05183", "authors": ["Vahe Galstyan", "Age Tjalma", "Pieter Rein ten Wolde"], "title": "Intuitive dissection of the Gaussian information bottleneck method with an application to optimal prediction", "categories": ["q-bio.MN", "cond-mat.stat-mech", "cs.IT", "math.IT", "physics.bio-ph"], "comment": null, "summary": "Efficient signal representation is essential for the functioning of living\nand artificial systems operating under resource constraints. A widely\nrecognized framework for deriving such representations is the information\nbottleneck method, which yields the optimal strategy for encoding a random\nvariable, such as the signal, in a way that preserves maximal information about\na functionally relevant variable, subject to an explicit constraint on the\namount of information encoded. While in its general formulation the method is\nnumerical, it admits an analytical solution in an important special case where\nthe variables involved are jointly Gaussian. In this setting, the solution\npredicts discrete transitions in the dimensionality of the optimal\nrepresentation as the encoding capacity is increased. Although these signature\ntransitions, along with other features of the optimal strategy, can be derived\nfrom a constrained optimization problem, a clear and intuitive understanding of\ntheir emergence is still lacking. In our work, we advance our understanding of\nthe Gaussian information bottleneck method through multiple mutually enriching\nperspectives, including geometric and information-theoretic ones. These\nperspectives offer novel intuition about the set of optimal encoding\ndirections, the nature of the critical points where the optimal number of\nencoding components changes, and about the way the optimal strategy navigates\nbetween these critical points. We then apply our treatment of the method to a\npreviously studied signal prediction problem, obtaining new insights on how\ndifferent features of the signal are encoded across multiple components to\nenable optimal prediction of future signals. Altogether, our work deepens the\nfoundational understanding of the information bottleneck method in the Gaussian\nsetting, motivating the exploration of analogous perspectives in broader,\nnon-Gaussian contexts."}
{"id": "2507.03209", "pdf": "https://arxiv.org/pdf/2507.03209", "abs": "https://arxiv.org/abs/2507.03209", "authors": ["Asal Mehradfar", "Mohammad Shahab Sepehri", "Jose Miguel Hernandez-Lobato", "Glen S. Kwon", "Mahdi Soltanolkotabi", "Salman Avestimehr", "Morteza Rasoulianboroujeni"], "title": "LANTERN: A Machine Learning Framework for Lipid Nanoparticle Transfection Efficiency Prediction", "categories": ["q-bio.QM", "cs.CE", "cs.LG", "q-bio.MN"], "comment": null, "summary": "The discovery of new ionizable lipids for efficient lipid nanoparticle\n(LNP)-mediated RNA delivery remains a critical bottleneck for RNA-based\ntherapeutics development. Recent advances have highlighted the potential of\nmachine learning (ML) to predict transfection efficiency from molecular\nstructure, enabling high-throughput virtual screening and accelerating lead\nidentification. However, existing approaches are hindered by inadequate data\nquality, ineffective feature representations, low predictive accuracy, and poor\ngeneralizability. Here, we present LANTERN (Lipid nANoparticle Transfection\nEfficiency pRedictioN), a robust ML framework for predicting transfection\nefficiency based on ionizable lipid representation. We benchmarked a diverse\nset of ML models against AGILE, a previously published model developed for\ntransfection prediction. Our results show that combining simpler models with\nchemically informative features, particularly count-based Morgan fingerprints,\noutperforms more complex models that rely on internally learned embeddings,\nsuch as AGILE. We also show that a multi-layer perceptron trained on a\ncombination of Morgan fingerprints and Expert descriptors achieved the highest\nperformance ($\\text{R}^2$ = 0.8161, r = 0.9053), significantly exceeding AGILE\n($\\text{R}^2$ = 0.2655, r = 0.5488). We show that the models in LANTERN\nconsistently have strong performance across multiple evaluation metrics. Thus,\nLANTERN offers a robust benchmarking framework for LNP transfection prediction\nand serves as a valuable tool for accelerating lipid-based RNA delivery systems\ndesign."}
{"id": "2507.03044", "pdf": "https://arxiv.org/pdf/2507.03044", "abs": "https://arxiv.org/abs/2507.03044", "authors": ["Sihan Hou", "Zhongfu Wang", "Yuting Zhu", "Hong Liu", "Jiajie Feng"], "title": "Positive effects and mechanisms of simulated lunar low-magnetic environment on earthworm-improved lunar soil simulant as a cultivation substrate", "categories": ["physics.geo-ph", "q-bio.MN"], "comment": "28 pages, 6 figures", "summary": "With the advancement of crewed deep-space missions, Bioregenerative Life\nSupport Systems (BLSS) for lunar bases face stresses from lunar environmental\nfactors. While microgravity and radiation are well-studied, the low-magnetic\nfield's effects remain unclear. Earthworms (\"soil scavengers\") improve lunar\nsoil simulant and degrade plant waste, as shown in our prior studies. We tested\nearthworms in lunar soil simulant mixed with organic waste (from \"Lunar Palace\n365\" experiment) under three magnetic conditions: lunar-low, Earth, and high.\nStronger fields increased earthworm oxidative stress (MDA) and impaired\nneurotransmitters. Weaker fields enhanced substrate cultivability: neutralized\npH, increased nutrients, humus, and wheat seedling rate. Microbial analyses\nshowed: (1) Higher fungal Shannon index under high fields indicated impaired\ndigestion; (2) More positive correlations in gut networks suggested slower\nmicrobial cooperation (e.g., lignocellulose degradation); (3) Reduced Network\nSize, Path Length and Modularity confirmed disrupted interactions. This\ndisproves lunar low-magnetic stress on earthworm-soil-waste systems, aiding\ndeep-space BLSS research."}
{"id": "2507.04704", "pdf": "https://arxiv.org/pdf/2507.04704", "abs": "https://arxiv.org/abs/2507.04704", "authors": ["Zhenglun Kong", "Mufan Qiu", "John Boesen", "Xiang Lin", "Sukwon Yun", "Tianlong Chen", "Manolis Kellis", "Marinka Zitnik"], "title": "SPATIA: Multimodal Model for Prediction and Generation of Spatial Cell Phenotypes", "categories": ["q-bio.QM", "cs.AI", "cs.CV"], "comment": null, "summary": "Understanding how cellular morphology, gene expression, and spatial\norganization jointly shape tissue function is a central challenge in biology.\nImage-based spatial transcriptomics technologies now provide high-resolution\nmeasurements of cell images and gene expression profiles, but machine learning\nmethods typically analyze these modalities in isolation or at limited\nresolution. We address the problem of learning unified, spatially aware\nrepresentations that integrate cell morphology, gene expression, and spatial\ncontext across biological scales. This requires models that can operate at\nsingle-cell resolution, reason across spatial neighborhoods, and generalize to\nwhole-slide tissue organization. Here, we introduce SPATIA, a multi-scale\ngenerative and predictive model for spatial transcriptomics. SPATIA learns\ncell-level embeddings by fusing image-derived morphological tokens and\ntranscriptomic vector tokens using cross-attention and then aggregates them at\nniche and tissue levels using transformer modules to capture spatial\ndependencies. SPATIA incorporates token merging in its generative diffusion\ndecoder to synthesize high-resolution cell images conditioned on gene\nexpression. We assembled a multi-scale dataset consisting of 17 million\ncell-gene pairs, 1 million niche-gene pairs, and 10,000 tissue-gene pairs\nacross 49 donors, 17 tissue types, and 12 disease states. We benchmark SPATIA\nagainst 13 existing models across 12 individual tasks, which span several\ncategories including cell annotation, cell clustering, gene imputation,\ncross-modal prediction, and image generation. SPATIA achieves improved\nperformance over all baselines and generates realistic cell morphologies that\nreflect transcriptomic perturbations."}
{"id": "2507.03209", "pdf": "https://arxiv.org/pdf/2507.03209", "abs": "https://arxiv.org/abs/2507.03209", "authors": ["Asal Mehradfar", "Mohammad Shahab Sepehri", "Jose Miguel Hernandez-Lobato", "Glen S. Kwon", "Mahdi Soltanolkotabi", "Salman Avestimehr", "Morteza Rasoulianboroujeni"], "title": "LANTERN: A Machine Learning Framework for Lipid Nanoparticle Transfection Efficiency Prediction", "categories": ["q-bio.QM", "cs.CE", "cs.LG", "q-bio.MN"], "comment": null, "summary": "The discovery of new ionizable lipids for efficient lipid nanoparticle\n(LNP)-mediated RNA delivery remains a critical bottleneck for RNA-based\ntherapeutics development. Recent advances have highlighted the potential of\nmachine learning (ML) to predict transfection efficiency from molecular\nstructure, enabling high-throughput virtual screening and accelerating lead\nidentification. However, existing approaches are hindered by inadequate data\nquality, ineffective feature representations, low predictive accuracy, and poor\ngeneralizability. Here, we present LANTERN (Lipid nANoparticle Transfection\nEfficiency pRedictioN), a robust ML framework for predicting transfection\nefficiency based on ionizable lipid representation. We benchmarked a diverse\nset of ML models against AGILE, a previously published model developed for\ntransfection prediction. Our results show that combining simpler models with\nchemically informative features, particularly count-based Morgan fingerprints,\noutperforms more complex models that rely on internally learned embeddings,\nsuch as AGILE. We also show that a multi-layer perceptron trained on a\ncombination of Morgan fingerprints and Expert descriptors achieved the highest\nperformance ($\\text{R}^2$ = 0.8161, r = 0.9053), significantly exceeding AGILE\n($\\text{R}^2$ = 0.2655, r = 0.5488). We show that the models in LANTERN\nconsistently have strong performance across multiple evaluation metrics. Thus,\nLANTERN offers a robust benchmarking framework for LNP transfection prediction\nand serves as a valuable tool for accelerating lipid-based RNA delivery systems\ndesign."}
{"id": "2507.04937", "pdf": "https://arxiv.org/pdf/2507.04937", "abs": "https://arxiv.org/abs/2507.04937", "authors": ["Charles G. Cameron", "Cameron A. Smith", "Christian A. Yates"], "title": "The Spatial Regime Conversion Method", "categories": ["q-bio.QM", "92-10, 35K57, 60J99, 92E99"], "comment": "29 Pages, 11 Figures", "summary": "We present the spatial regime conversion method (SRCM), a novel hybrid\nmodelling framework for simulating reaction-diffusion systems that adaptively\ncombines stochastic discrete and deterministic continuum representations.\nExtending the regime conversion method (RCM) to spatial settings, the SRCM\nemploys a discrete reaction-diffusion master equation (RDME) representation in\nregions of low concentration and continuum partial differential equations\n(PDEs) where concentrations are high, dynamically switching based on local\nthresholds. This enables efficient and accurate simulation of systems in which\nstochasticity plays a key role but is not required uniformly across the domain.\nWe specify the full mathematical formulation of the SRCM, including conversion\nreactions, hybrid kinetic rules, and consistent numerical updates. The method\nis validated across several one-dimensional test systems, including simple\ndiffusion from a region of high concentration, the formation of a morphogen\ngradient, and the propagation of FKPP travelling waves. Results show that the\nSRCM captures key stochastic features while offering substantial gains in\ncomputational efficiency over fully stochastic models."}
{"id": "2507.05101", "pdf": "https://arxiv.org/pdf/2507.05101", "abs": "https://arxiv.org/abs/2507.05101", "authors": ["Xinzhe Zheng", "Hao Du", "Fanding Xu", "Jinzhe Li", "Zhiyuan Liu", "Wenkang Wang", "Tao Chen", "Wanli Ouyang", "Stan Z. Li", "Yan Lu", "Nanqing Dong", "Yang Zhang"], "title": "PRING: Rethinking Protein-Protein Interaction Prediction from Pairs to Graphs", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.MN"], "comment": null, "summary": "Deep learning-based computational methods have achieved promising results in\npredicting protein-protein interactions (PPIs). However, existing benchmarks\npredominantly focus on isolated pairwise evaluations, overlooking a model's\ncapability to reconstruct biologically meaningful PPI networks, which is\ncrucial for biology research. To address this gap, we introduce PRING, the\nfirst comprehensive benchmark that evaluates protein-protein interaction\nprediction from a graph-level perspective. PRING curates a high-quality,\nmulti-species PPI network dataset comprising 21,484 proteins and 186,818\ninteractions, with well-designed strategies to address both data redundancy and\nleakage. Building on this golden-standard dataset, we establish two\ncomplementary evaluation paradigms: (1) topology-oriented tasks, which assess\nintra and cross-species PPI network construction, and (2) function-oriented\ntasks, including protein complex pathway prediction, GO module analysis, and\nessential protein justification. These evaluations not only reflect the model's\ncapability to understand the network topology but also facilitate protein\nfunction annotation, biological module detection, and even disease mechanism\nanalysis. Extensive experiments on four representative model categories,\nconsisting of sequence similarity-based, naive sequence-based, protein language\nmodel-based, and structure-based approaches, demonstrate that current PPI\nmodels have potential limitations in recovering both structural and functional\nproperties of PPI networks, highlighting the gap in supporting real-world\nbiological applications. We believe PRING provides a reliable platform to guide\nthe development of more effective PPI prediction models for the community. The\ndataset and source code of PRING are available at\nhttps://github.com/SophieSarceau/PRING."}
{"id": "2507.03024", "pdf": "https://arxiv.org/pdf/2507.03024", "abs": "https://arxiv.org/abs/2507.03024", "authors": ["Tan Nguyen", "Guojing Cong"], "title": "Completion of the DrugMatrix Toxicogenomics Database using 3-Dimensional Tensors", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": "11 pages, 6 figures, BioKDD'25", "summary": "We explore applying a tensor completion approach to complete the DrugMatrix\ntoxicogenomics dataset. Our hypothesis is that by preserving the 3-dimensional\nstructure of the data, which comprises tissue, treatment, and transcriptomic\nmeasurements, and by leveraging a machine learning formulation, our approach\nwill improve upon prior state-of-the-art results. Our results demonstrate that\nthe new tensor-based method more accurately reflects the original data\ndistribution and effectively captures organ-specific variability. The proposed\ntensor-based methodology achieved lower mean squared errors and mean absolute\nerrors compared to both conventional Canonical Polyadic decomposition and\n2-dimensional matrix factorization methods. In addition, our non-negative\ntensor completion implementation reveals relationships among tissues. Our\nfindings not only complete the world's largest in-vivo toxicogenomics database\nwith improved accuracy but also offer a promising methodology for future\nstudies of drugs that may cross species barriers, for example, from rats to\nhumans."}
{"id": "2507.03407", "pdf": "https://arxiv.org/pdf/2507.03407", "abs": "https://arxiv.org/abs/2507.03407", "authors": ["Junwei Su", "Cheng Xin", "Ao Shang", "Shan Wu", "Zhenzhen Xie", "Ruogu Xiong", "Xiaoyu Xu", "Cheng Zhang", "Guang Chen", "Yau-Tuen Chan", "Guoyi Tang", "Ning Wang", "Yong Xu", "Yibin Feng"], "title": "Artificial intelligence in drug discovery: A comprehensive review with a case study on hyperuricemia, gout arthritis, and hyperuricemic nephropathy", "categories": ["cs.AI", "q-bio.QM"], "comment": null, "summary": "This paper systematically reviews recent advances in artificial intelligence\n(AI), with a particular focus on machine learning (ML), across the entire drug\ndiscovery pipeline. Due to the inherent complexity, escalating costs, prolonged\ntimelines, and high failure rates of traditional drug discovery methods, there\nis a critical need to comprehensively understand how AI/ML can be effectively\nintegrated throughout the full process. Currently available literature reviews\noften narrowly focus on specific phases or methodologies, neglecting the\ndependence between key stages such as target identification, hit screening, and\nlead optimization. To bridge this gap, our review provides a detailed and\nholistic analysis of AI/ML applications across these core phases, highlighting\nsignificant methodological advances and their impacts at each stage. We further\nillustrate the practical impact of these techniques through an in-depth case\nstudy focused on hyperuricemia, gout arthritis, and hyperuricemic nephropathy,\nhighlighting real-world successes in molecular target identification and\ntherapeutic candidate discovery. Additionally, we discuss significant\nchallenges facing AI/ML in drug discovery and outline promising future research\ndirections. Ultimately, this review serves as an essential orientation for\nresearchers aiming to leverage AI/ML to overcome existing bottlenecks and\naccelerate drug discovery."}
{"id": "2507.03655", "pdf": "https://arxiv.org/pdf/2507.03655", "abs": "https://arxiv.org/abs/2507.03655", "authors": ["Christophe Lohou", "Bruno Miguel"], "title": "Segmentation of separated Lumens in 3D CTA images of Aortic Dissection", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "comment": null, "summary": "Aortic dissection is a serious pathology and requires an emergency\nmanagement. It is characterized by one or more tears of the intimal wall of the\nnormal blood duct of the aorta (true lumen); the blood under pressure then\ncreates a second blood lumen (false lumen) in the media tissue. The two lumens\nare separated by an intimal wall, called flap. From the segmentation of\nconnected lumens (more precisely, blood inside lumens) of an aortic dissection\n3D Computed Tomography Angiography (CTA) image, our previous studies allow us\nto retrieve the intimal flap by using Mathematical Morphology operators, and\ncharacterize intimal tears by 3d thin surfaces that fill them, these surfaces\nare obtained by operating the Aktouf et al. closing algorithm proposed in the\nframework of Digital Topology. Indeed, intimal tears are 3D holes in the\nintimal flap; although it is impossible to directly segment such non-concrete\ndata, it is nevertheless possible to \"materialize\" them with these 3D filling\nsurfaces that may be quantified or make easier the visualization of these\nholes.\n  In this paper, we use these surfaces that fill tears to cut connections\nbetween lumens in order to separate them.\n  This is the first time that surfaces filling tears are used as an image\nprocessing operator (to disconnect several parts of a 3D object). This lumen\nseparation allows us to provide one of the first cartographies of an aortic\ndissection, that may better visually assist physicians during their diagnosis.\n  Our method is able to disconnect lumens, that may also lead to enhance\nseveral current investigations (registration, segmentation, hemodynamics)."}
{"id": "2507.03951", "pdf": "https://arxiv.org/pdf/2507.03951", "abs": "https://arxiv.org/abs/2507.03951", "authors": ["Amnon Balanov", "Alon Zabatani", "Tamir Bendory"], "title": "Structure from Noise: Confirmation Bias in Particle Picking in Structural Biology", "categories": ["eess.SP", "q-bio.QM"], "comment": null, "summary": "Confirmation bias is a fundamental challenge in cryo-electron microscopy\n(cryo-EM) and cryo-electron tomography (cryo-ET), where prior expectations can\nlead to systematic errors in data interpretation. This bias may emerge at\nmultiple stages of the reconstruction pipeline, and in particular in the\ncritical particle picking stage, where 2D particles (in cryo-EM) or 3D\nsubtomograms (in cryo-ET) are extracted from highly noisy micrographs or\ntomograms. Focusing on two widely used methodologies, template matching and\ndeep neural networks, we combine theoretical analysis with controlled\nexperiments to demonstrate that both methods, when applied to pure noise, can\nproduce persistent molecular structures, a phenomenon we term structure from\nnoise. This artifact highlights a critical vulnerability in current workflows:\nthe potential for particle-picking algorithms to inject strong prior-driven\nbias into downstream analyses. We then propose practical mitigation strategies\nto reduce the impact of such biases. Together, our findings deepen the\ntheoretical understanding of confirmation bias in cryo-EM and cryo-ET and call\nfor cautious interpretation of reconstructions, primarily when relying on\ntemplate-driven particle picking."}
{"id": "2507.04496", "pdf": "https://arxiv.org/pdf/2507.04496", "abs": "https://arxiv.org/abs/2507.04496", "authors": ["Nicolette Meshkat", "Anne Shiu"], "title": "Structural Identifiability of Compartmental Models: Recent Progress and Future Directions", "categories": ["stat.ME", "math.DS", "q-bio.QM"], "comment": null, "summary": "We summarize recent progress on the theory and applications of structural\nidentifiability of compartmental models. On the applications side, we review\nidentifiability analyses undertaken recently for models arising in\nepidemiology, oncology, and other areas; and we summarize common approaches for\nhandling models that are unidentifiable. We also highlight recent theoretical\nand algorithmic results on how to reparametrize unidentifiable models and, in\nthe context of linear compartmental models, how to predict identifiability\nproperties directly from the model structure. Finally, we highlight future\nresearch directions."}
{"id": "2507.04894", "pdf": "https://arxiv.org/pdf/2507.04894", "abs": "https://arxiv.org/abs/2507.04894", "authors": ["Alexander P Browning", "Jennifer A Flegg", "Ryan J Murphy"], "title": "A cautionary tale of model misspecification and identifiability", "categories": ["stat.ME", "q-bio.QM", "97M10, 35Q92, 62F99, 62G08, 60G15"], "comment": null, "summary": "Mathematical models are routinely applied to interpret biological data, with\ncommon goals that include both prediction and parameter estimation. A challenge\nin mathematical biology, in particular, is that models are often complex and\nnon-identifiable, while data are limited. Rectifying identifiability through\nsimplification can seemingly yield more precise parameter estimates, albeit, as\nwe explore in this perspective, at the potentially catastrophic cost of\nintroducing model misspecification and poor accuracy. We demonstrate how\nuncertainty in model structure can be propagated through to uncertainty in\nparameter estimates using a semi-parametric Gaussian process approach that\ndelineates parameters of interest from uncertainty in model terms.\nSpecifically, we study generalised logistic growth with an unknown crowding\nfunction, and a spatially resolved process described by a partial differential\nequation with a time-dependent diffusivity parameter. Allowing for structural\nmodel uncertainty yields more robust and accurate parameter estimates, and a\nbetter quantification of remaining uncertainty. We conclude our perspective by\ndiscussing the connections between identifiability and model misspecification,\nand alternative approaches to dealing with model misspecification in\nmathematical biology."}
