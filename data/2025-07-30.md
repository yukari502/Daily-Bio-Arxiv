<div id=toc></div>

# Table of Contents

- [q-bio.QM](#q-bio.QM) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [1] [Exploring the Interplay of Adiposity, Ethnicity, and Hormone Receptor Profiles in Breast Cancer Subtypes](https://arxiv.org/abs/2507.21348)
*Izabel Valdez,Paramahansa Pramanik*

Main category: q-bio.QM

TL;DR: 研究探讨肥胖和种族如何共同影响Luminal亚型乳腺癌的发展与预后，重点关注区分Luminal A与更具侵袭性的Luminal B肿瘤。


<details>
  <summary>Details</summary>
Motivation: 揭示肥胖和种族背景对Luminal B乳腺癌风险的影响，并强调结合医学治疗与社会干预的必要性。

Method: 利用大规模流行病学数据，采用逻辑回归和中介分析等统计方法，研究雌激素代谢、脂肪因子、慢性炎症等生物因素，以及医疗资源、社会经济地位和文化态度等社会因素。

Result: 肥胖和种族背景是Luminal B乳腺癌风险的重要预测因素。

Conclusion: 研究强调需结合医学治疗与针对性社会干预以减少差异，为个体化风险评估和筛查项目提供依据，并支持减轻边缘化社区癌症负担的政策。

Abstract: This study explores how obesity and race jointly influence the development
and prognosis of Luminal subtypes of breast cancer, with a focus on
distinguishing Luminal A from the more aggressive Luminal B tumors. Drawing on
large-scale epidemiological data and employing statistical approaches such as
logistic regression and mediation analysis, the research examines biological
factors like estrogen metabolism, adipokines, and chronic inflammation
alongside social determinants including healthcare access, socioeconomic
status, and cultural attitudes toward body weight. The findings reveal that
both obesity and racial background are significant predictors of risk for
Luminal B breast cancers. The study highlights the need for a dual approach
that combines medical treatment with targeted social interventions aimed at
reducing disparities. These insights can improve individualized risk
assessments, guide tailored screening programs, and support policies that
address the heightened cancer burden experienced by marginalized communities.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Adaptive Multimodal Protein Plug-and-Play with Diffusion-Based Priors](https://arxiv.org/abs/2507.21260)
*Amartya Banerjee,Xingyu Xu,Caroline Moosmüller,Harlin Lee*

Main category: cs.LG

TL;DR: Adam-PnP框架通过自适应噪声估计和动态模态加权机制，利用预训练的蛋白质扩散模型，显著提高了复杂重建任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决多源噪声实验数据整合的挑战，减少手动超参数调整的需求。

Method: 提出Adam-PnP框架，结合自适应噪声估计和动态模态加权机制，指导预训练的蛋白质扩散模型。

Result: 实验表明，Adam-PnP在复杂重建任务中显著提高了准确性。

Conclusion: Adam-PnP为多源数据整合提供了一种高效且自动化的解决方案。

Abstract: In an inverse problem, the goal is to recover an unknown parameter (e.g., an
image) that has typically undergone some lossy or noisy transformation during
measurement. Recently, deep generative models, particularly diffusion models,
have emerged as powerful priors for protein structure generation. However,
integrating noisy experimental data from multiple sources to guide these models
remains a significant challenge. Existing methods often require precise
knowledge of experimental noise levels and manually tuned weights for each data
modality. In this work, we introduce Adam-PnP, a Plug-and-Play framework that
guides a pre-trained protein diffusion model using gradients from multiple,
heterogeneous experimental sources. Our framework features an adaptive noise
estimation scheme and a dynamic modality weighting mechanism integrated into
the diffusion process, which reduce the need for manual hyperparameter tuning.
Experiments on complex reconstruction tasks demonstrate significantly improved
accuracy using Adam-PnP.

</details>


### [3] [Data Leakage and Redundancy in the LIT-PCBA Benchmark](https://arxiv.org/abs/2507.21404)
*Amber Huang,Ian Scott Knight,Slava Naprienko*

Main category: cs.LG

TL;DR: LIT-PCBA基准数据集存在严重的数据泄漏、重复和结构冗余问题，导致模型评估不公平，甚至通过简单记忆方法即可超越先进模型。


<details>
  <summary>Details</summary>
Motivation: 揭示LIT-PCBA数据集在虚拟筛选基准测试中的根本性缺陷，以促进更严谨的数据集开发。

Method: 通过审计数据集，识别数据泄漏、重复和结构冗余问题，并设计一个基于记忆的基线方法验证问题的影响。

Result: 发现大量数据重复和泄漏，基线方法通过利用这些问题超越了先进模型，表明数据集无效。

Conclusion: LIT-PCBA数据集不适合其预期用途，需开发更可靠的数据集，并重新评估基于该数据集的研究结果。

Abstract: LIT-PCBA is a widely used benchmark for virtual screening, but our audit
reveals it is fundamentally compromised. The dataset suffers from egregious
data leakage, rampant duplication, and pervasive analog redundancy -- flaws
that invalidate its use for fair model evaluation. Notably, we identify 2,491
inactives duplicated across training and validation sets, and thousands more
repeated within individual data splits (2,945 in training, 789 in validation).
Critically, three ligands in the query set -- meant to represent unseen test
cases -- are leaked: two appear in the training set, one in validation.
Structural redundancy compounds these issues: for some targets, over 80% of
query ligands are near duplicates, with Tanimoto similarity >= 0.9. In ALDH1
alone, we find 323 highly similar active pairs between training and validation
sets, invalidating claims of chemical diversity. These and other flaws
collectively cause models trained on LIT-PCBA to memorize rather than
generalize. To demonstrate the consequences of these data integrity failures,
we implement a trivial memorization-based baseline -- using no learning, no
physics, and no modeling -- that outperforms state-of-the-art models, including
deep neural networks like CHEESE, on LIT-PCBA simply by exploiting these
artifacts. Our findings render the benchmark unfit for its intended purpose and
call into question previous results based on its use. We share this audit to
raise awareness and provide tooling to help the community develop more rigorous
and reliable datasets going forward. All scripts necessary to reproduce our
audit and the baseline implementation are available at:
https://github.com/sievestack/LIT-PCBA-audit

</details>
