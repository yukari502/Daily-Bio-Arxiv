{"id": "2507.23048", "pdf": "https://arxiv.org/pdf/2507.23048", "abs": "https://arxiv.org/abs/2507.23048", "authors": ["Kaitao Lai"], "title": "CARTEpigenoQC: A Quality Control Toolkit for CAR-T Single-Cell Epigenomic Data", "categories": ["q-bio.GN"], "comment": "5 pages, 2 figures, 2 tables", "summary": "CARTEpigenoQC is an R-based toolkit designed to streamline quality control\n(QC) for single-cell epigenomic datasets involving Chimeric Antigen Receptor\n(CAR)-engineered T cells. With the growing application of scATAC-seq,\nscCUT&Tag, and scBS-seq to characterize CAR-T cell states, it has become\ncritical to perform customized QC that not only addresses standard metrics like\nFRiP (Fraction of Reads in Peaks) and TSS enrichment, but also directly detects\nsignal from CAR vector insertion sites. CARTEpigenoQC supports both 10x\nGenomics and non-10x data formats and produces HTML and PNG summary outputs\nsuited for exploratory analysis and regulatory-grade preclinical reporting. It\nis intended to assist researchers, core facilities, and translational\nimmunologists in ensuring the validity of single-cell epigenomic profiling of\nengineered T cells."}
{"id": "2507.23101", "pdf": "https://arxiv.org/pdf/2507.23101", "abs": "https://arxiv.org/abs/2507.23101", "authors": ["Gaelen Guzman", "Andr√© Nadler", "Frank Stein", "Jeremy M. Baskin", "Carsten Schultz", "Fikadu Tafesse"], "title": "The Lipid Interactome: An interactive and open access platform for exploring cellular lipid-protein interactomes", "categories": ["q-bio.QM"], "comment": "10 pages", "summary": "Lipid-protein interactions play essential roles in cellular signaling and\nmembrane dynamics, yet their systematic characterization has long been hindered\nby the inherent biochemical properties of lipids. Recent advances in\nfunctionalized lipid probes -- equipped with photoactivatable crosslinkers,\naffinity handles, and photocleavable protecting groups -- have enabled\nproteomics-based identification of lipid interacting proteins with\nunprecedented specificity and resolution. Despite the growing number of\npublished lipid interactomes, there remains no centralized effort to harmonize,\ncompare, or integrate these datasets.\n  The Lipid Interactome addresses this gap by providing a structured,\ninteractive web portal that adheres to FAIR data principles -- ensuring that\nlipid interactome studies are Findable, Accessible, Interoperable, and\nReusable. Through standardized data formatting, interactive visualizations, and\ndirect cross-study comparisons, this resource enables researchers to\nsystematically explore the protein-binding partners of diverse bioactive\nlipids. By consolidating and curating lipid interactome proteomics data from\nmultiple studies, the Lipid Interactome database serves as a critical tool for\ndeciphering the biological functions of lipids in cellular systems."}
{"id": "2507.23146", "pdf": "https://arxiv.org/pdf/2507.23146", "abs": "https://arxiv.org/abs/2507.23146", "authors": ["Sarah Pungitore", "Shashank Yadav", "David Maughan", "Vignesh Subbian"], "title": "Lightweight Language Models are Prone to Reasoning Errors for Complex Computational Phenotyping Tasks", "categories": ["q-bio.QM"], "comment": null, "summary": "Objective: Although computational phenotyping is a central informatics\nactivity with resulting cohorts supporting a wide variety of applications, it\nis time-intensive because of manual data review. We previously assessed the\nability of LLMs to perform computational phenotyping tasks using computable\nphenotypes for ARF respiratory support therapies. They successfully performed\nconcept classification and classification of single-therapy phenotypes, but\nunderperformed on multiple-therapy phenotypes. To understand issues with these\ncomplex tasks, we expanded PHEONA, a generalizable framework for evaluation of\nLLMs, to include methods specifically for evaluating faulty reasoning.\nMaterials and Methods: We assessed the responses of three lightweight LLMs\n(DeepSeek-r1 32 billion, Mistral Small 24 billion, and Phi-4 14 billion) both\nwith and without prompt modifications to identify explanation correctness and\nunfaithfulness errors for phenotyping. Results: For experiments without prompt\nmodifications, both errors were present across all models although more\nresponses had explanation correctness errors than unfaithfulness errors. For\nexperiments assessing accuracy impact after prompt modifications, DeepSeek, a\nreasoning model, had the smallest overall accuracy impact when compared to\nMistral and Phi. Discussion: Since reasoning errors were ubiquitous across\nmodels, our enhancement of PHEONA to include a component for assessing faulty\nreasoning provides critical support for LLM evaluation and evidence for\nreasoning errors for complex tasks. While insights from reasoning errors can\nhelp prompt refinement, a deeper understanding of why LLM reasoning errors\noccur will likely require further development and refinement of\ninterpretability methods. Conclusion: Reasoning errors were pervasive across\nLLM responses for computational phenotyping, a complex reasoning task"}
{"id": "2507.23227", "pdf": "https://arxiv.org/pdf/2507.23227", "abs": "https://arxiv.org/abs/2507.23227", "authors": ["Sophie Kearney", "Shu Yang", "Zixuan Wen", "Bojian Hou", "Duy Duong-Tran", "Tianlong Chen", "Jason Moore", "Marylyn Ritchie", "Li Shen"], "title": "Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs", "categories": ["cs.CL", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Early and accurate diagnosis of Alzheimer's disease (AD), a complex\nneurodegenerative disorder, requires analysis of heterogeneous biomarkers\n(e.g., neuroimaging, genetic risk factors, cognitive tests, and cerebrospinal\nfluid proteins) typically represented in a tabular format. With flexible\nfew-shot reasoning, multimodal integration, and natural-language-based\ninterpretability, large language models (LLMs) offer unprecedented\nopportunities for prediction with structured biomedical data. We propose a\nnovel framework called TAP-GPT, Tabular Alzheimer's Prediction GPT, that adapts\nTableGPT2, a multimodal tabular-specialized LLM originally developed for\nbusiness intelligence tasks, for AD diagnosis using structured biomarker data\nwith small sample sizes. Our approach constructs few-shot tabular prompts using\nin-context learning examples from structured biomedical data and finetunes\nTableGPT2 using the parameter-efficient qLoRA adaption for a clinical binary\nclassification task of AD or cognitively normal (CN). The TAP-GPT framework\nharnesses the powerful tabular understanding ability of TableGPT2 and the\nencoded prior knowledge of LLMs to outperform more advanced general-purpose\nLLMs and a tabular foundation model (TFM) developed for prediction tasks. To\nour knowledge, this is the first application of LLMs to the prediction task\nusing tabular biomarker data, paving the way for future LLM-driven multi-agent\nframeworks in biomedical informatics."}
