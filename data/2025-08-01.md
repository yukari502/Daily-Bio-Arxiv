<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 2]
- [cs.CL](#cs.CL) [Total: 1]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [CARTEpigenoQC: A Quality Control Toolkit for CAR-T Single-Cell Epigenomic Data](https://arxiv.org/abs/2507.23048)
*Kaitao Lai*

Main category: q-bio.GN

TL;DR: CARTEpigenoQC是一个基于R的工具包，用于简化CAR-T细胞单细胞表观基因组数据的质量控制（QC）。


<details>
  <summary>Details</summary>
Motivation: 随着scATAC-seq、scCUT&Tag和scBS-seq在CAR-T细胞状态表征中的应用增加，需要定制化的QC工具来检测CAR载体插入位点的信号。

Method: 支持10x和非10x数据格式，提供HTML和PNG格式的总结输出，适用于探索性分析和监管级临床前报告。

Result: 该工具包旨在帮助研究人员、核心设施和转化免疫学家确保工程化T细胞单细胞表观基因组分析的有效性。

Conclusion: CARTEpigenoQC为CAR-T细胞单细胞表观基因组数据的质量控制提供了高效、定制化的解决方案。

Abstract: CARTEpigenoQC is an R-based toolkit designed to streamline quality control
(QC) for single-cell epigenomic datasets involving Chimeric Antigen Receptor
(CAR)-engineered T cells. With the growing application of scATAC-seq,
scCUT&Tag, and scBS-seq to characterize CAR-T cell states, it has become
critical to perform customized QC that not only addresses standard metrics like
FRiP (Fraction of Reads in Peaks) and TSS enrichment, but also directly detects
signal from CAR vector insertion sites. CARTEpigenoQC supports both 10x
Genomics and non-10x data formats and produces HTML and PNG summary outputs
suited for exploratory analysis and regulatory-grade preclinical reporting. It
is intended to assist researchers, core facilities, and translational
immunologists in ensuring the validity of single-cell epigenomic profiling of
engineered T cells.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [2] [The Lipid Interactome: An interactive and open access platform for exploring cellular lipid-protein interactomes](https://arxiv.org/abs/2507.23101)
*Gaelen Guzman,André Nadler,Frank Stein,Jeremy M. Baskin,Carsten Schultz,Fikadu Tafesse*

Main category: q-bio.QM

TL;DR: 该论文介绍了“脂质相互作用组”数据库，旨在整合和标准化脂质-蛋白质相互作用数据，提供一个基于FAIR原则的交互式网络平台。


<details>
  <summary>Details</summary>
Motivation: 脂质-蛋白质相互作用在细胞信号传导和膜动力学中至关重要，但缺乏系统性的数据整合和比较工具。

Method: 通过功能化脂质探针和蛋白质组学技术，结合标准化数据格式和交互式可视化工具，构建了一个集中化的数据库。

Result: 该数据库能够高效识别脂质结合蛋白，支持跨研究比较和数据共享。

Conclusion: “脂质相互作用组”为研究脂质在细胞系统中的生物学功能提供了重要工具。

Abstract: Lipid-protein interactions play essential roles in cellular signaling and
membrane dynamics, yet their systematic characterization has long been hindered
by the inherent biochemical properties of lipids. Recent advances in
functionalized lipid probes -- equipped with photoactivatable crosslinkers,
affinity handles, and photocleavable protecting groups -- have enabled
proteomics-based identification of lipid interacting proteins with
unprecedented specificity and resolution. Despite the growing number of
published lipid interactomes, there remains no centralized effort to harmonize,
compare, or integrate these datasets.
  The Lipid Interactome addresses this gap by providing a structured,
interactive web portal that adheres to FAIR data principles -- ensuring that
lipid interactome studies are Findable, Accessible, Interoperable, and
Reusable. Through standardized data formatting, interactive visualizations, and
direct cross-study comparisons, this resource enables researchers to
systematically explore the protein-binding partners of diverse bioactive
lipids. By consolidating and curating lipid interactome proteomics data from
multiple studies, the Lipid Interactome database serves as a critical tool for
deciphering the biological functions of lipids in cellular systems.

</details>


### [3] [Lightweight Language Models are Prone to Reasoning Errors for Complex Computational Phenotyping Tasks](https://arxiv.org/abs/2507.23146)
*Sarah Pungitore,Shashank Yadav,David Maughan,Vignesh Subbian*

Main category: q-bio.QM

TL;DR: LLMs在计算表型任务中表现不佳，尤其是在复杂任务中。通过扩展PHEONA框架评估推理错误，发现所有模型均存在推理错误，DeepSeek表现相对较好。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在复杂计算表型任务中表现不佳的问题，尤其是推理错误。

Method: 评估三种轻量级LLMs（DeepSeek、Mistral、Phi）在有无提示修改下的表现，分析解释正确性和不忠实错误。

Result: 所有模型均存在推理错误，DeepSeek在提示修改后准确率影响最小。

Conclusion: 推理错误在LLMs中普遍存在，需进一步开发解释性方法以理解错误原因。

Abstract: Objective: Although computational phenotyping is a central informatics
activity with resulting cohorts supporting a wide variety of applications, it
is time-intensive because of manual data review. We previously assessed the
ability of LLMs to perform computational phenotyping tasks using computable
phenotypes for ARF respiratory support therapies. They successfully performed
concept classification and classification of single-therapy phenotypes, but
underperformed on multiple-therapy phenotypes. To understand issues with these
complex tasks, we expanded PHEONA, a generalizable framework for evaluation of
LLMs, to include methods specifically for evaluating faulty reasoning.
Materials and Methods: We assessed the responses of three lightweight LLMs
(DeepSeek-r1 32 billion, Mistral Small 24 billion, and Phi-4 14 billion) both
with and without prompt modifications to identify explanation correctness and
unfaithfulness errors for phenotyping. Results: For experiments without prompt
modifications, both errors were present across all models although more
responses had explanation correctness errors than unfaithfulness errors. For
experiments assessing accuracy impact after prompt modifications, DeepSeek, a
reasoning model, had the smallest overall accuracy impact when compared to
Mistral and Phi. Discussion: Since reasoning errors were ubiquitous across
models, our enhancement of PHEONA to include a component for assessing faulty
reasoning provides critical support for LLM evaluation and evidence for
reasoning errors for complex tasks. While insights from reasoning errors can
help prompt refinement, a deeper understanding of why LLM reasoning errors
occur will likely require further development and refinement of
interpretability methods. Conclusion: Reasoning errors were pervasive across
LLM responses for computational phenotyping, a complex reasoning task

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [4] [Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs](https://arxiv.org/abs/2507.23227)
*Sophie Kearney,Shu Yang,Zixuan Wen,Bojian Hou,Duy Duong-Tran,Tianlong Chen,Jason Moore,Marylyn Ritchie,Li Shen*

Main category: cs.CL

TL;DR: TAP-GPT是一种基于TableGPT2的框架，用于利用少量样本的表格生物标志物数据诊断阿尔茨海默病（AD），性能优于通用LLM和表格基础模型。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的早期准确诊断需要分析多种异质生物标志物，而LLM在结构化生物医学数据中具有潜力。

Method: 通过上下文学习构建少样本表格提示，并使用qLoRA微调TableGPT2进行AD与认知正常（CN）的二元分类。

Result: TAP-GPT在表格理解能力和LLM先验知识的支持下，性能优于通用LLM和表格基础模型。

Conclusion: 这是首次将LLM应用于表格生物标志物数据预测任务，为未来生物医学信息学中的多智能体框架奠定了基础。

Abstract: Early and accurate diagnosis of Alzheimer's disease (AD), a complex
neurodegenerative disorder, requires analysis of heterogeneous biomarkers
(e.g., neuroimaging, genetic risk factors, cognitive tests, and cerebrospinal
fluid proteins) typically represented in a tabular format. With flexible
few-shot reasoning, multimodal integration, and natural-language-based
interpretability, large language models (LLMs) offer unprecedented
opportunities for prediction with structured biomedical data. We propose a
novel framework called TAP-GPT, Tabular Alzheimer's Prediction GPT, that adapts
TableGPT2, a multimodal tabular-specialized LLM originally developed for
business intelligence tasks, for AD diagnosis using structured biomarker data
with small sample sizes. Our approach constructs few-shot tabular prompts using
in-context learning examples from structured biomedical data and finetunes
TableGPT2 using the parameter-efficient qLoRA adaption for a clinical binary
classification task of AD or cognitively normal (CN). The TAP-GPT framework
harnesses the powerful tabular understanding ability of TableGPT2 and the
encoded prior knowledge of LLMs to outperform more advanced general-purpose
LLMs and a tabular foundation model (TFM) developed for prediction tasks. To
our knowledge, this is the first application of LLMs to the prediction task
using tabular biomarker data, paving the way for future LLM-driven multi-agent
frameworks in biomedical informatics.

</details>
