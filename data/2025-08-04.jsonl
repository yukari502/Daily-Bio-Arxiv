{"id": "2508.00781", "pdf": "https://arxiv.org/pdf/2508.00781", "abs": "https://arxiv.org/abs/2508.00781", "authors": ["Niusha Mirhakimi", "Yohan Chatelain", "Jean-Baptiste Poline", "Tristan Glatard"], "title": "Numerical Uncertainty in Linear Registration: An Experimental Study", "categories": ["q-bio.QM", "eess.IV"], "comment": null, "summary": "While linear registration is a critical step in MRI preprocessing pipelines,\nits numerical uncertainty is understudied. Using Monte-Carlo Arithmetic (MCA)\nsimulations, we assessed the most commonly used linear registration tools\nwithin major software packages (SPM, FSL, and ANTs) across multiple image\nsimilarity measures, two brain templates, and both healthy control (HC, n=50)\nand Parkinson's Disease (PD, n=50) cohorts. Our findings highlight the\ninfluence of linear registration tools and similarity measures on numerical\nstability. Among the evaluated tools and with default similarity measures, SPM\nexhibited the highest stability. FSL and ANTs showed greater and similar ranges\nof variability, with ANTs demonstrating particular sensitivity to numerical\nperturbations that occasionally led to registration failure. Furthermore, no\nsignificant differences were observed between healthy and PD cohorts,\nsuggesting that numerical stability analyses obtained with healthy subjects may\ngeneralise to clinical populations. Finally, we also demonstrated how numerical\nuncertainty measures may support automated quality control (QC) of linear\nregistration results. Overall, our experimental results characterize the\nnumerical stability of linear registration experimentally and can serve as a\nbasis for future uncertainty analyses."}
{"id": "2508.00164", "pdf": "https://arxiv.org/pdf/2508.00164", "abs": "https://arxiv.org/abs/2508.00164", "authors": ["Sourya Sengupta", "Jianquan Xu", "Phuong Nguyen", "Frank J. Brooks", "Yang Liu", "Mark A. Anastasio"], "title": "On the Utility of Virtual Staining for Downstream Applications as it relates to Task Network Capacity", "categories": ["eess.IV", "q-bio.QM"], "comment": null, "summary": "Virtual staining, or in-silico-labeling, has been proposed to computationally\ngenerate synthetic fluorescence images from label-free images by use of deep\nlearning-based image-to-image translation networks. In most reported studies,\nvirtually stained images have been assessed only using traditional image\nquality measures such as structural similarity or signal-to-noise ratio.\nHowever, in biomedical imaging, images are typically acquired to facilitate an\nimage-based inference, which we refer to as a downstream biological or clinical\ntask. This study systematically investigates the utility of virtual staining\nfor facilitating clinically relevant downstream tasks (like segmentation or\nclassification) with consideration of the capacity of the deep neural networks\nemployed to perform the tasks. Comprehensive empirical evaluations were\nconducted using biological datasets, assessing task performance by use of\nlabel-free, virtually stained, and ground truth fluorescence images. The\nresults demonstrated that the utility of virtual staining is largely dependent\non the ability of the segmentation or classification task network to extract\nmeaningful task-relevant information, which is related to the concept of\nnetwork capacity. Examples are provided in which virtual staining does not\nimprove, or even degrades, segmentation or classification performance when the\ncapacity of the associated task network is sufficiently large. The results\ndemonstrate that task network capacity should be considered when deciding\nwhether to perform virtual staining."}
