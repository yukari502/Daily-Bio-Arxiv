<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 4]
- [q-bio.QM](#q-bio.QM) [Total: 5]
- [q-bio.MN](#q-bio.MN) [Total: 2]
- [q-bio.TO](#q-bio.TO) [Total: 1]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [CodonMoE: DNA Language Models for mRNA Analyses](https://arxiv.org/abs/2508.04739)
*Shiyi Du,Litian Liang,Jiayi Li,Carl Kingsford*

Main category: q-bio.GN

TL;DR: CodonMoE是一种轻量级适配器，可将DNA语言模型转化为高效的RNA分析工具，无需RNA预训练，显著减少计算负担。


<details>
  <summary>Details</summary>
Motivation: 解决基因组语言模型在多模态任务中的效率问题，避免冗余计算和庞大参数需求。

Method: 引入CodonMoE适配器，通过混合专家技术将DNA模型转化为RNA分析工具。

Result: 在四项RNA预测任务中表现优异，参数减少80%，性能优于专用RNA模型。

Conclusion: CodonMoE为统一基因组语言建模提供了高效路径，减少计算开销并保持性能优势。

Abstract: Genomic language models (gLMs) face a fundamental efficiency challenge:
either maintain separate specialized models for each biological modality (DNA
and RNA) or develop large multi-modal architectures. Both approaches impose
significant computational burdens - modality-specific models require redundant
infrastructure despite inherent biological connections, while multi-modal
architectures demand massive parameter counts and extensive cross-modality
pretraining. To address this limitation, we introduce CodonMoE (Adaptive
Mixture of Codon Reformative Experts), a lightweight adapter that transforms
DNA language models into effective RNA analyzers without RNA-specific
pretraining. Our theoretical analysis establishes CodonMoE as a universal
approximator at the codon level, capable of mapping arbitrary functions from
codon sequences to RNA properties given sufficient expert capacity. Across four
RNA prediction tasks spanning stability, expression, and regulation, DNA models
augmented with CodonMoE significantly outperform their unmodified counterparts,
with HyenaDNA+CodonMoE series achieving state-of-the-art results using 80%
fewer parameters than specialized RNA models. By maintaining sub-quadratic
complexity while achieving superior performance, our approach provides a
principled path toward unifying genomic language modeling, leveraging more
abundant DNA data and reducing computational overhead while preserving
modality-specific performance advantages.

</details>


### [2] [Discovery of Disease Relationships via Transcriptomic Signature Analysis Powered by Agentic AI](https://arxiv.org/abs/2508.04742)
*Ke Chen,Haohan Wang*

Main category: q-bio.GN

TL;DR: 该研究提出了一种基于转录组学的框架，通过分析1300多种疾病-条件对，揭示疾病间的分子共性，并构建了基于通路的相似性网络，发现了新的跨类别联系和治疗再利用机会。


<details>
  <summary>Details</summary>
Motivation: 现代疾病分类常忽视临床表现差异下的分子共性，研究旨在通过转录组学方法揭示疾病间的潜在联系。

Method: 使用GenoMAS自动化AI系统分析疾病-条件对，开发基于通路的相似性框架，整合多数据库富集分析。

Result: 构建的疾病相似网络揭示了已知共病和新的跨类别联系，并识别了罕见疾病的治疗再利用机会。

Conclusion: 研究展示了基于生物学的AI如何扩展转录组分析，并为复杂疾病提供机制解释，结果公开于GitHub。

Abstract: Modern disease classification often overlooks molecular commonalities hidden
beneath divergent clinical presentations. This study introduces a
transcriptomics-driven framework for discovering disease relationships by
analyzing over 1300 disease-condition pairs using GenoMAS, a fully automated
agentic AI system. Beyond identifying robust gene-level overlaps, we develop a
novel pathway-based similarity framework that integrates multi-database
enrichment analysis to quantify functional convergence across diseases. The
resulting disease similarity network reveals both known comorbidities and
previously undocumented cross-category links. By examining shared biological
pathways, we explore potential molecular mechanisms underlying these
connections-offering functional hypotheses that go beyond symptom-based
taxonomies. We further show how background conditions such as obesity and
hypertension modulate transcriptomic similarity, and identify therapeutic
repurposing opportunities for rare diseases like autism spectrum disorder based
on their molecular proximity to better-characterized conditions. In addition,
this work demonstrates how biologically grounded agentic AI can scale
transcriptomic analysis while enabling mechanistic interpretation across
complex disease landscapes. All results are publicly accessible at
github.com/KeeeeChen/Pathway_Similarity_Network.

</details>


### [3] [GRIT: Graph-Regularized Logit Refinement for Zero-shot Cell Type Annotation](https://arxiv.org/abs/2508.04747)
*Tianxiang Hu,Chenyi Zhou,Jiaxiang Liu,Jiongxin Wang,Ruizhe Chen,Haoxiang Xia,Gaoang Wang,Jian Wu,Zuozhu Liu*

Main category: q-bio.GN

TL;DR: 论文提出了一种通过图正则化优化框架改进LangCell零样本预测的方法，结合预训练模型的可扩展性和专家注释的结构鲁棒性，显著提升了细胞类型注释的准确性。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序数据分析中，细胞类型注释是一个关键步骤，但现有方法（如LangCell）的零样本预测准确性不足，尤其是在所有细胞类型上的一致性较差。

Method: 提出了一种图正则化优化框架，通过任务特定的PCA-based k-NN图强制执行局部一致性，优化LangCell的零样本预测。

Result: 在14个标注的人类scRNA-seq数据集上评估，方法显著提升了零样本注释准确性，最高提升10%，并能有效纠正错误标签。

Conclusion: 该方法无需训练，模型无关，是一种简单有效的自动化细胞类型注释增强工具。

Abstract: Cell type annotation is a fundamental step in the analysis of single-cell RNA
sequencing (scRNA-seq) data. In practice, human experts often rely on the
structure revealed by principal component analysis (PCA) followed by
$k$-nearest neighbor ($k$-NN) graph construction to guide annotation. While
effective, this process is labor-intensive and does not scale to large
datasets. Recent advances in CLIP-style models offer a promising path toward
automating cell type annotation. By aligning scRNA-seq profiles with natural
language descriptions, models like LangCell enable zero-shot annotation. While
LangCell demonstrates decent zero-shot performance, its predictions remain
suboptimal, particularly in achieving consistent accuracy across all cell
types. In this paper, we propose to refine the zero-shot logits produced by
LangCell through a graph-regularized optimization framework. By enforcing local
consistency over the task-specific PCA-based k-NN graph, our method combines
the scalability of the pre-trained models with the structural robustness relied
upon in expert annotation. We evaluate our approach on 14 annotated human
scRNA-seq datasets from 4 distinct studies, spanning 11 organs and over 200,000
single cells. Our method consistently improves zero-shot annotation accuracy,
achieving accuracy gains of up to 10%. Further analysis showcase the mechanism
by which GRIT effectively propagates correct signals through the graph, pulling
back mislabeled cells toward more accurate predictions. The method is
training-free, model-agnostic, and serves as a simple yet effective plug-in for
enhancing automated cell type annotation in practice.

</details>


### [4] [Embedding Is (Almost) All You Need: Retrieval-Augmented Inference for Generalizable Genomic Prediction Tasks](https://arxiv.org/abs/2508.04757)
*Nirjhor Datta,Swakkhar Shatabda,M Sohel Rahman*

Main category: q-bio.GN

TL;DR: 研究表明，嵌入提取方法在基因组任务中能替代微调，提供更高的效率和泛化能力，同时显著降低碳排放。


<details>
  <summary>Details</summary>
Motivation: 探讨在基因组任务中是否必须进行任务特定的微调，寻找更高效、泛化性更强的替代方法。

Method: 使用嵌入提取方法，从预训练模型中提取固定表示，并输入轻量级分类器。

Result: 嵌入方法在不同数据分布下表现优于微调，推理时间减少10-20倍，碳排放显著降低。

Conclusion: 嵌入提取是一种更高效、环保且泛化性强的替代方案，适用于多样化或未见过的基因组任务。

Abstract: Large pre-trained DNA language models such as DNABERT-2, Nucleotide
Transformer, and HyenaDNA have demonstrated strong performance on various
genomic benchmarks. However, most applications rely on expensive fine-tuning,
which works best when the training and test data share a similar distribution.
In this work, we investigate whether task-specific fine-tuning is always
necessary. We show that simple embedding-based pipelines that extract fixed
representations from these models and feed them into lightweight classifiers
can achieve competitive performance. In evaluation settings with different data
distributions, embedding-based methods often outperform fine-tuning while
reducing inference time by 10x to 20x. Our results suggest that embedding
extraction is not only a strong baseline but also a more generalizable and
efficient alternative to fine-tuning, especially for deployment in diverse or
unseen genomic contexts. For example, in enhancer classification, HyenaDNA
embeddings combined with zCurve achieve 0.68 accuracy (vs. 0.58 for
fine-tuning), with an 88% reduction in inference time and over 8x lower carbon
emissions (0.02 kg vs. 0.17 kg CO2). In non-TATA promoter classification,
DNABERT-2 embeddings with zCurve or GC content reach 0.85 accuracy (vs. 0.89
with fine-tuning) with a 22x lower carbon footprint (0.02 kg vs. 0.44 kg CO2).
These results show that embedding-based pipelines offer over 10x better carbon
efficiency while maintaining strong predictive performance. The code is
available here:
https://github.com/NIRJHOR-DATTA/EMBEDDING-IS-ALMOST-ALL-YOU-NEED.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [5] [Understanding protein function with a multimodal retrieval-augmented foundation model](https://arxiv.org/abs/2508.04724)
*Timothy Fei Truong Jr,Tristan Bepler*

Main category: q-bio.QM

TL;DR: PoET-2是一个多模态、检索增强的蛋白质基础模型，通过结合家族特异性进化约束和可选结构条件，提升了蛋白质序列的生成和理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有蛋白质语言模型在结构预测方面表现良好，但在突变理解和功能预测方面仍有不足，因此需要改进模型设计。

Method: PoET-2采用分层Transformer编码器和双解码器架构，支持因果和掩码语言建模目标，结合检索增强和多模态学习。

Result: PoET-2在零样本变体效应预测和监督学习任务中表现优异，尤其在多突变和插入缺失突变评分上领先。

Conclusion: 结合检索增强和家族中心的多模态建模，PoET-2为蛋白质基础模型提供了新的发展方向。

Abstract: Protein language models (PLMs) learn probability distributions over natural
protein sequences. By learning from hundreds of millions of natural protein
sequences, protein understanding and design capabilities emerge. Recent works
have shown that scaling these models improves structure prediction, but does
not seem to improve mutation understanding and representation quality for
protein function prediction. We introduce PoET-2, a multimodal,
retrieval-augmented protein foundation model that incorporates in-context
learning of family-specific evolutionary constraints with optional structure
conditioning to learn generative distributions over protein sequences. PoET-2
uses a hierarchical transformer encoder that is equivariant to sequence context
ordering and a dual decoder architecture with both causal and masked language
modeling objectives, allowing PoET-2 to operate in both fully generative and
bidirectional representation learning modes. PoET-2 achieves state-of-the-art
performance on zero-shot variant effect prediction, excelling at scoring
variants with multiple mutations and challenging indel mutations. In supervised
settings, PoET-2 embeddings outperform previous methods for learning
sequence-function relationships, especially with small datasets. This work
highlights the benefits of combining retrieval augmentation with multimodal,
family-centric modeling for advancing protein foundation models.

</details>


### [6] [Cross-Domain Image Synthesis: Generating H&E from Multiplex Biomarker Imaging](https://arxiv.org/abs/2508.04734)
*Jillur Rahman Saurav,Mohammad Sadegh Nasr,Jacob M. Luber*

Main category: q-bio.QM

TL;DR: 该研究利用多级VQGAN从mIF图像生成高保真虚拟H&E染色，优于传统cGAN，为分子与形态学分析提供了桥梁。


<details>
  <summary>Details</summary>
Motivation: 整合mIF的分子数据与H&E的形态学信息，以提供互补的组织信息，并利用H&E的CAD工具分析分子数据。

Method: 采用多级VQGAN生成虚拟H&E染色，并在两个公开的结直肠癌数据集上与cGAN基线进行比较。

Result: VQGAN生成的图像在视觉上更优，且在下游任务（如核分割和组织分类）中表现更接近真实数据。

Conclusion: 多级VQGAN是生成科学有用虚拟染色的强大架构，有助于将mIF数据整合到H&E分析流程中。

Abstract: While multiplex immunofluorescence (mIF) imaging provides deep,
spatially-resolved molecular data, integrating this information with the
morphological standard of Hematoxylin & Eosin (H&E) can be very important for
obtaining complementary information about the underlying tissue. Generating a
virtual H&E stain from mIF data offers a powerful solution, providing immediate
morphological context. Crucially, this approach enables the application of the
vast ecosystem of H&E-based computer-aided diagnosis (CAD) tools to analyze
rich molecular data, bridging the gap between molecular and morphological
analysis. In this work, we investigate the use of a multi-level
Vector-Quantized Generative Adversarial Network (VQGAN) to create high-fidelity
virtual H&E stains from mIF images. We rigorously evaluated our VQGAN against a
standard conditional GAN (cGAN) baseline on two publicly available colorectal
cancer datasets, assessing performance on both image similarity and functional
utility for downstream analysis. Our results show that while both architectures
produce visually plausible images, the virtual stains generated by our VQGAN
provide a more effective substrate for computer-aided diagnosis. Specifically,
downstream nuclei segmentation and semantic preservation in tissue
classification tasks performed on VQGAN-generated images demonstrate superior
performance and agreement with ground-truth analysis compared to those from the
cGAN. This work establishes that a multi-level VQGAN is a robust and superior
architecture for generating scientifically useful virtual stains, offering a
viable pathway to integrate the rich molecular data of mIF into established and
powerful H&E-based analytical workflows.

</details>


### [7] [ERDES: A Benchmark Video Dataset for Retinal Detachment and Macular Status Classification in Ocular Ultrasound](https://arxiv.org/abs/2508.04735)
*Pouyan Navard,Yasemin Ozkut,Srikar Adhikari,Elaine Situ-LaCasse,Josie Acuña,Adrienne Yarnish,Alper Yilmaz*

Main category: q-bio.QM

TL;DR: 论文介绍了首个公开的眼部超声数据集ERDES，用于检测视网膜脱离（RD）及区分黄斑状态（完整或脱离），并提供了基于时空卷积神经网络的基准测试。


<details>
  <summary>Details</summary>
Motivation: 视网膜脱离（RD）是一种威胁视力的疾病，黄斑状态是关键预后因素。当前缺乏用于临床的超声检测RD的机器学习算法，且无公开数据集支持基于黄斑状态的分类。

Method: 研究团队创建了ERDES数据集，包含标记的超声视频片段，用于RD检测和黄斑状态分类，并采用多种时空卷积神经网络（CNN）架构进行基准测试。

Result: ERDES数据集为开发RD检测的机器学习模型提供了资源，并展示了基于CNN的初步性能。

Conclusion: ERDES填补了公开数据集和临床应用的空白，为自动化超声评估RD和黄斑状态提供了基础。

Abstract: Retinal detachment (RD) is a vision-threatening condition that requires
timely intervention to preserve vision. Macular involvement -- whether the
macula is still intact (macula-intact) or detached (macula-detached) -- is the
key determinant of visual outcomes and treatment urgency. Point-of-care
ultrasound (POCUS) offers a fast, non-invasive, cost-effective, and accessible
imaging modality widely used in diverse clinical settings to detect RD.
However, ultrasound image interpretation is limited by a lack of expertise
among healthcare providers, especially in resource-limited settings. Deep
learning offers the potential to automate ultrasound-based assessment of RD.
However, there are no ML ultrasound algorithms currently available for clinical
use to detect RD and no prior research has been done on assessing macular
status using ultrasound in RD cases -- an essential distinction for surgical
prioritization. Moreover, no public dataset currently supports macular-based RD
classification using ultrasound video clips. We introduce Eye Retinal
DEtachment ultraSound, ERDES, the first open-access dataset of ocular
ultrasound clips labeled for (i) presence of retinal detachment and (ii)
macula-intact versus macula-detached status. The dataset is intended to
facilitate the development and evaluation of machine learning models for
detecting retinal detachment. We also provide baseline benchmarks using
multiple spatiotemporal convolutional neural network (CNN) architectures. All
clips, labels, and training code are publicly available at
https://osupcvlab.github.io/ERDES/.

</details>


### [8] [PhysiBoSS-Models: A database for multiscale models](https://arxiv.org/abs/2508.05550)
*Vincent Noel,Marco Ruscone,Randy Heiland,Arnau Montagud,Alfonso Valencia,Emmanuel Barillot,Paul Macklin,Laurence Calzone*

Main category: q-bio.QM

TL;DR: PhysiBoSS-Models是一个开源平台，整合了细胞群体的基于代理建模和细胞内随机布尔网络，支持复杂生物行为的多尺度模拟。


<details>
  <summary>Details</summary>
Motivation: 促进模型共享和版本控制，支持生物学研究。

Method: 通过Python API提供标准化访问，方便下载和模拟现有模型。

Result: 创建了PhysiBoSS-Models数据库，支持模型重用、验证和基准测试。

Conclusion: PhysiBoSS-Models通过标准化访问和验证模型，推动了生物学研究。

Abstract: PhysiBoSS is an open-source platform that integrates agent-based modeling of
cell populations with intracellular stochastic Boolean networks, enabling
multiscale simulations of complex biological behaviors. To promote model
sharing and versioning, we present the PhysiBoSS-Models database: a curated
repository for multiscale models built with PhysiBoSS. By providing a simple
Python API, PhysiBoSS-Models provides an easy way to download and simulate
preexisting models through tools such as PhysiCell Studio. By providing
standardized access to validated models, PhysiBoSS-Models facilitates reuse,
validation, and benchmarking, supporting research in biology.

</details>


### [9] [Data Analysis and Modeling for Transitioning Between Laboratory Methods for Detecting SARS-CoV-2 in Wastewater](https://arxiv.org/abs/2508.05594)
*Maria M. Warns,Leah Mrowiec,Christopher Owen,Adam Horton,Chi-Yu Lin,Modou Lamin Jarju,Niall M. Mangan,Aaron Packman,Katelyn Plaisier Leisman,Abhilasha Shrestha,Rachel Poretsky*

Main category: q-bio.QM

TL;DR: 研究展示了如何通过重叠期和回归模型维持实验室方法转换期间的数据连续性，以比较不同方法对废水中SARS-CoV-2 RNA的定量结果。


<details>
  <summary>Details</summary>
Motivation: 废水监测是监测病原体的有效工具，但实验室方法动态变化时，如何保持数据连续性以准确评估疾病负担尚未有研究解决。

Method: 在两个月过渡期内，并行使用低通量手动过滤和高通量自动化磁珠法处理废水样本，并通过回归模型关联两种方法的数据。

Result: 研究发现对数-对数回归模型最适合关联两种方法的数据，且在去除异常值后模型性能提升。

Conclusion: 通过方法重叠期和适当模型，可以在实验室方法转换期间保持数据连续性。

Abstract: Wastewater surveillance has proven to be a useful tool to monitor pathogens
such as SARS-CoV-2 as it is a nonintrusive way to survey the potential disease
burden of the population contributing to a sewershed. With the expansion of
this field since the beginning of the COVID-19 pandemic, laboratory methods to
process wastewater and quantify pathogen nucleic acid levels have improved as
technologies changed, efforts expanded in size and scope, and supply chain
issues were resolved. Maintaining data continuity is crucial for labs
undergoing method transitions to accurately assess infectious disease levels
over time and compare measured RNA concentrations to public health data.
Despite the dynamic nature of laboratory methods and the necessity to ensure
uninterrupted data, to our knowledge there has not been a study that unites two
datasets from different lab methods for pathogen quantification from
environmental samples. Here, we describe a lab transition from SARS-CoV-2 RNA
quantification using a low-throughput, manual filtration-based wastewater
concentration and RNA extraction followed by qPCR to a high-throughput,
automated magnetic bead-based concentration and extraction followed by dPCR.
During the two-month transition period, wastewater samples from across the
Chicago metropolitan area were processed with both methods in parallel. We
evaluated a variety of regression models to relate the RNA measurements from
both methods and found a log-log model was most appropriate after removing
outliers and discrepancy points to improve model performance. We also evaluated
the consequences of assigning values to samples that were below the detection
limit. Our study demonstrates that data continuity can be maintained throughout
a transition of laboratory methods if there is a sufficient period of overlap
between the methods for an appropriate model to be constructed to relate the
datasets.

</details>


<div id='q-bio.MN'></div>

# q-bio.MN [[Back]](#toc)

### [10] [Alz-QNet: A Quantum Regression Network for Studying Alzheimer's Gene Interactions](https://arxiv.org/abs/2508.04743)
*Debanjan Konar,Neerav Sreekumar,Richard Jiang,Vaneet Aggarwal*

Main category: q-bio.MN

TL;DR: 论文提出了一种量子回归网络（Alz-QNet）来研究阿尔茨海默病（AD）中关键基因的相互作用，揭示了潜在的调控机制，为基因表达治疗提供新思路。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）是一种多因素疾病，理解其基因间相互作用对治疗和诊断至关重要。目前分子层面的机制仍不清楚。

Method: 使用量子回归网络（Alz-QNet）结合量子基因调控网络（QGRN）技术，分析AD患者关键基因（如APP、FGF14等）的相互作用。

Result: 研究发现复杂的基因间相互作用，揭示了AD发病的潜在调控机制，为寻找基因抑制剂或调节剂提供了依据。

Conclusion: Alz-QNet为AD的基因表达治疗提供了新方法，揭示了关键基因的调控网络，有助于未来的诊断和治疗研究。

Abstract: Understanding the molecular-level mechanisms underpinning Alzheimer's disease
(AD) by studying crucial genes associated with the disease remains a challenge.
Alzheimer's, being a multifactorial disease, requires understanding the
gene-gene interactions underlying it for theranostics and progress. In this
article, a novel attempt has been made using a quantum regression to decode how
some crucial genes in the AD Amyloid Beta Precursor Protein ($APP$), Sterol
regulatory element binding transcription factor 14 ($FGF14$), Yin Yang 1
($YY1$), and Phospholipase D Family Member 3 ($PLD3$) etc. become influenced by
other prominent switching genes during disease progression, which may help in
gene expression-based therapy for AD. Our proposed Quantum Regression Network
(Alz-QNet) introduces a pioneering approach with insights from the
state-of-the-art Quantum Gene Regulatory Networks (QGRN) to unravel the gene
interactions involved in AD pathology, particularly within the Entorhinal
Cortex (EC), where early pathological changes occur. Using the proposed
Alz-QNet framework, we explore the interactions between key genes ($APP$,
$FGF14$, $YY1$, $EGR1$, $GAS7$, $AKT3$, $SREBF2$, and $PLD3$) within the CE
microenvironment of AD patients, studying genetic samples from the database
$GSE138852$, all of which are believed to play a crucial role in the
progression of AD. Our investigation uncovers intricate gene-gene interactions,
shedding light on the potential regulatory mechanisms that underlie the
pathogenesis of AD, which help us to find potential gene inhibitors or
regulators for theranostics.

</details>


### [11] [GCnet: Using Granger causality to explore the dynamic causality relations among genes as-sociated with intellectual disability in human brain](https://arxiv.org/abs/2508.05136)
*Lukas Madsen Brandt,Katja Nowick,Jing Qin*

Main category: q-bio.MN

TL;DR: 该论文通过Granger因果检验分析基因表达数据，构建基因表达网络，以揭示与智力障碍相关的基因及其动态关系。


<details>
  <summary>Details</summary>
Motivation: 智力障碍（ID）部分由遗传因素引起，研究这些基因及其在脑发育过程中的表达模式有助于理解ID的分子机制。

Method: 将体外脑发育过程中的基因表达数据视为时间序列，应用Granger因果检验评估基因间的动态依赖关系，构建基因表达网络。

Result: 通过分析Granger因果网络，识别出与Mowat Wilson综合征相关的新基因，并提供了优先级列表。

Conclusion: 该方法有助于揭示ID的病理信息，并为相关疾病的基因研究提供了新工具。

Abstract: Intellectual disability (ID) is defined by an IQ under 70, in addition to
deficits in two or more adaptive behaviors that affect everyday living.
Throughout history, individuals with ID have often been margin-alized from
society and continue to suffer significantly even in modern times. A varying
proportion of ID cases are attributable to genetic causes. Identifying the
causal relation among these ID-associated genes and their gene expression
pattern during brain development process would gain us a better understanding
of the molecular basis of ID. In this paper, we interpret gene expression data
collected at different time points during the in vitro brain development
process as time series and further introduce Granger causality test to evaluate
the dynamic dependence relations among genes. These evaluations are used as
input to construct gene expression network and extract the pathological
information associated to ID including identi-fying new genes that can be
critically related to the disease. To demonstrate our methods, we pro-vide a
priority list of new genes that are most likely associated with Mowat Wilson
Syndrome via monitoring the community structure of ZEB2 in our Granger
causality network constructed based on the Kutsche dataset (Kutsche, et al.,
2018).

</details>


<div id='q-bio.TO'></div>

# q-bio.TO [[Back]](#toc)

### [12] [Adaptive k-space Radial Sampling for Cardiac MRI with Reinforcement Learning](https://arxiv.org/abs/2508.04727)
*Ruru Xu,Ilkay Oksuz*

Main category: q-bio.TO

TL;DR: 提出了一种基于强化学习的径向采样轨迹优化框架，用于心脏MRI，结合k空间和图像域信息，提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 探索强化学习在非笛卡尔轨迹优化中的潜力，以平衡MRI的采集速度与图像质量。

Method: 采用双分支架构处理k空间和图像域信息，引入交叉注意力融合机制和黄金比例采样策略。

Result: 实验表明，该方法能学习到优化的径向采样策略，并在多种加速因子下提升重建质量。

Conclusion: 该框架为MRI采样轨迹优化提供了新思路，尤其在心脏MRI中表现优异。

Abstract: Accelerated Magnetic Resonance Imaging (MRI) requires careful optimization of
k-space sampling patterns to balance acquisition speed and image quality. While
recent advances in deep learning have shown promise in optimizing Cartesian
sampling, the potential of reinforcement learning (RL) for non-Cartesian
trajectory optimization remains largely unexplored. In this work, we present a
novel RL framework for optimizing radial sampling trajectories in cardiac MRI.
Our approach features a dual-branch architecture that jointly processes k-space
and image-domain information, incorporating a cross-attention fusion mechanism
to facilitate effective information exchange between domains. The framework
employs an anatomically-aware reward design and a golden-ratio sampling
strategy to ensure uniform k-space coverage while preserving cardiac structural
details. Experimental results demonstrate that our method effectively learns
optimal radial sampling strategies across multiple acceleration factors,
achieving improved reconstruction quality compared to conventional approaches.
Code available: https://github.com/Ruru-Xu/RL-kspace-Radial-Sampling

</details>
