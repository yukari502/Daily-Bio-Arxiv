{"id": "2508.04739", "pdf": "https://arxiv.org/pdf/2508.04739", "abs": "https://arxiv.org/abs/2508.04739", "authors": ["Shiyi Du", "Litian Liang", "Jiayi Li", "Carl Kingsford"], "title": "CodonMoE: DNA Language Models for mRNA Analyses", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "Genomic language models (gLMs) face a fundamental efficiency challenge:\neither maintain separate specialized models for each biological modality (DNA\nand RNA) or develop large multi-modal architectures. Both approaches impose\nsignificant computational burdens - modality-specific models require redundant\ninfrastructure despite inherent biological connections, while multi-modal\narchitectures demand massive parameter counts and extensive cross-modality\npretraining. To address this limitation, we introduce CodonMoE (Adaptive\nMixture of Codon Reformative Experts), a lightweight adapter that transforms\nDNA language models into effective RNA analyzers without RNA-specific\npretraining. Our theoretical analysis establishes CodonMoE as a universal\napproximator at the codon level, capable of mapping arbitrary functions from\ncodon sequences to RNA properties given sufficient expert capacity. Across four\nRNA prediction tasks spanning stability, expression, and regulation, DNA models\naugmented with CodonMoE significantly outperform their unmodified counterparts,\nwith HyenaDNA+CodonMoE series achieving state-of-the-art results using 80%\nfewer parameters than specialized RNA models. By maintaining sub-quadratic\ncomplexity while achieving superior performance, our approach provides a\nprincipled path toward unifying genomic language modeling, leveraging more\nabundant DNA data and reducing computational overhead while preserving\nmodality-specific performance advantages.", "AI": {"tldr": "CodonMoE\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\uff0c\u53ef\u5c06DNA\u8bed\u8a00\u6a21\u578b\u8f6c\u5316\u4e3a\u9ad8\u6548\u7684RNA\u5206\u6790\u5de5\u5177\uff0c\u65e0\u9700RNA\u9884\u8bad\u7ec3\uff0c\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u8d1f\u62c5\u3002", "motivation": "\u89e3\u51b3\u57fa\u56e0\u7ec4\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u95ee\u9898\uff0c\u907f\u514d\u5197\u4f59\u8ba1\u7b97\u548c\u5e9e\u5927\u53c2\u6570\u9700\u6c42\u3002", "method": "\u5f15\u5165CodonMoE\u9002\u914d\u5668\uff0c\u901a\u8fc7\u6df7\u5408\u4e13\u5bb6\u6280\u672f\u5c06DNA\u6a21\u578b\u8f6c\u5316\u4e3aRNA\u5206\u6790\u5de5\u5177\u3002", "result": "\u5728\u56db\u9879RNA\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u53c2\u6570\u51cf\u5c1180%\uff0c\u6027\u80fd\u4f18\u4e8e\u4e13\u7528RNA\u6a21\u578b\u3002", "conclusion": "CodonMoE\u4e3a\u7edf\u4e00\u57fa\u56e0\u7ec4\u8bed\u8a00\u5efa\u6a21\u63d0\u4f9b\u4e86\u9ad8\u6548\u8def\u5f84\uff0c\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u5e76\u4fdd\u6301\u6027\u80fd\u4f18\u52bf\u3002"}}
{"id": "2508.04742", "pdf": "https://arxiv.org/pdf/2508.04742", "abs": "https://arxiv.org/abs/2508.04742", "authors": ["Ke Chen", "Haohan Wang"], "title": "Discovery of Disease Relationships via Transcriptomic Signature Analysis Powered by Agentic AI", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "Modern disease classification often overlooks molecular commonalities hidden\nbeneath divergent clinical presentations. This study introduces a\ntranscriptomics-driven framework for discovering disease relationships by\nanalyzing over 1300 disease-condition pairs using GenoMAS, a fully automated\nagentic AI system. Beyond identifying robust gene-level overlaps, we develop a\nnovel pathway-based similarity framework that integrates multi-database\nenrichment analysis to quantify functional convergence across diseases. The\nresulting disease similarity network reveals both known comorbidities and\npreviously undocumented cross-category links. By examining shared biological\npathways, we explore potential molecular mechanisms underlying these\nconnections-offering functional hypotheses that go beyond symptom-based\ntaxonomies. We further show how background conditions such as obesity and\nhypertension modulate transcriptomic similarity, and identify therapeutic\nrepurposing opportunities for rare diseases like autism spectrum disorder based\non their molecular proximity to better-characterized conditions. In addition,\nthis work demonstrates how biologically grounded agentic AI can scale\ntranscriptomic analysis while enabling mechanistic interpretation across\ncomplex disease landscapes. All results are publicly accessible at\ngithub.com/KeeeeChen/Pathway_Similarity_Network.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8f6c\u5f55\u7ec4\u5b66\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u67901300\u591a\u79cd\u75be\u75c5-\u6761\u4ef6\u5bf9\uff0c\u63ed\u793a\u75be\u75c5\u95f4\u7684\u5206\u5b50\u5171\u6027\uff0c\u5e76\u6784\u5efa\u4e86\u57fa\u4e8e\u901a\u8def\u7684\u76f8\u4f3c\u6027\u7f51\u7edc\uff0c\u53d1\u73b0\u4e86\u65b0\u7684\u8de8\u7c7b\u522b\u8054\u7cfb\u548c\u6cbb\u7597\u518d\u5229\u7528\u673a\u4f1a\u3002", "motivation": "\u73b0\u4ee3\u75be\u75c5\u5206\u7c7b\u5e38\u5ffd\u89c6\u4e34\u5e8a\u8868\u73b0\u5dee\u5f02\u4e0b\u7684\u5206\u5b50\u5171\u6027\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u8f6c\u5f55\u7ec4\u5b66\u65b9\u6cd5\u63ed\u793a\u75be\u75c5\u95f4\u7684\u6f5c\u5728\u8054\u7cfb\u3002", "method": "\u4f7f\u7528GenoMAS\u81ea\u52a8\u5316AI\u7cfb\u7edf\u5206\u6790\u75be\u75c5-\u6761\u4ef6\u5bf9\uff0c\u5f00\u53d1\u57fa\u4e8e\u901a\u8def\u7684\u76f8\u4f3c\u6027\u6846\u67b6\uff0c\u6574\u5408\u591a\u6570\u636e\u5e93\u5bcc\u96c6\u5206\u6790\u3002", "result": "\u6784\u5efa\u7684\u75be\u75c5\u76f8\u4f3c\u7f51\u7edc\u63ed\u793a\u4e86\u5df2\u77e5\u5171\u75c5\u548c\u65b0\u7684\u8de8\u7c7b\u522b\u8054\u7cfb\uff0c\u5e76\u8bc6\u522b\u4e86\u7f55\u89c1\u75be\u75c5\u7684\u6cbb\u7597\u518d\u5229\u7528\u673a\u4f1a\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86\u57fa\u4e8e\u751f\u7269\u5b66\u7684AI\u5982\u4f55\u6269\u5c55\u8f6c\u5f55\u7ec4\u5206\u6790\uff0c\u5e76\u4e3a\u590d\u6742\u75be\u75c5\u63d0\u4f9b\u673a\u5236\u89e3\u91ca\uff0c\u7ed3\u679c\u516c\u5f00\u4e8eGitHub\u3002"}}
{"id": "2508.04747", "pdf": "https://arxiv.org/pdf/2508.04747", "abs": "https://arxiv.org/abs/2508.04747", "authors": ["Tianxiang Hu", "Chenyi Zhou", "Jiaxiang Liu", "Jiongxin Wang", "Ruizhe Chen", "Haoxiang Xia", "Gaoang Wang", "Jian Wu", "Zuozhu Liu"], "title": "GRIT: Graph-Regularized Logit Refinement for Zero-shot Cell Type Annotation", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "Cell type annotation is a fundamental step in the analysis of single-cell RNA\nsequencing (scRNA-seq) data. In practice, human experts often rely on the\nstructure revealed by principal component analysis (PCA) followed by\n$k$-nearest neighbor ($k$-NN) graph construction to guide annotation. While\neffective, this process is labor-intensive and does not scale to large\ndatasets. Recent advances in CLIP-style models offer a promising path toward\nautomating cell type annotation. By aligning scRNA-seq profiles with natural\nlanguage descriptions, models like LangCell enable zero-shot annotation. While\nLangCell demonstrates decent zero-shot performance, its predictions remain\nsuboptimal, particularly in achieving consistent accuracy across all cell\ntypes. In this paper, we propose to refine the zero-shot logits produced by\nLangCell through a graph-regularized optimization framework. By enforcing local\nconsistency over the task-specific PCA-based k-NN graph, our method combines\nthe scalability of the pre-trained models with the structural robustness relied\nupon in expert annotation. We evaluate our approach on 14 annotated human\nscRNA-seq datasets from 4 distinct studies, spanning 11 organs and over 200,000\nsingle cells. Our method consistently improves zero-shot annotation accuracy,\nachieving accuracy gains of up to 10%. Further analysis showcase the mechanism\nby which GRIT effectively propagates correct signals through the graph, pulling\nback mislabeled cells toward more accurate predictions. The method is\ntraining-free, model-agnostic, and serves as a simple yet effective plug-in for\nenhancing automated cell type annotation in practice.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u56fe\u6b63\u5219\u5316\u4f18\u5316\u6846\u67b6\u6539\u8fdbLangCell\u96f6\u6837\u672c\u9884\u6d4b\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u548c\u4e13\u5bb6\u6ce8\u91ca\u7684\u7ed3\u6784\u9c81\u68d2\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ec6\u80de\u7c7b\u578b\u6ce8\u91ca\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u6570\u636e\u5206\u6790\u4e2d\uff0c\u7ec6\u80de\u7c7b\u578b\u6ce8\u91ca\u662f\u4e00\u4e2a\u5173\u952e\u6b65\u9aa4\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\uff08\u5982LangCell\uff09\u7684\u96f6\u6837\u672c\u9884\u6d4b\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u6240\u6709\u7ec6\u80de\u7c7b\u578b\u4e0a\u7684\u4e00\u81f4\u6027\u8f83\u5dee\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u56fe\u6b63\u5219\u5316\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u4efb\u52a1\u7279\u5b9a\u7684PCA-based k-NN\u56fe\u5f3a\u5236\u6267\u884c\u5c40\u90e8\u4e00\u81f4\u6027\uff0c\u4f18\u5316LangCell\u7684\u96f6\u6837\u672c\u9884\u6d4b\u3002", "result": "\u572814\u4e2a\u6807\u6ce8\u7684\u4eba\u7c7bscRNA-seq\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u96f6\u6837\u672c\u6ce8\u91ca\u51c6\u786e\u6027\uff0c\u6700\u9ad8\u63d0\u534710%\uff0c\u5e76\u80fd\u6709\u6548\u7ea0\u6b63\u9519\u8bef\u6807\u7b7e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u8bad\u7ec3\uff0c\u6a21\u578b\u65e0\u5173\uff0c\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u81ea\u52a8\u5316\u7ec6\u80de\u7c7b\u578b\u6ce8\u91ca\u589e\u5f3a\u5de5\u5177\u3002"}}
{"id": "2508.04757", "pdf": "https://arxiv.org/pdf/2508.04757", "abs": "https://arxiv.org/abs/2508.04757", "authors": ["Nirjhor Datta", "Swakkhar Shatabda", "M Sohel Rahman"], "title": "Embedding Is (Almost) All You Need: Retrieval-Augmented Inference for Generalizable Genomic Prediction Tasks", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "Large pre-trained DNA language models such as DNABERT-2, Nucleotide\nTransformer, and HyenaDNA have demonstrated strong performance on various\ngenomic benchmarks. However, most applications rely on expensive fine-tuning,\nwhich works best when the training and test data share a similar distribution.\nIn this work, we investigate whether task-specific fine-tuning is always\nnecessary. We show that simple embedding-based pipelines that extract fixed\nrepresentations from these models and feed them into lightweight classifiers\ncan achieve competitive performance. In evaluation settings with different data\ndistributions, embedding-based methods often outperform fine-tuning while\nreducing inference time by 10x to 20x. Our results suggest that embedding\nextraction is not only a strong baseline but also a more generalizable and\nefficient alternative to fine-tuning, especially for deployment in diverse or\nunseen genomic contexts. For example, in enhancer classification, HyenaDNA\nembeddings combined with zCurve achieve 0.68 accuracy (vs. 0.58 for\nfine-tuning), with an 88% reduction in inference time and over 8x lower carbon\nemissions (0.02 kg vs. 0.17 kg CO2). In non-TATA promoter classification,\nDNABERT-2 embeddings with zCurve or GC content reach 0.85 accuracy (vs. 0.89\nwith fine-tuning) with a 22x lower carbon footprint (0.02 kg vs. 0.44 kg CO2).\nThese results show that embedding-based pipelines offer over 10x better carbon\nefficiency while maintaining strong predictive performance. The code is\navailable here:\nhttps://github.com/NIRJHOR-DATTA/EMBEDDING-IS-ALMOST-ALL-YOU-NEED.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5d4c\u5165\u63d0\u53d6\u65b9\u6cd5\u5728\u57fa\u56e0\u7ec4\u4efb\u52a1\u4e2d\u80fd\u66ff\u4ee3\u5fae\u8c03\uff0c\u63d0\u4f9b\u66f4\u9ad8\u7684\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u78b3\u6392\u653e\u3002", "motivation": "\u63a2\u8ba8\u5728\u57fa\u56e0\u7ec4\u4efb\u52a1\u4e2d\u662f\u5426\u5fc5\u987b\u8fdb\u884c\u4efb\u52a1\u7279\u5b9a\u7684\u5fae\u8c03\uff0c\u5bfb\u627e\u66f4\u9ad8\u6548\u3001\u6cdb\u5316\u6027\u66f4\u5f3a\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5d4c\u5165\u63d0\u53d6\u65b9\u6cd5\uff0c\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u63d0\u53d6\u56fa\u5b9a\u8868\u793a\uff0c\u5e76\u8f93\u5165\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u3002", "result": "\u5d4c\u5165\u65b9\u6cd5\u5728\u4e0d\u540c\u6570\u636e\u5206\u5e03\u4e0b\u8868\u73b0\u4f18\u4e8e\u5fae\u8c03\uff0c\u63a8\u7406\u65f6\u95f4\u51cf\u5c1110-20\u500d\uff0c\u78b3\u6392\u653e\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "\u5d4c\u5165\u63d0\u53d6\u662f\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u73af\u4fdd\u4e14\u6cdb\u5316\u6027\u5f3a\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u6216\u672a\u89c1\u8fc7\u7684\u57fa\u56e0\u7ec4\u4efb\u52a1\u3002"}}
{"id": "2508.04743", "pdf": "https://arxiv.org/pdf/2508.04743", "abs": "https://arxiv.org/abs/2508.04743", "authors": ["Debanjan Konar", "Neerav Sreekumar", "Richard Jiang", "Vaneet Aggarwal"], "title": "Alz-QNet: A Quantum Regression Network for Studying Alzheimer's Gene Interactions", "categories": ["q-bio.MN", "cs.LG", "q-bio.GN", "quant-ph"], "comment": null, "summary": "Understanding the molecular-level mechanisms underpinning Alzheimer's disease\n(AD) by studying crucial genes associated with the disease remains a challenge.\nAlzheimer's, being a multifactorial disease, requires understanding the\ngene-gene interactions underlying it for theranostics and progress. In this\narticle, a novel attempt has been made using a quantum regression to decode how\nsome crucial genes in the AD Amyloid Beta Precursor Protein ($APP$), Sterol\nregulatory element binding transcription factor 14 ($FGF14$), Yin Yang 1\n($YY1$), and Phospholipase D Family Member 3 ($PLD3$) etc. become influenced by\nother prominent switching genes during disease progression, which may help in\ngene expression-based therapy for AD. Our proposed Quantum Regression Network\n(Alz-QNet) introduces a pioneering approach with insights from the\nstate-of-the-art Quantum Gene Regulatory Networks (QGRN) to unravel the gene\ninteractions involved in AD pathology, particularly within the Entorhinal\nCortex (EC), where early pathological changes occur. Using the proposed\nAlz-QNet framework, we explore the interactions between key genes ($APP$,\n$FGF14$, $YY1$, $EGR1$, $GAS7$, $AKT3$, $SREBF2$, and $PLD3$) within the CE\nmicroenvironment of AD patients, studying genetic samples from the database\n$GSE138852$, all of which are believed to play a crucial role in the\nprogression of AD. Our investigation uncovers intricate gene-gene interactions,\nshedding light on the potential regulatory mechanisms that underlie the\npathogenesis of AD, which help us to find potential gene inhibitors or\nregulators for theranostics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5b50\u56de\u5f52\u7f51\u7edc\uff08Alz-QNet\uff09\u6765\u7814\u7a76\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u4e2d\u5173\u952e\u57fa\u56e0\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u63ed\u793a\u4e86\u6f5c\u5728\u7684\u8c03\u63a7\u673a\u5236\uff0c\u4e3a\u57fa\u56e0\u8868\u8fbe\u6cbb\u7597\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u662f\u4e00\u79cd\u591a\u56e0\u7d20\u75be\u75c5\uff0c\u7406\u89e3\u5176\u57fa\u56e0\u95f4\u76f8\u4e92\u4f5c\u7528\u5bf9\u6cbb\u7597\u548c\u8bca\u65ad\u81f3\u5173\u91cd\u8981\u3002\u76ee\u524d\u5206\u5b50\u5c42\u9762\u7684\u673a\u5236\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u4f7f\u7528\u91cf\u5b50\u56de\u5f52\u7f51\u7edc\uff08Alz-QNet\uff09\u7ed3\u5408\u91cf\u5b50\u57fa\u56e0\u8c03\u63a7\u7f51\u7edc\uff08QGRN\uff09\u6280\u672f\uff0c\u5206\u6790AD\u60a3\u8005\u5173\u952e\u57fa\u56e0\uff08\u5982APP\u3001FGF14\u7b49\uff09\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u590d\u6742\u7684\u57fa\u56e0\u95f4\u76f8\u4e92\u4f5c\u7528\uff0c\u63ed\u793a\u4e86AD\u53d1\u75c5\u7684\u6f5c\u5728\u8c03\u63a7\u673a\u5236\uff0c\u4e3a\u5bfb\u627e\u57fa\u56e0\u6291\u5236\u5242\u6216\u8c03\u8282\u5242\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002", "conclusion": "Alz-QNet\u4e3aAD\u7684\u57fa\u56e0\u8868\u8fbe\u6cbb\u7597\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u5173\u952e\u57fa\u56e0\u7684\u8c03\u63a7\u7f51\u7edc\uff0c\u6709\u52a9\u4e8e\u672a\u6765\u7684\u8bca\u65ad\u548c\u6cbb\u7597\u7814\u7a76\u3002"}}
{"id": "2508.04724", "pdf": "https://arxiv.org/pdf/2508.04724", "abs": "https://arxiv.org/abs/2508.04724", "authors": ["Timothy Fei Truong Jr", "Tristan Bepler"], "title": "Understanding protein function with a multimodal retrieval-augmented foundation model", "categories": ["q-bio.QM", "cs.LG"], "comment": null, "summary": "Protein language models (PLMs) learn probability distributions over natural\nprotein sequences. By learning from hundreds of millions of natural protein\nsequences, protein understanding and design capabilities emerge. Recent works\nhave shown that scaling these models improves structure prediction, but does\nnot seem to improve mutation understanding and representation quality for\nprotein function prediction. We introduce PoET-2, a multimodal,\nretrieval-augmented protein foundation model that incorporates in-context\nlearning of family-specific evolutionary constraints with optional structure\nconditioning to learn generative distributions over protein sequences. PoET-2\nuses a hierarchical transformer encoder that is equivariant to sequence context\nordering and a dual decoder architecture with both causal and masked language\nmodeling objectives, allowing PoET-2 to operate in both fully generative and\nbidirectional representation learning modes. PoET-2 achieves state-of-the-art\nperformance on zero-shot variant effect prediction, excelling at scoring\nvariants with multiple mutations and challenging indel mutations. In supervised\nsettings, PoET-2 embeddings outperform previous methods for learning\nsequence-function relationships, especially with small datasets. This work\nhighlights the benefits of combining retrieval augmentation with multimodal,\nfamily-centric modeling for advancing protein foundation models.", "AI": {"tldr": "PoET-2\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u3001\u68c0\u7d22\u589e\u5f3a\u7684\u86cb\u767d\u8d28\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u5bb6\u65cf\u7279\u5f02\u6027\u8fdb\u5316\u7ea6\u675f\u548c\u53ef\u9009\u7ed3\u6784\u6761\u4ef6\uff0c\u63d0\u5347\u4e86\u86cb\u767d\u8d28\u5e8f\u5217\u7684\u751f\u6210\u548c\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7a81\u53d8\u7406\u89e3\u548c\u529f\u80fd\u9884\u6d4b\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u6a21\u578b\u8bbe\u8ba1\u3002", "method": "PoET-2\u91c7\u7528\u5206\u5c42Transformer\u7f16\u7801\u5668\u548c\u53cc\u89e3\u7801\u5668\u67b6\u6784\uff0c\u652f\u6301\u56e0\u679c\u548c\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\u76ee\u6807\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u548c\u591a\u6a21\u6001\u5b66\u4e60\u3002", "result": "PoET-2\u5728\u96f6\u6837\u672c\u53d8\u4f53\u6548\u5e94\u9884\u6d4b\u548c\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728\u591a\u7a81\u53d8\u548c\u63d2\u5165\u7f3a\u5931\u7a81\u53d8\u8bc4\u5206\u4e0a\u9886\u5148\u3002", "conclusion": "\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u548c\u5bb6\u65cf\u4e2d\u5fc3\u7684\u591a\u6a21\u6001\u5efa\u6a21\uff0cPoET-2\u4e3a\u86cb\u767d\u8d28\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2508.05136", "pdf": "https://arxiv.org/pdf/2508.05136", "abs": "https://arxiv.org/abs/2508.05136", "authors": ["Lukas Madsen Brandt", "Katja Nowick", "Jing Qin"], "title": "GCnet: Using Granger causality to explore the dynamic causality relations among genes as-sociated with intellectual disability in human brain", "categories": ["q-bio.MN"], "comment": null, "summary": "Intellectual disability (ID) is defined by an IQ under 70, in addition to\ndeficits in two or more adaptive behaviors that affect everyday living.\nThroughout history, individuals with ID have often been margin-alized from\nsociety and continue to suffer significantly even in modern times. A varying\nproportion of ID cases are attributable to genetic causes. Identifying the\ncausal relation among these ID-associated genes and their gene expression\npattern during brain development process would gain us a better understanding\nof the molecular basis of ID. In this paper, we interpret gene expression data\ncollected at different time points during the in vitro brain development\nprocess as time series and further introduce Granger causality test to evaluate\nthe dynamic dependence relations among genes. These evaluations are used as\ninput to construct gene expression network and extract the pathological\ninformation associated to ID including identi-fying new genes that can be\ncritically related to the disease. To demonstrate our methods, we pro-vide a\npriority list of new genes that are most likely associated with Mowat Wilson\nSyndrome via monitoring the community structure of ZEB2 in our Granger\ncausality network constructed based on the Kutsche dataset (Kutsche, et al.,\n2018).", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7Granger\u56e0\u679c\u68c0\u9a8c\u5206\u6790\u57fa\u56e0\u8868\u8fbe\u6570\u636e\uff0c\u6784\u5efa\u57fa\u56e0\u8868\u8fbe\u7f51\u7edc\uff0c\u4ee5\u63ed\u793a\u4e0e\u667a\u529b\u969c\u788d\u76f8\u5173\u7684\u57fa\u56e0\u53ca\u5176\u52a8\u6001\u5173\u7cfb\u3002", "motivation": "\u667a\u529b\u969c\u788d\uff08ID\uff09\u90e8\u5206\u7531\u9057\u4f20\u56e0\u7d20\u5f15\u8d77\uff0c\u7814\u7a76\u8fd9\u4e9b\u57fa\u56e0\u53ca\u5176\u5728\u8111\u53d1\u80b2\u8fc7\u7a0b\u4e2d\u7684\u8868\u8fbe\u6a21\u5f0f\u6709\u52a9\u4e8e\u7406\u89e3ID\u7684\u5206\u5b50\u673a\u5236\u3002", "method": "\u5c06\u4f53\u5916\u8111\u53d1\u80b2\u8fc7\u7a0b\u4e2d\u7684\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u89c6\u4e3a\u65f6\u95f4\u5e8f\u5217\uff0c\u5e94\u7528Granger\u56e0\u679c\u68c0\u9a8c\u8bc4\u4f30\u57fa\u56e0\u95f4\u7684\u52a8\u6001\u4f9d\u8d56\u5173\u7cfb\uff0c\u6784\u5efa\u57fa\u56e0\u8868\u8fbe\u7f51\u7edc\u3002", "result": "\u901a\u8fc7\u5206\u6790Granger\u56e0\u679c\u7f51\u7edc\uff0c\u8bc6\u522b\u51fa\u4e0eMowat Wilson\u7efc\u5408\u5f81\u76f8\u5173\u7684\u65b0\u57fa\u56e0\uff0c\u5e76\u63d0\u4f9b\u4e86\u4f18\u5148\u7ea7\u5217\u8868\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u63ed\u793aID\u7684\u75c5\u7406\u4fe1\u606f\uff0c\u5e76\u4e3a\u76f8\u5173\u75be\u75c5\u7684\u57fa\u56e0\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2508.04734", "pdf": "https://arxiv.org/pdf/2508.04734", "abs": "https://arxiv.org/abs/2508.04734", "authors": ["Jillur Rahman Saurav", "Mohammad Sadegh Nasr", "Jacob M. Luber"], "title": "Cross-Domain Image Synthesis: Generating H&E from Multiplex Biomarker Imaging", "categories": ["q-bio.QM", "cs.AI", "eess.IV"], "comment": null, "summary": "While multiplex immunofluorescence (mIF) imaging provides deep,\nspatially-resolved molecular data, integrating this information with the\nmorphological standard of Hematoxylin & Eosin (H&E) can be very important for\nobtaining complementary information about the underlying tissue. Generating a\nvirtual H&E stain from mIF data offers a powerful solution, providing immediate\nmorphological context. Crucially, this approach enables the application of the\nvast ecosystem of H&E-based computer-aided diagnosis (CAD) tools to analyze\nrich molecular data, bridging the gap between molecular and morphological\nanalysis. In this work, we investigate the use of a multi-level\nVector-Quantized Generative Adversarial Network (VQGAN) to create high-fidelity\nvirtual H&E stains from mIF images. We rigorously evaluated our VQGAN against a\nstandard conditional GAN (cGAN) baseline on two publicly available colorectal\ncancer datasets, assessing performance on both image similarity and functional\nutility for downstream analysis. Our results show that while both architectures\nproduce visually plausible images, the virtual stains generated by our VQGAN\nprovide a more effective substrate for computer-aided diagnosis. Specifically,\ndownstream nuclei segmentation and semantic preservation in tissue\nclassification tasks performed on VQGAN-generated images demonstrate superior\nperformance and agreement with ground-truth analysis compared to those from the\ncGAN. This work establishes that a multi-level VQGAN is a robust and superior\narchitecture for generating scientifically useful virtual stains, offering a\nviable pathway to integrate the rich molecular data of mIF into established and\npowerful H&E-based analytical workflows.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u591a\u7ea7VQGAN\u4ecemIF\u56fe\u50cf\u751f\u6210\u9ad8\u4fdd\u771f\u865a\u62dfH&E\u67d3\u8272\uff0c\u4f18\u4e8e\u4f20\u7edfcGAN\uff0c\u4e3a\u5206\u5b50\u4e0e\u5f62\u6001\u5b66\u5206\u6790\u63d0\u4f9b\u4e86\u6865\u6881\u3002", "motivation": "\u6574\u5408mIF\u7684\u5206\u5b50\u6570\u636e\u4e0eH&E\u7684\u5f62\u6001\u5b66\u4fe1\u606f\uff0c\u4ee5\u63d0\u4f9b\u4e92\u8865\u7684\u7ec4\u7ec7\u4fe1\u606f\uff0c\u5e76\u5229\u7528H&E\u7684CAD\u5de5\u5177\u5206\u6790\u5206\u5b50\u6570\u636e\u3002", "method": "\u91c7\u7528\u591a\u7ea7VQGAN\u751f\u6210\u865a\u62dfH&E\u67d3\u8272\uff0c\u5e76\u5728\u4e24\u4e2a\u516c\u5f00\u7684\u7ed3\u76f4\u80a0\u764c\u6570\u636e\u96c6\u4e0a\u4e0ecGAN\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "VQGAN\u751f\u6210\u7684\u56fe\u50cf\u5728\u89c6\u89c9\u4e0a\u66f4\u4f18\uff0c\u4e14\u5728\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u6838\u5206\u5272\u548c\u7ec4\u7ec7\u5206\u7c7b\uff09\u4e2d\u8868\u73b0\u66f4\u63a5\u8fd1\u771f\u5b9e\u6570\u636e\u3002", "conclusion": "\u591a\u7ea7VQGAN\u662f\u751f\u6210\u79d1\u5b66\u6709\u7528\u865a\u62df\u67d3\u8272\u7684\u5f3a\u5927\u67b6\u6784\uff0c\u6709\u52a9\u4e8e\u5c06mIF\u6570\u636e\u6574\u5408\u5230H&E\u5206\u6790\u6d41\u7a0b\u4e2d\u3002"}}
{"id": "2508.04735", "pdf": "https://arxiv.org/pdf/2508.04735", "abs": "https://arxiv.org/abs/2508.04735", "authors": ["Pouyan Navard", "Yasemin Ozkut", "Srikar Adhikari", "Elaine Situ-LaCasse", "Josie Acu\u00f1a", "Adrienne Yarnish", "Alper Yilmaz"], "title": "ERDES: A Benchmark Video Dataset for Retinal Detachment and Macular Status Classification in Ocular Ultrasound", "categories": ["q-bio.QM", "cs.AI"], "comment": "Under Review, https://github.com/OSUPCVLab/ERDES", "summary": "Retinal detachment (RD) is a vision-threatening condition that requires\ntimely intervention to preserve vision. Macular involvement -- whether the\nmacula is still intact (macula-intact) or detached (macula-detached) -- is the\nkey determinant of visual outcomes and treatment urgency. Point-of-care\nultrasound (POCUS) offers a fast, non-invasive, cost-effective, and accessible\nimaging modality widely used in diverse clinical settings to detect RD.\nHowever, ultrasound image interpretation is limited by a lack of expertise\namong healthcare providers, especially in resource-limited settings. Deep\nlearning offers the potential to automate ultrasound-based assessment of RD.\nHowever, there are no ML ultrasound algorithms currently available for clinical\nuse to detect RD and no prior research has been done on assessing macular\nstatus using ultrasound in RD cases -- an essential distinction for surgical\nprioritization. Moreover, no public dataset currently supports macular-based RD\nclassification using ultrasound video clips. We introduce Eye Retinal\nDEtachment ultraSound, ERDES, the first open-access dataset of ocular\nultrasound clips labeled for (i) presence of retinal detachment and (ii)\nmacula-intact versus macula-detached status. The dataset is intended to\nfacilitate the development and evaluation of machine learning models for\ndetecting retinal detachment. We also provide baseline benchmarks using\nmultiple spatiotemporal convolutional neural network (CNN) architectures. All\nclips, labels, and training code are publicly available at\nhttps://osupcvlab.github.io/ERDES/.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u9996\u4e2a\u516c\u5f00\u7684\u773c\u90e8\u8d85\u58f0\u6570\u636e\u96c6ERDES\uff0c\u7528\u4e8e\u68c0\u6d4b\u89c6\u7f51\u819c\u8131\u79bb\uff08RD\uff09\u53ca\u533a\u5206\u9ec4\u6591\u72b6\u6001\uff08\u5b8c\u6574\u6216\u8131\u79bb\uff09\uff0c\u5e76\u63d0\u4f9b\u4e86\u57fa\u4e8e\u65f6\u7a7a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u89c6\u7f51\u819c\u8131\u79bb\uff08RD\uff09\u662f\u4e00\u79cd\u5a01\u80c1\u89c6\u529b\u7684\u75be\u75c5\uff0c\u9ec4\u6591\u72b6\u6001\u662f\u5173\u952e\u9884\u540e\u56e0\u7d20\u3002\u5f53\u524d\u7f3a\u4e4f\u7528\u4e8e\u4e34\u5e8a\u7684\u8d85\u58f0\u68c0\u6d4bRD\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u4e14\u65e0\u516c\u5f00\u6570\u636e\u96c6\u652f\u6301\u57fa\u4e8e\u9ec4\u6591\u72b6\u6001\u7684\u5206\u7c7b\u3002", "method": "\u7814\u7a76\u56e2\u961f\u521b\u5efa\u4e86ERDES\u6570\u636e\u96c6\uff0c\u5305\u542b\u6807\u8bb0\u7684\u8d85\u58f0\u89c6\u9891\u7247\u6bb5\uff0c\u7528\u4e8eRD\u68c0\u6d4b\u548c\u9ec4\u6591\u72b6\u6001\u5206\u7c7b\uff0c\u5e76\u91c7\u7528\u591a\u79cd\u65f6\u7a7a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u67b6\u6784\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "ERDES\u6570\u636e\u96c6\u4e3a\u5f00\u53d1RD\u68c0\u6d4b\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u8d44\u6e90\uff0c\u5e76\u5c55\u793a\u4e86\u57fa\u4e8eCNN\u7684\u521d\u6b65\u6027\u80fd\u3002", "conclusion": "ERDES\u586b\u8865\u4e86\u516c\u5f00\u6570\u636e\u96c6\u548c\u4e34\u5e8a\u5e94\u7528\u7684\u7a7a\u767d\uff0c\u4e3a\u81ea\u52a8\u5316\u8d85\u58f0\u8bc4\u4f30RD\u548c\u9ec4\u6591\u72b6\u6001\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.05550", "pdf": "https://arxiv.org/pdf/2508.05550", "abs": "https://arxiv.org/abs/2508.05550", "authors": ["Vincent Noel", "Marco Ruscone", "Randy Heiland", "Arnau Montagud", "Alfonso Valencia", "Emmanuel Barillot", "Paul Macklin", "Laurence Calzone"], "title": "PhysiBoSS-Models: A database for multiscale models", "categories": ["q-bio.QM"], "comment": null, "summary": "PhysiBoSS is an open-source platform that integrates agent-based modeling of\ncell populations with intracellular stochastic Boolean networks, enabling\nmultiscale simulations of complex biological behaviors. To promote model\nsharing and versioning, we present the PhysiBoSS-Models database: a curated\nrepository for multiscale models built with PhysiBoSS. By providing a simple\nPython API, PhysiBoSS-Models provides an easy way to download and simulate\npreexisting models through tools such as PhysiCell Studio. By providing\nstandardized access to validated models, PhysiBoSS-Models facilitates reuse,\nvalidation, and benchmarking, supporting research in biology.", "AI": {"tldr": "PhysiBoSS-Models\u662f\u4e00\u4e2a\u5f00\u6e90\u5e73\u53f0\uff0c\u6574\u5408\u4e86\u7ec6\u80de\u7fa4\u4f53\u7684\u57fa\u4e8e\u4ee3\u7406\u5efa\u6a21\u548c\u7ec6\u80de\u5185\u968f\u673a\u5e03\u5c14\u7f51\u7edc\uff0c\u652f\u6301\u590d\u6742\u751f\u7269\u884c\u4e3a\u7684\u591a\u5c3a\u5ea6\u6a21\u62df\u3002", "motivation": "\u4fc3\u8fdb\u6a21\u578b\u5171\u4eab\u548c\u7248\u672c\u63a7\u5236\uff0c\u652f\u6301\u751f\u7269\u5b66\u7814\u7a76\u3002", "method": "\u901a\u8fc7Python API\u63d0\u4f9b\u6807\u51c6\u5316\u8bbf\u95ee\uff0c\u65b9\u4fbf\u4e0b\u8f7d\u548c\u6a21\u62df\u73b0\u6709\u6a21\u578b\u3002", "result": "\u521b\u5efa\u4e86PhysiBoSS-Models\u6570\u636e\u5e93\uff0c\u652f\u6301\u6a21\u578b\u91cd\u7528\u3001\u9a8c\u8bc1\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "PhysiBoSS-Models\u901a\u8fc7\u6807\u51c6\u5316\u8bbf\u95ee\u548c\u9a8c\u8bc1\u6a21\u578b\uff0c\u63a8\u52a8\u4e86\u751f\u7269\u5b66\u7814\u7a76\u3002"}}
{"id": "2508.05594", "pdf": "https://arxiv.org/pdf/2508.05594", "abs": "https://arxiv.org/abs/2508.05594", "authors": ["Maria M. Warns", "Leah Mrowiec", "Christopher Owen", "Adam Horton", "Chi-Yu Lin", "Modou Lamin Jarju", "Niall M. Mangan", "Aaron Packman", "Katelyn Plaisier Leisman", "Abhilasha Shrestha", "Rachel Poretsky"], "title": "Data Analysis and Modeling for Transitioning Between Laboratory Methods for Detecting SARS-CoV-2 in Wastewater", "categories": ["q-bio.QM"], "comment": null, "summary": "Wastewater surveillance has proven to be a useful tool to monitor pathogens\nsuch as SARS-CoV-2 as it is a nonintrusive way to survey the potential disease\nburden of the population contributing to a sewershed. With the expansion of\nthis field since the beginning of the COVID-19 pandemic, laboratory methods to\nprocess wastewater and quantify pathogen nucleic acid levels have improved as\ntechnologies changed, efforts expanded in size and scope, and supply chain\nissues were resolved. Maintaining data continuity is crucial for labs\nundergoing method transitions to accurately assess infectious disease levels\nover time and compare measured RNA concentrations to public health data.\nDespite the dynamic nature of laboratory methods and the necessity to ensure\nuninterrupted data, to our knowledge there has not been a study that unites two\ndatasets from different lab methods for pathogen quantification from\nenvironmental samples. Here, we describe a lab transition from SARS-CoV-2 RNA\nquantification using a low-throughput, manual filtration-based wastewater\nconcentration and RNA extraction followed by qPCR to a high-throughput,\nautomated magnetic bead-based concentration and extraction followed by dPCR.\nDuring the two-month transition period, wastewater samples from across the\nChicago metropolitan area were processed with both methods in parallel. We\nevaluated a variety of regression models to relate the RNA measurements from\nboth methods and found a log-log model was most appropriate after removing\noutliers and discrepancy points to improve model performance. We also evaluated\nthe consequences of assigning values to samples that were below the detection\nlimit. Our study demonstrates that data continuity can be maintained throughout\na transition of laboratory methods if there is a sufficient period of overlap\nbetween the methods for an appropriate model to be constructed to relate the\ndatasets.", "AI": {"tldr": "\u7814\u7a76\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u91cd\u53e0\u671f\u548c\u56de\u5f52\u6a21\u578b\u7ef4\u6301\u5b9e\u9a8c\u5ba4\u65b9\u6cd5\u8f6c\u6362\u671f\u95f4\u7684\u6570\u636e\u8fde\u7eed\u6027\uff0c\u4ee5\u6bd4\u8f83\u4e0d\u540c\u65b9\u6cd5\u5bf9\u5e9f\u6c34\u4e2dSARS-CoV-2 RNA\u7684\u5b9a\u91cf\u7ed3\u679c\u3002", "motivation": "\u5e9f\u6c34\u76d1\u6d4b\u662f\u76d1\u6d4b\u75c5\u539f\u4f53\u7684\u6709\u6548\u5de5\u5177\uff0c\u4f46\u5b9e\u9a8c\u5ba4\u65b9\u6cd5\u52a8\u6001\u53d8\u5316\u65f6\uff0c\u5982\u4f55\u4fdd\u6301\u6570\u636e\u8fde\u7eed\u6027\u4ee5\u51c6\u786e\u8bc4\u4f30\u75be\u75c5\u8d1f\u62c5\u5c1a\u672a\u6709\u7814\u7a76\u89e3\u51b3\u3002", "method": "\u5728\u4e24\u4e2a\u6708\u8fc7\u6e21\u671f\u5185\uff0c\u5e76\u884c\u4f7f\u7528\u4f4e\u901a\u91cf\u624b\u52a8\u8fc7\u6ee4\u548c\u9ad8\u901a\u91cf\u81ea\u52a8\u5316\u78c1\u73e0\u6cd5\u5904\u7406\u5e9f\u6c34\u6837\u672c\uff0c\u5e76\u901a\u8fc7\u56de\u5f52\u6a21\u578b\u5173\u8054\u4e24\u79cd\u65b9\u6cd5\u7684\u6570\u636e\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5bf9\u6570-\u5bf9\u6570\u56de\u5f52\u6a21\u578b\u6700\u9002\u5408\u5173\u8054\u4e24\u79cd\u65b9\u6cd5\u7684\u6570\u636e\uff0c\u4e14\u5728\u53bb\u9664\u5f02\u5e38\u503c\u540e\u6a21\u578b\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u65b9\u6cd5\u91cd\u53e0\u671f\u548c\u9002\u5f53\u6a21\u578b\uff0c\u53ef\u4ee5\u5728\u5b9e\u9a8c\u5ba4\u65b9\u6cd5\u8f6c\u6362\u671f\u95f4\u4fdd\u6301\u6570\u636e\u8fde\u7eed\u6027\u3002"}}
{"id": "2508.04727", "pdf": "https://arxiv.org/pdf/2508.04727", "abs": "https://arxiv.org/abs/2508.04727", "authors": ["Ruru Xu", "Ilkay Oksuz"], "title": "Adaptive k-space Radial Sampling for Cardiac MRI with Reinforcement Learning", "categories": ["q-bio.TO", "eess.IV", "q-bio.QM"], "comment": "MICCAI 2025 STACOM workshop", "summary": "Accelerated Magnetic Resonance Imaging (MRI) requires careful optimization of\nk-space sampling patterns to balance acquisition speed and image quality. While\nrecent advances in deep learning have shown promise in optimizing Cartesian\nsampling, the potential of reinforcement learning (RL) for non-Cartesian\ntrajectory optimization remains largely unexplored. In this work, we present a\nnovel RL framework for optimizing radial sampling trajectories in cardiac MRI.\nOur approach features a dual-branch architecture that jointly processes k-space\nand image-domain information, incorporating a cross-attention fusion mechanism\nto facilitate effective information exchange between domains. The framework\nemploys an anatomically-aware reward design and a golden-ratio sampling\nstrategy to ensure uniform k-space coverage while preserving cardiac structural\ndetails. Experimental results demonstrate that our method effectively learns\noptimal radial sampling strategies across multiple acceleration factors,\nachieving improved reconstruction quality compared to conventional approaches.\nCode available: https://github.com/Ruru-Xu/RL-kspace-Radial-Sampling", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5f84\u5411\u91c7\u6837\u8f68\u8ff9\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u5fc3\u810fMRI\uff0c\u7ed3\u5408k\u7a7a\u95f4\u548c\u56fe\u50cf\u57df\u4fe1\u606f\uff0c\u63d0\u5347\u91cd\u5efa\u8d28\u91cf\u3002", "motivation": "\u63a2\u7d22\u5f3a\u5316\u5b66\u4e60\u5728\u975e\u7b1b\u5361\u5c14\u8f68\u8ff9\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\uff0c\u4ee5\u5e73\u8861MRI\u7684\u91c7\u96c6\u901f\u5ea6\u4e0e\u56fe\u50cf\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u53cc\u5206\u652f\u67b6\u6784\u5904\u7406k\u7a7a\u95f4\u548c\u56fe\u50cf\u57df\u4fe1\u606f\uff0c\u5f15\u5165\u4ea4\u53c9\u6ce8\u610f\u529b\u878d\u5408\u673a\u5236\u548c\u9ec4\u91d1\u6bd4\u4f8b\u91c7\u6837\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u5b66\u4e60\u5230\u4f18\u5316\u7684\u5f84\u5411\u91c7\u6837\u7b56\u7565\uff0c\u5e76\u5728\u591a\u79cd\u52a0\u901f\u56e0\u5b50\u4e0b\u63d0\u5347\u91cd\u5efa\u8d28\u91cf\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aMRI\u91c7\u6837\u8f68\u8ff9\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5c24\u5176\u5728\u5fc3\u810fMRI\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
