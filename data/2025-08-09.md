<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 4]
- [q-bio.QM](#q-bio.QM) [Total: 5]
- [q-bio.MN](#q-bio.MN) [Total: 2]
- [q-bio.TO](#q-bio.TO) [Total: 1]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [CodonMoE: DNA Language Models for mRNA Analyses](https://arxiv.org/abs/2508.04739)
*Shiyi Du,Litian Liang,Jiayi Li,Carl Kingsford*

Main category: q-bio.GN

TL;DR: CodonMoE是一种轻量级适配器，可将DNA语言模型转化为高效的RNA分析工具，无需RNA特定预训练，显著减少计算负担。


<details>
  <summary>Details</summary>
Motivation: 解决基因组语言模型（gLMs）的效率问题，避免冗余基础设施或大规模多模态架构的需求。

Method: 提出CodonMoE（自适应混合密码子重构专家），通过轻量级适配器将DNA模型转化为RNA分析工具。

Result: 在四个RNA预测任务中，CodonMoE增强的DNA模型表现优于未修改版本，参数减少80%。

Conclusion: CodonMoE为统一基因组语言建模提供了高效路径，减少计算开销并保持性能优势。

Abstract: Genomic language models (gLMs) face a fundamental efficiency challenge:
either maintain separate specialized models for each biological modality (DNA
and RNA) or develop large multi-modal architectures. Both approaches impose
significant computational burdens - modality-specific models require redundant
infrastructure despite inherent biological connections, while multi-modal
architectures demand massive parameter counts and extensive cross-modality
pretraining. To address this limitation, we introduce CodonMoE (Adaptive
Mixture of Codon Reformative Experts), a lightweight adapter that transforms
DNA language models into effective RNA analyzers without RNA-specific
pretraining. Our theoretical analysis establishes CodonMoE as a universal
approximator at the codon level, capable of mapping arbitrary functions from
codon sequences to RNA properties given sufficient expert capacity. Across four
RNA prediction tasks spanning stability, expression, and regulation, DNA models
augmented with CodonMoE significantly outperform their unmodified counterparts,
with HyenaDNA+CodonMoE series achieving state-of-the-art results using 80%
fewer parameters than specialized RNA models. By maintaining sub-quadratic
complexity while achieving superior performance, our approach provides a
principled path toward unifying genomic language modeling, leveraging more
abundant DNA data and reducing computational overhead while preserving
modality-specific performance advantages.

</details>


### [2] [Discovery of Disease Relationships via Transcriptomic Signature Analysis Powered by Agentic AI](https://arxiv.org/abs/2508.04742)
*Ke Chen,Haohan Wang*

Main category: q-bio.GN

TL;DR: 本研究提出了一种基于转录组学的框架，通过分析1300多种疾病-条件对，揭示疾病间的分子共性，并开发了一种新的通路相似性框架。


<details>
  <summary>Details</summary>
Motivation: 现代疾病分类常忽略临床表现差异下的分子共性，本研究旨在通过转录组学方法揭示疾病间的潜在联系。

Method: 使用GenoMAS自动化AI系统分析疾病-条件对，开发通路相似性框架，整合多数据库富集分析。

Result: 构建的疾病相似网络揭示了已知共病和新的跨类别联系，并探索了共享通路的分子机制。

Conclusion: 研究提供了超越症状分类的功能假说，展示了生物基础AI在转录组分析中的潜力，并为罕见病治疗提供了新思路。

Abstract: Modern disease classification often overlooks molecular commonalities hidden
beneath divergent clinical presentations. This study introduces a
transcriptomics-driven framework for discovering disease relationships by
analyzing over 1300 disease-condition pairs using GenoMAS, a fully automated
agentic AI system. Beyond identifying robust gene-level overlaps, we develop a
novel pathway-based similarity framework that integrates multi-database
enrichment analysis to quantify functional convergence across diseases. The
resulting disease similarity network reveals both known comorbidities and
previously undocumented cross-category links. By examining shared biological
pathways, we explore potential molecular mechanisms underlying these
connections-offering functional hypotheses that go beyond symptom-based
taxonomies. We further show how background conditions such as obesity and
hypertension modulate transcriptomic similarity, and identify therapeutic
repurposing opportunities for rare diseases like autism spectrum disorder based
on their molecular proximity to better-characterized conditions. In addition,
this work demonstrates how biologically grounded agentic AI can scale
transcriptomic analysis while enabling mechanistic interpretation across
complex disease landscapes. All results are publicly accessible at
github.com/KeeeeChen/Pathway_Similarity_Network.

</details>


### [3] [GRIT: Graph-Regularized Logit Refinement for Zero-shot Cell Type Annotation](https://arxiv.org/abs/2508.04747)
*Tianxiang Hu,Chenyi Zhou,Jiaxiang Liu,Jiongxin Wang,Ruizhe Chen,Haoxiang Xia,Gaoang Wang,Jian Wu,Zuozhu Liu*

Main category: q-bio.GN

TL;DR: 论文提出了一种通过图正则化优化框架改进LangCell零样本预测的方法，结合预训练模型的可扩展性和专家注释的结构稳健性，显著提升了细胞类型注释的准确性。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序数据分析中，细胞类型注释是关键步骤，但现有方法如LangCell的零样本预测准确性不足，尤其是在不同细胞类型间的一致性较差。

Method: 提出了一种图正则化优化框架，通过任务特定的PCA-based k-NN图强制局部一致性，优化LangCell的零样本预测。

Result: 在14个数据集上验证，方法显著提升了零样本注释准确性，最高提升10%，且无需额外训练，模型无关。

Conclusion: 该方法是一种简单有效的插件，可增强自动化细胞类型注释的实践应用。

Abstract: Cell type annotation is a fundamental step in the analysis of single-cell RNA
sequencing (scRNA-seq) data. In practice, human experts often rely on the
structure revealed by principal component analysis (PCA) followed by
$k$-nearest neighbor ($k$-NN) graph construction to guide annotation. While
effective, this process is labor-intensive and does not scale to large
datasets. Recent advances in CLIP-style models offer a promising path toward
automating cell type annotation. By aligning scRNA-seq profiles with natural
language descriptions, models like LangCell enable zero-shot annotation. While
LangCell demonstrates decent zero-shot performance, its predictions remain
suboptimal, particularly in achieving consistent accuracy across all cell
types. In this paper, we propose to refine the zero-shot logits produced by
LangCell through a graph-regularized optimization framework. By enforcing local
consistency over the task-specific PCA-based k-NN graph, our method combines
the scalability of the pre-trained models with the structural robustness relied
upon in expert annotation. We evaluate our approach on 14 annotated human
scRNA-seq datasets from 4 distinct studies, spanning 11 organs and over 200,000
single cells. Our method consistently improves zero-shot annotation accuracy,
achieving accuracy gains of up to 10%. Further analysis showcase the mechanism
by which GRIT effectively propagates correct signals through the graph, pulling
back mislabeled cells toward more accurate predictions. The method is
training-free, model-agnostic, and serves as a simple yet effective plug-in for
enhancing automated cell type annotation in practice.

</details>


### [4] [Embedding Is (Almost) All You Need: Retrieval-Augmented Inference for Generalizable Genomic Prediction Tasks](https://arxiv.org/abs/2508.04757)
*Nirjhor Datta,Swakkhar Shatabda,M Sohel Rahman*

Main category: q-bio.GN

TL;DR: 研究表明，基于嵌入的管道在基因组任务中比微调更高效且通用，同时显著减少推理时间和碳排放。


<details>
  <summary>Details</summary>
Motivation: 探讨在基因组任务中是否必须进行任务特定的微调，寻找更高效且通用的替代方案。

Method: 使用预训练DNA语言模型的固定嵌入表示，结合轻量级分类器，与微调方法对比。

Result: 嵌入方法在不同数据分布下表现优于微调，推理时间减少10-20倍，碳排放显著降低。

Conclusion: 嵌入提取是一种更通用、高效且环保的替代方案，适用于多样化的基因组任务。

Abstract: Large pre-trained DNA language models such as DNABERT-2, Nucleotide
Transformer, and HyenaDNA have demonstrated strong performance on various
genomic benchmarks. However, most applications rely on expensive fine-tuning,
which works best when the training and test data share a similar distribution.
In this work, we investigate whether task-specific fine-tuning is always
necessary. We show that simple embedding-based pipelines that extract fixed
representations from these models and feed them into lightweight classifiers
can achieve competitive performance. In evaluation settings with different data
distributions, embedding-based methods often outperform fine-tuning while
reducing inference time by 10x to 20x. Our results suggest that embedding
extraction is not only a strong baseline but also a more generalizable and
efficient alternative to fine-tuning, especially for deployment in diverse or
unseen genomic contexts. For example, in enhancer classification, HyenaDNA
embeddings combined with zCurve achieve 0.68 accuracy (vs. 0.58 for
fine-tuning), with an 88% reduction in inference time and over 8x lower carbon
emissions (0.02 kg vs. 0.17 kg CO2). In non-TATA promoter classification,
DNABERT-2 embeddings with zCurve or GC content reach 0.85 accuracy (vs. 0.89
with fine-tuning) with a 22x lower carbon footprint (0.02 kg vs. 0.44 kg CO2).
These results show that embedding-based pipelines offer over 10x better carbon
efficiency while maintaining strong predictive performance. The code is
available here:
https://github.com/NIRJHOR-DATTA/EMBEDDING-IS-ALMOST-ALL-YOU-NEED.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [5] [Understanding protein function with a multimodal retrieval-augmented foundation model](https://arxiv.org/abs/2508.04724)
*Timothy Fei Truong Jr,Tristan Bepler*

Main category: q-bio.QM

TL;DR: PoET-2是一个多模态、检索增强的蛋白质基础模型，结合家族特异性进化约束和可选结构条件，在零变体效应预测和监督学习任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有蛋白质语言模型在结构预测方面表现良好，但在突变理解和功能预测方面仍有不足，需要改进。

Method: PoET-2采用分层Transformer编码器和双解码器架构，结合检索增强和多模态学习，支持生成和双向表示学习。

Result: PoET-2在零变体效应预测和监督学习任务中表现最佳，尤其在多突变和小数据集场景下。

Conclusion: 结合检索增强和多模态家族中心建模，能显著提升蛋白质基础模型的性能。

Abstract: Protein language models (PLMs) learn probability distributions over natural
protein sequences. By learning from hundreds of millions of natural protein
sequences, protein understanding and design capabilities emerge. Recent works
have shown that scaling these models improves structure prediction, but does
not seem to improve mutation understanding and representation quality for
protein function prediction. We introduce PoET-2, a multimodal,
retrieval-augmented protein foundation model that incorporates in-context
learning of family-specific evolutionary constraints with optional structure
conditioning to learn generative distributions over protein sequences. PoET-2
uses a hierarchical transformer encoder that is equivariant to sequence context
ordering and a dual decoder architecture with both causal and masked language
modeling objectives, allowing PoET-2 to operate in both fully generative and
bidirectional representation learning modes. PoET-2 achieves state-of-the-art
performance on zero-shot variant effect prediction, excelling at scoring
variants with multiple mutations and challenging indel mutations. In supervised
settings, PoET-2 embeddings outperform previous methods for learning
sequence-function relationships, especially with small datasets. This work
highlights the benefits of combining retrieval augmentation with multimodal,
family-centric modeling for advancing protein foundation models.

</details>


### [6] [Cross-Domain Image Synthesis: Generating H&E from Multiplex Biomarker Imaging](https://arxiv.org/abs/2508.04734)
*Jillur Rahman Saurav,Mohammad Sadegh Nasr,Jacob M. Luber*

Main category: q-bio.QM

TL;DR: 该研究提出了一种基于多级VQGAN的方法，从多路免疫荧光（mIF）图像生成高质量虚拟H&E染色图像，用于结合分子与形态学分析。


<details>
  <summary>Details</summary>
Motivation: 结合mIF的分子数据与H&E的形态学信息，以利用现有的H&E计算机辅助诊断工具分析分子数据。

Method: 使用多级VQGAN生成虚拟H&E染色图像，并与标准cGAN基线在结直肠癌数据集上进行比较。

Result: VQGAN生成的图像在下游任务（如核分割和组织分类）中表现优于cGAN，更接近真实H&E分析。

Conclusion: 多级VQGAN是生成科学有用虚拟染色的强大架构，为整合mIF数据到H&E分析流程提供了可行路径。

Abstract: While multiplex immunofluorescence (mIF) imaging provides deep,
spatially-resolved molecular data, integrating this information with the
morphological standard of Hematoxylin & Eosin (H&E) can be very important for
obtaining complementary information about the underlying tissue. Generating a
virtual H&E stain from mIF data offers a powerful solution, providing immediate
morphological context. Crucially, this approach enables the application of the
vast ecosystem of H&E-based computer-aided diagnosis (CAD) tools to analyze
rich molecular data, bridging the gap between molecular and morphological
analysis. In this work, we investigate the use of a multi-level
Vector-Quantized Generative Adversarial Network (VQGAN) to create high-fidelity
virtual H&E stains from mIF images. We rigorously evaluated our VQGAN against a
standard conditional GAN (cGAN) baseline on two publicly available colorectal
cancer datasets, assessing performance on both image similarity and functional
utility for downstream analysis. Our results show that while both architectures
produce visually plausible images, the virtual stains generated by our VQGAN
provide a more effective substrate for computer-aided diagnosis. Specifically,
downstream nuclei segmentation and semantic preservation in tissue
classification tasks performed on VQGAN-generated images demonstrate superior
performance and agreement with ground-truth analysis compared to those from the
cGAN. This work establishes that a multi-level VQGAN is a robust and superior
architecture for generating scientifically useful virtual stains, offering a
viable pathway to integrate the rich molecular data of mIF into established and
powerful H&E-based analytical workflows.

</details>


### [7] [ERDES: A Benchmark Video Dataset for Retinal Detachment and Macular Status Classification in Ocular Ultrasound](https://arxiv.org/abs/2508.04735)
*Pouyan Navard,Yasemin Ozkut,Srikar Adhikari,Elaine Situ-LaCasse,Josie Acuña,Adrienne Yarnish,Alper Yilmaz*

Main category: q-bio.QM

TL;DR: 论文介绍了首个公开的视网膜脱离超声数据集ERDES，用于开发机器学习模型，并提供了基线基准。


<details>
  <summary>Details</summary>
Motivation: 视网膜脱离（RD）需要及时干预，但超声图像解读缺乏专家资源，深度学习可自动化评估。

Method: 引入ERDES数据集，标注视网膜脱离及黄斑状态，使用时空卷积神经网络（CNN）进行基准测试。

Result: 提供了首个公开的视网膜脱离超声数据集及基线模型。

Conclusion: ERDES数据集和基线模型为开发机器学习辅助诊断视网膜脱离提供了基础。

Abstract: Retinal detachment (RD) is a vision-threatening condition that requires
timely intervention to preserve vision. Macular involvement -- whether the
macula is still intact (macula-intact) or detached (macula-detached) -- is the
key determinant of visual outcomes and treatment urgency. Point-of-care
ultrasound (POCUS) offers a fast, non-invasive, cost-effective, and accessible
imaging modality widely used in diverse clinical settings to detect RD.
However, ultrasound image interpretation is limited by a lack of expertise
among healthcare providers, especially in resource-limited settings. Deep
learning offers the potential to automate ultrasound-based assessment of RD.
However, there are no ML ultrasound algorithms currently available for clinical
use to detect RD and no prior research has been done on assessing macular
status using ultrasound in RD cases -- an essential distinction for surgical
prioritization. Moreover, no public dataset currently supports macular-based RD
classification using ultrasound video clips. We introduce Eye Retinal
DEtachment ultraSound, ERDES, the first open-access dataset of ocular
ultrasound clips labeled for (i) presence of retinal detachment and (ii)
macula-intact versus macula-detached status. The dataset is intended to
facilitate the development and evaluation of machine learning models for
detecting retinal detachment. We also provide baseline benchmarks using
multiple spatiotemporal convolutional neural network (CNN) architectures. All
clips, labels, and training code are publicly available at
https://osupcvlab.github.io/ERDES/.

</details>


### [8] [PhysiBoSS-Models: A database for multiscale models](https://arxiv.org/abs/2508.05550)
*Vincent Noel,Marco Ruscone,Randy Heiland,Arnau Montagud,Alfonso Valencia,Emmanuel Barillot,Paul Macklin,Laurence Calzone*

Main category: q-bio.QM

TL;DR: PhysiBoSS是一个开源平台，整合了细胞群体的基于代理建模和细胞内随机布尔网络，支持复杂生物行为的多尺度模拟。PhysiBoSS-Models数据库是一个用于共享和版本控制的多尺度模型库。


<details>
  <summary>Details</summary>
Motivation: 促进模型共享和版本控制，支持生物学研究中的模型重用、验证和基准测试。

Method: 通过简单的Python API和工具（如PhysiCell Studio）提供标准化访问，下载和模拟现有模型。

Result: 创建了一个经过验证的多尺度模型库，便于研究使用。

Conclusion: PhysiBoSS-Models通过标准化和简化模型访问，支持生物学研究的发展。

Abstract: PhysiBoSS is an open-source platform that integrates agent-based modeling of
cell populations with intracellular stochastic Boolean networks, enabling
multiscale simulations of complex biological behaviors. To promote model
sharing and versioning, we present the PhysiBoSS-Models database: a curated
repository for multiscale models built with PhysiBoSS. By providing a simple
Python API, PhysiBoSS-Models provides an easy way to download and simulate
preexisting models through tools such as PhysiCell Studio. By providing
standardized access to validated models, PhysiBoSS-Models facilitates reuse,
validation, and benchmarking, supporting research in biology.

</details>


### [9] [Data Analysis and Modeling for Transitioning Between Laboratory Methods for Detecting SARS-CoV-2 in Wastewater](https://arxiv.org/abs/2508.05594)
*Maria M. Warns,Leah Mrowiec,Christopher Owen,Adam Horton,Chi-Yu Lin,Modou Lamin Jarju,Niall M. Mangan,Aaron Packman,Katelyn Plaisier Leisman,Abhilasha Shrestha,Rachel Poretsky*

Main category: q-bio.QM

TL;DR: 该研究探讨了在废水监测中，从低通量手动方法过渡到高通量自动化方法时如何保持数据连续性，通过并行处理样本并建立回归模型实现。


<details>
  <summary>Details</summary>
Motivation: 废水监测是监测病原体（如SARS-CoV-2）的重要工具，但实验室方法的动态变化可能导致数据不连续。本研究旨在解决这一问题。

Method: 在过渡期间，并行使用低通量手动方法和高通量自动化方法处理废水样本，并通过回归模型关联两种方法的数据。

Result: 研究发现，通过去除异常值并使用对数-对数模型，可以在方法过渡期间保持数据连续性。

Conclusion: 研究证明，在方法过渡期间通过并行处理和适当建模，可以维持废水监测数据的连续性。

Abstract: Wastewater surveillance has proven to be a useful tool to monitor pathogens
such as SARS-CoV-2 as it is a nonintrusive way to survey the potential disease
burden of the population contributing to a sewershed. With the expansion of
this field since the beginning of the COVID-19 pandemic, laboratory methods to
process wastewater and quantify pathogen nucleic acid levels have improved as
technologies changed, efforts expanded in size and scope, and supply chain
issues were resolved. Maintaining data continuity is crucial for labs
undergoing method transitions to accurately assess infectious disease levels
over time and compare measured RNA concentrations to public health data.
Despite the dynamic nature of laboratory methods and the necessity to ensure
uninterrupted data, to our knowledge there has not been a study that unites two
datasets from different lab methods for pathogen quantification from
environmental samples. Here, we describe a lab transition from SARS-CoV-2 RNA
quantification using a low-throughput, manual filtration-based wastewater
concentration and RNA extraction followed by qPCR to a high-throughput,
automated magnetic bead-based concentration and extraction followed by dPCR.
During the two-month transition period, wastewater samples from across the
Chicago metropolitan area were processed with both methods in parallel. We
evaluated a variety of regression models to relate the RNA measurements from
both methods and found a log-log model was most appropriate after removing
outliers and discrepancy points to improve model performance. We also evaluated
the consequences of assigning values to samples that were below the detection
limit. Our study demonstrates that data continuity can be maintained throughout
a transition of laboratory methods if there is a sufficient period of overlap
between the methods for an appropriate model to be constructed to relate the
datasets.

</details>


<div id='q-bio.MN'></div>

# q-bio.MN [[Back]](#toc)

### [10] [Alz-QNet: A Quantum Regression Network for Studying Alzheimer's Gene Interactions](https://arxiv.org/abs/2508.04743)
*Debanjan Konar,Neerav Sreekumar,Richard Jiang,Vaneet Aggarwal*

Main category: q-bio.MN

TL;DR: 论文提出了一种基于量子回归网络（Alz-QNet）的新方法，用于研究阿尔茨海默病（AD）中关键基因的相互作用，以揭示潜在的基因调控机制。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病是一种多因素疾病，理解其基因间相互作用对治疗和诊断至关重要。

Method: 使用量子回归网络（Alz-QNet）分析关键基因（如APP、FGF14、YY1等）在AD进展中的相互作用，数据来自GSE138852数据库。

Result: 揭示了复杂的基因间相互作用，为AD的发病机制提供了新的见解，并可能帮助发现潜在的基因抑制剂或调控因子。

Conclusion: Alz-QNet为AD的基因表达治疗提供了新的研究工具和方向。

Abstract: Understanding the molecular-level mechanisms underpinning Alzheimer's disease
(AD) by studying crucial genes associated with the disease remains a challenge.
Alzheimer's, being a multifactorial disease, requires understanding the
gene-gene interactions underlying it for theranostics and progress. In this
article, a novel attempt has been made using a quantum regression to decode how
some crucial genes in the AD Amyloid Beta Precursor Protein ($APP$), Sterol
regulatory element binding transcription factor 14 ($FGF14$), Yin Yang 1
($YY1$), and Phospholipase D Family Member 3 ($PLD3$) etc. become influenced by
other prominent switching genes during disease progression, which may help in
gene expression-based therapy for AD. Our proposed Quantum Regression Network
(Alz-QNet) introduces a pioneering approach with insights from the
state-of-the-art Quantum Gene Regulatory Networks (QGRN) to unravel the gene
interactions involved in AD pathology, particularly within the Entorhinal
Cortex (EC), where early pathological changes occur. Using the proposed
Alz-QNet framework, we explore the interactions between key genes ($APP$,
$FGF14$, $YY1$, $EGR1$, $GAS7$, $AKT3$, $SREBF2$, and $PLD3$) within the CE
microenvironment of AD patients, studying genetic samples from the database
$GSE138852$, all of which are believed to play a crucial role in the
progression of AD. Our investigation uncovers intricate gene-gene interactions,
shedding light on the potential regulatory mechanisms that underlie the
pathogenesis of AD, which help us to find potential gene inhibitors or
regulators for theranostics.

</details>


### [11] [GCnet: Using Granger causality to explore the dynamic causality relations among genes as-sociated with intellectual disability in human brain](https://arxiv.org/abs/2508.05136)
*Lukas Madsen Brandt,Katja Nowick,Jing Qin*

Main category: q-bio.MN

TL;DR: 论文通过Granger因果检验分析基因表达数据，构建基因网络以识别与智力障碍（ID）相关的新基因，并以Mowat Wilson综合征为例验证方法。


<details>
  <summary>Details</summary>
Motivation: 智力障碍（ID）的分子机制尚不明确，基因表达模式与脑发育过程的动态关系研究有助于理解ID的病理基础。

Method: 将体外脑发育过程中的基因表达数据视为时间序列，应用Granger因果检验分析基因间动态依赖关系，构建基因表达网络并提取ID相关病理信息。

Result: 构建了Granger因果网络，识别出与Mowat Wilson综合征相关的新基因，并提供了优先级列表。

Conclusion: 该方法为理解ID的分子机制提供了新视角，并有助于发现潜在的治疗靶点。

Abstract: Intellectual disability (ID) is defined by an IQ under 70, in addition to
deficits in two or more adaptive behaviors that affect everyday living.
Throughout history, individuals with ID have often been margin-alized from
society and continue to suffer significantly even in modern times. A varying
proportion of ID cases are attributable to genetic causes. Identifying the
causal relation among these ID-associated genes and their gene expression
pattern during brain development process would gain us a better understanding
of the molecular basis of ID. In this paper, we interpret gene expression data
collected at different time points during the in vitro brain development
process as time series and further introduce Granger causality test to evaluate
the dynamic dependence relations among genes. These evaluations are used as
input to construct gene expression network and extract the pathological
information associated to ID including identi-fying new genes that can be
critically related to the disease. To demonstrate our methods, we pro-vide a
priority list of new genes that are most likely associated with Mowat Wilson
Syndrome via monitoring the community structure of ZEB2 in our Granger
causality network constructed based on the Kutsche dataset (Kutsche, et al.,
2018).

</details>


<div id='q-bio.TO'></div>

# q-bio.TO [[Back]](#toc)

### [12] [Adaptive k-space Radial Sampling for Cardiac MRI with Reinforcement Learning](https://arxiv.org/abs/2508.04727)
*Ruru Xu,Ilkay Oksuz*

Main category: q-bio.TO

TL;DR: 提出了一种基于强化学习的径向采样轨迹优化框架，用于心脏MRI，通过双分支架构和交叉注意力机制提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 探索强化学习在非笛卡尔轨迹优化中的潜力，以平衡MRI的采集速度与图像质量。

Method: 采用双分支架构联合处理k空间和图像域信息，结合交叉注意力机制和黄金比例采样策略。

Result: 实验表明，该方法能学习最优径向采样策略，并在多加速因子下提升重建质量。

Conclusion: 该强化学习框架在心脏MRI中表现出色，优于传统方法。

Abstract: Accelerated Magnetic Resonance Imaging (MRI) requires careful optimization of
k-space sampling patterns to balance acquisition speed and image quality. While
recent advances in deep learning have shown promise in optimizing Cartesian
sampling, the potential of reinforcement learning (RL) for non-Cartesian
trajectory optimization remains largely unexplored. In this work, we present a
novel RL framework for optimizing radial sampling trajectories in cardiac MRI.
Our approach features a dual-branch architecture that jointly processes k-space
and image-domain information, incorporating a cross-attention fusion mechanism
to facilitate effective information exchange between domains. The framework
employs an anatomically-aware reward design and a golden-ratio sampling
strategy to ensure uniform k-space coverage while preserving cardiac structural
details. Experimental results demonstrate that our method effectively learns
optimal radial sampling strategies across multiple acceleration factors,
achieving improved reconstruction quality compared to conventional approaches.
Code available: https://github.com/Ruru-Xu/RL-kspace-Radial-Sampling

</details>
