{"id": "2508.18304", "pdf": "https://arxiv.org/pdf/2508.18304", "abs": "https://arxiv.org/abs/2508.18304", "authors": ["Wuchao Liu", "Han Peng", "Wengen Li", "Yichao Zhang", "Jihong Guan", "Shuigeng Zhou"], "title": "scI2CL: Effectively Integrating Single-cell Multi-omics by Intra- and Inter-omics Contrastive Learning", "categories": ["q-bio.GN", "cs.AI", "cs.LG", "q-bio.CB"], "comment": "22 pages, 6figures", "summary": "Single-cell multi-omics data contain huge information of cellular states, and\nanalyzing these data can reveal valuable insights into cellular heterogeneity,\ndiseases, and biological processes. However, as cell differentiation \\&\ndevelopment is a continuous and dynamic process, it remains challenging to\ncomputationally model and infer cell interaction patterns based on single-cell\nmulti-omics data. This paper presents scI2CL, a new single-cell multi-omics\nfusion framework based on intra- and inter-omics contrastive learning, to learn\ncomprehensive and discriminative cellular representations from complementary\nmulti-omics data for various downstream tasks. Extensive experiments of four\ndownstream tasks validate the effectiveness of scI2CL and its superiority over\nexisting peers. Concretely, in cell clustering, scI2CL surpasses eight\nstate-of-the-art methods on four widely-used real-world datasets. In cell\nsubtyping, scI2CL effectively distinguishes three latent monocyte cell\nsubpopulations, which are not discovered by existing methods. Simultaneously,\nscI2CL is the only method that correctly constructs the cell developmental\ntrajectory from hematopoietic stem and progenitor cells to Memory B cells. In\naddition, scI2CL resolves the misclassification of cell types between two\nsubpopulations of CD4+ T cells, while existing methods fail to precisely\ndistinguish the mixed cells. In summary, scI2CL can accurately characterize\ncross-omics relationships among cells, thus effectively fuses multi-omics data\nand learns discriminative cellular representations to support various\ndownstream analysis tasks."}
{"id": "2508.18327", "pdf": "https://arxiv.org/pdf/2508.18327", "abs": "https://arxiv.org/abs/2508.18327", "authors": ["Yanfang Wang", "Liang Wei", "Liheng Zhong", "Xizi Yu", "Pengtao Huang", "Fang Wang", "John D. Marshall"], "title": "Adding a Storage Pool improves 3-PG Tree-ring Simulations", "categories": ["q-bio.QM"], "comment": null, "summary": "Tree rings provide long-term records of tree growth and climate changes,\nwhich makes them ideal benchmarks for forest modeling. Tree-ring information\nhas greatly improved the reliability of 3-PG, which is one of the most commonly\nused process-based forest growth models. Here we strengthen 3-PGs ability to\nsimulate tree-ring width and carbon stable isotopes ({\\delta}13C) by enhancing\nits descriptions of tree physiology. The major upgrade was adding a carbon\nstorage pool for tree-ring formation using stored carbohydrates. We also\nincorporated previous modifications (replacing the age modifier with a height\nmodifier) of 3-PG and tested their efficacy in improving tree-ring simulations.\nWe ran the model based on two grand fir (Abies grandis) stands. The updated\nmodel greatly improved the simulations for both tree-ring widths and\n{\\delta}13C. The results represent one of the best tree-ring {\\delta}13C\nsimulations, which accurately captured the amplitude in annual variations of\n{\\delta}13C. The correlations (R2) between simulations and observations reached\n0.50 and 0.73 at two stands respectively. The new model also greatly improved\nthe simulations of raw tree-ring widths and detrended ring-widths index.\nBecause of better descriptions of tree physiology and more accurate simulations\nof tree rings than the previous model version, the updated 3-PG should provide\nmore reliable simulations than previous 3-PG versions when tree-ring\ninformation is used as benchmark in future studies."}
{"id": "2508.18484", "pdf": "https://arxiv.org/pdf/2508.18484", "abs": "https://arxiv.org/abs/2508.18484", "authors": ["Daehyun Kim", "Jeffrey Tithof"], "title": "One-dimensional modeling of blood flow: A comprehensive yet concise review", "categories": ["q-bio.QM"], "comment": "45 pages, 14 figures", "summary": "One-dimensional (1D) blood flow simulations are extensively used in\ncardiovascular research due to their computational efficiency and effectiveness\nin analyzing pulse wave dynamics. Despite their versatility and simplicity,\nthere is a lack of a unified, step-by-step guide integrating theoretical\nderivations with practical implementation details. In this work, we summarize\nkey components for comprehensive 1D blood flow simulations, including the\nderivation of reduced-order governing equations, the method of characteristics\n(Riemann invariants), a finite volume-based numerical scheme, boundary\nconditions (application of Riemann invariants for reflective/non-reflective and\n3-element Windkessel outlet boundaries), junction treatments, verification of\npresented methodologies, and relevant practical applications. Additionally, we\nprovide detailed step-by-step instructions for implementing the numerical\nscheme, applying boundary conditions, and treatment of junctions. By\nintegrating rigorous theory with practical guidance for implementation, we seek\nto improve accessibility of 1D blood flow simulations. We anticipate that this\nguide will serve as a valuable resource and foundational reference for both\nnovice and experienced researchers in cardiovascular modeling."}
{"id": "2508.18303", "pdf": "https://arxiv.org/pdf/2508.18303", "abs": "https://arxiv.org/abs/2508.18303", "authors": ["Jueqi Wang", "Zachary Jacokes", "John Darrell Van Horn", "Michael C. Schatz", "Kevin A. Pelphrey", "Archana Venkataraman"], "title": "Learning Explainable Imaging-Genetics Associations Related to a Neurological Disorder", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "While imaging-genetics holds great promise for unraveling the complex\ninterplay between brain structure and genetic variation in neurological\ndisorders, traditional methods are limited to simplistic linear models or to\nblack-box techniques that lack interpretability. In this paper, we present\nNeuroPathX, an explainable deep learning framework that uses an early fusion\nstrategy powered by cross-attention mechanisms to capture meaningful\ninteractions between structural variations in the brain derived from MRI and\nestablished biological pathways derived from genetics data. To enhance\ninterpretability and robustness, we introduce two loss functions over the\nattention matrix - a sparsity loss that focuses on the most salient\ninteractions and a pathway similarity loss that enforces consistent\nrepresentations across the cohort. We validate NeuroPathX on both autism\nspectrum disorder and Alzheimer's disease. Our results demonstrate that\nNeuroPathX outperforms competing baseline approaches and reveals biologically\nplausible associations linked to the disorder. These findings underscore the\npotential of NeuroPathX to advance our understanding of complex brain\ndisorders. Code is available at https://github.com/jueqiw/NeuroPathX ."}
{"id": "2508.18404", "pdf": "https://arxiv.org/pdf/2508.18404", "abs": "https://arxiv.org/abs/2508.18404", "authors": ["Alex Szorkovszky", "Rujeena Mathema", "Pedro Lencastre", "Pedro Lind", "Anis Yazidi"], "title": "Saccade crossing avoidance as a visual search strategy", "categories": ["q-bio.NC", "q-bio.QM"], "comment": "Main text: 11 pages, 4 figures; Supplementary info: 12 pages, 9\n  figures", "summary": "Although visual search appears largely random, several oculomotor biases\nexist such that the likelihoods of saccade directions and lengths depend on the\nprevious scan path. Compared to the most recent fixations, the impact of the\nlonger path history is more difficult to quantify. Using the step-selection\nframework commonly used in movement ecology, and analyzing data from 45-second\nviewings of \"Where's Waldo\"?, we report a new memory-dependent effect that also\nvaries significantly between individuals, which we term self-crossing\navoidance. This is a tendency for saccades to avoid crossing those earlier in\nthe scan path, and is most evident when both have small amplitudes. We show\nthis by comparing real data to synthetic data generated from a memoryless\napproximation of the spatial statistics (i.e. a Markovian nonparametric model\nwith a matching distribution of saccade lengths over time). Maximum likelihood\nfitting indicates that this effect is strongest when including the last\n$\\approx 7$ seconds of a scan path. The effect size is comparable to well-known\nforms of history dependence such as inhibition of return. A parametric\nprobabilistic model including a self-crossing penalty term was able to\nreproduce joint statistics of saccade lengths and self-crossings. We also\nquantified individual strategic differences, and their consistency over the six\nimages viewed per participant, using mixed-effect regressions. Participants\nwith a higher tendency to avoid crossings displayed smaller saccade lengths and\nshorter fixation durations on average, but did not display more horizontal,\nvertical, forward or reverse saccades. Together, these results indicate that\nthe avoidance of crossings is a local orienting strategy that facilitates and\ncomplements inhibition of return, and hence exploration of visual scenes."}
{"id": "2508.18567", "pdf": "https://arxiv.org/pdf/2508.18567", "abs": "https://arxiv.org/abs/2508.18567", "authors": ["Darin Tsui", "Kunal Talreja", "Amirali Aghazadeh"], "title": "Sparse Autoencoders for Low-$N$ Protein Function Prediction and Design", "categories": ["cs.LG", "q-bio.QM"], "comment": "15 pages, 4 figures", "summary": "Predicting protein function from amino acid sequence remains a central\nchallenge in data-scarce (low-$N$) regimes, limiting machine learning-guided\nprotein design when only small amounts of assay-labeled sequence-function data\nare available. Protein language models (pLMs) have advanced the field by\nproviding evolutionary-informed embeddings and sparse autoencoders (SAEs) have\nenabled decomposition of these embeddings into interpretable latent variables\nthat capture structural and functional features. However, the effectiveness of\nSAEs for low-$N$ function prediction and protein design has not been\nsystematically studied. Herein, we evaluate SAEs trained on fine-tuned ESM2\nembeddings across diverse fitness extrapolation and protein engineering tasks.\nWe show that SAEs, with as few as 24 sequences, consistently outperform or\ncompete with their ESM2 baselines in fitness prediction, indicating that their\nsparse latent space encodes compact and biologically meaningful representations\nthat generalize more effectively from limited data. Moreover, steering\npredictive latents exploits biological motifs in pLM representations, yielding\ntop-fitness variants in 83% of cases compared to designing with ESM2 alone."}
{"id": "2508.18579", "pdf": "https://arxiv.org/pdf/2508.18579", "abs": "https://arxiv.org/abs/2508.18579", "authors": ["Mohammadreza Ghaffarzadeh-Esfahani", "Ali Motahharynia", "Nahid Yousefian", "Navid Mazrouei", "Jafar Ghaisari", "Yousof Gheisari"], "title": "DrugReasoner: Interpretable Drug Approval Prediction with a Reasoning-augmented Language Model", "categories": ["cs.LG", "cs.AI", "q-bio.QM", "I.2.7; J.3; I.2.6"], "comment": "13 pages, 2 figures. Corresponding author: alimotahharynia@gmail.com", "summary": "Drug discovery is a complex and resource-intensive process, making early\nprediction of approval outcomes critical for optimizing research investments.\nWhile classical machine learning and deep learning methods have shown promise\nin drug approval prediction, their limited interpretability constraints their\nimpact. Here, we present DrugReasoner, a reasoning-based large language model\n(LLM) built on the LLaMA architecture and fine-tuned with group relative policy\noptimization (GRPO) to predict the likelihood of small-molecule approval.\nDrugReasoner integrates molecular descriptors with comparative reasoning\nagainst structurally similar approved and unapproved compounds, generating\npredictions alongside step-by-step rationales and confidence scores.\nDrugReasoner achieved robust performance with an AUC of 0.732 and an F1 score\nof 0.729 on the validation set and 0.725 and 0.718 on the test set,\nrespectively. These results outperformed conventional baselines, including\nlogistic regression, support vector machine, and k-nearest neighbors and had\ncompetitive performance relative to XGBoost. On an external independent\ndataset, DrugReasoner outperformed both baseline and the recently developed\nChemAP model, achieving an AUC of 0.728 and an F1-score of 0.774, while\nmaintaining high precision and balanced sensitivity, demonstrating robustness\nin real-world scenarios. These findings demonstrate that DrugReasoner not only\ndelivers competitive predictive accuracy but also enhances transparency through\nits reasoning outputs, thereby addressing a key bottleneck in AI-assisted drug\ndiscovery. This study highlights the potential of reasoning-augmented LLMs as\ninterpretable and effective tools for pharmaceutical decision-making."}
{"id": "2508.18638", "pdf": "https://arxiv.org/pdf/2508.18638", "abs": "https://arxiv.org/abs/2508.18638", "authors": ["Ifrah Tariq", "Ernest Fraenkel"], "title": "Biologically Disentangled Multi-Omic Modeling Reveals Mechanistic Insights into Pan-Cancer Immunotherapy Resistance", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Immune checkpoint inhibitors (ICIs) have transformed cancer treatment, yet\npatient responses remain highly variable, and the biological mechanisms\nunderlying resistance are poorly understood. While machine learning models hold\npromise for predicting responses to ICIs, most existing methods lack\ninterpretability and do not effectively leverage the biological structure\ninherent to multi-omics data. Here, we introduce the Biologically Disentangled\nVariational Autoencoder (BDVAE), a deep generative model that integrates\ntranscriptomic and genomic data through modality- and pathway-specific\nencoders. Unlike existing rigid, pathway-informed models, BDVAE employs a\nmodular encoder architecture combined with variational inference to learn\nbiologically meaningful latent features associated with immune, genomic, and\nmetabolic processes. Applied to a pan-cancer cohort of 366 patients across four\ncancer types treated with ICIs, BDVAE accurately predicts treatment response\n(AUC-ROC = 0.94 on unseen test data) and uncovers critical resistance\nmechanisms, including immune suppression, metabolic shifts, and neuronal\nsignaling. Importantly, BDVAE reveals that resistance spans a continuous\nbiological spectrum rather than strictly binary states, reflecting gradations\nof tumor dysfunction. Several latent features correlate with survival outcomes\nand known clinical subtypes, demonstrating BDVAE's capability to generate\ninterpretable, clinically relevant insights. These findings underscore the\nvalue of biologically structured machine learning in elucidating complex\nresistance patterns and guiding precision immunotherapy strategies."}
{"id": "2508.18853", "pdf": "https://arxiv.org/pdf/2508.18853", "abs": "https://arxiv.org/abs/2508.18853", "authors": ["Simon P. Preston", "Richard D. Wilkinson", "Richard H. Clayton", "Mike J. Chappell", "Gary R. Mirams"], "title": "Think before you fit: parameter identifiability, sensitivity and uncertainty in systems biology models", "categories": ["stat.ME", "math.ST", "q-bio.QM", "stat.AP", "stat.TH", "62P10, 92BXX"], "comment": null, "summary": "Reliable predictions from systems biology models require knowing whether\nparameters can be estimated from available data, and with what certainty.\nIdentifiability analysis reveals whether parameters are learnable in principle\n(structural identifiability) and in practice (practical identifiability). We\nintroduce the core ideas using linear models, highlighting how experimental\ndesign and output sensitivity shape identifiability. In nonlinear models,\nidentifiability can vary with parameter values, motivating global and\nsimulation-based approaches. We summarise computational methods for assessing\nidentifiability noting that weakly identifiable parameters can undermine\npredictions beyond the calibration dataset. Strategies to improve\nidentifiability include measuring different outputs, refining model structure,\nand adding prior knowledge. Far from a technical afterthought, identifiability\ndetermines the limits of inference and prediction. Recognising and addressing\nidentifiability is essential for building models that are not only well-fitted\nto data, but also capable of delivering predictions with robust, quantifiable\nuncertainty."}
