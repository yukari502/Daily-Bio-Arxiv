{"id": "2508.19420", "pdf": "https://arxiv.org/pdf/2508.19420", "abs": "https://arxiv.org/abs/2508.19420", "authors": ["Ely F. Miller", "Abhishek Mallela", "Jacob Neumann", "Yen Ting Lin", "William S. Hlavacek", "Richard G. Posner"], "title": "Using PyBioNetFit to Leverage Qualitative and Quantitative Data in Biological Model Parameterization and Uncertainty Quantification", "categories": ["q-bio.QM"], "comment": "44 pages, 7 main figures, 4 supplemental figures. Main text, figures,\n  tables, all captions, and supplemental material included", "summary": "Data generated in studies of cellular regulatory systems are often\nqualitative. For example, measurements of signaling readouts in the presence\nand absence of mutations may reveal a rank ordering of responses across\nconditions but not the precise extents of mutation-induced differences.\nQualitative data are often ignored by mathematical modelers or are considered\nin an ad hoc manner, as in the study of Kocieniewski and Lipniacki (2013) [Phys\nBiol 10: 035006], which was focused on the roles of MEK isoforms in ERK\nactivation. In this earlier study, model parameter values were tuned manually\nto obtain consistency with a combination of qualitative and quantitative data.\nThis approach is not reproducible, nor does it provide insights into parametric\nor prediction uncertainties. Here, starting from the same data and the same\nordinary differential equation (ODE) model structure, we generate formalized\nstatements of qualitative observations, making these observations more\nreusable, and we improve the model parameterization procedure by applying a\nsystematic and automated approach enabled by the software package PyBioNetFit.\nWe also demonstrate uncertainty quantification (UQ), which was absent in the\noriginal study. Our results show that PyBioNetFit enables qualitative data to\nbe leveraged, together with quantitative data, in parameterization of systems\nbiology models and facilitates UQ. These capabilities are important for\nreliable estimation of model parameters and model analyses in studies of\ncellular regulatory systems and reproducibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528PyBioNetFit\u8f6f\u4ef6\u5305\u7cfb\u7edf\u5316\u5904\u7406\u5b9a\u6027\u6570\u636e\uff0c\u6539\u8fdb\u7ec6\u80de\u8c03\u63a7\u7cfb\u7edf\u6a21\u578b\u7684\u53c2\u6570\u5316\u8fc7\u7a0b\uff0c\u5e76\u5b9e\u73b0\u4e0d\u786e\u5b9a\u6027\u91cf\u5316", "motivation": "\u7ec6\u80de\u8c03\u63a7\u7cfb\u7edf\u7814\u7a76\u4e2d\u4ea7\u751f\u7684\u5b9a\u6027\u6570\u636e\u5f80\u5f80\u88ab\u5ffd\u7565\u6216\u4e34\u65f6\u5904\u7406\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u548c\u53ef\u91cd\u590d\u6027\uff0c\u9700\u8981\u5f00\u53d1\u6b63\u5f0f\u7684\u65b9\u6cd5\u6765\u5145\u5206\u5229\u7528\u8fd9\u4e9b\u6570\u636e", "method": "\u4f7f\u7528PyBioNetFit\u8f6f\u4ef6\u5305\uff0c\u5c06\u5b9a\u6027\u89c2\u5bdf\u8f6c\u5316\u4e3a\u5f62\u5f0f\u5316\u9648\u8ff0\uff0c\u91c7\u7528\u7cfb\u7edf\u5316\u3001\u81ea\u52a8\u5316\u7684\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u7ed3\u5408\u5b9a\u6027\u548c\u5b9a\u91cf\u6570\u636e\u8fdb\u884c\u6a21\u578b\u53c2\u6570\u4f30\u8ba1", "result": "PyBioNetFit\u80fd\u591f\u6709\u6548\u5229\u7528\u5b9a\u6027\u6570\u636e\u548c\u5b9a\u91cf\u6570\u636e\u5171\u540c\u8fdb\u884c\u7cfb\u7edf\u751f\u7269\u5b66\u6a21\u578b\u7684\u53c2\u6570\u5316\uff0c\u5e76\u5b9e\u73b0\u4e0d\u786e\u5b9a\u6027\u91cf\u5316", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6a21\u578b\u53c2\u6570\u4f30\u8ba1\u7684\u53ef\u9760\u6027\uff0c\u589e\u5f3a\u4e86\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\uff0c\u5bf9\u7ec6\u80de\u8c03\u63a7\u7cfb\u7edf\u7814\u7a76\u5177\u6709\u91cd\u8981\u610f\u4e49"}}
{"id": "2508.19914", "pdf": "https://arxiv.org/pdf/2508.19914", "abs": "https://arxiv.org/abs/2508.19914", "authors": ["Muhammad Waqas", "Rukhmini Bandyopadhyay", "Eman Showkatian", "Amgad Muneer", "Anas Zafar", "Frank Rojas Alvarez", "Maricel Corredor Marin", "Wentao Li", "David Jaffray", "Cara Haymaker", "John Heymach", "Natalie I Vokes", "Luisa Maren Solis Soto", "Jianjun Zhang", "Jia Wu"], "title": "The Next Layer: Augmenting Foundation Models with Structure-Preserving and Attention-Guided Learning for Local Patches to Global Context Awareness in Computational Pathology", "categories": ["q-bio.QM", "cs.AI", "stat.ML"], "comment": "43 pages, 7 main Figures, 8 Extended Data Figures", "summary": "Foundation models have recently emerged as powerful feature extractors in\ncomputational pathology, yet they typically omit mechanisms for leveraging the\nglobal spatial structure of tissues and the local contextual relationships\namong diagnostically relevant regions - key elements for understanding the\ntumor microenvironment. Multiple instance learning (MIL) remains an essential\nnext step following foundation model, designing a framework to aggregate\npatch-level features into slide-level predictions. We present EAGLE-Net, a\nstructure-preserving, attention-guided MIL architecture designed to augment\nprediction and interpretability. EAGLE-Net integrates multi-scale absolute\nspatial encoding to capture global tissue architecture, a top-K\nneighborhood-aware loss to focus attention on local microenvironments, and\nbackground suppression loss to minimize false positives. We benchmarked\nEAGLE-Net on large pan-cancer datasets, including three cancer types for\nclassification (10,260 slides) and seven cancer types for survival prediction\n(4,172 slides), using three distinct histology foundation backbones (REMEDIES,\nUni-V1, Uni2-h). Across tasks, EAGLE-Net achieved up to 3% higher\nclassification accuracy and the top concordance indices in 6 of 7 cancer types,\nproducing smooth, biologically coherent attention maps that aligned with expert\nannotations and highlighted invasive fronts, necrosis, and immune infiltration.\nThese results position EAGLE-Net as a generalizable, interpretable framework\nthat complements foundation models, enabling improved biomarker discovery,\nprognostic modeling, and clinical decision support", "AI": {"tldr": "EAGLE-Net\u662f\u4e00\u4e2a\u7ed3\u6784\u4fdd\u6301\u7684\u6ce8\u610f\u529b\u5f15\u5bfc\u591a\u5b9e\u4f8b\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u591a\u5c3a\u5ea6\u7a7a\u95f4\u7f16\u7801\u548c\u5c40\u90e8\u5fae\u73af\u5883\u5173\u6ce8\u673a\u5236\uff0c\u5728\u8ba1\u7b97\u75c5\u7406\u5b66\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u51c6\u786e\u6027\u548c\u751f\u5b58\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u7840\u6a21\u578b\u5728\u8ba1\u7b97\u75c5\u7406\u5b66\u4e2d\u7f3a\u4e4f\u5229\u7528\u7ec4\u7ec7\u5168\u5c40\u7a7a\u95f4\u7ed3\u6784\u548c\u5c40\u90e8\u8bca\u65ad\u76f8\u5173\u533a\u57df\u4e0a\u4e0b\u6587\u5173\u7cfb\u7684\u673a\u5236\uff0c\u800c\u8fd9\u4e9b\u5bf9\u4e8e\u7406\u89e3\u80bf\u7624\u5fae\u73af\u5883\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faEAGLE-Net\u67b6\u6784\uff0c\u6574\u5408\u591a\u5c3a\u5ea6\u7edd\u5bf9\u7a7a\u95f4\u7f16\u7801\u6355\u83b7\u5168\u5c40\u7ec4\u7ec7\u7ed3\u6784\uff0c\u4f7f\u7528top-K\u90bb\u57df\u611f\u77e5\u635f\u5931\u5173\u6ce8\u5c40\u90e8\u5fae\u73af\u5883\uff0c\u5e76\u901a\u8fc7\u80cc\u666f\u6291\u5236\u635f\u5931\u51cf\u5c11\u5047\u9633\u6027\u3002", "result": "\u5728\u5927\u578b\u6cdb\u764c\u6570\u636e\u96c6\u4e0a\uff0cEAGLE-Net\u5b9e\u73b0\u4e86\u9ad8\u8fbe3%\u7684\u5206\u7c7b\u51c6\u786e\u7387\u63d0\u5347\uff0c\u57287\u79cd\u764c\u75c7\u7c7b\u578b\u4e2d\u76846\u79cd\u83b7\u5f97\u6700\u9ad8\u4e00\u81f4\u6027\u6307\u6570\uff0c\u751f\u6210\u5e73\u6ed1\u4e14\u751f\u7269\u5b66\u4e00\u81f4\u7684\u6ce8\u610f\u529b\u56fe\u3002", "conclusion": "EAGLE-Net\u4f5c\u4e3a\u4e00\u4e2a\u901a\u7528\u53ef\u89e3\u91ca\u6846\u67b6\uff0c\u8865\u5145\u4e86\u57fa\u7840\u6a21\u578b\uff0c\u80fd\u591f\u6539\u5584\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u3001\u9884\u540e\u5efa\u6a21\u548c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u3002"}}
