{"id": "2508.21220", "pdf": "https://arxiv.org/pdf/2508.21220", "abs": "https://arxiv.org/abs/2508.21220", "authors": ["Manuel Reinhardt", "Age J. Tjalma", "Anne-Lena Moor", "Christoph Zechner", "Pieter Rein ten Wolde"], "title": "Mutual Information Rate -- Linear Noise Approximation and Exact Computation", "categories": ["q-bio.MN", "cs.IT", "math.IT", "physics.bio-ph"], "comment": "12 pages, 5 figures", "summary": "Efficient information processing is crucial for both living organisms and\nengineered systems. The mutual information rate, a core concept of information\ntheory, quantifies the amount of information shared between the trajectories of\ninput and output signals, and enables the quantification of information flow in\ndynamic systems. A common approach for estimating the mutual information rate\nis the Gaussian approximation which assumes that the input and output\ntrajectories follow Gaussian statistics. However, this method is limited to\nlinear systems, and its accuracy in nonlinear or discrete systems remains\nunclear. In this work, we assess the accuracy of the Gaussian approximation for\nnon-Gaussian systems by leveraging Path Weight Sampling (PWS), a recent\ntechnique for exactly computing the mutual information rate. In two case\nstudies, we examine the limitations of the Gaussian approximation. First, we\nfocus on discrete linear systems and demonstrate that, even when the system's\nstatistics are nearly Gaussian, the Gaussian approximation fails to accurately\nestimate the mutual information rate. Second, we explore a continuous diffusive\nsystem with a nonlinear transfer function, revealing significant deviations\nbetween the Gaussian approximation and the exact mutual information rate as\nnonlinearity increases. Our results provide a quantitative evaluation of the\nGaussian approximation's performance across different stochastic models and\nhighlight when more computationally intensive methods, such as PWS, are\nnecessary."}
{"id": "2508.21082", "pdf": "https://arxiv.org/pdf/2508.21082", "abs": "https://arxiv.org/abs/2508.21082", "authors": ["Shawnak Shivakumar", "Matthew Sandora"], "title": "ImmunoAI: Accelerated Antibody Discovery Using Gradient-Boosted Machine Learning with Thermodynamic-Hydrodynamic Descriptors and 3D Geometric Interface Topology", "categories": ["q-bio.QM", "cs.LG", "q-bio.BM"], "comment": "6 pages, accepted at IEEE International Conference on Electrical,\n  Computer, Communications and Mechatronics Engineering (ICECCME) '25", "summary": "Human metapneumovirus (hMPV) poses serious risks to pediatric, elderly, and\nimmunocompromised populations. Traditional antibody discovery pipelines require\n10-12 months, limiting their applicability for rapid outbreak response. This\nproject introduces ImmunoAI, a machine learning framework that accelerates\nantibody discovery by predicting high-affinity candidates using\ngradient-boosted models trained on thermodynamic, hydrodynamic, and 3D\ntopological interface descriptors. A dataset of 213 antibody-antigen complexes\nwas curated to extract geometric and physicochemical features, and a LightGBM\nregressor was trained to predict binding affinity with high precision. The\nmodel reduced the antibody candidate search space by 89%, and fine-tuning on\n117 SARS-CoV-2 binding pairs further reduced Root Mean Square Error (RMSE) from\n1.70 to 0.92. In the absence of an experimental structure for the hMPV A2.2\nvariant, AlphaFold2 was used to predict its 3D structure. The fine-tuned model\nidentified two optimal antibodies with predicted picomolar affinities targeting\nkey mutation sites (G42V and E96K), making them excellent candidates for\nexperimental testing. In summary, ImmunoAI shortens design cycles and enables\nfaster, structure-informed responses to viral outbreaks."}
{"id": "2508.21484", "pdf": "https://arxiv.org/pdf/2508.21484", "abs": "https://arxiv.org/abs/2508.21484", "authors": ["Clémence Métayer", "Annabelle Ballesta", "Julien Martinelli"], "title": "Data-driven Discovery of Digital Twins in Biomedical Research", "categories": ["q-bio.QM", "cs.LG", "stat.ML"], "comment": null, "summary": "Recent technological advances have expanded the availability of\nhigh-throughput biological datasets, enabling the reliable design of digital\ntwins of biomedical systems or patients. Such computational tools represent key\nreaction networks driving perturbation or drug response and can guide drug\ndiscovery and personalized therapeutics. Yet, their development still relies on\nlaborious data integration by the human modeler, so that automated approaches\nare critically needed. The success of data-driven system discovery in Physics,\nrooted in clean datasets and well-defined governing laws, has fueled interest\nin applying similar techniques in Biology, which presents unique challenges.\nHere, we reviewed methodologies for automatically inferring digital twins from\nbiological time series, which mostly involve symbolic or sparse regression. We\nevaluate algorithms according to eight biological and methodological\nchallenges, associated to noisy/incomplete data, multiple conditions, prior\nknowledge integration, latent variables, high dimensionality, unobserved\nvariable derivatives, candidate library design, and uncertainty quantification.\nUpon these criteria, sparse regression generally outperformed symbolic\nregression, particularly when using Bayesian frameworks. We further highlight\nthe emerging role of deep learning and large language models, which enable\ninnovative prior knowledge integration, though the reliability and consistency\nof such approaches must be improved. While no single method addresses all\nchallenges, we argue that progress in learning digital twins will come from\nhybrid and modular frameworks combining chemical reaction network-based\nmechanistic grounding, Bayesian uncertainty quantification, and the generative\nand knowledge integration capacities of deep learning. To support their\ndevelopment, we further propose a benchmarking framework to evaluate methods\nacross all challenges."}
{"id": "2508.21749", "pdf": "https://arxiv.org/pdf/2508.21749", "abs": "https://arxiv.org/abs/2508.21749", "authors": ["Mathias Weller", "Norbert Zeh"], "title": "When Many Trees Go to War", "categories": ["math.CO", "cs.DM", "q-bio.QM", "05C20", "G.2.1"], "comment": null, "summary": "It is known that any two trees on the same $n$ leaves can be displayed by a\nnetwork with $n-2$ reticulations, and there are two trees that cannot be\ndisplayed by a network with fewer reticulations. But how many reticulations are\nneeded to display multiple trees? For any set of $t$ trees on $n$ leaves, there\nis a trivial network with $(t - 1)n$ reticulations that displays them. To do\nbetter, we have to exploit common structure of the trees to embed non-trivial\nsubtrees of different trees into the same part of the network. In this paper,\nwe show that for $t \\in o(\\sqrt{\\lg n})$, there is a set of $t$ trees with\nvirtually no common structure that could be exploited. More precisely, we show\nfor any $t\\in o(\\sqrt{\\lg n})$, there are $t$ trees such that any network\ndisplaying them has $(t-1)n - o(n)$ reticulations. For $t \\in o(\\lg n)$, we\nobtain a slightly weaker bound. We also prove that already for $t = c\\lg n$,\nfor any constant $c > 0$, there is a set of $t$ trees that cannot be displayed\nby a network with $o(n \\lg n)$ reticulations, matching up to constant factors\nthe known upper bound of $O(n \\lg n)$ reticulations sufficient to display\n\\emph{all} trees with $n$ leaves. These results are based on simple counting\narguments and extend to unrooted networks and trees."}
