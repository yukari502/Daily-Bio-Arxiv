{"id": "2509.02639", "pdf": "https://arxiv.org/pdf/2509.02639", "abs": "https://arxiv.org/abs/2509.02639", "authors": ["Hojjat Torabi Goudarzi", "Maziyar Baran Pouyan"], "title": "Enhanced Single-Cell RNA-seq Embedding through Gene Expression and Data-Driven Gene-Gene Interaction Integration", "categories": ["q-bio.GN", "cs.AI", "68T07, 68T05, 62H30, 92C42, 62P10, 05C85", "I.2.6; I.5.3; I.5.1; H.2.8; J.3"], "comment": "33 pages, 9 figures, article", "summary": "Single-cell RNA sequencing (scRNA-seq) provides unprecedented insights into\ncellular heterogeneity, enabling detailed analysis of complex biological\nsystems at single-cell resolution. However, the high dimensionality and\ntechnical noise inherent in scRNA-seq data pose significant analytical\nchallenges. While current embedding methods focus primarily on gene expression\nlevels, they often overlook crucial gene-gene interactions that govern cellular\nidentity and function. To address this limitation, we present a novel embedding\napproach that integrates both gene expression profiles and data-driven\ngene-gene interactions. Our method first constructs a Cell-Leaf Graph (CLG)\nusing random forest models to capture regulatory relationships between genes,\nwhile simultaneously building a K-Nearest Neighbor Graph (KNNG) to represent\nexpression similarities between cells. These graphs are then combined into an\nEnriched Cell-Leaf Graph (ECLG), which serves as input for a graph neural\nnetwork to compute cell embeddings. By incorporating both expression levels and\ngene-gene interactions, our approach provides a more comprehensive\nrepresentation of cellular states. Extensive evaluation across multiple\ndatasets demonstrates that our method enhances the detection of rare cell\npopulations and improves downstream analyses such as visualization, clustering,\nand trajectory inference. This integrated approach represents a significant\nadvance in single-cell data analysis, offering a more complete framework for\nunderstanding cellular diversity and dynamics.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u5355\u7ec6\u80deRNA\u5e8f\u5217\u6570\u636e\u5d4c\u5165\u65b9\u6cd5\uff0c\u901a\u8fc7\u7edf\u5408\u57fa\u56e0\u8868\u8fbe\u548c\u57fa\u56e0-\u57fa\u56e0\u4ea4\u4e92\u4f5c\u7528\uff0c\u63d0\u9ad8\u4e86\u7a00\u6709\u7ec6\u80de\u7fa4\u68c0\u6d4b\u548c\u4e0b\u6e38\u5206\u6790\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5355\u7ec6\u80deRNA\u5e8f\u5217\u5d4c\u5165\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u57fa\u56e0\u8868\u8fbe\u6c34\u5e73\uff0c\u5ffd\u89c6\u4e86\u5173\u952e\u7684\u57fa\u56e0-\u57fa\u56e0\u4ea4\u4e92\u4f5c\u7528\uff0c\u800c\u8fd9\u4e9b\u4ea4\u4e92\u4f5c\u7528\u5bf9\u4e8e\u7ec6\u80de\u8bc6\u522b\u548c\u529f\u80fd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u9996\u5148\u4f7f\u7528\u968f\u673a\u68ee\u6797\u6a21\u578b\u6784\u5efa\u7ec6\u80de-\u53f6\u5b50\u56fe(CLG)\u6765\u6350\u6349\u57fa\u56e0\u95f4\u8c03\u63a7\u5173\u7cfb\uff0c\u540c\u65f6\u6784\u5efaK\u8fd1\u90bb\u56fe(KNNG)\u8868\u793a\u7ec6\u80de\u95f4\u8868\u8fbe\u76f8\u4f3c\u6027\uff0c\u7136\u540e\u5c06\u4e24\u8005\u7ed3\u5408\u6210\u4e30\u5bcc\u7ec6\u80de-\u53f6\u5b50\u56fe(ECLG)\uff0c\u6700\u540e\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u8ba1\u7b97\u7ec6\u80de\u5d4c\u5165\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u9ad8\u7a00\u6709\u7ec6\u80de\u7fa4\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5e76\u6539\u5584\u4e86\u53ef\u89c6\u5316\u3001\u805a\u7c7b\u548c\u8f68\u8ff9\u63a8\u65ad\u7b49\u4e0b\u6e38\u5206\u6790\u7684\u6027\u80fd\u3002", "conclusion": "\u8fd9\u79cd\u96c6\u6210\u65b9\u6cd5\u4ee3\u8868\u4e86\u5355\u7ec6\u80de\u6570\u636e\u5206\u6790\u9886\u57df\u7684\u91cd\u8981\u8fdb\u5c55\uff0c\u4e3a\u7406\u89e3\u7ec6\u80de\u5f02\u8d28\u6027\u548c\u52a8\u6001\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u66f4\u5b8c\u6574\u7684\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2509.02648", "pdf": "https://arxiv.org/pdf/2509.02648", "abs": "https://arxiv.org/abs/2509.02648", "authors": ["John Zobolas", "Anne-Marie George", "Alberto L\u00f3pez", "Sebastian Fischer", "Marc Becker", "Tero Aittokallio"], "title": "Optimizing Prognostic Biomarker Discovery in Pancreatic Cancer Through Hybrid Ensemble Feature Selection and Multi-Omics Data", "categories": ["q-bio.GN", "cs.LG", "q-bio.QM", "stat.AP"], "comment": "52 pages, 5 figures, 9 Supplementary Figures, 1 Supplementary Table", "summary": "Prediction of patient survival using high-dimensional multi-omics data\nrequires systematic feature selection methods that ensure predictive\nperformance, sparsity, and reliability for prognostic biomarker discovery. We\ndeveloped a hybrid ensemble feature selection (hEFS) approach that combines\ndata subsampling with multiple prognostic models, integrating both embedded and\nwrapper-based strategies for survival prediction. Omics features are ranked\nusing a voting-theory-inspired aggregation mechanism across models and\nsubsamples, while the optimal number of features is selected via a Pareto\nfront, balancing predictive accuracy and model sparsity without any\nuser-defined thresholds. When applied to multi-omics datasets from three\npancreatic cancer cohorts, hEFS identifies significantly fewer and more stable\nbiomarkers compared to the conventional, late-fusion CoxLasso models, while\nmaintaining comparable discrimination performance. Implemented within the\nopen-source mlr3fselect R package, hEFS offers a robust, interpretable, and\nclinically valuable tool for prognostic modelling and biomarker discovery in\nhigh-dimensional survival settings.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u6df7\u5408\u96c6\u6210\u7279\u5f81\u9009\u62e9\u65b9\u6cd5hEFS\uff0c\u7528\u4e8e\u9ad8\u7ef4\u591a\u7ec4\u5b66\u6570\u636e\u7684\u751f\u5b58\u9884\u6d4b\uff0c\u901a\u8fc7\u6295\u7968\u673a\u5236\u548c\u5e15\u7d2f\u6258\u524d\u6cbf\u9009\u62e9\u6700\u4f18\u7279\u5f81\uff0c\u5728\u80f0\u817a\u764c\u6570\u636e\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u7a00\u758f\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u9ad8\u7ef4\u591a\u7ec4\u5b66\u6570\u636e\u751f\u5b58\u9884\u6d4b\u9700\u8981\u7cfb\u7edf\u6027\u7684\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u786e\u4fdd\u9884\u6d4b\u6027\u80fd\u3001\u7a00\u758f\u6027\u548c\u53ef\u9760\u6027\uff0c\u4ee5\u53d1\u73b0\u9884\u540e\u751f\u7269\u6807\u5fd7\u7269\u3002", "method": "\u7ed3\u5408\u6570\u636e\u5b50\u91c7\u6837\u548c\u591a\u79cd\u9884\u540e\u6a21\u578b\u7684\u6df7\u5408\u96c6\u6210\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u6574\u5408\u5d4c\u5165\u5f0f\u4e0e\u5305\u88c5\u5f0f\u7b56\u7565\uff0c\u4f7f\u7528\u6295\u7968\u7406\u8bba\u805a\u5408\u673a\u5236\u5bf9\u7279\u5f81\u6392\u5e8f\uff0c\u901a\u8fc7\u5e15\u7d2f\u6258\u524d\u6cbf\u5e73\u8861\u9884\u6d4b\u7cbe\u5ea6\u548c\u6a21\u578b\u7a00\u758f\u6027\u6765\u9009\u62e9\u6700\u4f18\u7279\u5f81\u6570\u91cf\u3002", "result": "\u5728\u4e09\u4e2a\u80f0\u817a\u764c\u961f\u5217\u7684\u591a\u7ec4\u5b66\u6570\u636e\u4e2d\uff0chEFS\u76f8\u6bd4\u4f20\u7edf\u7684CoxLasso\u6a21\u578b\u8bc6\u522b\u51fa\u66f4\u5c11\u3001\u66f4\u7a33\u5b9a\u7684\u751f\u7269\u6807\u5fd7\u7269\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u5224\u522b\u6027\u80fd\u3002", "conclusion": "hEFS\u4e3a\u9ad8\u7ef4\u751f\u5b58\u73af\u5883\u4e0b\u7684\u9884\u540e\u5efa\u6a21\u548c\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5065\u3001\u53ef\u89e3\u91ca\u4e14\u5177\u6709\u4e34\u5e8a\u4ef7\u503c\u7684\u5de5\u5177\uff0c\u5df2\u96c6\u6210\u5230mlr3fselect R\u5305\u4e2d\u3002"}}
{"id": "2509.03330", "pdf": "https://arxiv.org/pdf/2509.03330", "abs": "https://arxiv.org/abs/2509.03330", "authors": ["Bnaya Gross", "Joseph Ehlert", "Vadim N. Gladyshev", "Joseph Loscalzo", "Albert-L\u00e1szl\u00f3 Barab\u00e1si"], "title": "Network-driven discovery of repurposable drugs targeting hallmarks of aging", "categories": ["q-bio.MN", "physics.soc-ph"], "comment": null, "summary": "Despite the thousands of genes implicated in age-related phenotypes,\neffective interventions for aging remain elusive, a lack of advance rooted in\nthe multifactorial nature of longevity and the functional interconnectedness of\nthe molecular components implicated in aging. Here, we introduce a network\nmedicine framework that integrates 2,358 longevity-associated genes onto the\nhuman interactome to identify existing drugs that can modulate aging processes.\nWe find that genes associated with each hallmark of aging form a connected\nsubgraph, or hallmark module, a discovery enabling us to measure the proximity\nof 6,442 clinically approved or experimental compounds to each hallmark. We\nthen introduce a transcription-based metric, $pAGE$, which evaluates whether\nthe drug-induced expression shifts reinforce or counteract known age-related\nexpression changes. By integrating network proximity and $pAGE$, we identify\nmultiple drug repurposing candidate that not only target specific hallmarks but\nact to reverse their aging-associated transcriptional changes. Our findings are\ninterpretable, revealing for each drug the molecular mechanisms through which\nit modulates the hallmark, offering an experimentally falsifiable framework to\nleverage genomic discoveries to accelerate drug repurposing for longevity.", "AI": {"tldr": "\u7f51\u7edc\u533b\u5b66\u6846\u67b6\u6574\u5408\u957f\u5bff\u76f8\u5173\u57fa\u56e0\u5230\u4eba\u7c7b\u76f8\u4e92\u4f5c\u7528\u7ec4\uff0c\u8bc6\u522b\u53ef\u8c03\u8282\u8870\u8001\u8fc7\u7a0b\u7684\u73b0\u6709\u836f\u7269\uff0c\u53d1\u73b0\u836f\u7269\u53ef\u9006\u8f6c\u8870\u8001\u76f8\u5173\u8f6c\u5f55\u53d8\u5316", "motivation": "\u5c3d\u7ba1\u6709\u6570\u5343\u4e2a\u57fa\u56e0\u4e0e\u5e74\u9f84\u76f8\u5173\u8868\u578b\u6709\u5173\uff0c\u4f46\u7531\u4e8e\u957f\u5bff\u7684\u591a\u56e0\u7d20\u6027\u8d28\u548c\u8870\u8001\u5206\u5b50\u6210\u5206\u7684\u529f\u80fd\u4e92\u8fde\u6027\uff0c\u6709\u6548\u7684\u8870\u8001\u5e72\u9884\u63aa\u65bd\u4ecd\u7136\u96be\u4ee5\u627e\u5230", "method": "\u6574\u54082,358\u4e2a\u957f\u5bff\u76f8\u5173\u57fa\u56e0\u5230\u4eba\u7c7b\u76f8\u4e92\u4f5c\u7528\u7ec4\uff0c\u6784\u5efa\u8870\u8001\u6807\u5fd7\u6a21\u5757\uff0c\u6d4b\u91cf6,442\u79cd\u5316\u5408\u7269\u4e0e\u6bcf\u4e2a\u6807\u5fd7\u7684\u63a5\u8fd1\u5ea6\uff0c\u5f15\u5165\u8f6c\u5f55\u6307\u6807pAGE\u8bc4\u4f30\u836f\u7269\u8bf1\u5bfc\u8868\u8fbe\u53d8\u5316", "result": "\u8bc6\u522b\u51fa\u591a\u4e2a\u836f\u7269\u91cd\u5b9a\u4f4d\u5019\u9009\uff0c\u8fd9\u4e9b\u836f\u7269\u4e0d\u4ec5\u9776\u5411\u7279\u5b9a\u8870\u8001\u6807\u5fd7\uff0c\u8fd8\u80fd\u9006\u8f6c\u5176\u8870\u8001\u76f8\u5173\u8f6c\u5f55\u53d8\u5316", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u5b9e\u9a8c\u9a8c\u8bc1\u7684\u6846\u67b6\uff0c\u5229\u7528\u57fa\u56e0\u7ec4\u53d1\u73b0\u52a0\u901f\u836f\u7269\u91cd\u5b9a\u4f4d\u4ee5\u5ef6\u957f\u5bff\u547d\uff0c\u63ed\u793a\u4e86\u6bcf\u79cd\u836f\u7269\u8c03\u8282\u8870\u8001\u6807\u5fd7\u7684\u5206\u5b50\u673a\u5236"}}
{"id": "2509.02594", "pdf": "https://arxiv.org/pdf/2509.02594", "abs": "https://arxiv.org/abs/2509.02594", "authors": ["Sandhanakrishnan Ravichandran", "Shivesh Kumar", "Rogerio Corga Da Silva", "Miguel Romano", "Reinhard Berkels", "Michiel van der Heijden", "Olivier Fail", "Valentine Emmanuel Gnanapragasam"], "title": "OpenAIs HealthBench in Action: Evaluating an LLM-Based Medical Assistant on Realistic Clinical Queries", "categories": ["q-bio.QM", "cs.AI", "cs.ET", "cs.IR"], "comment": "13 pages, two graphs", "summary": "Evaluating large language models (LLMs) on their ability to generate\nhigh-quality, accurate, situationally aware answers to clinical questions\nrequires going beyond conventional benchmarks to assess how these systems\nbehave in complex, high-stake clincal scenarios. Traditional evaluations are\noften limited to multiple-choice questions that fail to capture essential\ncompetencies such as contextual reasoning, awareness and uncertainty handling\netc. To address these limitations, we evaluate our agentic, RAG-based clinical\nsupport assistant, DR.INFO, using HealthBench, a rubric-driven benchmark\ncomposed of open-ended, expert-annotated health conversations. On the Hard\nsubset of 1,000 challenging examples, DR.INFO achieves a HealthBench score of\n0.51, substantially outperforming leading frontier LLMs (GPT-5, o3, Grok 3,\nGPT-4, Gemini 2.5, etc.) across all behavioral axes (accuracy, completeness,\ninstruction following, etc.). In a separate 100-sample evaluation against\nsimilar agentic RAG assistants (OpenEvidence, Pathway.md), it maintains a\nperformance lead with a health-bench score of 0.54. These results highlight\nDR.INFOs strengths in communication, instruction following, and accuracy, while\nalso revealing areas for improvement in context awareness and completeness of a\nresponse. Overall, the findings underscore the utility of behavior-level,\nrubric-based evaluation for building a reliable and trustworthy AI-enabled\nclinical support assistant.", "AI": {"tldr": "DR.INFO\u4e34\u5e8a\u652f\u6301\u52a9\u624b\u5728HealthBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u8d85\u8d8a\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5176\u4ed6RAG\u52a9\u624b\uff0c\u5c55\u793a\u4e86\u5728\u4e34\u5e8a\u573a\u666f\u4e2d\u7684\u5f3a\u5927\u80fd\u529b", "motivation": "\u4f20\u7edf\u4e34\u5e8a\u8bc4\u4f30\u65b9\u6cd5\u5c40\u9650\u4e8e\u9009\u62e9\u9898\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30LLM\u5728\u590d\u6742\u9ad8\u98ce\u9669\u4e34\u5e8a\u573a\u666f\u4e2d\u7684\u60c5\u5883\u63a8\u7406\u3001\u610f\u8bc6\u8bc6\u522b\u548c\u4e0d\u786e\u5b9a\u6027\u5904\u7406\u7b49\u5173\u952e\u80fd\u529b", "method": "\u4f7f\u7528HealthBench\u57fa\u51c6\uff08\u57fa\u4e8e\u4e13\u5bb6\u6807\u6ce8\u7684\u5f00\u653e\u5f0f\u5065\u5eb7\u5bf9\u8bdd\u7684\u8bc4\u5206\u9a71\u52a8\u57fa\u51c6\uff09\u8bc4\u4f30DR.INFO\u4ee3\u7406\u5f0fRAG\u4e34\u5e8a\u652f\u6301\u52a9\u624b\uff0c\u5305\u542b1000\u4e2a\u56f0\u96be\u6837\u672c\u548c100\u4e2a\u5bf9\u6bd4\u6837\u672c", "result": "DR.INFO\u5728\u56f0\u96be\u5b50\u96c6\u4e0a\u83b7\u5f970.51\u5206\uff0c\u663e\u8457\u8d85\u8d8aGPT-5\u3001o3\u3001Grok 3\u3001GPT-4\u3001Gemini 2.5\u7b49\u524d\u6cbf\u6a21\u578b\uff1b\u5728100\u6837\u672c\u5bf9\u6bd4\u4e2d\u4fdd\u6301\u9886\u5148\uff080.54\u5206\uff09\uff0c\u5728\u6c9f\u901a\u3001\u6307\u4ee4\u9075\u5faa\u548c\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u7a81\u51fa", "conclusion": "\u57fa\u4e8e\u884c\u4e3a\u5c42\u9762\u7684\u8bc4\u5206\u9a71\u52a8\u8bc4\u4f30\u65b9\u6cd5\u5bf9\u4e8e\u6784\u5efa\u53ef\u9760\u53ef\u4fe1\u7684AI\u4e34\u5e8a\u652f\u6301\u52a9\u624b\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5728\u60c5\u5883\u610f\u8bc6\u548c\u56de\u7b54\u5b8c\u6574\u6027\u65b9\u9762\u4ecd\u9700\u6539\u8fdb"}}
{"id": "2509.03336", "pdf": "https://arxiv.org/pdf/2509.03336", "abs": "https://arxiv.org/abs/2509.03336", "authors": ["Sharanya Manoharan", "Balu Bhasuran", "Oviya Ramalakshmi Iyyappan", "Mohamed Saleem Abdul Shukkoor", "Malathi Sellapan", "Kalpana Raja"], "title": "AI-Driven Drug Repurposing through miRNA-mRNA Relation", "categories": ["q-bio.MN", "cs.IR", "q-bio.QM"], "comment": null, "summary": "miRNA mRNA relations are closely linked to several biological processes and\ndisease mechanisms In a recent study we tested the performance of large\nlanguage models LLMs on extracting miRNA mRNA relations from PubMed PubMedBERT\nachieved the best performance of 0.783 F1 score for miRNA mRNA Interaction\nCorpus MMIC Here we first applied the finetuned PubMedBERT model to extract\nmiRNA mRNA relations from PubMed for chronic obstructive pulmonary disease COPD\nAlzheimers disease AD stroke type 2 diabetes mellitus T2DM chronic liver\ndisease and cancer Next we retrieved miRNA drug relations using KinderMiner a\nliterature mining tool for relation extraction Then we constructed three\ninteraction networks 1 disease centric network 2 drug centric network and 3\nmiRNA centric network comprising 3497 nodes and 16417 edges organized as a\ndirected graph to capture complex biological relationships Finally we validated\nthe drugs using MIMIC IV Our integrative approach revealed both established and\nnovel candidate drugs for diseases under study through 595 miRNA drug relations\nextracted from PubMed To the best of our knowledge this is the first study to\nsystematically extract and visualize relationships among four distinct\nbiomedical entities miRNA mRNA drug and disease", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528PubMedBERT\u548cKinderMiner\u4ecePubMed\u4e2d\u63d0\u53d6miRNA-mRNA\u5173\u7cfb\u548cmiRNA-\u836f\u7269\u5173\u7cfb\uff0c\u6784\u5efa\u4e86\u5305\u542b3497\u4e2a\u8282\u70b9\u548c16417\u6761\u8fb9\u7684\u4e09\u79cd\u4ea4\u4e92\u7f51\u7edc\uff0c\u9a8c\u8bc1\u4e86595\u4e2amiRNA-\u836f\u7269\u5173\u7cfb\uff0c\u4e3a\u591a\u79cd\u75be\u75c5\u53d1\u73b0\u4e86\u5df2\u5efa\u7acb\u548c\u65b0\u7684\u5019\u9009\u836f\u7269\u3002", "motivation": "miRNA-mRNA\u5173\u7cfb\u4e0e\u591a\u79cd\u751f\u7269\u8fc7\u7a0b\u548c\u75be\u75c5\u673a\u5236\u5bc6\u5207\u76f8\u5173\uff0c\u4f46\u7cfb\u7edf\u6027\u5730\u63d0\u53d6\u548c\u53ef\u89c6\u5316miRNA\u3001mRNA\u3001\u836f\u7269\u548c\u75be\u75c5\u56db\u79cd\u4e0d\u540c\u751f\u7269\u533b\u5b66\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb\u5c1a\u672a\u6709\u7814\u7a76\u3002", "method": "1) \u4f7f\u7528\u5fae\u8c03\u7684PubMedBERT\u6a21\u578b\u4ecePubMed\u63d0\u53d6COPD\u3001AD\u3001\u4e2d\u98ce\u3001T2DM\u3001\u6162\u6027\u809d\u75c5\u548c\u764c\u75c7\u7684miRNA-mRNA\u5173\u7cfb\uff1b2) \u4f7f\u7528KinderMiner\u63d0\u53d6miRNA-\u836f\u7269\u5173\u7cfb\uff1b3) \u6784\u5efa\u75be\u75c5\u4e2d\u5fc3\u7f51\u7edc\u3001\u836f\u7269\u4e2d\u5fc3\u7f51\u7edc\u548cmiRNA\u4e2d\u5fc3\u7f51\u7edc\u4e09\u79cd\u4ea4\u4e92\u7f51\u7edc\uff1b4) \u4f7f\u7528MIMIC IV\u9a8c\u8bc1\u836f\u7269\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b3497\u4e2a\u8282\u70b9\u548c16417\u6761\u8fb9\u7684\u6709\u5411\u56fe\u7f51\u7edc\uff0c\u63d0\u53d6\u4e86595\u4e2amiRNA-\u836f\u7269\u5173\u7cfb\uff0c\u53d1\u73b0\u4e86\u5df2\u5efa\u7acb\u548c\u65b0\u7684\u5019\u9009\u836f\u7269\u3002PubMedBERT\u5728MMIC\u8bed\u6599\u5e93\u4e0a\u8fbe\u5230\u4e860.783\u7684F1\u5206\u6570\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u7cfb\u7edf\u63d0\u53d6\u548c\u53ef\u89c6\u5316miRNA\u3001mRNA\u3001\u836f\u7269\u548c\u75be\u75c5\u56db\u79cd\u751f\u7269\u533b\u5b66\u5b9e\u4f53\u5173\u7cfb\u7684\u7814\u7a76\uff0c\u6574\u5408\u65b9\u6cd5\u6210\u529f\u63ed\u793a\u4e86\u591a\u79cd\u75be\u75c5\u7684\u5019\u9009\u836f\u7269\uff0c\u4e3a\u75be\u75c5\u6cbb\u7597\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2509.02606", "pdf": "https://arxiv.org/pdf/2509.02606", "abs": "https://arxiv.org/abs/2509.02606", "authors": ["Thanh Tung Khuat", "Johnny Peng", "Robert Bassett", "Ellen Otte", "Bogdan Gabrys"], "title": "Lessons Learned from Deploying Adaptive Machine Learning Agents with Limited Data for Real-time Cell Culture Process Monitoring", "categories": ["q-bio.QM", "cs.LG", "A.1; J.3; I.2.0; I.2.6; I.2.m; I.5.4"], "comment": null, "summary": "This study explores the deployment of three machine learning (ML) approaches\nfor real-time prediction of glucose, lactate, and ammonium concentrations in\ncell culture processes, using Raman spectroscopy as input features. The\nresearch addresses challenges associated with limited data availability and\nprocess variability, providing a comparative analysis of pretrained models,\njust-in-time learning (JITL), and online learning algorithms. Two industrial\ncase studies are presented to evaluate the impact of varying bioprocess\nconditions on model performance. The findings highlight the specific conditions\nunder which pretrained models demonstrate superior predictive accuracy and\nidentify scenarios where JITL or online learning approaches are more effective\nfor adaptive process monitoring. This study also highlights the critical\nimportance of updating the deployed models/agents with the latest offline\nanalytical measurements during bioreactor operations to maintain the model\nperformance against the changes in cell growth behaviours and operating\nconditions throughout the bioreactor run. Additionally, the study confirms the\nusefulness of a simple mixture-of-experts framework in achieving enhanced\naccuracy and robustness for real-time predictions of metabolite concentrations\nbased on Raman spectral data. These insights contribute to the development of\nrobust strategies for the efficient deployment of ML models in dynamic and\nchanging biomanufacturing environments.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u4e09\u79cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff08\u9884\u8bad\u7ec3\u6a21\u578b\u3001\u5373\u65f6\u5b66\u4e60\u548c\u5728\u7ebf\u5b66\u4e60\uff09\u5728\u7ec6\u80de\u57f9\u517b\u8fc7\u7a0b\u4e2d\u57fa\u4e8e\u62c9\u66fc\u5149\u8c31\u5b9e\u65f6\u9884\u6d4b\u4ee3\u8c22\u7269\u6d53\u5ea6\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u4e24\u4e2a\u5de5\u4e1a\u6848\u4f8b\u7814\u7a76\u5206\u6790\u4e86\u4e0d\u540c\u751f\u7269\u5de5\u827a\u6761\u4ef6\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u89e3\u51b3\u751f\u7269\u5236\u9020\u8fc7\u7a0b\u4e2d\u6570\u636e\u6709\u9650\u548c\u5de5\u827a\u53d8\u5f02\u6027\u5e26\u6765\u7684\u6311\u6218\uff0c\u5f00\u53d1\u80fd\u591f\u9002\u5e94\u52a8\u6001\u53d8\u5316\u73af\u5883\u7684\u9c81\u68d2\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5b9e\u73b0\u4ee3\u8c22\u7269\u6d53\u5ea6\u7684\u5b9e\u65f6\u51c6\u786e\u9884\u6d4b\u3002", "method": "\u4f7f\u7528\u4e09\u79cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff1a\u9884\u8bad\u7ec3\u6a21\u578b\u3001\u5373\u65f6\u5b66\u4e60(JITL)\u548c\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\uff0c\u57fa\u4e8e\u62c9\u66fc\u5149\u8c31\u6570\u636e\u9884\u6d4b\u8461\u8404\u7cd6\u3001\u4e73\u9178\u548c\u94f5\u79bb\u5b50\u6d53\u5ea6\u3002\u901a\u8fc7\u4e24\u4e2a\u5de5\u4e1a\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u4e0d\u540c\u751f\u7269\u5de5\u827a\u6761\u4ef6\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u800c\u5373\u65f6\u5b66\u4e60\u548c\u5728\u7ebf\u5b66\u4e60\u65b9\u6cd5\u5728\u9700\u8981\u81ea\u9002\u5e94\u8fc7\u7a0b\u76d1\u63a7\u7684\u573a\u666f\u4e2d\u66f4\u6709\u6548\u3002\u7814\u7a76\u8fd8\u8bc1\u5b9e\u4e86\u6df7\u5408\u4e13\u5bb6\u6846\u67b6\u5728\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u751f\u7269\u53cd\u5e94\u5668\u8fd0\u884c\u671f\u95f4\u4f7f\u7528\u6700\u65b0\u79bb\u7ebf\u5206\u6790\u6d4b\u91cf\u66f4\u65b0\u6a21\u578b\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u5728\u52a8\u6001\u53d8\u5316\u7684\u751f\u7269\u5236\u9020\u73af\u5883\u4e2d\u6709\u6548\u90e8\u7f72\u673a\u5668\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u9c81\u68d2\u7b56\u7565\u3002\u6df7\u5408\u4e13\u5bb6\u6846\u67b6\u80fd\u591f\u663e\u8457\u63d0\u5347\u57fa\u4e8e\u62c9\u66fc\u5149\u8c31\u6570\u636e\u7684\u4ee3\u8c22\u7269\u6d53\u5ea6\u5b9e\u65f6\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2509.02610", "pdf": "https://arxiv.org/pdf/2509.02610", "abs": "https://arxiv.org/abs/2509.02610", "authors": ["Jonathan Feldman", "Tal Feldman"], "title": "Resilient Biosecurity in the Era of AI-Enabled Bioweapons", "categories": ["q-bio.QM", "cs.AI"], "comment": null, "summary": "Recent advances in generative biology have enabled the design of novel\nproteins, creating significant opportunities for drug discovery while also\nintroducing new risks, including the potential development of synthetic\nbioweapons. Existing biosafety measures primarily rely on inference-time\nfilters such as sequence alignment and protein-protein interaction (PPI)\nprediction to detect dangerous outputs. In this study, we evaluate the\nperformance of three leading PPI prediction tools: AlphaFold 3, AF3Complex, and\nSpatialPPIv2. These models were tested on well-characterized viral-host\ninteractions, such as those involving Hepatitis B and SARS-CoV-2. Despite being\ntrained on many of the same viruses, the models fail to detect a substantial\nnumber of known interactions. Strikingly, none of the tools successfully\nidentify any of the four experimentally validated SARS-CoV-2 mutants with\nconfirmed binding. These findings suggest that current predictive filters are\ninadequate for reliably flagging even known biological threats and are even\nmore unlikely to detect novel ones. We argue for a shift toward\nresponse-oriented infrastructure, including rapid experimental validation,\nadaptable biomanufacturing, and regulatory frameworks capable of operating at\nthe speed of AI-driven developments.", "AI": {"tldr": "\u5f53\u524dPPI\u9884\u6d4b\u5de5\u5177\uff08AlphaFold 3\u3001AF3Complex\u3001SpatialPPIv2\uff09\u5728\u68c0\u6d4b\u5df2\u77e5\u75c5\u6bd2-\u5bbf\u4e3b\u76f8\u4e92\u4f5c\u7528\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u53ef\u9760\u8bc6\u522b\u751f\u7269\u5a01\u80c1\uff0c\u9700\u8981\u8f6c\u5411\u54cd\u5e94\u5bfc\u5411\u7684\u57fa\u7840\u8bbe\u65bd\u3002", "motivation": "\u8bc4\u4f30\u73b0\u6709\u751f\u7269\u5b89\u5168\u63aa\u65bd\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u7684\u63a8\u7406\u65f6\u8fc7\u6ee4\u5668\uff0c\u4ee5\u5e94\u5bf9\u751f\u6210\u751f\u7269\u5b66\u5e26\u6765\u7684\u65b0\u578b\u751f\u7269\u6b66\u5668\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u4e09\u79cd\u9886\u5148\u7684PPI\u9884\u6d4b\u5de5\u5177\uff08AlphaFold 3\u3001AF3Complex\u3001SpatialPPIv2\uff09\u6d4b\u8bd5\u5df2\u77e5\u7684\u75c5\u6bd2-\u5bbf\u4e3b\u76f8\u4e92\u4f5c\u7528\uff0c\u5305\u62ec\u4e59\u578b\u809d\u708e\u548cSARS-CoV-2\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u8fd9\u4e9b\u6a21\u578b\u672a\u80fd\u68c0\u6d4b\u5230\u5927\u91cf\u5df2\u77e5\u76f8\u4e92\u4f5c\u7528\uff0c\u7279\u522b\u662f\u65e0\u6cd5\u8bc6\u522b\u4efb\u4f55\u7ecf\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u7684SARS-CoV-2\u7a81\u53d8\u4f53\u7684\u7ed3\u5408\u80fd\u529b\uff0c\u8868\u660e\u73b0\u6709\u9884\u6d4b\u8fc7\u6ee4\u5668\u4e0d\u53ef\u9760\u3002", "conclusion": "\u9700\u8981\u8f6c\u5411\u54cd\u5e94\u5bfc\u5411\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u5305\u62ec\u5feb\u901f\u5b9e\u9a8c\u9a8c\u8bc1\u3001\u9002\u5e94\u6027\u751f\u7269\u5236\u9020\u548c\u80fd\u591f\u8ddf\u4e0aAI\u53d1\u5c55\u901f\u5ea6\u7684\u76d1\u7ba1\u6846\u67b6\u3002"}}
{"id": "2509.02626", "pdf": "https://arxiv.org/pdf/2509.02626", "abs": "https://arxiv.org/abs/2509.02626", "authors": ["Abhigyan Sarkar", "Boris Rubinsky"], "title": "A Wrist-Worn Multimodal Reaction Time Monitoring Device for Ecologically-Valid Cognitive Assessment", "categories": ["q-bio.QM"], "comment": null, "summary": "Reaction time (RT) is a fundamental measure in cognitive and\nneurophysiological assessment, yet most existing RT systems require active user\nengagement and controlled environments, limiting their use in real-world\nsettings. This paper introduces a low cost wrist-worn instrumentation platform\ndesigned to capture human reaction times (RT) across auditory, visual, and\nhaptic modalities with millisecond latency in real-world conditions. The device\nintegrates synchronized stimulus delivery and event detection within a compact\nmicrocontroller-based system, eliminating the need for user focus or examiner\nsupervision. Emphasizing measurement fidelity, we detail the hardware\narchitecture, timing control algorithms, and calibration methodology used to\nensure consistent latency handling across modalities. A proof-of-concept study\nwith six adult participants compares this system against a benchmark\ncomputer-based RT tool across five experimental conditions. The results confirm\nthat the device achieves statistically comparable RT measurements with strong\nmodality consistency, supporting its potential as a novel tool for\nnon-obtrusive cognitive monitoring. Contributions include a validated design\nfor time-critical behavioral measurement and a demonstration of its robustness\nin unconstrained, ambient-noise environments. It offers a powerful new tool for\ncontinuous, real-world cognitive monitoring and has significant potential for\nboth research and clinical applications.", "AI": {"tldr": "\u5f00\u53d1\u4f4e\u6210\u672c\u8155\u6234\u5f0f\u53cd\u5e94\u65f6\u95f4\u6d4b\u91cf\u8bbe\u5907\uff0c\u53ef\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u901a\u8fc7\u542c\u89c9\u3001\u89c6\u89c9\u548c\u89e6\u89c9\u6a21\u6001\u8fdb\u884c\u6beb\u79d2\u7ea7\u5ef6\u8fdf\u7684\u8ba4\u77e5\u76d1\u6d4b", "motivation": "\u73b0\u6709\u53cd\u5e94\u65f6\u95f4\u6d4b\u91cf\u7cfb\u7edf\u9700\u8981\u7528\u6237\u4e3b\u52a8\u53c2\u4e0e\u548c\u53d7\u63a7\u73af\u5883\uff0c\u9650\u5236\u4e86\u5728\u771f\u5b9e\u4e16\u754c\u573a\u666f\u4e2d\u7684\u5e94\u7528\uff0c\u9700\u8981\u5f00\u53d1\u975e\u4fb5\u5165\u5f0f\u7684\u5b9e\u65f6\u76d1\u6d4b\u5de5\u5177", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u5fae\u63a7\u5236\u5668\u7684\u7d27\u51d1\u7cfb\u7edf\uff0c\u96c6\u6210\u540c\u6b65\u523a\u6fc0\u4f20\u9012\u548c\u4e8b\u4ef6\u68c0\u6d4b\uff0c\u91c7\u7528\u786c\u4ef6\u67b6\u6784\u3001\u65f6\u5e8f\u63a7\u5236\u7b97\u6cd5\u548c\u6821\u51c6\u65b9\u6cd5\u786e\u4fdd\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u5ef6\u8fdf\u5904\u7406", "result": "6\u540d\u6210\u4eba\u53c2\u4e0e\u7684\u6982\u5ff5\u9a8c\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u4e0e\u57fa\u51c6\u8ba1\u7b97\u673a\u5de5\u5177\u5728\u4e94\u79cd\u5b9e\u9a8c\u6761\u4ef6\u4e0b\u83b7\u5f97\u7edf\u8ba1\u53ef\u6bd4\u7684\u53cd\u5e94\u65f6\u95f4\u6d4b\u91cf\u7ed3\u679c\uff0c\u5177\u6709\u5f3a\u5927\u7684\u6a21\u6001\u4e00\u81f4\u6027", "conclusion": "\u8be5\u8bbe\u5907\u4e3a\u65f6\u95f4\u5173\u952e\u884c\u4e3a\u6d4b\u91cf\u63d0\u4f9b\u4e86\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u8bbe\u8ba1\uff0c\u5728\u65e0\u7ea6\u675f\u73af\u5883\u566a\u58f0\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u9c81\u68d2\u6027\uff0c\u4e3a\u8fde\u7eed\u5b9e\u65f6\u8ba4\u77e5\u76d1\u6d4b\u63d0\u4f9b\u4e86\u5f3a\u5927\u65b0\u5de5\u5177\uff0c\u5177\u6709\u7814\u7a76\u548c\u4e34\u5e8a\u5e94\u7528\u6f5c\u529b"}}
{"id": "2509.02940", "pdf": "https://arxiv.org/pdf/2509.02940", "abs": "https://arxiv.org/abs/2509.02940", "authors": ["Brittany A. Laing", "M. Gabriela M\u00e1ngano", "Luis A. Buatois", "Glenn A. Brock", "Romain Gougeon", "Zoe Vestrum", "Luke C. Strotz", "Lyndon Koens"], "title": "Remember when? Deciphering Ediacaran-Cambrian Metazoan behaviour and temporal memory using fossil movement paths", "categories": ["physics.bio-ph", "q-bio.PE", "q-bio.QM"], "comment": null, "summary": "Evaluating the timing and trajectory of sensory system innovations is crucial\nfor understanding the increase in phylogenetic, behavioural, and ecological\ndiversity during the Ediacaran-Cambrian transition. Elucidation of sensory\nadaptations has relied on either body-fossil evidence based on anatomical\nfeatures or qualitative descriptions of trace-fossil morphology, leaving a gap\nin the record of sensory system innovations between the development of basic\nsensory capacities and that of more advanced sensory organs and brains. Here,\nwe examine fossil movement trajectories of Ediacaran and Cambrian grazers for\nthe presence of autocorrelation. Our analysis reveals a lack of temporal\ncorrelation in the studied Ediacaran trajectories and its presence in both\nanalysed Cambrian trajectories, indicating time-tuned behaviours were in place\nby the early Cambrian. These results support the Cambrian Information\nRevolution hypothesis and indicates that increases in cognitive complexity and\nbehavioural strategies were yet another important evolutionary innovation that\noccurred during the Ediacaran Cambrian transition.", "AI": {"tldr": "\u901a\u8fc7\u5206\u6790\u57c3\u8fea\u5361\u62c9\u7eaa\u5481\u5bd2\u6b66\u7eaa\u653e\u7267\u52a8\u7269\u79fb\u52a8\u8f68\u8ff9\u7684\u81ea\u76f8\u5173\u6027\uff0c\u53d1\u73b0\u5bd2\u6b66\u7eaa\u5df2\u51fa\u73b0\u65f6\u95f4\u8c03\u8282\u884c\u4e3a\uff0c\u652f\u6301\u5bd2\u6b66\u7eaa\u4fe1\u606f\u9769\u547d\u5047\u8bbef3002", "motivation": "\u8bc4\u4f30\u611f\u5b98\u7cfb\u7edf\u521b\u65b0\u7684\u65f6\u95f4\u5481\u8f68\u8ff9\uff0c\u4ee5\u7406\u89e3\u57c3\u8fea\u5361\u62c9\u7eaa-\u5bd2\u6b66\u7eaa\u8fc7\u6e21\u671f\u95f4\u7cfb\u7edf\u53d1\u751f\u5b66\u3001\u884c\u4e3a\u5481\u751f\u6001\u591a\u6837\u6027\u7684\u589e\u52a0\u3002", "method": "\u68c0\u67e5\u57c3\u8fea\u5361\u62c9\u7eaa\u5481\u5bd2\u6b66\u7eaa\u653e\u7267\u52a8\u7269\u7684\u5316\u77f3\u79fb\u52a8\u8f68\u8ff9\u7684\u81ea\u76f8\u5173\u6027\u5b58\u5728\u60c5\u51b5\u3002", "result": "\u5728\u7814\u7a76\u7684\u57c3\u8fea\u5361\u62c9\u7eaa\u8f68\u8ff9\u4e2d\u7f3a\u4e4f\u65f6\u95f4\u76f8\u5173\u6027\uff0c\u800c\u5728\u5206\u6790\u7684\u5bd2\u6b66\u7eaa\u8f68\u8ff9\u4e2d\u5b58\u5728\u65f6\u95f4\u76f8\u5173\u6027\uff0c\u8868\u660e\u65f6\u95f4\u8c03\u8282\u884c\u4e3a\u5728\u65e9\u671f\u5bd2\u6b66\u7eaa\u5df2\u5f62\u6210\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u652f\u6301\u5bd2\u6b66\u7eaa\u4fe1\u606f\u9769\u547d\u5047\u8bbef3002\uff0c\u8868\u660e\u8ba4\u77e5\u590d\u6742\u6027\u5481\u884c\u4e3a\u7b56\u7565\u7684\u589e\u52a0\u662f\u57c3\u8fea\u5361\u62c9\u7eaa-\u5bd2\u6b66\u7eaa\u8fc7\u6e21\u671f\u53d1\u751f\u7684\u53e6\u4e00\u4e2a\u91cd\u8981\u8fdb\u5316\u521b\u65b0\u3002"}}
{"id": "2509.03351", "pdf": "https://arxiv.org/pdf/2509.03351", "abs": "https://arxiv.org/abs/2509.03351", "authors": ["Natalia Flechas Manrique", "Alberto Mart\u00ednez", "Elena L\u00f3pez-Mart\u00ednez", "Luc Andrea", "Rom\u00e1n Orus", "Aitor Manteca", "Aitziber L. Cortajarena", "Lloren\u00e7 Espinosa-Portal\u00e9s"], "title": "epiGPTope: A machine learning-based epitope generator and classifier", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": "11 pages, 4 figures. Supplementary Information with 5 pages, 4\n  figures", "summary": "Epitopes are short antigenic peptide sequences which are recognized by\nantibodies or immune cell receptors. These are central to the development of\nimmunotherapies, vaccines, and diagnostics. However, the rational design of\nsynthetic epitope libraries is challenging due to the large combinatorial\nsequence space, $20^n$ combinations for linear epitopes of n amino acids,\nmaking screening and testing unfeasible, even with high throughput experimental\ntechniques. In this study, we present a large language model, epiGPTope,\npre-trained on protein data and specifically fine-tuned on linear epitopes,\nwhich for the first time can directly generate novel epitope-like sequences,\nwhich are found to possess statistical properties analogous to the ones of\nknown epitopes. This generative approach can be used to prepare libraries of\nepitope candidate sequences. We further train statistical classifiers to\npredict whether an epitope sequence is of bacterial or viral origin, thus\nnarrowing the candidate library and increasing the likelihood of identifying\nspecific epitopes. We propose that such combination of generative and\npredictive models can be of assistance in epitope discovery. The approach uses\nonly primary amino acid sequences of linear epitopes, bypassing the need for a\ngeometric framework or hand-crafted features of the sequences. By developing a\nmethod to create biologically feasible sequences, we anticipate faster and more\ncost-effective generation and screening of synthetic epitopes, with relevant\napplications in the development of new biotechnologies.", "AI": {"tldr": "\u63d0\u51fa\u4e86epiGPTope\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u751f\u6210\u65b0\u578b\u8868\u4f4d\u5e8f\u5217\uff0c\u7ed3\u5408\u5206\u7c7b\u5668\u9884\u6d4b\u7ec6\u83cc/\u75c5\u6bd2\u6765\u6e90\uff0c\u52a0\u901f\u8868\u4f4d\u53d1\u73b0\u548c\u7b5b\u9009\u3002", "motivation": "\u8868\u4f4d\u8bbe\u8ba1\u9762\u4e34\u7ec4\u5408\u5e8f\u5217\u7a7a\u95f4\u5de8\u5927\u7684\u6311\u6218\uff0c\u4f20\u7edf\u7b5b\u9009\u65b9\u6cd5\u4e0d\u53ef\u884c\uff0c\u9700\u8981\u65b0\u7684\u751f\u6210\u65b9\u6cd5\u6765\u521b\u5efa\u53ef\u884c\u7684\u8868\u4f4d\u5019\u9009\u5e93\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u6570\u636e\u7684\u8bed\u8a00\u6a21\u578bepiGPTope\uff0c\u5728\u7ebf\u6027\u8868\u4f4d\u6570\u636e\u4e0a\u5fae\u8c03\uff0c\u76f4\u63a5\u751f\u6210\u8868\u4f4d\u6837\u5e8f\u5217\uff0c\u5e76\u8bad\u7ec3\u7edf\u8ba1\u5206\u7c7b\u5668\u9884\u6d4b\u5e8f\u5217\u6765\u6e90\u3002", "result": "\u751f\u6210\u7684\u5e8f\u5217\u5177\u6709\u4e0e\u5df2\u77e5\u8868\u4f4d\u76f8\u4f3c\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u80fd\u591f\u521b\u5efa\u8868\u4f4d\u5019\u9009\u5e93\uff0c\u5e76\u901a\u8fc7\u5206\u7c7b\u5668\u7f29\u5c0f\u641c\u7d22\u8303\u56f4\u3002", "conclusion": "\u751f\u6210\u5f0f\u4e0e\u9884\u6d4b\u5f0f\u6a21\u578b\u7ed3\u5408\u7684\u65b9\u6cd5\u53ef\u8f85\u52a9\u8868\u4f4d\u53d1\u73b0\uff0c\u4ec5\u9700\u6c28\u57fa\u9178\u5e8f\u5217\uff0c\u65e0\u9700\u51e0\u4f55\u6846\u67b6\u6216\u624b\u5de5\u7279\u5f81\uff0c\u6709\u671b\u52a0\u901f\u65b0\u751f\u7269\u6280\u672f\u5f00\u53d1\u3002"}}
{"id": "2509.03398", "pdf": "https://arxiv.org/pdf/2509.03398", "abs": "https://arxiv.org/abs/2509.03398", "authors": ["Majid Aalizadeh", "Chinmay Raut", "Ali Tabartehfarahani", "Xudong Fan"], "title": "Machine Learning-Enhanced Colorimetric Sensing: Achieving over 5700-fold Accuracy Improvement via Full-Spectrum Modeling", "categories": ["physics.med-ph", "math-ph", "math.MP", "q-bio.QM"], "comment": "24 pages, 7 figures, 1 table", "summary": "Conventional colorimetric sensing methods typically rely on signal intensity\nat a single wavelength, often selected heuristically based on peak visual\nmodulation. This approach overlooks the structured information embedded in\nfull-spectrum transmission profiles, particularly in intensity-based systems\nwhere linear models may be highly effective. In this study, we experimentally\ndemonstrate that applying a forward feature selection strategy to normalized\ntransmission spectra, combined with linear regression and ten-fold\ncross-validation, yields significant improvements in predictive accuracy. Using\nfood dye dilutions as a model system, the mean squared error was reduced from\nover 22,000 with a single wavelength to 3.87 using twelve selected features,\ncorresponding to a more than 5,700-fold enhancement. These results validate\nthat full-spectrum modeling enables precise concentration prediction without\nrequiring changes to the sensing hardware. The approach is broadly applicable\nto colorimetric assays used in medical diagnostics, environmental monitoring,\nand industrial analysis, offering a scalable pathway to improve sensitivity and\nreliability in existing platforms.", "AI": {"tldr": "\u901a\u8fc7\u5168\u8c31\u5206\u6790\u548c\u7ebf\u6027\u56de\u5f52\u63d0\u5347\u989c\u8272\u6d4b\u5b9a\u7684\u51c6\u786e\u5ea6\uff0c\u5747\u65b9\u8bef\u5dee\u4ece22,000\u964d\u81f33.87\uff0c\u63d0\u5347\u8d85700\u500d", "motivation": "\u4f20\u7edf\u989c\u8272\u6d4b\u5b9a\u65b9\u6cd5\u4ec5\u4f7f\u7528\u5355\u4e00\u6ce2\u957f\u4fe1\u53f7\u5f3a\u5ea6\uff0c\u5ffd\u89c6\u4e86\u5168\u8c31\u4f20\u8f93\u8c31\u4e2d\u7684\u7ed3\u6784\u5316\u4fe1\u606f", "method": "\u91c7\u7528\u524d\u5411\u7279\u5f81\u9009\u62e9\u7b56\u7565\u5904\u7406\u6807\u51c6\u5316\u4f20\u8f93\u8c31\uff0c\u7ed3\u5408\u7ebf\u6027\u56de\u5f52\u548c\u5341\u6298\u4ea4\u53c9\u9a8c\u8bc1", "result": "\u4f7f\u7528\u98df\u54c1\u67d3\u6599\u6a21\u578b\u7cfb\u7edf\uff0c\u5747\u65b9\u8bef\u5dee\u4ece22,000\u964d\u81f33.87\uff0c\u51c6\u786e\u5ea6\u63d0\u5347\u8d85700\u500d", "conclusion": "\u5168\u8c31\u5efa\u6a21\u65b9\u6cd5\u53ef\u5728\u4e0d\u6539\u53d8\u786c\u4ef6\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u7cbe\u786e\u6d53\u5ea6\u9884\u6d4b\uff0c\u5e94\u7528\u4e8e\u533b\u7597\u8bca\u65ad\u3001\u73af\u5883\u76d1\u6d4b\u548c\u5de5\u4e1a\u5206\u6790"}}
{"id": "2509.03425", "pdf": "https://arxiv.org/pdf/2509.03425", "abs": "https://arxiv.org/abs/2509.03425", "authors": ["Phuc Pham", "Viet Thanh Duy Nguyen", "Truong-Son Hy"], "title": "LINKER: Learning Interactions Between Functional Groups and Residues With Chemical Knowledge-Enhanced Reasoning and Explainability", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Accurate identification of interactions between protein residues and ligand\nfunctional groups is essential to understand molecular recognition and guide\nrational drug design. Existing deep learning approaches for protein-ligand\ninterpretability often rely on 3D structural input or use distance-based\ncontact labels, limiting both their applicability and biological relevance. We\nintroduce LINKER, the first sequence-based model to predict residue-functional\ngroup interactions in terms of biologically defined interaction types, using\nonly protein sequences and the ligand SMILES as input. LINKER is trained with\nstructure-supervised attention, where interaction labels are derived from 3D\nprotein-ligand complexes via functional group-based motif extraction. By\nabstracting ligand structures into functional groups, the model focuses on\nchemically meaningful substructures while predicting interaction types rather\nthan mere spatial proximity. Crucially, LINKER requires only sequence-level\ninput at inference time, enabling large-scale application in settings where\nstructural data is unavailable. Experiments on the LP-PDBBind benchmark\ndemonstrate that structure-informed supervision over functional group\nabstractions yields interaction predictions closely aligned with ground-truth\nbiochemical annotations.", "AI": {"tldr": "LINKER\u662f\u9996\u4e2a\u57fa\u4e8e\u5e8f\u5217\u7684\u6a21\u578b\uff0c\u4ec5\u4f7f\u7528\u86cb\u767d\u8d28\u5e8f\u5217\u548c\u914d\u4f53SMILES\u5c31\u80fd\u9884\u6d4b\u6b8b\u57fa-\u529f\u80fd\u57fa\u56e2\u76f8\u4e92\u4f5c\u7528\u7c7b\u578b\uff0c\u65e0\u97003D\u7ed3\u6784\u8f93\u5165", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d563D\u7ed3\u6784\u8f93\u5165\u6216\u57fa\u4e8e\u8ddd\u79bb\u7684\u63a5\u89e6\u6807\u7b7e\uff0c\u9650\u5236\u4e86\u5e94\u7528\u8303\u56f4\u548c\u751f\u7269\u5b66\u76f8\u5173\u6027\uff0c\u9700\u8981\u5f00\u53d1\u4ec5\u57fa\u4e8e\u5e8f\u5217\u7684\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u65b9\u6cd5", "method": "\u91c7\u7528\u7ed3\u6784\u76d1\u7763\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u529f\u80fd\u57fa\u56e2\u57fa\u5e8f\u63d0\u53d6\u4ece3D\u86cb\u767d-\u914d\u4f53\u590d\u5408\u7269\u83b7\u5f97\u4ea4\u4e92\u6807\u7b7e\uff0c\u5c06\u914d\u4f53\u7ed3\u6784\u62bd\u8c61\u4e3a\u529f\u80fd\u57fa\u56e2", "result": "\u5728LP-PDBBind\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u57fa\u4e8e\u529f\u80fd\u57fa\u56e2\u62bd\u8c61\u7684\u7ed3\u6784\u76d1\u7763\u80fd\u591f\u4ea7\u751f\u4e0e\u771f\u5b9e\u751f\u5316\u6ce8\u91ca\u9ad8\u5ea6\u4e00\u81f4\u7684\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b", "conclusion": "LINKER\u901a\u8fc7\u5e8f\u5217\u7ea7\u8f93\u5165\u5b9e\u73b0\u5927\u89c4\u6a21\u5e94\u7528\uff0c\u5728\u7f3a\u4e4f\u7ed3\u6784\u6570\u636e\u7684\u573a\u666f\u4e0b\u4ecd\u80fd\u51c6\u786e\u9884\u6d4b\u5177\u6709\u751f\u7269\u5b66\u610f\u4e49\u7684\u76f8\u4e92\u4f5c\u7528\u7c7b\u578b"}}
{"id": "2509.03487", "pdf": "https://arxiv.org/pdf/2509.03487", "abs": "https://arxiv.org/abs/2509.03487", "authors": ["Jigang Fan", "Zhenghong Zhou", "Ruofan Jin", "Le Cong", "Mengdi Wang", "Zaixi Zhang"], "title": "SafeProtein: Red-Teaming Framework and Benchmark for Protein Foundation Models", "categories": ["cs.LG", "cs.AI", "cs.CR", "q-bio.BM", "q-bio.QM"], "comment": null, "summary": "Proteins play crucial roles in almost all biological processes. The\nadvancement of deep learning has greatly accelerated the development of protein\nfoundation models, leading to significant successes in protein understanding\nand design. However, the lack of systematic red-teaming for these models has\nraised serious concerns about their potential misuse, such as generating\nproteins with biological safety risks. This paper introduces SafeProtein, the\nfirst red-teaming framework designed for protein foundation models to the best\nof our knowledge. SafeProtein combines multimodal prompt engineering and\nheuristic beam search to systematically design red-teaming methods and conduct\ntests on protein foundation models. We also curated SafeProtein-Bench, which\nincludes a manually constructed red-teaming benchmark dataset and a\ncomprehensive evaluation protocol. SafeProtein achieved continuous jailbreaks\non state-of-the-art protein foundation models (up to 70% attack success rate\nfor ESM3), revealing potential biological safety risks in current protein\nfoundation models and providing insights for the development of robust security\nprotection technologies for frontier models. The codes will be made publicly\navailable at https://github.com/jigang-fan/SafeProtein.", "AI": {"tldr": "SafeProtein\u662f\u9996\u4e2a\u9488\u5bf9\u86cb\u767d\u8d28\u57fa\u7840\u6a21\u578b\u7684\u7ea2\u961f\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u63d0\u793a\u5de5\u7a0b\u548c\u542f\u53d1\u5f0f\u675f\u641c\u7d22\u7cfb\u7edf\u6027\u5730\u6d4b\u8bd5\u6a21\u578b\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5b58\u5728\u9ad8\u8fbe70%\u7684\u751f\u7269\u5b89\u5168\u98ce\u9669\u6f0f\u6d1e\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u63a8\u52a8\u4e86\u86cb\u767d\u8d28\u57fa\u7840\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7ea2\u961f\u6d4b\u8bd5\u5f15\u53d1\u4e86\u5bf9\u5176\u53ef\u80fd\u88ab\u6ee5\u7528\u4e8e\u751f\u6210\u5177\u6709\u751f\u7269\u5b89\u5168\u98ce\u9669\u86cb\u767d\u8d28\u7684\u4e25\u91cd\u62c5\u5fe7\u3002", "method": "\u7ed3\u5408\u591a\u6a21\u6001\u63d0\u793a\u5de5\u7a0b\u548c\u542f\u53d1\u5f0f\u675f\u641c\u7d22\uff0c\u6784\u5efa\u4e86SafeProtein-Bench\u57fa\u51c6\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u534f\u8bae\uff0c\u5bf9\u86cb\u767d\u8d28\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u6027\u7ea2\u961f\u6d4b\u8bd5\u3002", "result": "\u5728\u5148\u8fdb\u86cb\u767d\u8d28\u57fa\u7840\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u6301\u7eed\u8d8a\u72f1\uff08ESM3\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe70%\uff09\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5b58\u5728\u7684\u6f5c\u5728\u751f\u7269\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u524d\u6cbf\u6a21\u578b\u5f00\u53d1\u5f3a\u5927\u7684\u5b89\u5168\u4fdd\u62a4\u6280\u672f\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0c\u4ee3\u7801\u5c06\u516c\u5f00\u63d0\u4f9b\u4ee5\u4fc3\u8fdb\u86cb\u767d\u8d28\u6a21\u578b\u5b89\u5168\u6027\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
