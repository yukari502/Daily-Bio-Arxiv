<div id=toc></div>

# Table of Contents

- [q-bio.QM](#q-bio.QM) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [1] [HypoGeneAgent: A Hypothesis Language Agent for Gene-Set Cluster Resolution Selection Using Perturb-seq Datasets](https://arxiv.org/abs/2509.09740)
*Ying Yuan,Xing-Yue Monica Ge,Aaron Archer Waterman,Tommaso Biancalani,David Richmond,Yogesh Pandit,Avtar Singh,Russell Littman,Jin Liu,Jan-Christian Huetter,Vladimir Ermakov*

Main category: q-bio.QM

TL;DR: HYPOGENEAGENT是一个基于大语言模型的框架，将细胞聚类注释转化为可量化优化的任务，通过LLM生成GO假设并计算内部一致性和外部区分度评分，自动选择最佳聚类粒度。


<details>
  <summary>Details</summary>
Motivation: 解决单细胞研究中聚类分辨率选择和功能注释的主观性问题，传统方法依赖启发式规则和专家经验，缺乏客观量化标准。

Method: 使用LLM作为基因集分析师生成GO假设和置信度评分，然后通过句子嵌入模型计算类内一致性（intra-cluster agreement）和类间区分度（inter-cluster separation），组合得到分辨率评分。

Result: 在K562 CRISPRi Perturb-seq数据集测试中，该方法选择的聚类粒度与已知通路对齐度优于传统指标（如轮廓系数、模块度评分）。

Conclusion: LLM代理可作为聚类分辨率和功能注释的客观裁决者，为单细胞多组学研究实现全自动、上下文感知的解读流程铺平道路。

Abstract: Large-scale single-cell and Perturb-seq investigations routinely involve
clustering cells and subsequently annotating each cluster with Gene-Ontology
(GO) terms to elucidate the underlying biological programs. However, both
stages, resolution selection and functional annotation, are inherently
subjective, relying on heuristics and expert curation. We present
HYPOGENEAGENT, a large language model (LLM)-driven framework, transforming
cluster annotation into a quantitatively optimizable task. Initially, an LLM
functioning as a gene-set analyst analyzes the content of each gene program or
perturbation module and generates a ranked list of GO-based hypotheses,
accompanied by calibrated confidence scores. Subsequently, we embed every
predicted description with a sentence-embedding model, compute pair-wise cosine
similarities, and let the agent referee panel score (i) the internal
consistency of the predictions, high average similarity within the same
cluster, termed intra-cluster agreement (ii) their external distinctiveness,
low similarity between clusters, termed inter-cluster separation. These two
quantities are combined to produce an agent-derived resolution score, which is
maximized when clusters exhibit simultaneous coherence and mutual exclusivity.
When applied to a public K562 CRISPRi Perturb-seq dataset as a preliminary
test, our Resolution Score selects clustering granularities that exhibit
alignment with known pathway compared to classical metrics such silhouette
score, modularity score for gene functional enrichment summary. These findings
establish LLM agents as objective adjudicators of cluster resolution and
functional annotation, thereby paving the way for fully automated,
context-aware interpretation pipelines in single-cell multi-omics studies.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [Human-AI Collaboration Increases Efficiency in Regulatory Writing](https://arxiv.org/abs/2509.09738)
*Umut Eser,Yael Gozin,L. Jay Stallons,Ari Caroline,Martin Preusse,Brandon Rice,Scott Wright,Andrew Robertson*

Main category: cs.AI

TL;DR: AutoIND LLM平台可将IND申请的非临床书面总结初稿撰写时间减少约97%，从约100小时缩短至3-4小时，质量评分69-78%，无关键监管错误，但仍需专家进一步完善。


<details>
  <summary>Details</summary>
Motivation: IND申请准备过程耗时且依赖专业知识，减缓了早期临床开发进程，需要寻找提高效率的解决方案。

Method: 使用AutoIND LLM平台生成IND非临床书面总结(eCTD模块2.6.2、2.6.4、2.6.6)，记录起草时间并与人工起草时间对比，由盲法监管写作评估员使用7个预设类别评估质量。

Result: 起草时间减少97%(从~100小时降至3.7小时和2.6小时)，质量评分分别为69.6%和77.9%，未发现关键监管错误，但在重点突出、简洁性和清晰度方面存在不足。

Conclusion: AutoIND能显著加速IND起草过程，但专家监管作者仍需将输出完善至提交质量水平，发现的系统性缺陷为针对性模型改进提供了路线图。

Abstract: Background: Investigational New Drug (IND) application preparation is
time-intensive and expertise-dependent, slowing early clinical development.
Objective: To evaluate whether a large language model (LLM) platform (AutoIND)
can reduce first-draft composition time while maintaining document quality in
regulatory submissions. Methods: Drafting times for IND nonclinical written
summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly
recorded. For comparison, manual drafting times for IND summaries previously
cleared by the U.S. FDA were estimated from the experience of regulatory
writers ($\geq$6 years) and used as industry-standard benchmarks. Quality was
assessed by a blinded regulatory writing assessor using seven pre-specified
categories: correctness, completeness, conciseness, consistency, clarity,
redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a
percentage. A critical regulatory error was defined as any misrepresentation or
omission likely to alter regulatory interpretation (e.g., incorrect NOAEL,
omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced
initial drafting time by $\sim$97% (from $\sim$100 h to 3.7 h for 18,870
pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).
Quality scores were 69.6\% and 77.9\% for IND-1 and IND-2. No critical
regulatory errors were detected, but deficiencies in emphasis, conciseness, and
clarity were noted. Conclusions: AutoIND can dramatically accelerate IND
drafting, but expert regulatory writers remain essential to mature outputs to
submission-ready quality. Systematic deficiencies identified provide a roadmap
for targeted model improvements.

</details>
