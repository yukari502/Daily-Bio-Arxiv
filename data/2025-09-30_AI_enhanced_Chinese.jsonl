{"id": "2509.23057", "pdf": "https://arxiv.org/pdf/2509.23057", "abs": "https://arxiv.org/abs/2509.23057", "authors": ["Qian Qin", "Heng Li"], "title": "Challenges in structural variant calling in low-complexity regions", "categories": ["q-bio.GN"], "comment": "5 pages, 4 figures", "summary": "Background: Structural variants (SVs) are genomic differences $\\ge$50 bp in\nlength. They remain challenging to detect even with long sequence reads, and\nthe sources of these difficulties are not well quantified.\n  Results: We identified 35.4 Mb of low-complexity regions (LCRs) in GRCh38.\nAlthough these regions cover only 1.2% of the genome, they contain 69.1% of\nconfident SVs in sample HG002. Across long-read SV callers, 77.3-91.3% of\nerroneous SV calls occur within LCRs, with error rates increasing with LCR\nlength.\n  Conclusion: SVs are enriched and difficult to call in LCRs. Special care need\nto be taken for calling and analyzing these variants.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u57fa\u56e0\u7ec4\u4e2d\u4ec5\u53601.2%\u7684\u4f4e\u590d\u6742\u5ea6\u533a\u57df(LCRs)\u5305\u542b\u4e8669.1%\u7684\u7ed3\u6784\u53d8\u5f02(SVs)\uff0c\u4e14\u957f\u8bfb\u957fSV\u68c0\u6d4b\u5de5\u5177\u5728\u8fd9\u4e9b\u533a\u57df\u7684\u9519\u8bef\u7387\u9ad8\u8fbe77.3-91.3%\u3002", "motivation": "\u7ed3\u6784\u53d8\u5f02(SVs)\u662f\u957f\u5ea6\u226550bp\u7684\u57fa\u56e0\u7ec4\u5dee\u5f02\uff0c\u5373\u4f7f\u5728\u957f\u5e8f\u5217\u8bfb\u53d6\u4e0b\u4e5f\u96be\u4ee5\u68c0\u6d4b\uff0c\u4e14\u8fd9\u4e9b\u56f0\u96be\u7684\u6765\u6e90\u5c1a\u672a\u5f97\u5230\u5145\u5206\u91cf\u5316\u3002", "method": "\u8bc6\u522b\u4e86GRCh38\u57fa\u56e0\u7ec4\u4e2d\u768435.4Mb\u4f4e\u590d\u6742\u5ea6\u533a\u57df(LCRs)\uff0c\u5e76\u5206\u6790\u4e86HG002\u6837\u672c\u4e2dSV\u5728\u8fd9\u4e9b\u533a\u57df\u7684\u5206\u5e03\u60c5\u51b5\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u957f\u8bfb\u957fSV\u68c0\u6d4b\u5de5\u5177\u5728LCRs\u4e2d\u7684\u9519\u8bef\u7387\u3002", "result": "LCRs\u867d\u7136\u53ea\u8986\u76d6\u57fa\u56e0\u7ec4\u76841.2%\uff0c\u4f46\u5305\u542b\u4e8669.1%\u7684\u53ef\u9760SVs\uff1b\u4e0d\u540cSV\u68c0\u6d4b\u5de5\u5177\u5728LCRs\u4e2d\u7684\u9519\u8befSV\u8c03\u7528\u6bd4\u4f8b\u8fbe77.3-91.3%\uff0c\u4e14\u9519\u8bef\u7387\u968fLCR\u957f\u5ea6\u589e\u52a0\u800c\u4e0a\u5347\u3002", "conclusion": "SVs\u5728LCRs\u4e2d\u5bcc\u96c6\u4e14\u96be\u4ee5\u51c6\u786e\u68c0\u6d4b\uff0c\u9700\u8981\u5bf9\u8fd9\u7c7b\u53d8\u5f02\u8fdb\u884c\u7279\u6b8a\u5173\u6ce8\u548c\u8c28\u614e\u5206\u6790\u3002"}}
{"id": "2509.23543", "pdf": "https://arxiv.org/pdf/2509.23543", "abs": "https://arxiv.org/abs/2509.23543", "authors": ["Luxuan Zhang", "Douglas Jiang", "Qinglong Wang", "Haoqi Sun", "Feng Tian"], "title": "Contrastive Learning Enhances Language Model Based Cell Embeddings for Low-Sample Single Cell Transcriptomics", "categories": ["q-bio.GN", "cs.NE", "q-bio.MN"], "comment": "14 pages, 4 figures, 2 tables", "summary": "Large language models (LLMs) have shown strong ability in generating rich\nrepresentations across domains such as natural language processing and\ngeneration, computer vision, and multimodal learning. However, their\napplication in biomedical data analysis remains nascent. Single-cell\ntranscriptomic profiling is essential for dissecting cell subtype diversity in\ndevelopment and disease, but rare subtypes pose challenges for scaling laws. We\npresent a computational framework that integrates single-cell RNA sequencing\n(scRNA-seq) with LLMs to derive knowledge-informed gene embeddings. Highly\nexpressed genes for each cell are mapped to NCBI Gene descriptions and embedded\nusing models such as text-embedding-ada-002, BioBERT, and SciBERT. Applied to\nretinal ganglion cells (RGCs), which differ in vulnerability to\nglaucoma-related neurodegeneration, this strategy improves subtype\nclassification, highlights biologically significant features, and reveals\npathways underlying selective neuronal vulnerability. More broadly, it\nillustrates how LLM-derived embeddings can augment biological analysis under\ndata-limited conditions and lay the groundwork for future foundation models in\nsingle-cell biology.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u9ad8\u8868\u8fbe\u57fa\u56e0\u6620\u5c04\u5230NCBI\u57fa\u56e0\u63cf\u8ff0\u5e76\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5d4c\u5165\uff0c\u6539\u8fdb\u4e86\u89c6\u7f51\u819c\u795e\u7ecf\u8282\u7ec6\u80de\u7684\u4e9a\u578b\u5206\u7c7b\u5e76\u63ed\u793a\u4e86\u9009\u62e9\u6027\u795e\u7ecf\u5143\u6613\u635f\u6027\u7684\u901a\u8def\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u7269\u533b\u5b66\u6570\u636e\u5206\u6790\u4e2d\u7684\u5e94\u7528\u4ecd\u5904\u4e8e\u8d77\u6b65\u9636\u6bb5\uff0c\u7279\u522b\u662f\u5728\u5355\u7ec6\u80de\u8f6c\u5f55\u7ec4\u5206\u6790\u4e2d\uff0c\u7f55\u89c1\u4e9a\u578b\u5bf9\u6269\u5c55\u6cd5\u5219\u63d0\u51fa\u4e86\u6311\u6218\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u589e\u5f3a\u751f\u7269\u5206\u6790\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u6570\u636e\u4e2d\u6bcf\u4e2a\u7ec6\u80de\u7684\u9ad8\u8868\u8fbe\u57fa\u56e0\u6620\u5c04\u5230NCBI\u57fa\u56e0\u63cf\u8ff0\uff0c\u7136\u540e\u4f7f\u7528text-embedding-ada-002\u3001BioBERT\u548cSciBERT\u7b49\u6a21\u578b\u751f\u6210\u77e5\u8bc6\u5f15\u5bfc\u7684\u57fa\u56e0\u5d4c\u5165\u3002", "result": "\u5e94\u7528\u4e8e\u89c6\u7f51\u819c\u795e\u7ecf\u8282\u7ec6\u80de\u5206\u6790\uff0c\u8be5\u7b56\u7565\u6539\u8fdb\u4e86\u4e9a\u578b\u5206\u7c7b\uff0c\u7a81\u51fa\u4e86\u751f\u7269\u5b66\u663e\u8457\u7279\u5f81\uff0c\u5e76\u63ed\u793a\u4e86\u4e0e\u9752\u5149\u773c\u76f8\u5173\u795e\u7ecf\u9000\u884c\u6027\u53d8\u4e2d\u9009\u62e9\u6027\u795e\u7ecf\u5143\u6613\u635f\u6027\u76f8\u5173\u7684\u901a\u8def\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u5728\u6570\u636e\u6709\u9650\u6761\u4ef6\u4e0b\uff0cLLM\u884d\u751f\u7684\u5d4c\u5165\u5982\u4f55\u589e\u5f3a\u751f\u7269\u5206\u6790\uff0c\u5e76\u4e3a\u5355\u7ec6\u80de\u751f\u7269\u5b66\u4e2d\u672a\u6765\u57fa\u7840\u6a21\u578b\u7684\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.24926", "pdf": "https://arxiv.org/pdf/2509.24926", "abs": "https://arxiv.org/abs/2509.24926", "authors": ["Rebecca J. Rousseau", "Rob Phillips"], "title": "Bifurcations and multistability in inducible three-gene toggle switch networks", "categories": ["q-bio.MN", "physics.bio-ph", "q-bio.SC"], "comment": "32 pages, 23 figures", "summary": "Control of transcription presides over a vast array of biological processes\nincluding through gene regulatory circuits that exhibit multistability. Two-\nand three-gene network motifs are often found to be critical parts of the\nrepertoire of metabolic and developmental pathways. Theoretical models of these\ncircuits, however, typically vary parameters such as dissociation constants,\ntranscription rates, and degradation rates without specifying precisely how\nthese parameters are controlled biologically. In this paper, we examine the\nrole of effector molecules, which can alter the concentrations of the active\ntranscription factors that control regulation, and are ubiquitous to regulatory\nprocesses across biological settings. We specifically consider allosteric\nregulation in the context of extending the standard bistable switch to\nthree-gene networks, and explore the rich multistable dynamics exhibited in\nthese architectures as a function of effector concentrations. We then study how\nthe conditions required for tristability and more complex dynamics, and the\nbifurcations in dynamic phase space upon tuning effector concentrations, evolve\nunder various interpretations of regulatory circuit mechanics, the underlying\nactivity of inducers, and perturbations thereof. Notably, the biological\nmechanism by which we model effector control over dual-function proteins\ntransforms not only the phenotypic trend of dynamic tuning but also the set of\navailable dynamic regimes. In this way, we determine key parameters and\nregulatory features that drive phenotypic decisions, and offer an\nexperimentally tunable structure for encoding inducible multistable behavior\narising from both single and dual-function allosteric transcription factors.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6548\u5e94\u5206\u5b50\u5728\u8c03\u63a7\u4e09\u57fa\u56e0\u7f51\u7edc\u591a\u7a33\u6001\u52a8\u6001\u4e2d\u7684\u4f5c\u7528\uff0c\u901a\u8fc7\u6269\u5c55\u6807\u51c6\u53cc\u7a33\u6001\u5f00\u5173\u6a21\u578b\uff0c\u63a2\u7d22\u4e86\u6548\u5e94\u5206\u5b50\u6d53\u5ea6\u5982\u4f55\u5f71\u54cd\u591a\u7a33\u6001\u52a8\u6001\u548c\u5206\u5c94\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u6a21\u578b\u901a\u5e38\u968f\u610f\u8c03\u6574\u53c2\u6570\u800c\u4e0d\u8003\u8651\u751f\u7269\u63a7\u5236\u673a\u5236\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76\u6548\u5e94\u5206\u5b50\uff08\u666e\u904d\u5b58\u5728\u4e8e\u751f\u7269\u8c03\u63a7\u8fc7\u7a0b\u4e2d\uff09\u5982\u4f55\u901a\u8fc7\u6539\u53d8\u6d3b\u6027\u8f6c\u5f55\u56e0\u5b50\u6d53\u5ea6\u6765\u8c03\u63a7\u57fa\u56e0\u7f51\u7edc\u52a8\u6001\u3002", "method": "\u5728\u6807\u51c6\u53cc\u7a33\u6001\u5f00\u5173\u57fa\u7840\u4e0a\u6269\u5c55\u5230\u4e09\u57fa\u56e0\u7f51\u7edc\uff0c\u8003\u8651\u53d8\u6784\u8c03\u63a7\u673a\u5236\uff0c\u5206\u6790\u6548\u5e94\u5206\u5b50\u6d53\u5ea6\u5bf9\u591a\u7a33\u6001\u52a8\u6001\u7684\u5f71\u54cd\uff0c\u7814\u7a76\u4e0d\u540c\u8c03\u63a7\u673a\u5236\u89e3\u91ca\u4e0b\u7684\u52a8\u6001\u76f8\u7a7a\u95f4\u5206\u5c94\u3002", "result": "\u53d1\u73b0\u6548\u5e94\u5206\u5b50\u63a7\u5236\u53cc\u529f\u80fd\u86cb\u767d\u7684\u751f\u7269\u673a\u5236\u4e0d\u4ec5\u6539\u53d8\u4e86\u52a8\u6001\u8c03\u63a7\u7684\u8868\u578b\u8d8b\u52bf\uff0c\u8fd8\u6539\u53d8\u4e86\u53ef\u7528\u7684\u52a8\u6001\u673a\u5236\u96c6\u5408\uff0c\u786e\u5b9a\u4e86\u9a71\u52a8\u8868\u578b\u51b3\u7b56\u7684\u5173\u952e\u53c2\u6570\u548c\u8c03\u63a7\u7279\u5f81\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u9a8c\u53ef\u8c03\u63a7\u7684\u7ed3\u6784\uff0c\u7528\u4e8e\u7f16\u7801\u7531\u5355\u529f\u80fd\u548c\u53cc\u529f\u80fd\u53d8\u6784\u8f6c\u5f55\u56e0\u5b50\u4ea7\u751f\u7684\u53ef\u8bf1\u5bfc\u591a\u7a33\u6001\u884c\u4e3a\uff0c\u63ed\u793a\u4e86\u6548\u5e94\u5206\u5b50\u5728\u8c03\u63a7\u590d\u6742\u57fa\u56e0\u7f51\u7edc\u52a8\u6001\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2509.22853", "pdf": "https://arxiv.org/pdf/2509.22853", "abs": "https://arxiv.org/abs/2509.22853", "authors": ["Irsyad Adam", "Zekai Chen", "David Laub", "Shaun Porwal", "Arda Pekis", "Kevin Brown"], "title": "Patient-specific Biomolecular Instruction Tuning", "categories": ["q-bio.QM", "cs.AI", "cs.CL", "cs.LG", "92C40, 68T07, 62P10", "I.2.7; I.5.1; J.3"], "comment": null, "summary": "Proteomics data is essential to pathogenic understanding of a disease\nphenotype. In cancer, analysis of molecular signatures enables precision\nmedicine through the identification of biological processes that drive\nindividualized tumor progression, therapeutic resistance, and clinical\nheterogeneity. Recent advances in multimodal large language models (LLMs) have\nshown remarkable capacity to integrate and reason across heterogeneous data\nmodalities. However, performing multi-modal language modeling for molecular\nunderstanding of patient-specific proteomics remains a significant challenge\ndue to two barriers: (1) the lack of instruction-tuning datasets that enable\nclinical interpretation from proteomics data, and (2) the absence of language\nmodeling architectures designed to capture the rich heterogeneity of molecular\ndata. In this work, we introduce CPTAC-PROTSTRUCT, the first instruction tuning\ndataset for molecular understanding of oncology, comprising over 400k\nopen-ended examples derived from individualized proteomic profiles curated from\nthe largest national proteomics cancer study (CPTAC). Additionally, we propose\nKRONOS (Knowledge Representation of patient Omics Networks in Oncology via\nStructured tuning), a novel graph-LLM framework that leverages molecular\ninteraction topology with proteomics to learn patient-specific graph\nrepresentations for enhanced clinical reasoning. We show that KRONOS achieves\ncompetitive performance across benchmark clinical tasks, including molecular\nclassification, temporal trajectory modeling, and tumor stage prediction from\nproteomics data. Ultimately, this approach empowers LLMs to understand\npatient-level pathogenesis, advancing precision medicine through more accurate\ndiagnosis, prognosis, and treatment stratification.", "AI": {"tldr": "\u63d0\u51fa\u4e86CPTAC-PROTSTRUCT\u6570\u636e\u96c6\u548cKRONOS\u6846\u67b6\uff0c\u7528\u4e8e\u57fa\u4e8e\u86cb\u767d\u8d28\u7ec4\u5b66\u7684\u764c\u75c7\u7cbe\u51c6\u533b\u7597\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u7406\u89e3\u60a3\u8005\u7279\u5f02\u6027\u5206\u5b50\u7279\u5f81\u3002", "motivation": "\u86cb\u767d\u8d28\u7ec4\u5b66\u6570\u636e\u5bf9\u7406\u89e3\u75be\u75c5\u8868\u578b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7528\u4e8e\u4e34\u5e8a\u89e3\u91ca\u7684\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u96c6\u548c\u9002\u5408\u5206\u5b50\u6570\u636e\u5f02\u8d28\u6027\u7684\u8bed\u8a00\u5efa\u6a21\u67b6\u6784\u3002", "method": "\u521b\u5efa\u4e86\u5305\u542b40\u4e07+\u5f00\u653e\u793a\u4f8b\u7684CPTAC-PROTSTRUCT\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51faKRONOS\u56fe-LLM\u6846\u67b6\uff0c\u5229\u7528\u5206\u5b50\u76f8\u4e92\u4f5c\u7528\u62d3\u6251\u5b66\u4e60\u60a3\u8005\u7279\u5f02\u6027\u56fe\u8868\u793a\u3002", "result": "KRONOS\u5728\u5206\u5b50\u5206\u7c7b\u3001\u65f6\u95f4\u8f68\u8ff9\u5efa\u6a21\u548c\u80bf\u7624\u5206\u671f\u9884\u6d4b\u7b49\u4e34\u5e8a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u7ade\u4e89\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f7fLLM\u80fd\u591f\u7406\u89e3\u60a3\u8005\u5c42\u9762\u7684\u53d1\u75c5\u673a\u5236\uff0c\u901a\u8fc7\u66f4\u51c6\u786e\u7684\u8bca\u65ad\u3001\u9884\u540e\u548c\u6cbb\u7597\u5206\u5c42\u63a8\u8fdb\u7cbe\u51c6\u533b\u7597\u3002"}}
{"id": "2509.22920", "pdf": "https://arxiv.org/pdf/2509.22920", "abs": "https://arxiv.org/abs/2509.22920", "authors": ["Will Ke Wang", "Rui Yang", "Chao Pang", "Karthik Natarajan", "Nan Liu", "Daniel McDuff", "David Slotwiner", "Fei Wang", "Xuhai Orson Xu"], "title": "Beyond the Clinic: A Large-Scale Evaluation of Augmenting EHR with Wearable Data for Diverse Health Prediction", "categories": ["q-bio.QM"], "comment": null, "summary": "Electronic health records (EHRs) provide a powerful basis for predicting the\nonset of health outcomes. Yet EHRs primarily capture in-clinic events and miss\naspects of daily behavior and lifestyle containing rich health information.\nConsumer wearables, by contrast, continuously measure activity, heart rate, and\nsleep, and more, offering complementary signals that can fill this gap. Despite\nthis potential, there has been little systematic evaluation of the benefit that\nwearable data can bring to health outcome prediction on top of EHRs. In this\nstudy, we present an extensible framework for multimodal health outcome\nprediction that integrates EHR and wearable data streams. Using data from the\nAll of Us Program, we systematically compared the combination of different\nencoding methods on EHR and wearable data, including the traditional feature\nengineering approach, as well as foundation model embeddings. Across ten\nclinical outcomes, wearable integration consistently improved model performance\nrelative to EHR-only baselines, e.g., average delta AUROC +5.8% for major\ndepressive disorder, +10.7% for hypertension, and +12.2% for diabetes. On\naverage across all ten outcomes, fusing EHRs with wearable features shows 8.9%\nimprovement in AUROC. To our knowledge, this is the first large-scale\nevaluation of wearable-EHR fusion, underscoring the utility of wearable-derived\nsignals in complementing EHRs and enabling more holistic, personalized health\noutcome predictions. Meanwhile, our analysis elucidates future directions for\noptimizing foundation models for wearable data and its integration with EHR\ndata.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u5065\u5eb7\u7ed3\u679c\u9884\u6d4b\u6846\u67b6\uff0c\u6574\u5408\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u548c\u53ef\u7a7f\u6234\u8bbe\u5907\u6570\u636e\uff0c\u8bc1\u660e\u53ef\u7a7f\u6234\u6570\u636e\u80fd\u663e\u8457\u63d0\u5347\u5065\u5eb7\u7ed3\u679c\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "EHR\u4e3b\u8981\u8bb0\u5f55\u4e34\u5e8a\u4e8b\u4ef6\uff0c\u4f46\u7f3a\u4e4f\u65e5\u5e38\u884c\u4e3a\u548c\u751f\u6d3b\u65b9\u5f0f\u4fe1\u606f\uff1b\u53ef\u7a7f\u6234\u8bbe\u5907\u80fd\u63d0\u4f9b\u8fde\u7eed\u7684\u6d3b\u52a8\u3001\u5fc3\u7387\u548c\u7761\u7720\u7b49\u8865\u5145\u4fe1\u53f7\uff0c\u4f46\u4e4b\u524d\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\u53ef\u7a7f\u6234\u6570\u636e\u5bf9EHR\u9884\u6d4b\u7684\u589e\u76ca\u6548\u679c\u3002", "method": "\u5f00\u53d1\u53ef\u6269\u5c55\u7684\u591a\u6a21\u6001\u5065\u5eb7\u7ed3\u679c\u9884\u6d4b\u6846\u67b6\uff0c\u6574\u5408EHR\u548c\u53ef\u7a7f\u6234\u6570\u636e\u6d41\uff0c\u6bd4\u8f83\u4e0d\u540c\u7f16\u7801\u65b9\u6cd5\uff08\u4f20\u7edf\u7279\u5f81\u5de5\u7a0b\u548c\u57fa\u7840\u6a21\u578b\u5d4c\u5165\uff09\u5728All of Us\u9879\u76ee\u6570\u636e\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u572810\u4e2a\u4e34\u5e8a\u7ed3\u679c\u4e2d\uff0c\u53ef\u7a7f\u6234\u6570\u636e\u6574\u5408\u6301\u7eed\u6539\u5584\u6a21\u578b\u6027\u80fd\uff1a\u91cd\u5ea6\u6291\u90c1\u75c7AUROC\u5e73\u5747\u63d0\u53475.8%\uff0c\u9ad8\u8840\u538b\u63d0\u534710.7%\uff0c\u7cd6\u5c3f\u75c5\u63d0\u534712.2%\uff1b\u5e73\u5747\u6240\u6709\u7ed3\u679cAUROC\u63d0\u53478.9%\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5927\u89c4\u6a21\u8bc4\u4f30\u53ef\u7a7f\u6234-EHR\u878d\u5408\u7684\u7814\u7a76\uff0c\u8bc1\u660e\u53ef\u7a7f\u6234\u4fe1\u53f7\u80fd\u8865\u5145EHR\uff0c\u5b9e\u73b0\u66f4\u5168\u9762\u3001\u4e2a\u6027\u5316\u7684\u5065\u5eb7\u7ed3\u679c\u9884\u6d4b\uff0c\u5e76\u4e3a\u4f18\u5316\u53ef\u7a7f\u6234\u6570\u636e\u57fa\u7840\u6a21\u578b\u53ca\u5176\u4e0eEHR\u7684\u6574\u5408\u6307\u660e\u4e86\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2509.22950", "pdf": "https://arxiv.org/pdf/2509.22950", "abs": "https://arxiv.org/abs/2509.22950", "authors": ["Supantha Dey", "Ratul Chowdhury"], "title": "Twin Peaks: Dual-Head Architecture for Structure-Free Prediction of Protein-Protein Binding Affinity and Mutation Effects", "categories": ["q-bio.QM"], "comment": null, "summary": "We present a novel dual-head deep learning architecture for protein-protein\ninteraction modeling that enables simultaneous prediction of binding affinity\n($\\Delta G$) and mutation-induced affinity changes ($\\Delta\\Delta G$) using\nonly protein sequence information. Our approach offers a significant\nadvancement over existing methods by employing specialized prediction heads\nthat operate on a shared representation network, allowing direct and optimized\nprediction of both values. To ensure robust generalization, we integrated\ncomplementary datasets from SKEMPI v2 and PDBbind with a rigorous protein\ndomain-based splitting strategy that prevents information leakage between\ntraining and validation sets. Our architecture combines transformer-based\nencoders with a novel cross-attention mechanism that processes paired protein\nsequences directly, without requiring any structural information. The network\nembeds input sequences using ESM3 representations, then employs a learnable\nsliced window embedding layer to manage variable-length sequences efficiently.\nA multi-layer transformer encoder with bidirectional self-attention captures\nintra-protein patterns, while cross-attention layers enable explicit modeling\nof interactions between protein pairs. This shared representation network feeds\ninto separate $\\Delta G$ and $\\Delta\\Delta G$ prediction heads, allowing\ntask-specific optimization while leveraging common features. The model achieves\n$\\Delta\\Delta G$ validation of Pearson correlation at 0.485, while maintaining\nstrong $\\Delta G$ predictions (Pearson: 0.638). While existing approaches\nrequire protein structure data and binding interface information, our model\neliminates these constraints. This provides a critical advantage for the\nnumerous proteins with unknown structures or those challenging to crystallize,\nsuch as viral and intrinsically disordered proteins.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53cc\u5934\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u4ec5\u4f7f\u7528\u86cb\u767d\u8d28\u5e8f\u5217\u4fe1\u606f\u5373\u53ef\u540c\u65f6\u9884\u6d4b\u7ed3\u5408\u4eb2\u548c\u529b(\u0394G)\u548c\u7a81\u53d8\u8bf1\u5bfc\u7684\u4eb2\u548c\u529b\u53d8\u5316(\u0394\u0394G)\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u86cb\u767d\u8d28\u7ed3\u6784\u6570\u636e\u548c\u7ed3\u5408\u754c\u9762\u4fe1\u606f\uff0c\u8fd9\u9650\u5236\u4e86\u5728\u672a\u77e5\u7ed3\u6784\u6216\u96be\u4ee5\u7ed3\u6676\u86cb\u767d\u8d28\uff08\u5982\u75c5\u6bd2\u86cb\u767d\u548c\u5185\u5728\u65e0\u5e8f\u86cb\u767d\uff09\u4e0a\u7684\u5e94\u7528\u3002", "method": "\u91c7\u7528\u57fa\u4e8etransformer\u7684\u7f16\u7801\u5668\u548c\u65b0\u9896\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5904\u7406\u6210\u5bf9\u86cb\u767d\u8d28\u5e8f\u5217\uff0c\u65e0\u9700\u7ed3\u6784\u4fe1\u606f\u3002\u4f7f\u7528ESM3\u8868\u793a\u5d4c\u5165\u8f93\u5165\u5e8f\u5217\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5207\u7247\u7a97\u53e3\u5d4c\u5165\u5c42\u7ba1\u7406\u53d8\u957f\u5e8f\u5217\uff0c\u5171\u4eab\u8868\u793a\u7f51\u7edc\u5206\u522b\u8f93\u51fa\u0394G\u548c\u0394\u0394G\u9884\u6d4b\u3002", "result": "\u6a21\u578b\u5728\u0394\u0394G\u9a8c\u8bc1\u4e2d\u8fbe\u5230Pearson\u76f8\u5173\u7cfb\u65700.485\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u529b\u7684\u0394G\u9884\u6d4b\u80fd\u529b(Pearson: 0.638)\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6d88\u9664\u4e86\u5bf9\u86cb\u767d\u8d28\u7ed3\u6784\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u4e3a\u4f17\u591a\u672a\u77e5\u7ed3\u6784\u6216\u96be\u4ee5\u7ed3\u6676\u7684\u86cb\u767d\u8d28\u63d0\u4f9b\u4e86\u5173\u952e\u4f18\u52bf\u3002"}}
{"id": "2509.23445", "pdf": "https://arxiv.org/pdf/2509.23445", "abs": "https://arxiv.org/abs/2509.23445", "authors": ["Andre Archer", "Brett J. Palmero", "Charlotte Abrahamson", "Carolyn E. Mills", "Nolan W. Kennedy", "Danielle Tullman-Ercek", "Niall M. Mangan"], "title": "Uncertainty Quantification of Bacterial Microcompartment Permeability", "categories": ["q-bio.QM", "q-bio.SC"], "comment": "30 pages, 7 figures", "summary": "$\\textit{Salmonella}$ expresses bacterial microcompartments (MCPs) upon\n1,2-propanediol exposure. MCPs are nanoscale protein-bound shells that encase\nenzymes for the cofactor-dependent 1,2-propanediol metabolism. They are\nhypothesized to limit exposure to the toxic intermediate, propionaldehyde,\ndecrease cofactor involvement in competing reactions, and enhance flux. We\nconstruct a mass-action mathematical model of purified MCPs and calibrate\nparameters to measured metabolite concentrations. We constrain mass-action\nkinetic parameters to previously estimated Michaelis-Menten parameters. We\nidentified two distinct fits with different dynamics in the pathway product,\npropionate, but similar goodness of fit. Across fits, we inferred that the MCP\n1,2-propanediol and propionaldehyde permeability should be greater than\n$10^{-6}$ and $10^{-8}$ m/s, respectively. Our results identify parameter\nranges consistent with prevailing theories that MCPs impose preferential\ndiffusion to 1,2-propanediol over propionaldehyde, and sequester toxic\npropionaldehyde away from the cell cytosol. The bimodality of the posterior\ndistribution arises from bimodality in the estimated coenzyme-A (CoA)\npermeability and inhibition rates. The MCP permeability to CoA was inferred to\nbe either less than $10^{-8.8}$ m/s or greater than $10^{-7.3}$ m/s. In a high\nCoA permeability environment with low rates of CoA inhibition, enzymes produced\nmetabolites by recycling (NAD+)/(NADH). In a low CoA permeability environment\nwith high rates of CoA inhibition, enzymes required external NAD+/H to produce\nmetabolites. Dynamics are consistent with prevailing hypotheses about MCP\nfunction to sequester toxic propionaldehyde, and additional collection of data\npoints between 6 and 24 hours or characterization of enzyme inhibition rates\ncould further reduce uncertainty and provide better permeability estimates.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u6c99\u95e8\u6c0f\u83cc\u5fae\u533a\u5ba4(MCPs)\u7684\u6570\u5b66\u6a21\u578b\uff0c\u53d1\u73b0\u5b58\u5728\u4e24\u79cd\u4e0d\u540c\u7684\u52a8\u529b\u5b66\u673a\u5236\uff0c\u63ed\u793a\u4e86MCPs\u901a\u8fc7\u9009\u62e9\u6027\u6e17\u900f\u6027\u6765\u9694\u79bb\u6709\u6bd2\u4e2d\u95f4\u4ea7\u7269\u4e19\u919b\u7684\u673a\u5236\u3002", "motivation": "\u7814\u7a76\u6c99\u95e8\u6c0f\u83cc\u57281,2-\u4e19\u4e8c\u9187\u66b4\u9732\u4e0b\u8868\u8fbe\u7684\u5fae\u533a\u5ba4(MCPs)\u5982\u4f55\u901a\u8fc7\u9009\u62e9\u6027\u6e17\u900f\u6027\u6765\u9650\u5236\u6709\u6bd2\u4e2d\u95f4\u4ea7\u7269\u4e19\u919b\u7684\u66b4\u9732\uff0c\u5e76\u63d0\u9ad8\u4ee3\u8c22\u901a\u91cf\u3002", "method": "\u6784\u5efa\u4e86\u7eaf\u5316MCPs\u7684\u8d28\u91cf\u4f5c\u7528\u6570\u5b66\u6a21\u578b\uff0c\u5c06\u53c2\u6570\u6821\u51c6\u5230\u6d4b\u91cf\u7684\u4ee3\u8c22\u7269\u6d53\u5ea6\uff0c\u5e76\u5c06\u8d28\u91cf\u4f5c\u7528\u52a8\u529b\u5b66\u53c2\u6570\u7ea6\u675f\u5230\u5148\u524d\u4f30\u8ba1\u7684\u7c73\u6c0f\u53c2\u6570\u3002", "result": "\u8bc6\u522b\u51fa\u4e24\u79cd\u4e0d\u540c\u7684\u62df\u5408\u7ed3\u679c\uff0c\u63a8\u65adMCP\u5bf91,2-\u4e19\u4e8c\u9187\u548c\u4e19\u919b\u7684\u6e17\u900f\u6027\u5e94\u5206\u522b\u5927\u4e8e10^-6\u548c10^-8 m/s\u3002\u8f85\u9176A(CoA)\u6e17\u900f\u6027\u5b58\u5728\u53cc\u5cf0\u5206\u5e03\uff0c\u8981\u4e48\u5c0f\u4e8e10^-8.8 m/s\uff0c\u8981\u4e48\u5927\u4e8e10^-7.3 m/s\u3002", "conclusion": "\u7ed3\u679c\u652f\u6301MCPs\u901a\u8fc7\u9009\u62e9\u6027\u6269\u6563\u9694\u79bb\u6709\u6bd2\u4e19\u919b\u7684\u7406\u8bba\uff0c\u53cc\u5cf0\u6027\u6e90\u4e8eCoA\u6e17\u900f\u6027\u548c\u6291\u5236\u7387\u7684\u53cc\u5cf0\u5206\u5e03\u3002\u9700\u89816-24\u5c0f\u65f6\u4e4b\u95f4\u7684\u989d\u5916\u6570\u636e\u70b9\u6216\u9176\u6291\u5236\u7387\u8868\u5f81\u6765\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2509.23847", "pdf": "https://arxiv.org/pdf/2509.23847", "abs": "https://arxiv.org/abs/2509.23847", "authors": ["Anton Stratmann", "Martin Bey\u00df", "Johann F. Jadebeck", "Wolfgang Wiechert", "Katharina N\u00f6h"], "title": "13CFLUX -- Third-generation high-performance engine for isotopically (non)stationary 13C metabolic flux analysis", "categories": ["q-bio.QM"], "comment": null, "summary": "13C-based metabolic flux analysis (13C-MFA) is a cornerstone of quantitative\nsystems biology, yet its increasing data complexity and methodological\ndiversity place high demands on simulation software. We introduce 13CFLUX(v3),\na third-generation simulation platform that combines a high-performance C++\nengine with a convenient Python interface. The software delivers substantial\nperformance gains across isotopically stationary and nonstationary analysis\nworkflows, while remaining flexible to accommodate diverse labeling strategies\nand analytical platforms. Its open-source availability facilitates seamless\nintegration into computational ecosystems and community-driven extension. By\nsupporting multi-experiment integration, multi-tracer studies, and advanced\nstatistical inference such as Bayesian analysis, 13CFLUX provides a robust and\nextensible framework for modern fluxomics research.", "AI": {"tldr": "13CFLUX(v3)\u662f\u4e00\u4e2a\u7b2c\u4e09\u4ee313C\u4ee3\u8c22\u901a\u91cf\u5206\u6790\u6a21\u62df\u5e73\u53f0\uff0c\u7ed3\u5408\u9ad8\u6027\u80fdC++\u5f15\u64ce\u548cPython\u63a5\u53e3\uff0c\u63d0\u4f9b\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u652f\u6301\u591a\u79cd\u6807\u8bb0\u7b56\u7565\u548c\u5206\u6790\u5e73\u53f0\u3002", "motivation": "\u968f\u774013C-MFA\u6570\u636e\u590d\u6742\u6027\u548c\u65b9\u6cd5\u591a\u6837\u6027\u7684\u589e\u52a0\uff0c\u5bf9\u6a21\u62df\u8f6f\u4ef6\u63d0\u51fa\u4e86\u66f4\u9ad8\u8981\u6c42\uff0c\u9700\u8981\u9ad8\u6027\u80fd\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86\u7ed3\u5408\u9ad8\u6027\u80fdC++\u5f15\u64ce\u548cPython\u63a5\u53e3\u7684\u6a21\u62df\u5e73\u53f0\uff0c\u652f\u6301\u540c\u4f4d\u7d20\u7a33\u6001\u548c\u975e\u7a33\u6001\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5177\u5907\u591a\u5b9e\u9a8c\u96c6\u6210\u3001\u591a\u793a\u8e2a\u5242\u7814\u7a76\u548c\u9ad8\u7ea7\u7edf\u8ba1\u63a8\u65ad\u529f\u80fd\u3002", "result": "\u8f6f\u4ef6\u5b9e\u73b0\u4e86\u8de8\u5de5\u4f5c\u6d41\u7a0b\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u4fdd\u6301\u7075\u6d3b\u6027\u4ee5\u9002\u5e94\u591a\u6837\u5316\u7684\u6807\u8bb0\u7b56\u7565\u548c\u5206\u6790\u5e73\u53f0\uff0c\u5f00\u6e90\u53ef\u7528\u6027\u4fbf\u4e8e\u96c6\u6210\u548c\u6269\u5c55\u3002", "conclusion": "13CFLUX\u4e3a\u73b0\u4ee3\u901a\u91cf\u7ec4\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5065\u4e14\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u652f\u6301\u591a\u5b9e\u9a8c\u96c6\u6210\u3001\u591a\u793a\u8e2a\u5242\u7814\u7a76\u548c\u8d1d\u53f6\u65af\u5206\u6790\u7b49\u9ad8\u7ea7\u529f\u80fd\u3002"}}
{"id": "2509.24262", "pdf": "https://arxiv.org/pdf/2509.24262", "abs": "https://arxiv.org/abs/2509.24262", "authors": ["Nimisha Ghosh", "Dheeran Sankaran", "Rahul Balakrishnan Adhi", "Sharath S", "Amrut Anand"], "title": "LAMP-PRo: Label-aware Attention for Multi-label Prediction of DNA- and RNA-binding Proteins using Protein Language Models", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "Identifying DNA- (DBPs) and RNA-binding proteins (RBPs) is crucial for the\nunderstanding of cell function, molecular interactions as well as regulatory\nfunctions. Owing to their high similarity, most of the existing approaches face\nchallenges in differentiating between DBPs and RBPs leading to high\ncross-prediction errors. Moreover, identifying proteins which bind to both DNA\nand RNA (DRBPs) is also quite a challenging task. In this regard, we propose a\nnovel framework viz. LAMP-PRo which is based on pre-trained protein language\nmodel (PLM), attention mechanisms and multi-label learning to mitigate these\nissues. First, pre-trained PLM such ESM-2 is used for embedding the protein\nsequences followed by convolutional neural network (CNN). Subsequently\nmulti-head self-attention mechanism is applied for the contextual information\nwhile label-aware attention is used to compute class-specific representations\nby attending to the sequence in a way that is tailored to each label (DBP, RBP\nand non-NABP) in a multi-label setup. We have also included a novel cross-label\nattention mechanism to explicitly capture dependencies between DNA- and\nRNA-binding proteins, enabling more accurate prediction of DRBP. Finally, a\nlinear layer followed by a sigmoid function are used for the final prediction.\nExtensive experiments are carried out to compare LAMP-PRo with the existing\nmethods wherein the proposed model shows consistent competent performance.\nFurthermore, we also provide visualization to showcase model interpretability,\nhighlighting which parts of the sequence are most relevant for a predicted\nlabel. The original datasets are available at http://bliulab.net/iDRBP\\_MMC and\nthe codes are available at https://github.com/NimishaGhosh/LAMP-PRo.", "AI": {"tldr": "LAMP-PRo\u662f\u4e00\u4e2a\u57fa\u4e8e\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u3001\u6ce8\u610f\u529b\u673a\u5236\u548c\u591a\u6807\u7b7e\u5b66\u4e60\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u51c6\u786e\u533a\u5206DNA\u7ed3\u5408\u86cb\u767d(DBP)\u3001RNA\u7ed3\u5408\u86cb\u767d(RBP)\u4ee5\u53ca\u540c\u65f6\u7ed3\u5408\u4e24\u8005\u7684\u86cb\u767d(DRBP)\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4ea4\u53c9\u9884\u6d4b\u9519\u8bef\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u7531\u4e8eDNA\u548cRNA\u7ed3\u5408\u86cb\u767d\u9ad8\u5ea6\u76f8\u4f3c\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u533a\u5206\u5b83\u4eec\uff0c\u5bfc\u81f4\u9ad8\u4ea4\u53c9\u9884\u6d4b\u9519\u8bef\u3002\u540c\u65f6\u8bc6\u522b\u540c\u65f6\u7ed3\u5408DNA\u548cRNA\u7684\u86cb\u767d\u8d28(DRBP)\u4e5f\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578bESM-2\u5d4c\u5165\u86cb\u767d\u8d28\u5e8f\u5217\uff0c\u7ed3\u5408CNN\u3001\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u6807\u7b7e\u611f\u77e5\u6ce8\u610f\u529b\uff0c\u5e76\u5f15\u5165\u8de8\u6807\u7b7e\u6ce8\u610f\u529b\u673a\u5236\u6765\u6355\u83b7DNA\u548cRNA\u7ed3\u5408\u86cb\u767d\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u6700\u540e\u901a\u8fc7\u7ebf\u6027\u5c42\u548csigmoid\u51fd\u6570\u8fdb\u884c\u591a\u6807\u7b7e\u9884\u6d4b\u3002", "result": "\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cLAMP-PRo\u8868\u73b0\u51fa\u6301\u7eed\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u53ef\u89c6\u5316\u5c55\u793a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\uff0c\u7a81\u51fa\u663e\u793a\u5e8f\u5217\u4e2d\u5bf9\u9884\u6d4b\u6807\u7b7e\u6700\u76f8\u5173\u7684\u90e8\u5206\u3002", "conclusion": "LAMP-PRo\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3DNA\u548cRNA\u7ed3\u5408\u86cb\u767d\u7684\u533a\u5206\u95ee\u9898\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6ce8\u610f\u529b\u673a\u5236\u63d0\u9ad8\u4e86DRBP\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5206\u6790\u3002"}}
{"id": "2509.24952", "pdf": "https://arxiv.org/pdf/2509.24952", "abs": "https://arxiv.org/abs/2509.24952", "authors": ["Amandla Mabona", "Jemma Daniel", "Henrik Servais Janssen Knudsen", "Rachel Catzel", "Kevin Michael Eloff", "Erwin M. Schoof", "Nicolas Lopez Carranza", "Timothy P. Jenkins", "Jeroen Van Goey", "Konstantinos Kalogeropoulos"], "title": "De novo peptide sequencing rescoring and FDR estimation with Winnow", "categories": ["q-bio.QM"], "comment": null, "summary": "Machine learning has markedly advanced de novo peptide sequencing (DNS) for\nmass spectrometry-based proteomics. DNS tools offer a reliable way to identify\npeptides without relying on reference databases, extending proteomic analysis\nand unlocking applications into less-charted regions of the proteome. However,\nthey still face a key limitation. DNS tools lack principled methods for\nestimating false discovery rates (FDR) and instead rely on model-specific\nconfidence scores that are often miscalibrated. This limits trust in results,\nhinders cross-model comparisons and reduces validation success. Here we present\nWinnow, a model-agnostic framework for estimating FDR from calibrated DNS\noutputs. Winnow maps raw model scores to calibrated confidences using a neural\nnetwork trained on peptide-spectrum match (PSM)-derived features. From these\ncalibrated scores, Winnow computes PSM-specific error metrics and an\nexperiment-wide FDR estimate using a novel decoy-free FDR estimator. It\nsupports both zero-shot and dataset-specific calibration, enabling flexible\napplication via direct inference, fine-tuning, or training a custom model. We\ndemonstrate that, when applied to InstaNovo predictions, Winnow's calibrator\nimproves recall at fixed FDR thresholds, and its FDR estimator tracks true\nerror rates when benchmarked against reference proteomes and database search.\nWinnow ensures accurate FDR control across datasets, helping unlock the full\npotential of DNS.", "AI": {"tldr": "Winnow\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u6821\u51c6\u7684de novo\u6d4b\u5e8f\u8f93\u51fa\u4e2d\u4f30\u8ba1\u5047\u53d1\u73b0\u7387\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u7f3a\u4e4f\u539f\u5219\u6027FDR\u4f30\u8ba1\u65b9\u6cd5\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684de novo\u6d4b\u5e8f\u5de5\u5177\u7f3a\u4e4f\u539f\u5219\u6027\u7684\u5047\u53d1\u73b0\u7387\u4f30\u8ba1\u65b9\u6cd5\uff0c\u4f9d\u8d56\u6a21\u578b\u7279\u5b9a\u7684\u7f6e\u4fe1\u5ea6\u5206\u6570\uff0c\u8fd9\u4e9b\u5206\u6570\u901a\u5e38\u6821\u51c6\u4e0d\u5f53\uff0c\u9650\u5236\u4e86\u7ed3\u679c\u7684\u53ef\u4fe1\u5ea6\u3001\u8de8\u6a21\u578b\u6bd4\u8f83\u548c\u9a8c\u8bc1\u6210\u529f\u7387\u3002", "method": "Winnow\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u5c06\u539f\u59cb\u6a21\u578b\u5206\u6570\u6620\u5c04\u5230\u6821\u51c6\u7f6e\u4fe1\u5ea6\uff0c\u57fa\u4e8e\u80bd\u8c31\u5339\u914d\u7279\u5f81\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u91c7\u7528\u65b0\u9896\u7684\u65e0\u8bf1\u9975FDR\u4f30\u8ba1\u5668\u8ba1\u7b97PSM\u7279\u5b9a\u8bef\u5dee\u6307\u6807\u548c\u5b9e\u9a8c\u8303\u56f4\u7684FDR\u4f30\u8ba1\u3002", "result": "\u5e94\u7528\u4e8eInstaNovo\u9884\u6d4b\u65f6\uff0cWinnow\u7684\u6821\u51c6\u5668\u5728\u56fa\u5b9aFDR\u9608\u503c\u4e0b\u63d0\u9ad8\u4e86\u53ec\u56de\u7387\uff0c\u5176FDR\u4f30\u8ba1\u5668\u5728\u53c2\u8003\u86cb\u767d\u8d28\u7ec4\u548c\u6570\u636e\u5e93\u641c\u7d22\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u80fd\u51c6\u786e\u8ddf\u8e2a\u771f\u5b9e\u8bef\u5dee\u7387\u3002", "conclusion": "Winnow\u786e\u4fdd\u4e86\u8de8\u6570\u636e\u96c6\u7684\u51c6\u786eFDR\u63a7\u5236\uff0c\u6709\u52a9\u4e8e\u91ca\u653ede novo\u6d4b\u5e8f\u7684\u5168\u90e8\u6f5c\u529b\u3002"}}
{"id": "2509.22760", "pdf": "https://arxiv.org/pdf/2509.22760", "abs": "https://arxiv.org/abs/2509.22760", "authors": ["Achraf Zinihi"], "title": "Identifying Memory Effects in Epidemics via a Fractional SEIRD Model and Physics-Informed Neural Networks", "categories": ["stat.ML", "cs.LG", "q-bio.QM", "92C60, 26A33, 65L05, 68T07"], "comment": null, "summary": "We develop a physics-informed neural network (PINN) framework for parameter\nestimation in fractional-order SEIRD epidemic models. By embedding the Caputo\nfractional derivative into the network residuals via the L1 discretization\nscheme, our method simultaneously reconstructs epidemic trajectories and infers\nboth epidemiological parameters and the fractional memory order $\\alpha$. The\nfractional formulation extends classical integer-order models by capturing\nlong-range memory effects in disease progression, incubation, and recovery. Our\nframework learns the fractional memory order $\\alpha$ as a trainable parameter\nwhile simultaneously estimating the epidemiological rates $(\\beta, \\sigma,\n\\gamma, \\mu)$. A composite loss combining data misfit, physics residuals, and\ninitial conditions, with constraints on positivity and population conservation,\nensures both accuracy and biological consistency. Tests on synthetic Mpox data\nconfirm reliable recovery of $\\alpha$ and parameters under noise, while\napplications to COVID-19 show that optimal $\\alpha \\in (0, 1]$ captures memory\neffects and improves predictive performance over the classical SEIRD model.\nThis work establishes PINNs as a robust tool for learning memory effects in\nepidemic dynamics, with implications for forecasting, control strategies, and\nthe analysis of non-Markovian epidemic processes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc(PINN)\u7684\u5206\u6570\u9636SEIRD\u6d41\u884c\u75c5\u6a21\u578b\u53c2\u6570\u4f30\u8ba1\u6846\u67b6\uff0c\u80fd\u591f\u540c\u65f6\u91cd\u5efa\u75ab\u60c5\u8f68\u8ff9\u5e76\u63a8\u65ad\u6d41\u884c\u75c5\u5b66\u53c2\u6570\u548c\u5206\u6570\u8bb0\u5fc6\u9636\u6570\u03b1\u3002", "motivation": "\u6269\u5c55\u7ecf\u5178\u6574\u6570\u9636\u6a21\u578b\u4ee5\u6355\u6349\u75be\u75c5\u8fdb\u5c55\u3001\u6f5c\u4f0f\u548c\u6062\u590d\u8fc7\u7a0b\u4e2d\u7684\u957f\u7a0b\u8bb0\u5fc6\u6548\u5e94\uff0c\u4e3a\u9884\u6d4b\u3001\u63a7\u5236\u7b56\u7565\u548c\u975e\u9a6c\u5c14\u53ef\u592b\u6d41\u884c\u75c5\u8fc7\u7a0b\u5206\u6790\u63d0\u4f9b\u5de5\u5177\u3002", "method": "\u901a\u8fc7L1\u79bb\u6563\u5316\u65b9\u6848\u5c06Caputo\u5206\u6570\u9636\u5bfc\u6570\u5d4c\u5165\u7f51\u7edc\u6b8b\u5dee\uff0c\u4f7f\u7528\u5305\u542b\u6570\u636e\u5931\u914d\u3001\u7269\u7406\u6b8b\u5dee\u548c\u521d\u59cb\u6761\u4ef6\u7684\u590d\u5408\u635f\u5931\u51fd\u6570\uff0c\u540c\u65f6\u5b66\u4e60\u5206\u6570\u8bb0\u5fc6\u9636\u6570\u03b1\u548c\u6d41\u884c\u75c5\u5b66\u53c2\u6570\u3002", "result": "\u5728\u5408\u6210Mpox\u6570\u636e\u4e0a\u53ef\u9760\u6062\u590d\u03b1\u548c\u53c2\u6570\uff0c\u5728COVID-19\u5e94\u7528\u4e2d\u663e\u793a\u6700\u4f18\u03b1\u2208(0,1]\u80fd\u6355\u6349\u8bb0\u5fc6\u6548\u5e94\u5e76\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u5efa\u7acb\u4e86PINN\u4f5c\u4e3a\u5b66\u4e60\u6d41\u884c\u75c5\u52a8\u6001\u4e2d\u8bb0\u5fc6\u6548\u5e94\u7684\u7a33\u5065\u5de5\u5177\uff0c\u5bf9\u9884\u6d4b\u3001\u63a7\u5236\u7b56\u7565\u548c\u975e\u9a6c\u5c14\u53ef\u592b\u6d41\u884c\u75c5\u8fc7\u7a0b\u5206\u6790\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2509.23552", "pdf": "https://arxiv.org/pdf/2509.23552", "abs": "https://arxiv.org/abs/2509.23552", "authors": ["Md. Saiful Bari Siddiqui", "Nowshin Tarannum"], "title": "Fusing Sequence Motifs and Pan-Genomic Features: Antimicrobial Resistance Prediction using an Explainable Lightweight 1D CNN-XGBoost Ensemble", "categories": ["cs.LG", "cs.AI", "q-bio.GN", "q-bio.QM"], "comment": "Submitted to SCA/HPCAsia 2026. This preprint version has been\n  prepared for open-access distribution and may differ in formatting from the\n  official proceedings. Also available on bioRxiv for visibility to the life\n  sciences community", "summary": "Antimicrobial Resistance (AMR) is a rapidly escalating global health crisis.\nWhile genomic sequencing enables rapid prediction of resistance phenotypes,\ncurrent computational methods have limitations. Standard machine learning\nmodels treat the genome as an unordered collection of features, ignoring the\nsequential context of Single Nucleotide Polymorphisms (SNPs). State-of-the-art\nsequence models like Transformers are often too data-hungry and computationally\nexpensive for the moderately-sized datasets that are typical in this domain. To\naddress these challenges, we propose AMR-EnsembleNet, an ensemble framework\nthat synergistically combines sequence-based and feature-based learning. We\ndeveloped a lightweight, custom 1D Convolutional Neural Network (CNN) to\nefficiently learn predictive sequence motifs from high-dimensional SNP data.\nThis sequence-aware model was ensembled with an XGBoost model, a powerful\ngradient boosting system adept at capturing complex, non-local feature\ninteractions. We trained and evaluated our framework on a benchmark dataset of\n809 E. coli strains, predicting resistance across four antibiotics with varying\nclass imbalance. Our 1D CNN-XGBoost ensemble consistently achieved top-tier\nperformance across all the antibiotics, reaching a Matthews Correlation\nCoefficient (MCC) of 0.926 for Ciprofloxacin (CIP) and the highest Macro\nF1-score of 0.691 for the challenging Gentamicin (GEN) AMR prediction. We also\nshow that our model consistently focuses on SNPs within well-known AMR genes\nlike fusA and parC, confirming it learns the correct genetic signals for\nresistance. Our work demonstrates that fusing a sequence-aware 1D CNN with a\nfeature-based XGBoost model creates a powerful ensemble, overcoming the\nlimitations of using either an order-agnostic or a standalone sequence model.", "AI": {"tldr": "\u63d0\u51faAMR-EnsembleNet\u96c6\u6210\u6846\u67b6\uff0c\u7ed3\u5408\u5e8f\u5217\u611f\u77e5\u76841D CNN\u548c\u7279\u5f81\u5b66\u4e60\u7684XGBoost\u6a21\u578b\uff0c\u7528\u4e8e\u6297\u751f\u7d20\u8010\u836f\u6027\u9884\u6d4b\uff0c\u5728E. coli\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u57fa\u56e0\u7ec4\u5e8f\u5217\u5206\u6790\u65b9\u6cd5\u5ffd\u7565SNP\u987a\u5e8f\u4e0a\u4e0b\u6587\uff0c\u4ee5\u53caTransformer\u7b49\u6a21\u578b\u5728\u4e2d\u7b49\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u8f7b\u91cf\u7ea71D CNN\u4eceSNP\u6570\u636e\u4e2d\u5b66\u4e60\u5e8f\u5217\u6a21\u5f0f\uff0c\u4e0eXGBoost\u6a21\u578b\u96c6\u6210\uff0c\u7ed3\u5408\u5e8f\u5217\u7279\u5f81\u548c\u7279\u5f81\u4ea4\u4e92\u5b66\u4e60\u3002", "result": "\u5728809\u682aE. coli\u83cc\u682a\u6570\u636e\u96c6\u4e0a\uff0c\u5bf94\u79cd\u6297\u751f\u7d20\u7684\u8010\u836f\u6027\u9884\u6d4b\u8868\u73b0\u4f18\u5f02\uff0cCIP\u7684MCC\u8fbe0.926\uff0cGEN\u7684Macro F1-score\u8fbe0.691\u3002", "conclusion": "\u878d\u5408\u5e8f\u5217\u611f\u77e5CNN\u548c\u7279\u5f81\u5b66\u4e60XGBoost\u7684\u96c6\u6210\u65b9\u6cd5\u514b\u670d\u4e86\u5355\u72ec\u4f7f\u7528\u65e0\u5e8f\u7279\u5f81\u6216\u5e8f\u5217\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u80fd\u6709\u6548\u5b66\u4e60\u8010\u836f\u6027\u9057\u4f20\u4fe1\u53f7\u3002"}}
{"id": "2509.23942", "pdf": "https://arxiv.org/pdf/2509.23942", "abs": "https://arxiv.org/abs/2509.23942", "authors": ["John N. Daras"], "title": "Efficient Identification of High Similarity Clusters in Polygon Datasets", "categories": ["cs.LG", "cs.DB", "q-bio.QM"], "comment": "11 pages, 3 figures", "summary": "Advancements in tools like Shapely 2.0 and Triton can significantly improve\nthe efficiency of spatial similarity computations by enabling faster and more\nscalable geometric operations. However, for extremely large datasets, these\noptimizations may face challenges due to the sheer volume of computations\nrequired. To address this, we propose a framework that reduces the number of\nclusters requiring verification, thereby decreasing the computational load on\nthese systems. The framework integrates dynamic similarity index thresholding,\nsupervised scheduling, and recall-constrained optimization to efficiently\nidentify clusters with the highest spatial similarity while meeting\nuser-defined precision and recall requirements. By leveraging Kernel Density\nEstimation (KDE) to dynamically determine similarity thresholds and machine\nlearning models to prioritize clusters, our approach achieves substantial\nreductions in computational cost without sacrificing accuracy. Experimental\nresults demonstrate the scalability and effectiveness of the method, offering a\npractical solution for large-scale geospatial analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u901a\u8fc7\u51cf\u5c11\u9700\u8981\u9a8c\u8bc1\u7684\u805a\u7c7b\u6570\u91cf\u6765\u964d\u4f4e\u8ba1\u7b97\u8d1f\u8f7d\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u52a8\u6001\u76f8\u4f3c\u5ea6\u7d22\u5f15\u9608\u503c\u3001\u76d1\u7763\u8c03\u5ea6\u548c\u53ec\u56de\u7ea6\u675f\u4f18\u5316\uff0c\u5728\u5927\u89c4\u6a21\u5730\u7406\u7a7a\u95f4\u5206\u6790\u4e2d\u5b9e\u73b0\u8ba1\u7b97\u6210\u672c\u663e\u8457\u964d\u4f4e\u800c\u4e0d\u727a\u7272\u51c6\u786e\u6027\u3002", "motivation": "\u867d\u7136Shapely 2.0\u548cTriton\u7b49\u5de5\u5177\u80fd\u63d0\u9ad8\u7a7a\u95f4\u76f8\u4f3c\u6027\u8ba1\u7b97\u6548\u7387\uff0c\u4f46\u5728\u5904\u7406\u6781\u5927\u6570\u636e\u96c6\u65f6\u4ecd\u9762\u4e34\u8ba1\u7b97\u91cf\u8fc7\u5927\u7684\u6311\u6218\u3002", "method": "\u96c6\u6210\u52a8\u6001\u76f8\u4f3c\u5ea6\u7d22\u5f15\u9608\u503c\u3001\u76d1\u7763\u8c03\u5ea6\u548c\u53ec\u56de\u7ea6\u675f\u4f18\u5316\u7684\u6846\u67b6\uff0c\u5229\u7528\u6838\u5bc6\u5ea6\u4f30\u8ba1\u52a8\u6001\u786e\u5b9a\u76f8\u4f3c\u5ea6\u9608\u503c\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4f18\u5148\u5904\u7406\u805a\u7c7b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u6709\u6548\u6027\uff0c\u5728\u5927\u89c4\u6a21\u5730\u7406\u7a7a\u95f4\u5206\u6790\u4e2d\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6210\u672c\u7684\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5927\u89c4\u6a21\u5730\u7406\u7a7a\u95f4\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u5728\u4e0d\u727a\u7272\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u8d1f\u8f7d\u3002"}}
{"id": "2509.24063", "pdf": "https://arxiv.org/pdf/2509.24063", "abs": "https://arxiv.org/abs/2509.24063", "authors": ["Lukas Breitwieser", "Ahmad Hesam", "Abdullah Giray Ya\u011fl\u0131k\u00e7\u0131", "Mohammad Sadrosadati", "Fons Rademakers", "Onur Mutlu"], "title": "TeraAgent: A Distributed Agent-Based Simulation Engine for Simulating Half a Trillion Agents", "categories": ["cs.DC", "cs.CE", "cs.MA", "cs.PF", "q-bio.QM"], "comment": null, "summary": "Agent-based simulation is an indispensable paradigm for studying complex\nsystems. These systems can comprise billions of agents, requiring the computing\nresources of multiple servers to simulate. Unfortunately, the state-of-the-art\nplatform, BioDynaMo, does not scale out across servers due to its\nshared-memory-based implementation.\n  To overcome this key limitation, we introduce TeraAgent, a distributed\nagent-based simulation engine. A critical challenge in distributed execution is\nthe exchange of agent information across servers, which we identify as a major\nperformance bottleneck. We propose two solutions: 1) a tailored serialization\nmechanism that allows agents to be accessed and mutated directly from the\nreceive buffer, and 2) leveraging the iterative nature of agent-based\nsimulations to reduce data transfer with delta encoding.\n  Built on our solutions, TeraAgent enables extreme-scale simulations with half\na trillion agents (an 84x improvement), reduces time-to-result with additional\ncompute nodes, improves interoperability with third-party tools, and provides\nusers with more hardware flexibility.", "AI": {"tldr": "TeraAgent\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u4ee3\u7406\u4eff\u771f\u5f15\u64ce\uff0c\u901a\u8fc7\u5b9a\u5236\u5e8f\u5217\u5316\u673a\u5236\u548c\u589e\u91cf\u7f16\u7801\u89e3\u51b3\u4e86\u8de8\u670d\u52a1\u5668\u4ee3\u7406\u4fe1\u606f\u4ea4\u6362\u7684\u6027\u80fd\u74f6\u9888\uff0c\u5b9e\u73b0\u4e86\u534a\u4e07\u4ebf\u4ee3\u7406\u7684\u6781\u7aef\u89c4\u6a21\u4eff\u771f\u3002", "motivation": "\u73b0\u6709\u7684BioDynaMo\u5e73\u53f0\u7531\u4e8e\u57fa\u4e8e\u5171\u4eab\u5185\u5b58\u5b9e\u73b0\uff0c\u65e0\u6cd5\u8de8\u670d\u52a1\u5668\u6269\u5c55\uff0c\u9650\u5236\u4e86\u5927\u89c4\u6a21\u590d\u6742\u7cfb\u7edf\u4eff\u771f\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u89e3\u51b3\u65b9\u6848\uff1a1\uff09\u5b9a\u5236\u5e8f\u5217\u5316\u673a\u5236\uff0c\u5141\u8bb8\u4ece\u63a5\u6536\u7f13\u51b2\u533a\u76f4\u63a5\u8bbf\u95ee\u548c\u4fee\u6539\u4ee3\u7406\uff1b2\uff09\u5229\u7528\u4ee3\u7406\u4eff\u771f\u7684\u8fed\u4ee3\u7279\u6027\uff0c\u901a\u8fc7\u589e\u91cf\u7f16\u7801\u51cf\u5c11\u6570\u636e\u4f20\u8f93\u3002", "result": "\u5b9e\u73b0\u4e86\u534a\u4e07\u4ebf\u4ee3\u7406\u7684\u4eff\u771f\uff0884\u500d\u6539\u8fdb\uff09\uff0c\u901a\u8fc7\u589e\u52a0\u8ba1\u7b97\u8282\u70b9\u51cf\u5c11\u7ed3\u679c\u65f6\u95f4\uff0c\u63d0\u9ad8\u4e0e\u7b2c\u4e09\u65b9\u5de5\u5177\u7684\u4e92\u64cd\u4f5c\u6027\uff0c\u63d0\u4f9b\u66f4\u591a\u786c\u4ef6\u7075\u6d3b\u6027\u3002", "conclusion": "TeraAgent\u6210\u529f\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u4ee3\u7406\u4eff\u771f\u7684\u5173\u952e\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u6781\u7aef\u89c4\u6a21\u590d\u6742\u7cfb\u7edf\u4eff\u771f\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2509.24933", "pdf": "https://arxiv.org/pdf/2509.24933", "abs": "https://arxiv.org/abs/2509.24933", "authors": ["Sebastian W. Ober", "Calvin McCarter", "Aniruddh Raghu", "Yucen Lily Li", "Alan N. Amin", "Andrew Gordon Wilson", "Hunter Elliott"], "title": "Is Sequence Information All You Need for Bayesian Optimization of Antibodies?", "categories": ["cs.LG", "q-bio.QM"], "comment": "Accepted into the AI for Science Workshop, NeurIPS 2025", "summary": "Bayesian optimization is a natural candidate for the engineering of antibody\ntherapeutic properties, which is often iterative and expensive. However,\nfinding the optimal choice of surrogate model for optimization over the highly\nstructured antibody space is difficult, and may differ depending on the\nproperty being optimized. Moreover, to the best of our knowledge, no prior\nworks have attempted to incorporate structural information into antibody\nBayesian optimization. In this work, we explore different approaches to\nincorporating structural information into Bayesian optimization, and compare\nthem to a variety of sequence-only approaches on two different antibody\nproperties, binding affinity and stability. In addition, we propose the use of\na protein language model-based ``soft constraint,'' which helps guide the\noptimization to promising regions of the space. We find that certain types of\nstructural information improve data efficiency in early optimization rounds for\nstability, but have equivalent peak performance. Moreover, when incorporating\nthe protein language model soft constraint we find that the data efficiency gap\nis diminished for affinity and eliminated for stability, resulting in\nsequence-only methods that match the performance of structure-based methods,\nraising questions about the necessity of structure in Bayesian optimization for\nantibodies.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u5728\u6297\u4f53\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\u878d\u5165\u7ed3\u6784\u4fe1\u606f\u7684\u4e0d\u540c\u65b9\u6cd5\uff0c\u5e76\u4e0e\u4ec5\u4f7f\u7528\u5e8f\u5217\u7684\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u53d1\u73b0\u7ed3\u6784\u4fe1\u606f\u5728\u65e9\u671f\u4f18\u5316\u9636\u6bb5\u5bf9\u7a33\u5b9a\u6027\u6709\u6570\u636e\u6548\u7387\u4f18\u52bf\uff0c\u4f46\u7ed3\u5408\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u8f6f\u7ea6\u675f\u540e\uff0c\u5e8f\u5217\u65b9\u6cd5\u53ef\u4ee5\u8fbe\u5230\u4e0e\u7ed3\u6784\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u6297\u4f53\u6cbb\u7597\u7279\u6027\u5de5\u7a0b\u901a\u5e38\u8fed\u4ee3\u4e14\u6602\u8d35\uff0c\u8d1d\u53f6\u65af\u4f18\u5316\u662f\u81ea\u7136\u9009\u62e9\u3002\u4f46\u4e3a\u9ad8\u5ea6\u7ed3\u6784\u5316\u7684\u6297\u4f53\u7a7a\u95f4\u9009\u62e9\u6700\u4f18\u4ee3\u7406\u6a21\u578b\u5f88\u56f0\u96be\uff0c\u4e14\u53ef\u80fd\u56e0\u4f18\u5316\u7279\u6027\u800c\u5f02\u3002\u6b64\u524d\u6ca1\u6709\u7814\u7a76\u5c1d\u8bd5\u5c06\u7ed3\u6784\u4fe1\u606f\u878d\u5165\u6297\u4f53\u8d1d\u53f6\u65af\u4f18\u5316\u3002", "method": "\u63a2\u7d22\u4e86\u5c06\u7ed3\u6784\u4fe1\u606f\u878d\u5165\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u4e0d\u540c\u65b9\u6cd5\uff0c\u4e0e\u591a\u79cd\u4ec5\u5e8f\u5217\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u6d4b\u8bd5\u4e86\u4e24\u4e2a\u6297\u4f53\u7279\u6027\uff08\u7ed3\u5408\u4eb2\u548c\u529b\u548c\u7a33\u5b9a\u6027\uff09\u3002\u63d0\u51fa\u4e86\u57fa\u4e8e\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u7684\"\u8f6f\u7ea6\u675f\"\u6765\u5f15\u5bfc\u4f18\u5316\u5230\u6709\u524d\u666f\u7684\u7a7a\u95f4\u533a\u57df\u3002", "result": "\u67d0\u4e9b\u7c7b\u578b\u7684\u7ed3\u6784\u4fe1\u606f\u5728\u65e9\u671f\u4f18\u5316\u8f6e\u6b21\u4e2d\u5bf9\u7a33\u5b9a\u6027\u63d0\u9ad8\u4e86\u6570\u636e\u6548\u7387\uff0c\u4f46\u5cf0\u503c\u6027\u80fd\u76f8\u5f53\u3002\u5f53\u7ed3\u5408\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u8f6f\u7ea6\u675f\u65f6\uff0c\u4eb2\u548c\u529b\u7684\u6570\u636e\u6548\u7387\u5dee\u8ddd\u7f29\u5c0f\uff0c\u7a33\u5b9a\u6027\u7684\u5dee\u8ddd\u6d88\u9664\uff0c\u5e8f\u5217\u65b9\u6cd5\u6027\u80fd\u4e0e\u57fa\u4e8e\u7ed3\u6784\u7684\u65b9\u6cd5\u5339\u914d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\u7ed3\u6784\u4fe1\u606f\u7684\u5fc5\u8981\u6027\u63d0\u51fa\u4e86\u8d28\u7591\uff0c\u8868\u660e\u5728\u9002\u5f53\u7ea6\u675f\u4e0b\uff0c\u4ec5\u5e8f\u5217\u65b9\u6cd5\u53ef\u4ee5\u8fbe\u5230\u4e0e\u7ed3\u6784\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002"}}
