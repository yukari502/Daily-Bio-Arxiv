{"id": "2510.01935", "pdf": "https://arxiv.org/pdf/2510.01935", "abs": "https://arxiv.org/abs/2510.01935", "authors": ["Evgeny Knyazev", "Timur Kulagin", "Ivan Antipenko", "Alexander Tonevitsky"], "title": "Single-cell sequencing of trophoblasts in preeclampsia and chemical hypoxia in BeWo b30 cells reveals EBI3, COL17A1, miR-27a-5p, and miR-193b-5p as hypoxia-response markers", "categories": ["q-bio.GN", "q-bio.CB", "q-bio.TO"], "comment": "27 pages, 10 figures, 2 tables", "summary": "Background. Preeclampsia (PE) complicates 2-8% of pregnancies and is marked\nby placental hypoxia and HIF-pathway activation, especially in early-onset PE\n(eoPE). Integrating patient tissue analyses with experimental models may reveal\ncommon molecular markers of trophoblast hypoxia.\n  Methods. We analyzed scRNA-seq data from 10 eoPE, 7 late-onset PE (loPE), and\ncorresponding control placentas, identifying villous cytotrophoblast (VCT),\nsyncytiotrophoblast (SCT), and extravillous trophoblast (EVT) subpopulations.\nBeWo b30 cells were treated for 24 h with CoCl2 (300 $\\mu$M) or an oxyquinoline\nderivative (OD, 5 $\\mu$M) to induce hypoxia. RNA and small RNA sequencing\nquantified mRNA and microRNA changes. PROGENy inferred pathway activities.\n  Results. ScRNA-seq revealed highest hypoxia pathway activation in eoPE, with\nEVT showing maximum activity among trophoblast populations. Nine genes were\nupregulated across all trophoblast types in eoPE: EBI3, CST6, FN1, RFK,\nCOL17A1, LDHA, PKP2, RPS4Y1, and RPS26. In vitro, OD induced more specific\nhypoxia responses than CoCl2, with 1,284 versus 3,032 differentially expressed\ngenes respectively. Critically, EBI3, FN1, and COL17A1 showed concordant\nupregulation in both placental tissue and OD-treated cells, while CoCl2\ntreatment produced opposite expression patterns. MicroRNA analysis identified\nhsa-miR-27a-5p and hsa-miR-193b-5p as consistently elevated in both\nexperimental conditions and previously reported in PE placental vesicles. We\nalso identified isoforms of hsa-miR-9-5p and hsa-miR-92b-3p as\nhypoxia-associated in trophoblast.\n  Conclusions. EBI3, COL17A1, hsa-miR-27a-5p, and hsa-miR-193b-5p emerge as\ntrophoblast hypoxia markers in PE. Oxyquinoline derivatives offer a more\nphysiologically relevant in vitro hypoxia model than CoCl2. This integrated\napproach advances understanding of PE pathophysiology and suggests candidate\ntherapeutic targets.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u6574\u5408\u65e9\u53d1\u578b\u5b50\u75eb\u524d\u671f\u60a3\u8005\u80ce\u76d8\u7ec4\u7ec7\u5206\u6790\u548c\u4f53\u5916\u7f3a\u6c27\u6a21\u578b\uff0c\u9274\u5b9a\u51faEBI3\u3001COL17A1\u3001hsa-miR-27a-5p\u548chsa-miR-193b-5p\u4f5c\u4e3a\u5b50\u75eb\u524d\u671f\u4e2d\u6ecb\u517b\u7ec6\u80de\u7f3a\u6c27\u7684\u5206\u5b50\u6807\u5fd7\u7269\uff0c\u5e76\u53d1\u73b0\u6c27\u55b9\u5549\u884d\u751f\u7269\u6bd4CoCl2\u63d0\u4f9b\u66f4\u751f\u7406\u76f8\u5173\u7684\u4f53\u5916\u7f3a\u6c27\u6a21\u578b\u3002", "motivation": "\u5b50\u75eb\u524d\u671f\u5f71\u54cd2-8%\u7684\u598a\u5a20\uff0c\u4ee5\u80ce\u76d8\u7f3a\u6c27\u548cHIF\u901a\u8def\u6fc0\u6d3b\u4e3a\u7279\u5f81\uff0c\u7279\u522b\u662f\u5728\u65e9\u53d1\u578b\u5b50\u75eb\u524d\u671f\u4e2d\u3002\u6574\u5408\u60a3\u8005\u7ec4\u7ec7\u5206\u6790\u548c\u5b9e\u9a8c\u6a21\u578b\u53ef\u80fd\u63ed\u793a\u6ecb\u517b\u7ec6\u80de\u7f3a\u6c27\u7684\u5171\u540c\u5206\u5b50\u6807\u8bb0\u3002", "method": "\u5206\u679010\u4f8b\u65e9\u53d1\u578b\u5b50\u75eb\u524d\u671f\u30017\u4f8b\u665a\u53d1\u578b\u5b50\u75eb\u524d\u671f\u548c\u5bf9\u7167\u80ce\u76d8\u7684scRNA-seq\u6570\u636e\uff0c\u9274\u5b9a\u7ed2\u6bdb\u7ec6\u80de\u6ecb\u517b\u7ec6\u80de\u3001\u5408\u4f53\u6ecb\u517b\u7ec6\u80de\u548c\u7ed2\u6bdb\u5916\u6ecb\u517b\u7ec6\u80de\u4e9a\u7fa4\u3002\u4f7f\u7528CoCl2\u6216\u6c27\u55b9\u5549\u884d\u751f\u7269\u5904\u7406BeWo b30\u7ec6\u80de\u8bf1\u5bfc\u7f3a\u6c27\uff0c\u8fdb\u884cRNA\u548c\u5c0fRNA\u6d4b\u5e8f\u5206\u6790mRNA\u548cmicroRNA\u53d8\u5316\uff0c\u4f7f\u7528PROGENy\u63a8\u65ad\u901a\u8def\u6d3b\u6027\u3002", "result": "\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u663e\u793a\u65e9\u53d1\u578b\u5b50\u75eb\u524d\u671f\u7f3a\u6c27\u901a\u8def\u6fc0\u6d3b\u6700\u9ad8\uff0c\u7ed2\u6bdb\u5916\u6ecb\u517b\u7ec6\u80de\u6d3b\u6027\u6700\u5f3a\u3002\u9274\u5b9a\u51fa9\u4e2a\u5728\u65e9\u53d1\u578b\u5b50\u75eb\u524d\u671f\u6240\u6709\u6ecb\u517b\u7ec6\u80de\u7c7b\u578b\u4e2d\u4e0a\u8c03\u7684\u57fa\u56e0\u3002\u4f53\u5916\u5b9e\u9a8c\u4e2d\uff0c\u6c27\u55b9\u5549\u884d\u751f\u7269\u6bd4CoCl2\u8bf1\u5bfc\u66f4\u7279\u5f02\u7684\u7f3a\u6c27\u53cd\u5e94\u3002EBI3\u3001FN1\u548cCOL17A1\u5728\u80ce\u76d8\u7ec4\u7ec7\u548c\u6c27\u55b9\u5549\u884d\u751f\u7269\u5904\u7406\u7ec6\u80de\u4e2d\u4e00\u81f4\u4e0a\u8c03\u3002\u9274\u5b9a\u51fahsa-miR-27a-5p\u548chsa-miR-193b-5p\u5728\u5b9e\u9a8c\u6761\u4ef6\u548c\u5b50\u75eb\u524d\u671f\u80ce\u76d8\u56ca\u6ce1\u4e2d\u6301\u7eed\u5347\u9ad8\u3002", "conclusion": "EBI3\u3001COL17A1\u3001hsa-miR-27a-5p\u548chsa-miR-193b-5p\u662f\u5b50\u75eb\u524d\u671f\u4e2d\u6ecb\u517b\u7ec6\u80de\u7f3a\u6c27\u7684\u6807\u5fd7\u7269\u3002\u6c27\u55b9\u5549\u884d\u751f\u7269\u6bd4CoCl2\u63d0\u4f9b\u66f4\u751f\u7406\u76f8\u5173\u7684\u4f53\u5916\u7f3a\u6c27\u6a21\u578b\u3002\u8fd9\u79cd\u6574\u5408\u65b9\u6cd5\u63a8\u8fdb\u4e86\u5bf9\u5b50\u75eb\u524d\u671f\u75c5\u7406\u751f\u7406\u5b66\u7684\u7406\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u5019\u9009\u6cbb\u7597\u9776\u70b9\u3002"}}
{"id": "2510.01282", "pdf": "https://arxiv.org/pdf/2510.01282", "abs": "https://arxiv.org/abs/2510.01282", "authors": ["Shuyang Chu", "Jingang Shi", "Xu Cheng", "Haoyu Chen", "Xin Liu", "Jian Xu", "Guoying Zhao"], "title": "To Remember, To Adapt, To Preempt: A Stable Continual Test-Time Adaptation Framework for Remote Physiological Measurement in Dynamic Domain Shifts", "categories": ["q-bio.QM"], "comment": null, "summary": "Remote photoplethysmography (rPPG) aims to extract non-contact physiological\nsignals from facial videos and has shown great potential. However, existing\nrPPG approaches struggle to bridge the gap between source and target domains.\nRecent test-time adaptation (TTA) solutions typically optimize rPPG model for\nthe incoming test videos using self-training loss under an unrealistic\nassumption that the target domain remains stationary. However, time-varying\nfactors like weather and lighting in dynamic environments often cause continual\ndomain shifts. The erroneous gradients accumulation from these shifts may\ncorrupt the model's key parameters for physiological information, leading to\ncatastrophic forgetting. Therefore, We propose a physiology-related parameters\nfreezing strategy to retain such knowledge. It isolates physiology-related and\ndomain-related parameters by assessing the model's uncertainty to current\ndomain and freezes the physiology-related parameters during adaptation to\nprevent catastrophic forgetting. Moreover, the dynamic domain shifts with\nvarious non-physiological characteristics may lead to conflicting optimization\nobjectives during TTA, which is manifested as the over-adapted model losing its\nadaptability to future domains. To fix over-adaptation, we propose a preemptive\ngradient modification strategy. It preemptively adapts to future domains and\nuses the acquired gradients to modify current adaptation, thereby preserving\nthe model's adaptability. In summary, we propose a stable continual test-time\nadaptation (CTTA) framework for rPPG measurement, called \\textbf{PhysRAP},\nwhich \\textbf{R}emembers the past, \\textbf{A}dapts to the present, and\n\\textbf{P}reempts the future. Extensive experiments show its state-of-the-art\nperformance, especially in domain shifts. The code is available at\nhttps://github.com/xjtucsy/PhysRAP.", "AI": {"tldr": "\u63d0\u51fa\u4e86PhysRAP\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u7406\u76f8\u5173\u53c2\u6570\u51bb\u7ed3\u548c\u9884\u5224\u6027\u68af\u5ea6\u4fee\u6539\u7b56\u7565\uff0c\u89e3\u51b3\u8fdc\u7a0b\u5149\u7535\u5bb9\u79ef\u63cf\u8bb0(rPPG)\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6301\u7eed\u6d4b\u8bd5\u65f6\u9002\u5e94\u95ee\u9898\u3002", "motivation": "\u73b0\u6709rPPG\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u6e90\u57df\u548c\u76ee\u6807\u57df\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u800c\u4f20\u7edf\u6d4b\u8bd5\u65f6\u9002\u5e94\u65b9\u6cd5\u5047\u8bbe\u76ee\u6807\u57df\u9759\u6b62\uff0c\u65e0\u6cd5\u5904\u7406\u52a8\u6001\u73af\u5883\u4e2d\u6301\u7eed\u53d8\u5316\u7684\u57df\u504f\u79fb\uff0c\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\u548c\u8fc7\u9002\u5e94\u95ee\u9898\u3002", "method": "1. \u751f\u7406\u76f8\u5173\u53c2\u6570\u51bb\u7ed3\u7b56\u7565\uff1a\u901a\u8fc7\u8bc4\u4f30\u6a21\u578b\u5bf9\u5f53\u524d\u57df\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u5206\u79bb\u751f\u7406\u76f8\u5173\u548c\u57df\u76f8\u5173\u53c2\u6570\uff0c\u51bb\u7ed3\u751f\u7406\u76f8\u5173\u53c2\u6570\u4ee5\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\uff1b2. \u9884\u5224\u6027\u68af\u5ea6\u4fee\u6539\u7b56\u7565\uff1a\u9884\u5148\u9002\u5e94\u672a\u6765\u57df\u5e76\u4f7f\u7528\u83b7\u5f97\u7684\u68af\u5ea6\u4fee\u6539\u5f53\u524d\u9002\u5e94\uff0c\u4fdd\u6301\u6a21\u578b\u9002\u5e94\u6027\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660ePhysRAP\u5728\u57df\u504f\u79fb\u60c5\u51b5\u4e0b\u5177\u6709\u6700\u5148\u8fdb\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "PhysRAP\u6846\u67b6\u80fd\u591f\u8bb0\u4f4f\u8fc7\u53bb\u3001\u9002\u5e94\u73b0\u5728\u3001\u9884\u5224\u672a\u6765\uff0c\u6709\u6548\u89e3\u51b3\u4e86rPPG\u6d4b\u91cf\u4e2d\u7684\u6301\u7eed\u6d4b\u8bd5\u65f6\u9002\u5e94\u6311\u6218\u3002"}}
{"id": "2510.01287", "pdf": "https://arxiv.org/pdf/2510.01287", "abs": "https://arxiv.org/abs/2510.01287", "authors": ["Runchen Wang", "Junlin Guo", "Siqi Lu", "Ruining Deng", "Zhengyi Lu", "Yanfan Zhu", "Yuechen Yang", "Chongyu Qu", "Yu Wang", "Shilin Zhao", "Catie Chang", "Mitchell Wilkes", "Mengmeng Yin", "Haichun Yang", "Yuankai Huo"], "title": "Evaluating New AI Cell Foundation Models on Challenging Kidney Pathology Cases Unaddressed by Previous Foundation Models", "categories": ["q-bio.QM", "cs.AI"], "comment": null, "summary": "Accurate cell nuclei segmentation is critical for downstream tasks in kidney\npathology and remains a major challenge due to the morphological diversity and\nimaging variability of renal tissues. While our prior work has evaluated\nearly-generation AI cell foundation models in this domain, the effectiveness of\nrecent cell foundation models remains unclear. In this study, we benchmark\nadvanced AI cell foundation models (2025), including CellViT++ variants and\nCellpose-SAM, against three widely used cell foundation models developed prior\nto 2024, using a diverse large-scale set of kidney image patches within a\nhuman-in-the-loop rating framework. We further performed fusion-based ensemble\nevaluation and model agreement analysis to assess the segmentation capabilities\nof the different models. Our results show that CellViT++ [Virchow] yields the\nhighest standalone performance with 40.3% of predictions rated as \"Good\" on a\ncurated set of 2,091 challenging samples, outperforming all prior models. In\naddition, our fused model achieves 62.2% \"Good\" predictions and only 0.4%\n\"Bad\", substantially reducing segmentation errors. Notably, the fusion model\n(2025) successfully resolved the majority of challenging cases that remained\nunaddressed in our previous study. These findings demonstrate the potential of\nAI cell foundation model development in renal pathology and provide a curated\ndataset of challenging samples to support future kidney-specific model\nrefinement.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e862025\u5e74\u5148\u8fdb\u7684AI\u7ec6\u80de\u57fa\u7840\u6a21\u578b\uff08\u5305\u62ecCellViT++\u53d8\u4f53\u548cCellpose-SAM\uff09\u5728\u80be\u810f\u75c5\u7406\u56fe\u50cf\u4e2d\u7684\u7ec6\u80de\u6838\u5206\u5272\u6027\u80fd\uff0c\u53d1\u73b0CellViT++ [Virchow]\u8868\u73b0\u6700\u4f73\uff0c\u878d\u5408\u6a21\u578b\u80fd\u663e\u8457\u51cf\u5c11\u5206\u5272\u9519\u8bef\u3002", "motivation": "\u7531\u4e8e\u80be\u810f\u7ec4\u7ec7\u5f62\u6001\u591a\u6837\u6027\u548c\u6210\u50cf\u53d8\u5f02\u6027\uff0c\u51c6\u786e\u7684\u7ec6\u80de\u6838\u5206\u5272\u5bf9\u80be\u810f\u75c5\u7406\u5b66\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8fd1\u671f\u7ec6\u80de\u57fa\u7840\u6a21\u578b\u5728\u8be5\u9886\u57df\u7684\u6709\u6548\u6027\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u4f7f\u7528\u4eba\u7c7b\u53c2\u4e0e\u8bc4\u5206\u6846\u67b6\uff0c\u5728\u5927\u578b\u591a\u6837\u5316\u80be\u810f\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u5bf9\u6bd4\u65b0\u65e7\u7ec6\u80de\u57fa\u7840\u6a21\u578b\uff0c\u5e76\u8fdb\u884c\u878d\u5408\u96c6\u6210\u8bc4\u4f30\u548c\u6a21\u578b\u4e00\u81f4\u6027\u5206\u6790\u3002", "result": "CellViT++ [Virchow]\u57282091\u4e2a\u6311\u6218\u6027\u6837\u672c\u4e2d40.3%\u9884\u6d4b\u88ab\u8bc4\u4e3a\"\u826f\u597d\"\uff0c\u878d\u5408\u6a21\u578b\u8fbe\u523062.2%\"\u826f\u597d\"\u9884\u6d4b\u4e14\u4ec50.4%\"\u5dee\"\u9884\u6d4b\uff0c\u663e\u8457\u6539\u5584\u5206\u5272\u8d28\u91cf\u3002", "conclusion": "AI\u7ec6\u80de\u57fa\u7840\u6a21\u578b\u5728\u80be\u810f\u75c5\u7406\u5b66\u4e2d\u5177\u6709\u91cd\u8981\u6f5c\u529b\uff0c\u878d\u5408\u6a21\u578b\u80fd\u6709\u6548\u89e3\u51b3\u5148\u524d\u7814\u7a76\u4e2d\u672a\u89e3\u51b3\u7684\u6311\u6218\u6027\u6848\u4f8b\uff0c\u4e3a\u672a\u6765\u80be\u810f\u7279\u5f02\u6027\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9d\u8d35\u6570\u636e\u96c6\u3002"}}
{"id": "2510.01298", "pdf": "https://arxiv.org/pdf/2510.01298", "abs": "https://arxiv.org/abs/2510.01298", "authors": ["Berker Demirel", "Marco Fumero", "Theofanis Karaletsos", "Francesco Locatello"], "title": "MorphGen: Controllable and Morphologically Plausible Generative Cell-Imaging", "categories": ["q-bio.QM", "cs.CV", "cs.LG"], "comment": null, "summary": "Simulating in silico cellular responses to interventions is a promising\ndirection to accelerate high-content image-based assays, critical for advancing\ndrug discovery and gene editing. To support this, we introduce MorphGen, a\nstate-of-the-art diffusion-based generative model for fluorescent microscopy\nthat enables controllable generation across multiple cell types and\nperturbations. To capture biologically meaningful patterns consistent with\nknown cellular morphologies, MorphGen is trained with an alignment loss to\nmatch its representations to the phenotypic embeddings of OpenPhenom, a\nstate-of-the-art biological foundation model. Unlike prior approaches that\ncompress multichannel stains into RGB images -- thus sacrificing\norganelle-specific detail -- MorphGen generates the complete set of fluorescent\nchannels jointly, preserving per-organelle structures and enabling a\nfine-grained morphological analysis that is essential for biological\ninterpretation. We demonstrate biological consistency with real images via\nCellProfiler features, and MorphGen attains an FID score over $35\\%$ lower than\nthe prior state-of-the-art MorphoDiff, which only generates RGB images for a\nsingle cell type. Code is available at https://github.com/czi-ai/MorphGen.", "AI": {"tldr": "MorphGen\u662f\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u8367\u5149\u663e\u5fae\u955c\u56fe\u50cf\u751f\u6210\u6a21\u578b\uff0c\u80fd\u591f\u8de8\u591a\u79cd\u7ec6\u80de\u7c7b\u578b\u548c\u6270\u52a8\u8fdb\u884c\u53ef\u63a7\u751f\u6210\uff0c\u901a\u8fc7\u5339\u914dOpenPhenom\u7684\u8868\u578b\u5d4c\u5165\u6765\u4fdd\u6301\u751f\u7269\u5b66\u4e00\u81f4\u6027\uff0c\u5e76\u8054\u5408\u751f\u6210\u5b8c\u6574\u7684\u8367\u5149\u901a\u9053\u4ee5\u4fdd\u7559\u7ec6\u80de\u5668\u7ec6\u8282\u3002", "motivation": "\u52a0\u901f\u57fa\u4e8e\u9ad8\u5185\u6db5\u56fe\u50cf\u7684\u7ec6\u80de\u5e72\u9884\u53cd\u5e94\u5206\u6790\uff0c\u8fd9\u5bf9\u836f\u7269\u53d1\u73b0\u548c\u57fa\u56e0\u7f16\u8f91\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u5c06\u591a\u901a\u9053\u67d3\u8272\u538b\u7f29\u4e3aRGB\u56fe\u50cf\u4f1a\u727a\u7272\u7ec6\u80de\u5668\u7279\u5f02\u6027\u7ec6\u8282\u3002", "method": "\u4f7f\u7528\u6269\u6563\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u5bf9\u9f50\u635f\u5931\u5c06\u6a21\u578b\u8868\u793a\u4e0eOpenPhenom\u751f\u7269\u57fa\u7840\u6a21\u578b\u7684\u8868\u578b\u5d4c\u5165\u5339\u914d\uff0c\u8054\u5408\u751f\u6210\u5b8c\u6574\u7684\u8367\u5149\u901a\u9053\u800c\u975e\u538b\u7f29\u4e3aRGB\u3002", "result": "\u901a\u8fc7CellProfiler\u7279\u5f81\u9a8c\u8bc1\u4e86\u4e0e\u771f\u5b9e\u56fe\u50cf\u7684\u751f\u7269\u5b66\u4e00\u81f4\u6027\uff0cFID\u5206\u6570\u6bd4\u4e4b\u524d\u6700\u5148\u8fdb\u7684MorphoDiff\u6a21\u578b\u964d\u4f4e\u4e8635%\u4ee5\u4e0a\u3002", "conclusion": "MorphGen\u80fd\u591f\u751f\u6210\u751f\u7269\u5b66\u4e00\u81f4\u7684\u591a\u901a\u9053\u8367\u5149\u663e\u5fae\u955c\u56fe\u50cf\uff0c\u4e3a\u836f\u7269\u53d1\u73b0\u548c\u57fa\u56e0\u7f16\u8f91\u63d0\u4f9b\u66f4\u7cbe\u7ec6\u7684\u5f62\u6001\u5b66\u5206\u6790\u80fd\u529b\u3002"}}
{"id": "2510.01428", "pdf": "https://arxiv.org/pdf/2510.01428", "abs": "https://arxiv.org/abs/2510.01428", "authors": ["Ching-Huei Tsou", "Michal Ozery-Flato", "Ella Barkan", "Diwakar Mahajan", "Ben Shapira"], "title": "BioVERSE: Representation Alignment of Biomedical Modalities to LLMs for Multi-Modal Reasoning", "categories": ["q-bio.QM", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) and biomedical foundation\nmodels (BioFMs) have achieved strong results in biological text reasoning,\nmolecular modeling, and single-cell analysis, yet they remain siloed in\ndisjoint embedding spaces, limiting cross-modal reasoning. We present BIOVERSE\n(Biomedical Vector Embedding Realignment for Semantic Engagement), a two-stage\napproach that adapts pretrained BioFMs as modality encoders and aligns them\nwith LLMs through lightweight, modality-specific projection layers. The\napproach first aligns each modality to a shared LLM space through independently\ntrained projections, allowing them to interoperate naturally, and then applies\nstandard instruction tuning with multi-modal data to bring them together for\ndownstream reasoning. By unifying raw biomedical data with knowledge embedded\nin LLMs, the approach enables zero-shot annotation, cross-modal question\nanswering, and interactive, explainable dialogue. Across tasks spanning\ncell-type annotation, molecular description, and protein function reasoning,\ncompact BIOVERSE configurations surpass larger LLM baselines while enabling\nricher, generative outputs than existing BioFMs, establishing a foundation for\nprincipled multi-modal biomedical reasoning.", "AI": {"tldr": "BIOVERSE\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6295\u5f71\u5c42\u5c06\u9884\u8bad\u7ec3\u7684\u751f\u7269\u533b\u5b66\u57fa\u7840\u6a21\u578b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\uff0c\u5b9e\u73b0\u8de8\u6a21\u6001\u63a8\u7406", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u751f\u7269\u533b\u5b66\u57fa\u7840\u6a21\u578b\u5728\u5404\u81ea\u5d4c\u5165\u7a7a\u95f4\u4e2d\u72ec\u7acb\u5de5\u4f5c\uff0c\u9650\u5236\u4e86\u8de8\u6a21\u6001\u63a8\u7406\u80fd\u529b", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u9996\u5148\u901a\u8fc7\u72ec\u7acb\u8bad\u7ec3\u7684\u6295\u5f71\u5c42\u5c06\u5404\u6a21\u6001\u5bf9\u9f50\u5230\u5171\u4eab\u7684LLM\u7a7a\u95f4\uff0c\u7136\u540e\u4f7f\u7528\u591a\u6a21\u6001\u6570\u636e\u8fdb\u884c\u6807\u51c6\u6307\u4ee4\u8c03\u4f18", "result": "\u5728\u7ec6\u80de\u7c7b\u578b\u6ce8\u91ca\u3001\u5206\u5b50\u63cf\u8ff0\u548c\u86cb\u767d\u8d28\u529f\u80fd\u63a8\u7406\u7b49\u4efb\u52a1\u4e2d\uff0c\u7d27\u51d1\u7684BIOVERSE\u914d\u7f6e\u8d85\u8d8a\u4e86\u66f4\u5927\u7684LLM\u57fa\u7ebf\uff0c\u540c\u65f6\u6bd4\u73b0\u6709BioFMs\u4ea7\u751f\u66f4\u4e30\u5bcc\u7684\u751f\u6210\u8f93\u51fa", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u539f\u5219\u6027\u7684\u591a\u6a21\u6001\u751f\u7269\u533b\u5b66\u63a8\u7406\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\u96f6\u6837\u672c\u6ce8\u91ca\u3001\u8de8\u6a21\u6001\u95ee\u7b54\u548c\u4ea4\u4e92\u5f0f\u53ef\u89e3\u91ca\u5bf9\u8bdd"}}
{"id": "2510.01480", "pdf": "https://arxiv.org/pdf/2510.01480", "abs": "https://arxiv.org/abs/2510.01480", "authors": ["Ekaterina Podplutova", "Anastasia Vepreva", "Olga A. Konovalova", "Vladimir Vinogradov", "Dmitrii O. Shkil", "Andrei Dmitrenko"], "title": "Pharmacophore-Guided Generative Design of Novel Drug-Like Molecules", "categories": ["q-bio.QM", "cs.AI"], "comment": "AI4Mat-NeurIPS-2025 Poster", "summary": "The integration of artificial intelligence (AI) in early-stage drug discovery\noffers unprecedented opportunities for exploring chemical space and\naccelerating hit-to-lead optimization. However, docking optimization in\ngenerative approaches is computationally expensive and may lead to inaccurate\nresults. Here, we present a novel generative framework that balances\npharmacophore similarity to reference compounds with structural diversity from\nactive molecules. The framework allows users to provide custom reference sets,\nincluding FDA-approved drugs or clinical candidates, and guides the \\textit{de\nnovo} generation of potential therapeutics. We demonstrate its applicability\nthrough a case study targeting estrogen receptor modulators and antagonists for\nbreast cancer. The generated compounds maintain high pharmacophoric fidelity to\nknown active molecules while introducing substantial structural novelty,\nsuggesting strong potential for functional innovation and patentability.\nComprehensive evaluation of the generated molecules against common drug-like\nproperties confirms the robustness and pharmaceutical relevance of the\napproach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u751f\u6210\u6846\u67b6\uff0c\u5728\u836f\u7269\u53d1\u73b0\u4e2d\u5e73\u8861\u836f\u6548\u56e2\u76f8\u4f3c\u6027\u548c\u7ed3\u6784\u591a\u6837\u6027\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u5728\u4e73\u817a\u764c\u6cbb\u7597\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "AI\u5728\u65e9\u671f\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u5e94\u7528\u867d\u7136\u63d0\u4f9b\u4e86\u63a2\u7d22\u5316\u5b66\u7a7a\u95f4\u7684\u5de8\u5927\u673a\u4f1a\uff0c\u4f46\u5bf9\u63a5\u4f18\u5316\u5728\u751f\u6210\u65b9\u6cd5\u4e2d\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u7ed3\u679c\u53ef\u80fd\u4e0d\u51c6\u786e\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u751f\u6210\u6846\u67b6\uff0c\u5141\u8bb8\u7528\u6237\u63d0\u4f9b\u81ea\u5b9a\u4e49\u53c2\u8003\u96c6\uff08\u5982FDA\u6279\u51c6\u836f\u7269\uff09\uff0c\u6307\u5bfc\u4ece\u5934\u751f\u6210\u6f5c\u5728\u6cbb\u7597\u836f\u7269\uff0c\u5e73\u8861\u53c2\u8003\u5316\u5408\u7269\u7684\u836f\u6548\u56e2\u76f8\u4f3c\u6027\u548c\u6d3b\u6027\u5206\u5b50\u7684\u7ed3\u6784\u591a\u6837\u6027\u3002", "result": "\u751f\u6210\u7684\u5316\u5408\u7269\u5728\u4fdd\u6301\u5bf9\u5df2\u77e5\u6d3b\u6027\u5206\u5b50\u9ad8\u836f\u6548\u56e2\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\uff0c\u5f15\u5165\u4e86\u663e\u8457\u7684\u7ed3\u6784\u65b0\u9896\u6027\uff0c\u663e\u793a\u51fa\u529f\u80fd\u521b\u65b0\u548c\u53ef\u4e13\u5229\u6027\u7684\u5f3a\u5927\u6f5c\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5168\u9762\u8bc4\u4f30\u751f\u6210\u7684\u5206\u5b50\u5bf9\u5e38\u89c1\u7c7b\u836f\u7269\u6027\u8d28\u7684\u7b26\u5408\u7a0b\u5ea6\uff0c\u8bc1\u5b9e\u4e86\u5176\u7a33\u5065\u6027\u548c\u836f\u7269\u76f8\u5173\u6027\u3002"}}
{"id": "2510.01694", "pdf": "https://arxiv.org/pdf/2510.01694", "abs": "https://arxiv.org/abs/2510.01694", "authors": ["Tony Wong", "Ikchang Cho", "Maria R. D'Orsogna", "Tom Chou"], "title": "First passage times to T cell activation", "categories": ["q-bio.QM", "q-bio.CB", "35K57, 35Q92, 60J70, 92C17, 92C37"], "comment": null, "summary": "Effective recognition of foreign antigens by the adaptive immune system\nrelies on T cells being activated by antigen-presenting cells (APCs) in lymph\nnodes. Here, diffusing T cells may encounter cognate APCs that present matching\nantigen fragments or non-cognate ones that do not; they are also subject to\ndegradation. We develop a stochastic model in which T cell-APCs interact via a\nsequence of recognition steps, represented as a multistage Markov chain. T\ncells are successfully activated only if the terminal state associated with a\ncognate APC is reached. We compute the probability of successful activation in\nthe presence of interfering non-cognate APCs, T cell degradation, and lymph\nnode exit, and analyze the mean first-passage time to activation. We also\nincorporate a kinetic proofreading mechanism that enables state resetting, and\nshow how this enhances specificity toward cognate APCs.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u968f\u673a\u6a21\u578b\u6765\u7814\u7a76T\u7ec6\u80de\u5728\u6dcb\u5df4\u7ed3\u4e2d\u5982\u4f55\u901a\u8fc7\u591a\u9636\u6bb5\u8bc6\u522b\u8fc7\u7a0b\u88ab\u6297\u539f\u5448\u9012\u7ec6\u80de\u6fc0\u6d3b\uff0c\u5206\u6790\u4e86\u5728\u975e\u7279\u5f02\u6027APC\u5e72\u6270\u3001T\u7ec6\u80de\u964d\u89e3\u548c\u6dcb\u5df4\u7ed3\u9000\u51fa\u7684\u60c5\u51b5\u4e0b\u6210\u529f\u6fc0\u6d3b\u7684\u6982\u7387\u548c\u5e73\u5747\u65f6\u95f4\u3002", "motivation": "\u7814\u7a76\u9002\u5e94\u6027\u514d\u75ab\u7cfb\u7edf\u4e2dT\u7ec6\u80de\u5982\u4f55\u6709\u6548\u8bc6\u522b\u5916\u6765\u6297\u539f\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u975e\u7279\u5f02\u6027\u6297\u539f\u5448\u9012\u7ec6\u80de\u5e72\u6270\u3001T\u7ec6\u80de\u964d\u89e3\u548c\u6dcb\u5df4\u7ed3\u9000\u51fa\u7684\u590d\u6742\u73af\u5883\u4e2d\u3002", "method": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u968f\u673a\u6a21\u578b\uff0c\u5c06T\u7ec6\u80de\u4e0eAPC\u7684\u76f8\u4e92\u4f5c\u7528\u8868\u793a\u4e3a\u591a\u9636\u6bb5\u9a6c\u5c14\u53ef\u592b\u94fe\uff0cT\u7ec6\u80de\u53ea\u6709\u5728\u8fbe\u5230\u4e0e\u7279\u5f02\u6027APC\u76f8\u5173\u7684\u7ec8\u7aef\u72b6\u6001\u65f6\u624d\u80fd\u6210\u529f\u6fc0\u6d3b\u3002", "result": "\u8ba1\u7b97\u4e86\u5728\u5e72\u6270\u56e0\u7d20\u5b58\u5728\u4e0b\u6210\u529f\u6fc0\u6d3b\u7684\u6982\u7387\u548c\u5e73\u5747\u9996\u6b21\u901a\u8fc7\u65f6\u95f4\uff0c\u5e76\u8bc1\u660e\u5f15\u5165\u52a8\u529b\u5b66\u6821\u5bf9\u673a\u5236\uff08\u5141\u8bb8\u72b6\u6001\u91cd\u7f6e\uff09\u80fd\u589e\u5f3a\u5bf9\u7279\u5f02\u6027APC\u7684\u9009\u62e9\u6027\u3002", "conclusion": "\u591a\u9636\u6bb5\u8bc6\u522b\u8fc7\u7a0b\u548c\u72b6\u6001\u91cd\u7f6e\u673a\u5236\u80fd\u591f\u63d0\u9ad8T\u7ec6\u80de\u5bf9\u6297\u539f\u7684\u7279\u5f02\u6027\u8bc6\u522b\uff0c\u589e\u5f3a\u514d\u75ab\u7cfb\u7edf\u7684\u7cbe\u786e\u6027\u3002"}}
{"id": "2510.02037", "pdf": "https://arxiv.org/pdf/2510.02037", "abs": "https://arxiv.org/abs/2510.02037", "authors": ["Carlijn Lems", "Leslie Tessier", "John-Melle Bokhorst", "Mart van Rijthoven", "Witali Aswolinskiy", "Matteo Pozzi", "Natalie Klubickova", "Suzanne Dintzis", "Michela Campora", "Maschenka Balkenhol", "Peter Bult", "Joey Spronck", "Thomas Detone", "Mattia Barbareschi", "Enrico Munari", "Giuseppe Bogina", "Jelle Wesseling", "Esther H. Lips", "Francesco Ciompi", "Fr\u00e9d\u00e9rique Meeuwsen", "Jeroen van der Laak"], "title": "A Multicentric Dataset for Training and Benchmarking Breast Cancer Segmentation in H&E Slides", "categories": ["q-bio.QM", "cs.CV", "eess.IV"], "comment": "Our dataset is available at https://zenodo.org/records/16812932 , our\n  code is available at https://github.com/DIAGNijmegen/beetle , and our\n  benchmark is available at https://beetle.grand-challenge.org/", "summary": "Automated semantic segmentation of whole-slide images (WSIs) stained with\nhematoxylin and eosin (H&E) is essential for large-scale artificial\nintelligence-based biomarker analysis in breast cancer. However, existing\npublic datasets for breast cancer segmentation lack the morphological diversity\nneeded to support model generalizability and robust biomarker validation across\nheterogeneous patient cohorts. We introduce BrEast cancEr hisTopathoLogy\nsEgmentation (BEETLE), a dataset for multiclass semantic segmentation of\nH&E-stained breast cancer WSIs. It consists of 587 biopsies and resections from\nthree collaborating clinical centers and two public datasets, digitized using\nseven scanners, and covers all molecular subtypes and histological grades.\nUsing diverse annotation strategies, we collected annotations across four\nclasses - invasive epithelium, non-invasive epithelium, necrosis, and other -\nwith particular focus on morphologies underrepresented in existing datasets,\nsuch as ductal carcinoma in situ and dispersed lobular tumor cells. The\ndataset's diversity and relevance to the rapidly growing field of automated\nbiomarker quantification in breast cancer ensure its high potential for reuse.\nFinally, we provide a well-curated, multicentric external evaluation set to\nenable standardized benchmarking of breast cancer segmentation models.", "AI": {"tldr": "BEETLE\u6570\u636e\u96c6\u662f\u4e00\u4e2a\u7528\u4e8e\u4e73\u817a\u764cH&E\u67d3\u8272\u5168\u5207\u7247\u56fe\u50cf\u591a\u7c7b\u8bed\u4e49\u5206\u5272\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b587\u4e2a\u6d3b\u68c0\u548c\u5207\u9664\u6837\u672c\uff0c\u6db5\u76d6\u6240\u6709\u5206\u5b50\u4e9a\u578b\u548c\u7ec4\u7ec7\u5b66\u7b49\u7ea7\uff0c\u7279\u522b\u5173\u6ce8\u73b0\u6709\u6570\u636e\u96c6\u4e2d\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u5f62\u6001\u5b66\u7279\u5f81\u3002", "motivation": "\u73b0\u6709\u7684\u4e73\u817a\u764c\u5206\u5272\u516c\u5171\u6570\u636e\u96c6\u7f3a\u4e4f\u5f62\u6001\u591a\u6837\u6027\uff0c\u65e0\u6cd5\u652f\u6301\u6a21\u578b\u6cdb\u5316\u6027\u548c\u5728\u5f02\u8d28\u6027\u60a3\u8005\u961f\u5217\u4e2d\u8fdb\u884c\u7a33\u5065\u7684\u751f\u7269\u6807\u5fd7\u7269\u9a8c\u8bc1\u3002", "method": "\u4ece\u4e09\u4e2a\u4e34\u5e8a\u4e2d\u5fc3\u548c\u4e24\u4e2a\u516c\u5171\u6570\u636e\u96c6\u6536\u96c6587\u4e2a\u6837\u672c\uff0c\u4f7f\u7528\u4e03\u79cd\u626b\u63cf\u4eea\u6570\u5b57\u5316\uff0c\u91c7\u7528\u591a\u6837\u5316\u6807\u6ce8\u7b56\u7565\u6536\u96c6\u56db\u4e2a\u7c7b\u522b\u7684\u6ce8\u91ca\uff1a\u4fb5\u88ad\u6027\u4e0a\u76ae\u3001\u975e\u4fb5\u88ad\u6027\u4e0a\u76ae\u3001\u574f\u6b7b\u548c\u5176\u4ed6\u3002", "result": "\u521b\u5efa\u4e86BEETLE\u6570\u636e\u96c6\uff0c\u7279\u522b\u5173\u6ce8\u5bfc\u7ba1\u539f\u4f4d\u764c\u548c\u5206\u6563\u6027\u5c0f\u53f6\u80bf\u7624\u7ec6\u80de\u7b49\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u5f62\u6001\u5b66\u7279\u5f81\uff0c\u5e76\u63d0\u4f9b\u7cbe\u5fc3\u7b56\u5212\u7684\u591a\u4e2d\u5fc3\u5916\u90e8\u8bc4\u4f30\u96c6\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u7684\u591a\u6837\u6027\u548c\u4e0e\u81ea\u52a8\u5316\u751f\u7269\u6807\u5fd7\u7269\u91cf\u5316\u9886\u57df\u7684\u76f8\u5173\u6027\u786e\u4fdd\u4e86\u5176\u9ad8\u91cd\u7528\u6f5c\u529b\uff0c\u80fd\u591f\u5b9e\u73b0\u4e73\u817a\u764c\u5206\u5272\u6a21\u578b\u7684\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2510.02139", "pdf": "https://arxiv.org/pdf/2510.02139", "abs": "https://arxiv.org/abs/2510.02139", "authors": ["Florensia Widjaja", "Zhangtianyi Chen", "Juexiao Zhou"], "title": "BioinfoMCP: A Unified Platform Enabling MCP Interfaces in Agentic Bioinformatics", "categories": ["q-bio.QM", "cs.AI", "cs.LG", "cs.MA"], "comment": "20 pages, 8 figures, 3 tables", "summary": "Bioinformatics tools are essential for complex computational biology tasks,\nyet their integration with emerging AI-agent frameworks is hindered by\nincompatible interfaces, heterogeneous input-output formats, and inconsistent\nparameter conventions. The Model Context Protocol (MCP) provides a standardized\nframework for tool-AI communication, but manually converting hundreds of\nexisting and rapidly growing specialized bioinformatics tools into\nMCP-compliant servers is labor-intensive and unsustainable. Here, we present\nBioinfoMCP, a unified platform comprising two components: BioinfoMCP Converter,\nwhich automatically generates robust MCP servers from tool documentation using\nlarge language models, and BioinfoMCP Benchmark, which systematically validates\nthe reliability and versatility of converted tools across diverse computational\ntasks. We present a platform of 38 MCP-converted bioinformatics tools,\nextensively validated to show that 94.7% successfully executed complex\nworkflows across three widely used AI-agent platforms. By removing technical\nbarriers to AI automation, BioinfoMCP enables natural-language interaction with\nsophisticated bioinformatics analyses without requiring extensive programming\nexpertise, offering a scalable path to intelligent, interoperable computational\nbiology.", "AI": {"tldr": "BioinfoMCP\u662f\u4e00\u4e2a\u7edf\u4e00\u5e73\u53f0\uff0c\u901a\u8fc7\u81ea\u52a8\u8f6c\u6362\u73b0\u6709\u751f\u7269\u4fe1\u606f\u5b66\u5de5\u5177\u4e3aMCP\u517c\u5bb9\u670d\u52a1\u5668\uff0c\u89e3\u51b3\u4e86AI\u4ee3\u7406\u6846\u67b6\u4e0e\u751f\u7269\u4fe1\u606f\u5b66\u5de5\u5177\u96c6\u6210\u7684\u95ee\u9898\u3002", "motivation": "\u751f\u7269\u4fe1\u606f\u5b66\u5de5\u5177\u4e0e\u65b0\u5174AI\u4ee3\u7406\u6846\u67b6\u96c6\u6210\u5b58\u5728\u63a5\u53e3\u4e0d\u517c\u5bb9\u3001\u8f93\u5165\u8f93\u51fa\u683c\u5f0f\u5f02\u6784\u548c\u53c2\u6570\u7ea6\u5b9a\u4e0d\u4e00\u81f4\u7b49\u6280\u672f\u969c\u788d\uff0c\u624b\u52a8\u8f6c\u6362\u6570\u767e\u4e2a\u5de5\u5177\u5230MCP\u6807\u51c6\u65e2\u8d39\u65f6\u53c8\u4e0d\u53ef\u6301\u7eed\u3002", "method": "BioinfoMCP\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1aBioinfoMCP Converter\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u5de5\u5177\u6587\u6863\u81ea\u52a8\u751f\u6210MCP\u670d\u52a1\u5668\uff1bBioinfoMCP Benchmark\u7cfb\u7edf\u9a8c\u8bc1\u8f6c\u6362\u5de5\u5177\u7684\u53ef\u9760\u6027\u548c\u591a\u529f\u80fd\u6027\u3002", "result": "\u6784\u5efa\u4e8638\u4e2aMCP\u8f6c\u6362\u7684\u751f\u7269\u4fe1\u606f\u5b66\u5de5\u5177\u5e73\u53f0\uff0c\u9a8c\u8bc1\u663e\u793a94.7%\u7684\u5de5\u5177\u5728\u4e09\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684AI\u4ee3\u7406\u5e73\u53f0\u4e0a\u6210\u529f\u6267\u884c\u590d\u6742\u5de5\u4f5c\u6d41\u7a0b\u3002", "conclusion": "BioinfoMCP\u901a\u8fc7\u6d88\u9664AI\u81ea\u52a8\u5316\u7684\u6280\u672f\u969c\u788d\uff0c\u5b9e\u73b0\u4e86\u4e0e\u590d\u6742\u751f\u7269\u4fe1\u606f\u5b66\u5206\u6790\u7684\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\uff0c\u65e0\u9700\u5927\u91cf\u7f16\u7a0b\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e3a\u667a\u80fd\u3001\u4e92\u64cd\u4f5c\u7684\u8ba1\u7b97\u751f\u7269\u5b66\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u8def\u5f84\u3002"}}
{"id": "2510.01484", "pdf": "https://arxiv.org/pdf/2510.01484", "abs": "https://arxiv.org/abs/2510.01484", "authors": ["Michael B. Weissman"], "title": "Bayesian Re-Analysis of the Phylogenetic Topology of Early SARS-CoV-2 Case Sequences", "categories": ["q-bio.PE", "q-bio.QM"], "comment": "4642 words in main text", "summary": "A much-cited 2022 paper by Pekar et al. claimed that Bayesian analysis of the\nmolecular phylogeny of early SARS-CoV-2 cases indicated that it was more likely\nthat two successful introductions to humans had occurred than that just one\nhad. Here I show that after correcting a fundamental error in Bayesian\nreasoning the results in that paper give larger likelihood for a single\nintroduction than for two.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7ea0\u6b63\u4e86Pekar\u7b49\u4eba2022\u5e74\u8bba\u6587\u4e2d\u7684\u8d1d\u53f6\u65af\u63a8\u7406\u9519\u8bef\uff0c\u53d1\u73b0SARS-CoV-2\u66f4\u53ef\u80fd\u662f\u4e00\u6b21\u6027\u800c\u975e\u4e24\u6b21\u5f15\u5165\u4eba\u7c7b", "motivation": "\u7ea0\u6b63Pekar\u7b49\u4eba\u8bba\u6587\u4e2d\u5173\u4e8eSARS-CoV-2\u8d77\u6e90\u7684\u8d1d\u53f6\u65af\u63a8\u7406\u9519\u8bef\uff0c\u91cd\u65b0\u8bc4\u4f30\u75c5\u6bd2\u5f15\u5165\u4eba\u7c7b\u7684\u53ef\u80fd\u6027", "method": "\u901a\u8fc7\u4fee\u6b63\u8d1d\u53f6\u65af\u63a8\u7406\u7684\u57fa\u672c\u9519\u8bef\uff0c\u91cd\u65b0\u5206\u6790\u65e9\u671fSARS-CoV-2\u75c5\u4f8b\u7684\u5206\u5b50\u7cfb\u7edf\u53d1\u80b2\u6570\u636e", "result": "\u4fee\u6b63\u540e\u7684\u5206\u6790\u663e\u793a\uff0c\u5355\u6b21\u5f15\u5165\u7684\u53ef\u80fd\u6027\u5927\u4e8e\u4e24\u6b21\u5f15\u5165\u7684\u53ef\u80fd\u6027\uff0c\u4e0e\u539f\u59cb\u8bba\u6587\u7ed3\u8bba\u76f8\u53cd", "conclusion": "SARS-CoV-2\u66f4\u53ef\u80fd\u662f\u4e00\u6b21\u6027\u5f15\u5165\u4eba\u7c7b\uff0c\u800c\u975ePekar\u7b49\u4eba\u58f0\u79f0\u7684\u4e24\u6b21\u5f15\u5165"}}
{"id": "2510.01666", "pdf": "https://arxiv.org/pdf/2510.01666", "abs": "https://arxiv.org/abs/2510.01666", "authors": ["Jianxu Wang", "Ge Wang"], "title": "Median2Median: Zero-shot Suppression of Structured Noise in Images", "categories": ["eess.IV", "cs.CV", "q-bio.QM", "stat.ML"], "comment": "13 pages, 6 figures, not published yet", "summary": "Image denoising is a fundamental problem in computer vision and medical\nimaging. However, real-world images are often degraded by structured noise with\nstrong anisotropic correlations that existing methods struggle to remove. Most\ndata-driven approaches rely on large datasets with high-quality labels and\nstill suffer from limited generalizability, whereas existing zero-shot methods\navoid this limitation but remain effective only for independent and identically\ndistributed (i.i.d.) noise. To address this gap, we propose Median2Median\n(M2M), a zero-shot denoising framework designed for structured noise. M2M\nintroduces a novel sampling strategy that generates pseudo-independent\nsub-image pairs from a single noisy input. This strategy leverages directional\ninterpolation and generalized median filtering to adaptively exclude values\ndistorted by structured artifacts. To further enlarge the effective sampling\nspace and eliminate systematic bias, a randomized assignment strategy is\nemployed, ensuring that the sampled sub-image pairs are suitable for\nNoise2Noise training. In our realistic simulation studies, M2M performs on par\nwith state-of-the-art zero-shot methods under i.i.d. noise, while consistently\noutperforming them under correlated noise. These findings establish M2M as an\nefficient, data-free solution for structured noise suppression and mark the\nfirst step toward effective zero-shot denoising beyond the strict i.i.d.\nassumption.", "AI": {"tldr": "\u63d0\u51fa\u4e86Median2Median\uff08M2M\uff09\u96f6\u6837\u672c\u53bb\u566a\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u7ed3\u6784\u5316\u566a\u58f0\u8bbe\u8ba1\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u91c7\u6837\u7b56\u7565\u751f\u6210\u4f2a\u72ec\u7acb\u5b50\u56fe\u50cf\u5bf9\uff0c\u65e0\u9700\u5e72\u51c0\u6807\u7b7e\u6570\u636e\u5373\u53ef\u6709\u6548\u53bb\u9664\u76f8\u5173\u566a\u58f0\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u56fe\u50cf\u5e38\u53d7\u5f3a\u5404\u5411\u5f02\u6027\u76f8\u5173\u7ed3\u6784\u5316\u566a\u58f0\u5f71\u54cd\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u53bb\u9664\u3002\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u4f9d\u8d56\u9ad8\u8d28\u91cf\u6807\u7b7e\u4e14\u6cdb\u5316\u6027\u6709\u9650\uff0c\u800c\u96f6\u6837\u672c\u65b9\u6cd5\u4ec5\u5bf9\u72ec\u7acb\u540c\u5206\u5e03\u566a\u58f0\u6709\u6548\u3002", "method": "M2M\u5f15\u5165\u65b9\u5411\u6027\u63d2\u503c\u548c\u5e7f\u4e49\u4e2d\u503c\u6ee4\u6ce2\u751f\u6210\u4f2a\u72ec\u7acb\u5b50\u56fe\u50cf\u5bf9\uff0c\u91c7\u7528\u968f\u673a\u5206\u914d\u7b56\u7565\u6269\u5927\u91c7\u6837\u7a7a\u95f4\u5e76\u6d88\u9664\u7cfb\u7edf\u504f\u5dee\uff0c\u9002\u7528\u4e8eNoise2Noise\u8bad\u7ec3\u3002", "result": "\u5728\u771f\u5b9e\u6a21\u62df\u7814\u7a76\u4e2d\uff0cM2M\u5728\u72ec\u7acb\u540c\u5206\u5e03\u566a\u58f0\u4e0b\u4e0e\u6700\u5148\u8fdb\u96f6\u6837\u672c\u65b9\u6cd5\u76f8\u5f53\uff0c\u5728\u76f8\u5173\u566a\u58f0\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "M2M\u662f\u7ed3\u6784\u5316\u566a\u58f0\u6291\u5236\u7684\u9ad8\u6548\u3001\u65e0\u6570\u636e\u89e3\u51b3\u65b9\u6848\uff0c\u6807\u5fd7\u7740\u8d85\u8d8a\u4e25\u683c\u72ec\u7acb\u540c\u5206\u5e03\u5047\u8bbe\u7684\u6709\u6548\u96f6\u6837\u672c\u53bb\u566a\u7684\u7b2c\u4e00\u6b65\u3002"}}
