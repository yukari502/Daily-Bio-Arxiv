{"id": "2510.09702", "pdf": "https://arxiv.org/pdf/2510.09702", "abs": "https://arxiv.org/abs/2510.09702", "authors": ["Sara Behnamian", "Fatemeh Fogh"], "title": "Interval-Censored Survival Analysis of Grapevine Phenology: Thermal Controls on Flowering and Fruit Ripening", "categories": ["q-bio.QM", "stat.AP", "stat.CO"], "comment": null, "summary": "European grapevine (\\textit{Vitis vinifera} L.) is a climate-sensitive\nperennial whose flowering and ripening govern yield and quality. Phenological\nrecords from monitoring programs are typically collected at irregular\nintervals, so true transition dates are interval-censored, and many site-years\nare right-censored. We develop a reproducible workflow that treats phenology as\na time-to-event outcome: Status \\& Intensity observations from the USA-NPN are\nconverted to interval bounds, linked to NASA POWER daily weather, and analyzed\nwith parametric accelerated failure time (AFT) models (Weibull and\nlog-logistic). To avoid outcome-dependent bias from aggregating weather up to\nthe event date, antecedent conditions are summarized in fixed pre-season\nwindows and standardized; quality-control filters ensure adequate within-window\ndata coverage. Applied to flowering and ripening of \\textit{V.~vinifera}, the\nframework yields interpretable time-ratio effects and publication-ready tables\nand figures. Warmer pre-season conditions are associated with earlier ripening,\nwhereas flowering responses are modest and uncertain in these data;\nprecipitation plays, at most, a secondary role. The approach demonstrates how\ninterval-censored survival models with exogenous weather windows can extract\nrobust climate signals from citizen-science phenology while preserving\nobservation uncertainty, and it generalizes readily to other species and\nnetworks."}
{"id": "2510.09716", "pdf": "https://arxiv.org/pdf/2510.09716", "abs": "https://arxiv.org/abs/2510.09716", "authors": ["Hansol Hong", "Sangwon Lee", "Jang-Ho Ha", "Sung-June Chu", "So-Hee An", "Woo-Hyun Paek", "Gyuhwa Chung", "Kyoung Tai No"], "title": "MS2toImg: A Framework for Direct Bioactivity Prediction from Raw LC-MS/MS Data", "categories": ["q-bio.QM"], "comment": "35 pages, 5 figures, 2 tables", "summary": "Untargeted metabolomics using LC-MS/MS offers the potential to\ncomprehensively profile the chemical diversity of biological samples. However,\nthe process is fundamentally limited by the \"identification bottleneck,\" where\nonly a small fraction of detected features can be annotated using existing\nspectral libraries, leaving the majority of data uncharacterized and unused. In\naddition, the inherently low reproducibility of LC-MS/MS instruments introduces\nalignment errors between runs, making feature alignment across large datasets\nboth error-prone and challenging. To overcome these constraints, we developed a\ndeep learning method that eliminates the requirement for metabolite\nidentification and reduces the influence of alignment inaccuracies. Here, we\npropose MS2toImg, a method that converts raw LC-MS/MS data into a\ntwo-dimensional images representing the global fragmentation pattern of each\nsample. These images are then used as direct input for a convolutional neural\nnetwork (CNN), enabling end-to-end prediction of biological activity without\nexplicit feature engineering or alignment. Our approach was validated using\nwild soybean samples and multiple bioactivity assays (e.g., DPPH, elastase\ninhibition). The MS2toImg-CNN model outperformed conventional machine learning\nbaselines (e.g., Random Forest, PCA), demonstrating robust classification\naccuracy across diverse tasks. By transforming raw spectral data into images,\nour framework is inherently less sensitive to alignment errors caused by low\ninstrument reproducibility, as it leverages the overall fragmentation landscape\nrather than relying on precise feature matching. This identification-free,\nimage-based approach enables more robust and scalable bioactivity prediction\nfrom untargeted metabolomics data, offering a new paradigm for high-throughput\nfunctional screening in complex biological systems."}
{"id": "2510.09837", "pdf": "https://arxiv.org/pdf/2510.09837", "abs": "https://arxiv.org/abs/2510.09837", "authors": ["Bing Hu", "Jong-Hoon Park", "Helen Chen", "Young-Rae Cho", "Anita Layton"], "title": "Domain Knowledge Infused Generative Models for Drug Discovery Synthetic Data", "categories": ["q-bio.QM"], "comment": "11 pages, Chen Institute Symposium for AI Accelerated Science (AIAS\n  2025)", "summary": "The role of Artificial Intelligence (AI) is growing in every stage of drug\ndevelopment. Nevertheless, a major challenge in drug discovery AI remains: Drug\npharmacokinetic (PK) and Drug-Target Interaction (DTI) datasets collected in\ndifferent studies often exhibit limited overlap, creating data overlap\nsparsity. Thus, data curation becomes difficult, negatively impacting\ndownstream research investigations in high-throughput screening, polypharmacy,\nand drug combination. We propose xImagand-DKI, a novel\nSMILES/Protein-to-Pharmacokinetic/DTI (SP2PKDTI) diffusion model capable of\ngenerating an array of PK and DTI target properties conditioned on SMILES and\nprotein inputs that exhibit data overlap sparsity. We infuse additional\nmolecular and genomic domain knowledge from the Gene Ontology (GO) and\nmolecular fingerprints to further improve our model performance. We show that\nxImagand-DKI-generated synthetic PK data closely resemble real data univariate\nand bivariate distributions, and can adequately fill in gaps among PK and DTI\ndatasets. As such, xImagand-DKI is a promising solution for data overlap\nsparsity and may improve performance for downstream drug discovery research\ntasks. Code available at:\nhttps://github.com/GenerativeDrugDiscovery/xImagand-DKI"}
{"id": "2510.11275", "pdf": "https://arxiv.org/pdf/2510.11275", "abs": "https://arxiv.org/abs/2510.11275", "authors": ["Ana Sofia Carmo", "Lourenço Abrunhosa Rodrigues", "Ana Rita Peralta", "Ana Fred", "Carla Bentes", "Hugo Plácido da Silva"], "title": "SeFEF: A Seizure Forecasting Evaluation Framework", "categories": ["q-bio.QM", "cs.LG"], "comment": "main document: 14 pages, 9 figures, 2 tables; appendix: 7 pages, 2\n  figures, 3 tables, 2 algorithms", "summary": "The lack of standardization in seizure forecasting slows progress in the\nfield and limits the clinical translation of forecasting models. In this work,\nwe introduce a Python-based framework aimed at streamlining the development,\nassessment, and documentation of individualized seizure forecasting algorithms.\n  The framework automates data labeling, cross-validation splitting, forecast\npost-processing, performance evaluation, and reporting. It supports various\nforecasting horizons and includes a model card that documents implementation\ndetails, training and evaluation settings, and performance metrics. Three\ndifferent models were implemented as a proof-of-concept. The models leveraged\nfeatures extracted from time series data and seizure periodicity. Model\nperformance was assessed using time series cross-validation and key\ndeterministic and probabilistic metrics.\n  Implementation of the three models was successful, demonstrating the\nflexibility of the framework. The results also emphasize the importance of\ncareful model interpretation due to variations in probability scaling,\ncalibration, and subject-specific differences. Although formal usability\nmetrics were not recorded, empirical observations suggest reduced development\ntime and methodological consistency, minimizing unintentional variations that\ncould affect the comparability of different approaches.\n  As a proof-of-concept, this validation is inherently limited, relying on a\nsingle-user experiment without statistical analyses or replication across\nindependent datasets. At this stage, our objective is to make the framework\npublicly available to foster community engagement, facilitate experimentation,\nand gather feedback. In the long term, we aim to contribute to the\nestablishment of a consensus on a standardized methodology for the development\nand validation of seizure forecasting algorithms in people with epilepsy."}
{"id": "2510.09784", "pdf": "https://arxiv.org/pdf/2510.09784", "abs": "https://arxiv.org/abs/2510.09784", "authors": ["Richard John", "Yunrui Qiu", "Lukas Herron", "Pratyush Tiwary"], "title": "Combined Representation and Generation with Diffusive State Predictive Information Bottleneck", "categories": ["cs.LG", "cond-mat.stat-mech", "q-bio.QM"], "comment": null, "summary": "Generative modeling becomes increasingly data-intensive in high-dimensional\nspaces. In molecular science, where data collection is expensive and important\nevents are rare, compression to lower-dimensional manifolds is especially\nimportant for various downstream tasks, including generation. We combine a\ntime-lagged information bottleneck designed to characterize molecular important\nrepresentations and a diffusion model in one joint training objective. The\nresulting protocol, which we term Diffusive State Predictive Information\nBottleneck (D-SPIB), enables the balancing of representation learning and\ngeneration aims in one flexible architecture. Additionally, the model is\ncapable of combining temperature information from different molecular\nsimulation trajectories to learn a coherent and useful internal representation\nof thermodynamics. We benchmark D-SPIB on multiple molecular tasks and showcase\nits potential for exploring physical conditions outside the training set."}
{"id": "2510.09903", "pdf": "https://arxiv.org/pdf/2510.09903", "abs": "https://arxiv.org/abs/2510.09903", "authors": ["Lenny Aharon", "Keemin Lee", "Karan Sikka", "Selmaan Chettih", "Cole Hurwitz", "Liam Paninski", "Matthew R Whiteway"], "title": "An uncertainty-aware framework for data-efficient multi-view animal pose estimation", "categories": ["cs.CV", "q-bio.QM"], "comment": null, "summary": "Multi-view pose estimation is essential for quantifying animal behavior in\nscientific research, yet current methods struggle to achieve accurate tracking\nwith limited labeled data and suffer from poor uncertainty estimates. We\naddress these challenges with a comprehensive framework combining novel\ntraining and post-processing techniques, and a model distillation procedure\nthat leverages the strengths of these techniques to produce a more efficient\nand effective pose estimator. Our multi-view transformer (MVT) utilizes\npretrained backbones and enables simultaneous processing of information across\nall views, while a novel patch masking scheme learns robust cross-view\ncorrespondences without camera calibration. For calibrated setups, we\nincorporate geometric consistency through 3D augmentation and a triangulation\nloss. We extend the existing Ensemble Kalman Smoother (EKS) post-processor to\nthe nonlinear case and enhance uncertainty quantification via a variance\ninflation technique. Finally, to leverage the scaling properties of the MVT, we\ndesign a distillation procedure that exploits improved EKS predictions and\nuncertainty estimates to generate high-quality pseudo-labels, thereby reducing\ndependence on manual labels. Our framework components consistently outperform\nexisting methods across three diverse animal species (flies, mice, chickadees),\nwith each component contributing complementary benefits. The result is a\npractical, uncertainty-aware system for reliable pose estimation that enables\ndownstream behavioral analyses under real-world data constraints."}
{"id": "2510.09914", "pdf": "https://arxiv.org/pdf/2510.09914", "abs": "https://arxiv.org/abs/2510.09914", "authors": ["Aditya Malusare", "Vineet Punyamoorty", "Vaneet Aggarwal"], "title": "Augmenting generative models with biomedical knowledge graphs improves targeted drug discovery", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": "This paper has been accepted for publication in the IEEE Transactions\n  on Artificial Intelligence, October 2025", "summary": "Recent breakthroughs in generative modeling have demonstrated remarkable\ncapabilities in molecular generation, yet the integration of comprehensive\nbiomedical knowledge into these models has remained an untapped frontier. In\nthis study, we introduce K-DREAM (Knowledge-Driven Embedding-Augmented Model),\na novel framework that leverages knowledge graphs to augment diffusion-based\ngenerative models for drug discovery. By embedding structured information from\nlarge-scale knowledge graphs, K-DREAM directs molecular generation toward\ncandidates with higher biological relevance and therapeutic suitability. This\nintegration ensures that the generated molecules are aligned with specific\ntherapeutic targets, moving beyond traditional heuristic-driven approaches. In\ntargeted drug design tasks, K-DREAM generates drug candidates with improved\nbinding affinities and predicted efficacy, surpassing current state-of-the-art\ngenerative models. It also demonstrates flexibility by producing molecules\ndesigned for multiple targets, enabling applications to complex disease\nmechanisms. These results highlight the utility of knowledge-enhanced\ngenerative models in rational drug design and their relevance to practical\ntherapeutic development."}
{"id": "2510.10614", "pdf": "https://arxiv.org/pdf/2510.10614", "abs": "https://arxiv.org/abs/2510.10614", "authors": ["Robert G. Cowell"], "title": "A clustering algorithm for the single cell analysis of mixtures", "categories": ["stat.AP", "q-bio.QM"], "comment": "48 paegs, 5 figures", "summary": "A probabilistic clustering algorithm is proposed for the analysis of forensic\nDNA mixtures in which individual cells are isolated and short tandem repeats\nare amplified using the polymerase chain reaction to generate single cell\nelectropherograms. The task of the algorithm is to use the peak height\ninformation in the electropherograms to group the cells according to their\ncontributors. Using a recently developed experimental set of individual cell\nelectropherograms, a large set of simulations shows that the proposed\nclustering algorithm has excellent performance in correctly grouping single\ncells, and for assigning likelihood ratios for persons of interest (of known\ngenotype)."}
{"id": "2510.10733", "pdf": "https://arxiv.org/pdf/2510.10733", "abs": "https://arxiv.org/abs/2510.10733", "authors": ["Eva Guttmann-Flury", "Jian Zhao", "Mohamad Sawan"], "title": "Does Re-referencing Matter? Large Laplacian Filter Optimizes Single-Trial P300 BCI Performance", "categories": ["q-bio.NC", "q-bio.QM"], "comment": null, "summary": "Electroencephalography (EEG) provides a non-invasive window into brain\nactivity, enabling Brain-Computer Interfaces (BCIs) for communication and\ncontrol. However, their performance is limited by signal fidelity issues, among\nwhich the choice of re-referencing strategy is a pervasive but often overlooked\npreprocessing bias. Addressing controversies about its necessity and optimal\nchoice, we adopted a quantified approach to evaluate four strategies - no\nre-referencing, Common Average Reference (CAR), small Laplacian, and large\nLaplacian - using 62-channels EEG (31 subjects, 2,520 trials). To our\nknowledge, this is the first study systematically quantifying their impact on\nsingle-trial P300 classification accuracy. Our controlled pipeline isolated\nre-referencing effects for source-space reconstruction (eLORETA with Phase Lag\nIndex) and anatomically constrained classification. The large Laplacian\nresolves distributed P3b networks while maintaining P3a specificity, achieving\nthe best P300 peak classification accuracy (81.57% hybrid method; 75.97%\nmajority regions of interest). Performance follows a consistent and\nstatistically significant hierarchy: large Laplacian > CAR > no re-reference >\nsmall Laplacian, providing a foundation for unified methodological evaluation."}
{"id": "2510.10770", "pdf": "https://arxiv.org/pdf/2510.10770", "abs": "https://arxiv.org/abs/2510.10770", "authors": ["Eva Guttmann-Flury", "Yanyan Wei", "Shan Zhao", "Jian Zhao", "Mohamad Sawan"], "title": "The Cost of Simplicity: How Reducing EEG Electrodes Affects Source Localization and BCI Accuracy", "categories": ["q-bio.NC", "q-bio.QM"], "comment": null, "summary": "Electrode density optimization in electroencephalography (EEG)-based\nBrain-Computer Interfaces (BCIs) requires balancing practical usability against\nsignal fidelity, particularly for source localization. Reducing electrodes\nenhances portability but its effects on neural source reconstruction quality\nand source connectivity - treated as proxies to BCI performance - remain\nunderstudied. We address this gap through systematic evaluation of 62-, 32-,\nand 16-channel configurations using a fixed, fully automated processing\npipeline applied to the well-characterized P300 potential. This approach's\nrationale is to minimize variability and bias inherent to EEG analysis by\nleveraging the P300's stimulus-locked reproducibility and pipeline\nstandardization. Analyzing 63 sessions (31 subjects) from the Eye-BCI dataset\nwith rigorous artifact correction and channel validation, we demonstrate: (1)\nProgressive degradation in source reconstruction quality with sparser\nconfigurations, including obscured deep neural generators and spatiotemporal\ndistortions; (2) A novel sqrt(Re) scaling law linking electrode reduction ratio\n(Re) to localization accuracy - a previously unquantified relationship to the\nbest of our knowledge; (3) While reduced configurations preserve basic P300\ntopography and may suffice for communicative BCIs, higher-density channels are\nessential for reliable deep source reconstruction. Overall, this study\nestablishes a first step towards quantitative benchmarks for electrode\nselection, with critical implications for clinical BCIs requiring anatomical\nprecision in applications like neurodegenerative disease monitoring, where\ncompromised spatial resolution could mask pathological signatures. Most\nimportantly, the sqrt(Re) scaling law may provide the first principled method\nto determine the minimal electrode density required based on acceptable error\nmargins or expected effect sizes."}
{"id": "2510.11257", "pdf": "https://arxiv.org/pdf/2510.11257", "abs": "https://arxiv.org/abs/2510.11257", "authors": ["Davide Borghini", "Davide Marchi", "Angelo Nardone", "Giordano Scerra", "Silvia Giulia Galfrè", "Alessandro Pingitore", "Giuseppe Prencipe", "Corrado Priami", "Alina Sîrbu"], "title": "MIEO: encoding clinical data to enhance cardiovascular event prediction", "categories": ["cs.LG", "q-bio.QM"], "comment": "Presented in the Poster Session of Computational Intelligence methods\n  for Bioinformatics and Biostatistics (CIBB) 2025", "summary": "As clinical data are becoming increasingly available, machine learning\nmethods have been employed to extract knowledge from them and predict clinical\nevents. While promising, approaches suffer from at least two main issues: low\navailability of labelled data and data heterogeneity leading to missing values.\nThis work proposes the use of self-supervised auto-encoders to efficiently\naddress these challenges. We apply our methodology to a clinical dataset from\npatients with ischaemic heart disease. Patient data is embedded in a latent\nspace, built using unlabelled data, which is then used to train a neural\nnetwork classifier to predict cardiovascular death. Results show improved\nbalanced accuracy compared to applying the classifier directly to the raw data,\ndemonstrating that this solution is promising, especially in conditions where\navailability of unlabelled data could increase."}
