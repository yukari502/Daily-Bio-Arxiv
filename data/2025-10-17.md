<div id=toc></div>

# Table of Contents

- [q-bio.QM](#q-bio.QM) [Total: 5]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]
- [q-bio.PE](#q-bio.PE) [Total: 1]


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [1] [Physics-Informed autoencoder for DSC-MRI Perfusion post-processing: application to glioma grading](https://arxiv.org/abs/2510.13886)
*Pierre Fayolle,Alexandre Bône,Noëlie Debs,Mathieu Naudin,Pascal Bourdon,Remy Guillevin,David Helbert*

Main category: q-bio.QM

TL;DR: 提出了一种物理信息自编码器，用于DSC-MRI灌注参数估计，无需第三方反卷积算法，在噪声环境下表现良好。


<details>
  <summary>Details</summary>
Motivation: 临床环境中噪声和运动伪影会干扰传统反卷积算法，导致灌注参数估计错误。现有深度学习方法依赖第三方算法生成参考输出，会复制其局限性。

Method: 使用物理信息自编码器，利用解析模型解码灌注参数并指导编码网络学习，以自监督方式训练，无需第三方软件。

Result: 在胶质瘤患者数据库中评估，与知名反卷积算法结果一致但计算时间更短，在高噪声环境下仍保持竞争力。

Conclusion: 该方法能可靠估计灌注参数，在临床环境中具有实用价值，特别是在噪声干扰情况下表现稳健。

Abstract: DSC-MRI perfusion is a medical imaging technique for diagnosing and
prognosing brain tumors and strokes. Its analysis relies on mathematical
deconvolution, but noise or motion artifacts in a clinical environment can
disrupt this process, leading to incorrect estimate of perfusion parameters.
Although deep learning approaches have shown promising results, their
calibration typically rely on third-party deconvolution algorithms to generate
reference outputs and are bound to reproduce their limitations.
  To adress this problem, we propose a physics-informed autoencoder that
leverages an analytical model to decode the perfusion parameters and guide the
learning of the encoding network. This autoencoder is trained in a
self-supervised fashion without any third-party software and its performance is
evaluated on a database with glioma patients. Our method shows reliable results
for glioma grading in accordance with other well-known deconvolution algorithms
despite a lower computation time. It also achieved competitive performance even
in the presence of high noise which is critical in a medical environment.

</details>


### [2] [GenCellAgent: Generalizable, Training-Free Cellular Image Segmentation via Large Language Model Agents](https://arxiv.org/abs/2510.13896)
*Xi Yu,Yang Yang,Qun Liu,Yonghua Du,Sean McSweeney,Yuewei Lin*

Main category: q-bio.QM

TL;DR: GenCellAgent是一个无需训练的多智能体框架，通过规划器-执行器-评估器循环和长期记忆，自动选择最佳分割工具并适应不同成像条件，显著提升细胞图像分割精度。


<details>
  <summary>Details</summary>
Motivation: 细胞图像分割在定量生物学中至关重要，但由于模态异质性、形态变异性和有限标注而面临困难。

Method: 采用训练免费的多智能体框架，通过规划器-执行器-评估器循环（选择工具→运行→质量检查）协调专业分割器和通用视觉语言模型，具有长期记忆功能。

Result: 在四个细胞分割基准测试中，路由策略比最先进基线平均准确率提升15.7%；在新数据集的内质网和线粒体分割中，IoU平均提高37.6%。

Conclusion: 该框架为无需重新训练的稳健、适应性强的细胞图像分割提供了实用路径，同时减少了标注负担并匹配用户偏好。

Abstract: Cellular image segmentation is essential for quantitative biology yet remains
difficult due to heterogeneous modalities, morphological variability, and
limited annotations. We present GenCellAgent, a training-free multi-agent
framework that orchestrates specialist segmenters and generalist
vision-language models via a planner-executor-evaluator loop (choose tool
$\rightarrow$ run $\rightarrow$ quality-check) with long-term memory. The
system (i) automatically routes images to the best tool, (ii) adapts on the fly
using a few reference images when imaging conditions differ from what a tool
expects, (iii) supports text-guided segmentation of organelles not covered by
existing models, and (iv) commits expert edits to memory, enabling
self-evolution and personalized workflows. Across four cell-segmentation
benchmarks, this routing yields a 15.7\% mean accuracy gain over
state-of-the-art baselines. On endoplasmic reticulum and mitochondria from new
datasets, GenCellAgent improves average IoU by 37.6\% over specialist models.
It also segments novel objects such as the Golgi apparatus via iterative
text-guided refinement, with light human correction further boosting
performance. Together, these capabilities provide a practical path to robust,
adaptable cellular image segmentation without retraining, while reducing
annotation burden and matching user preferences.

</details>


### [3] [Dual-attention ResNet outperforms transformers in HER2 prediction on DCE-MRI](https://arxiv.org/abs/2510.13897)
*Naomi Fridman,Anat Goldstein*

Main category: q-bio.QM

TL;DR: 该研究开发了一个基于DCE-MRI的三头双注意力ResNet模型，用于非侵入性预测乳腺癌HER2状态，在多个中心数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是女性最常见的癌症，HER2状态对治疗决策至关重要。从DCE-MRI非侵入性预测HER2状态可以简化诊断流程并减少对活检的依赖。

Method: 使用三头双注意力ResNet处理三个DCE时相的RGB融合时间序列，比较了不同的强度归一化策略，并在I-SPY试验的多中心队列上进行训练。

Result: 模型在I-SPY测试数据上达到0.75准确率和0.74 AUC，优于基于transformer的架构。外部验证在BreastDCEDL_AMBL数据集上获得0.66 AUC，展示了跨机构泛化能力。

Conclusion: 双注意力机制在捕捉可转移的时空特征方面非常有效，为乳腺癌影像中可重复的深度学习生物标志物开发提供了进展。

Abstract: Breast cancer is the most diagnosed cancer in women, with HER2 status
critically guiding treatment decisions. Noninvasive prediction of HER2 status
from dynamic contrast-enhanced MRI (DCE-MRI) could streamline diagnostics and
reduce reliance on biopsy. However, preprocessing high-dynamic-range DCE-MRI
into standardized 8-bit RGB format for pretrained neural networks is
nontrivial, and normalization strategy significantly affects model performance.
We benchmarked intensity normalization strategies using a Triple-Head
Dual-Attention ResNet that processes RGB-fused temporal sequences from three
DCE phases. Trained on a multicenter cohort (n=1,149) from the I-SPY trials and
externally validated on BreastDCEDL_AMBL (n=43 lesions), our model outperformed
transformer-based architectures, achieving 0.75 accuracy and 0.74 AUC on I-SPY
test data. N4 bias field correction slightly degraded performance. Without
fine-tuning, external validation yielded 0.66 AUC, demonstrating
cross-institutional generalizability. These findings highlight the
effectiveness of dual-attention mechanisms in capturing transferable
spatiotemporal features for HER2 stratification, advancing reproducible deep
learning biomarkers in breast cancer imaging.

</details>


### [4] [OralGPT: A Two-Stage Vision-Language Model for Oral Mucosal Disease Diagnosis and Description](https://arxiv.org/abs/2510.13911)
*Jia Zhang,Bodong Du,Yitong Miao,Dongwei Sun,Xiangyong Cao*

Main category: q-bio.QM

TL;DR: OralGPT是一个专用于口腔黏膜疾病诊断和描述的两阶段视觉语言框架，通过分类标签学习视觉表示，再利用专家撰写的长文本增强语言生成能力，解决了口腔医疗领域数据标注不足的问题。


<details>
  <summary>Details</summary>
Motivation: 口腔黏膜疾病（如白斑、口腔扁平苔藓等）具有多样且重叠的视觉特征，非专科医生诊断困难。虽然视觉语言模型在医学图像解释方面有潜力，但由于缺乏大规模标注数据集，在口腔医疗领域的应用仍待探索。

Method: 提出两阶段框架：第一阶段从分类标签学习视觉表示和疾病相关概念；第二阶段利用专家撰写的长文本增强语言生成能力。采用相似性引导的数据增强策略，将专家标注图像的知识传播到弱标注图像。构建了首个口腔黏膜疾病基准数据集，整合多源图像数据和结构化/非结构化文本标注。

Result: 在四种常见口腔疾病的实验结果表明，OralGPT在保持竞争力的诊断性能的同时，能生成流畅且具有临床意义的图像描述。

Conclusion: 该研究为口腔医疗领域的语言辅助诊断工具奠定了基础，展示了视觉语言模型在口腔疾病诊断中的潜力。

Abstract: Oral mucosal diseases such as leukoplakia, oral lichen planus, and recurrent
  aphthous ulcers exhibit diverse and overlapping visual features,
  making diagnosis challenging for non-specialists. While vision-language
  models (VLMs) have shown promise in medical image interpretation,
  their application in oral healthcare remains underexplored due to
  the lack of large-scale, well-annotated datasets. In this work, we present
  \textbf{OralGPT}, the first domain-specific two-stage vision-language
  framework designed for oral mucosal disease diagnosis and captioning.
  In Stage 1, OralGPT learns visual representations and disease-related
  concepts from classification labels. In Stage 2, it enhances its language
  generation ability using long-form expert-authored captions. To
  overcome the annotation bottleneck, we propose a novel similarity-guided
  data augmentation strategy that propagates descriptive knowledge from
  expert-labeled images to weakly labeled ones. We also construct the
  first benchmark dataset for oral mucosal diseases, integrating multi-source
  image data with both structured and unstructured textual annotations.
  Experimental results on four common oral conditions demonstrate that
  OralGPT achieves competitive diagnostic performance while generating
  fluent, clinically meaningful image descriptions. This study
  provides a foundation for language-assisted diagnostic tools in oral
  healthcare.

</details>


### [5] [SUND: simulation using nonlinear dynamic models - a toolbox for simulating multi-level, time-dynamic systems in a modular way](https://arxiv.org/abs/2510.13932)
*Henrik Podéus,Gustav Magnusson,Sasan Keshmiri,Kajsa Tunedal,Nicolas Sundqvist,William Lövfors,Gunnar Cedersund*

Main category: q-bio.QM

TL;DR: SUND是一个Python工具箱，为建模复杂、分层和时间动态系统提供统一框架，支持模块化模型组合、层次化系统构建和时间相关输入处理。


<details>
  <summary>Details</summary>
Motivation: 当前工具缺乏对模块化模型组合、层次化系统构建和时间相关输入处理的全面框架支持，特别是在Python生态系统中。

Method: 开发SUND工具箱，提供定义、组合和模拟多级时间动态系统的统一框架，支持可互连输入输出的模型定义，以及时间相关函数和分段常数输入。

Result: 通过模拟多层次人类葡萄糖-胰岛素系统模型展示了工具箱的能力，证明其能够灵活处理多个时间尺度和生物细节层次。

Conclusion: SUND是一个开源、易于扩展的工具箱，为复杂动态系统建模提供了有效的解决方案。

Abstract: When modeling complex, hierarchical, and time-dynamic systems, such as
biological systems, good computational tools are essential. Current tools,
while powerful, often lack comprehensive frameworks for modular model
composition, hierarchical system building, and time-dependent input handling,
particularly within the Python ecosystem. We present SUND (Simulation Using
Nonlinear Dynamic models), a Python toolbox designed to address these
challenges. SUND provides a unified framework for defining, combining, and
simulating multi-level time-dynamic systems. The toolbox enables users to
define models with interconnectable inputs and outputs, facilitating the
construction of complex systems from simpler, reusable components. It supports
time-dependent functions and piecewise constant inputs, enabling intuitive
simulation of various experimental conditions such as multiple dosing schemes.
We demonstrate the toolbox's capabilities through simulation of a multi-level
human glucose-insulin system model, showcasing its flexibility in handling
multiple temporal scales, and levels of biological detail. SUND is open-source,
easily extensible, and available at PyPI (https://pypi.org/project/sund/) and
at Gitlab (https://gitlab.liu.se/ISBgroup/projects/sund/).

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [6] [Using Information Geometry to Characterize Higher-Order Interactions in EEG](https://arxiv.org/abs/2510.14188)
*Eric Albers,Paul Marriott,Masami Tatsuno*

Main category: q-bio.NC

TL;DR: 将信息几何方法应用于EEG连续信号，通过三种二值化策略识别三阶神经相互作用，并在想象运动任务中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 信息几何方法在尖峰序列的二元向量建模中很成功，但EEG是连续信号需要适当的离散化策略，需要验证这些方法在连续神经记录中的适用性。

Method: 开发并比较三种不同的二值化方法，使用相位随机化替代数据评估统计显著性，通过前向模型验证已知的二阶和三阶依赖性。

Result: 在真实EEG数据集中检测到任务条件下统计显著的三阶相互作用，尽管数据相对稀疏（每个条件45次试验）。信息衰减分析显示从理想二元情况到使用振荡信号实施这些依赖性时信息损失最大。

Conclusion: 信息几何方法结合适当的二值化方案可以成功从连续神经记录中提取真正的高阶依赖性。

Abstract: In neuroscience, methods from information geometry (IG) have been
successfully applied in the modelling of binary vectors from spike train data,
using the orthogonal decomposition of the Kullback-Leibler divergence and
mutual information to isolate different orders of interaction between neurons.
While spike train data is well-approximated with a binary model, here we apply
these IG methods to data from electroencephalography (EEG), a continuous signal
requiring appropriate discretization strategies. We developed and compared
three different binarization methods and used them to identify third-order
interactions in an experiment involving imagined motor movements. The
statistical significance of these interactions was assessed using
phase-randomized surrogate data that eliminated higher-order dependencies while
preserving the spectral characteristics of the original signals. We validated
our approach by implementing known second- and third-order dependencies in a
forward model and quantified information attenuation at different steps of the
analysis. This revealed that the greatest loss in information occurred when
going from the idealized binary case to enforcing these dependencies using
oscillatory signals. When applied to the real EEG dataset, our analysis
detected statistically significant third-order interactions during the task
condition despite the relatively sparse data (45 trials per condition). This
work demonstrates that IG methods can successfully extract genuine higher-order
dependencies from continuous neural recordings when paired with appropriate
binarization schemes.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [7] [cubic: CUDA-accelerated 3D Bioimage Computing](https://arxiv.org/abs/2510.14143)
*Alexandr A. Kalinin,Anne E. Carpenter,Shantanu Singh,Matthew J. O'Meara*

Main category: cs.CV

TL;DR: cubic是一个开源的Python库，通过为SciPy和scikit-image API提供GPU加速的替代方案，解决生物图像分析中的可扩展性和效率问题。


<details>
  <summary>Details</summary>
Motivation: 现代显微镜生成的大型2D和3D数据集需要更高效的计算方法，现有工具在可扩展性、GPU加速和与现代科学计算工作流的集成方面存在局限。

Method: cubic通过CuPy和RAPIDS cuCIM为SciPy和scikit-image API提供设备无关的GPU加速替代方案，自动在GPU和CPU之间调度操作。

Result: 在单个操作和现有去卷积、分割流程的基准测试中，cubic实现了显著的加速，同时保持算法保真度。

Conclusion: cubic为可扩展、可重现的生物图像分析建立了坚实基础，能够与更广泛的Python科学计算生态系统集成，支持交互式探索和自动化高通量分析工作流。

Abstract: Quantitative analysis of multidimensional biological images is useful for
understanding complex cellular phenotypes and accelerating advances in
biomedical research. As modern microscopy generates ever-larger 2D and 3D
datasets, existing computational approaches are increasingly limited by their
scalability, efficiency, and integration with modern scientific computing
workflows. Existing bioimage analysis tools often lack application programmable
interfaces (APIs), do not support graphics processing unit (GPU) acceleration,
lack broad 3D image processing capabilities, and/or have poor interoperability
for compute-heavy workflows. Here, we introduce cubic, an open-source Python
library that addresses these challenges by augmenting widely used SciPy and
scikit-image APIs with GPU-accelerated alternatives from CuPy and RAPIDS cuCIM.
cubic's API is device-agnostic and dispatches operations to GPU when data
reside on the device and otherwise executes on CPU, seamlessly accelerating a
broad range of image processing routines. This approach enables GPU
acceleration of existing bioimage analysis workflows, from preprocessing to
segmentation and feature extraction for 2D and 3D data. We evaluate cubic both
by benchmarking individual operations and by reproducing existing deconvolution
and segmentation pipelines, achieving substantial speedups while maintaining
algorithmic fidelity. These advances establish a robust foundation for
scalable, reproducible bioimage analysis that integrates with the broader
Python scientific computing ecosystem, including other GPU-accelerated methods,
enabling both interactive exploration and automated high-throughput analysis
workflows. cubic is openly available at
https://github$.$com/alxndrkalinin/cubic

</details>


<div id='q-bio.PE'></div>

# q-bio.PE [[Back]](#toc)

### [8] [Viral population dynamics at the cellular level, considering the replication cycle](https://arxiv.org/abs/2510.14481)
*Seong Jun Park*

Main category: q-bio.PE

TL;DR: 提出了一种病毒复制简化模型，将每个阶段视为具有独立同分布完成时间的更新过程，推导出细胞水平病毒数量的解析公式。


<details>
  <summary>Details</summary>
Motivation: 由于细胞环境差异，病毒复制各阶段完成时间是随机变量，但现有方法缺乏对此情况下细胞水平病毒数量的解析表达式。

Method: 将病毒复制建模为更新过程，每个阶段具有独立同分布完成时间，基于生死过程推导病毒数量的解析公式。

Result: 得到了病毒平均数量的解析表达式，用概率密度函数表示各复制步骤的完成时间，并通过随机模拟验证了结果。

Conclusion: 本研究为理解病毒感染动态提供了一个新的定量框架。

Abstract: Viruses are microscopic infectious agents that require a host cell for
replication. Viral replication occurs in several stages, and the completion
time for each stage varies due to differences in the cellular environment.
Thus, the time to complete each stage in viral replication is a random
variable. However, no analytic expression exists for the viral population at
the cellular level when the completion time for each process constituting viral
replication is a random variable. This paper presents a simplified model of
viral replication, treating each stage as a renewal process with independently
and identically distributed completion times. Using the proposed model, we
derive an analytical formula for viral populations at the cellular level, based
on viewing viral replication as a birth-death process. The mean viral count is
expressed via probability density functions representing the completion time
for each step in the replication process. This work validates the results with
stochastic simulations. This study provides a new quantitative framework for
understanding viral infection dynamics.

</details>
