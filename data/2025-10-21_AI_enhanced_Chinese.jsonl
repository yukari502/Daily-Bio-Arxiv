{"id": "2510.16013", "pdf": "https://arxiv.org/pdf/2510.16013", "abs": "https://arxiv.org/abs/2510.16013", "authors": ["Jahidul Arafat", "Sanjaya Poudel", "Fariha Tasmin", "Md Kaosar Uddin", "Eftakhar Ahmed Arnob"], "title": "AGNES: Adaptive Graph Neural Network and Dynamic Programming Hybrid Framework for Real-Time Nanopore Seed Chaining", "categories": ["q-bio.GN", "cs.LG", "92D20, 68T05, 62P10", "I.2.6; J.3; H.2.8; I.5"], "comment": "31 pages, 12 figures, 6 tables. Submitted to ACM Conference on\n  Bioinformatics, Computational Biology, and Health Informatics (ACM-BCB).\n  Includes comprehensive evaluation with statistical validation, ablation\n  studies, and open-source implementation", "summary": "Nanopore sequencing enables real-time long-read DNA sequencing with reads\nexceeding 10 kilobases, but inherent error rates of 12-15 percent present\nsignificant computational challenges for read alignment. The critical seed\nchaining step must connect exact k-mer matches between reads and reference\ngenomes while filtering spurious matches, yet state-of-the-art methods rely on\nfixed gap penalty functions unable to adapt to varying genomic contexts\nincluding tandem repeats and structural variants. This paper presents RawHash3,\na hybrid framework combining graph neural networks with classical dynamic\nprogramming for adaptive seed chaining that maintains real-time performance\nwhile providing statistical guarantees. We formalize seed chaining as graph\nlearning where seeds constitute nodes with 12-dimensional feature vectors and\nedges encode 8-dimensional spatial relationships including gap consistency. Our\narchitecture employs three-layer EdgeConv GNN with confidence-based method\nselection that dynamically switches between learned guidance and algorithmic\nfallback. Comprehensive evaluation on 1,000 synthetic nanopore reads with 5,200\ntest seeds demonstrates RawHash3 achieves 99.94 percent precision and 40.07\npercent recall, representing statistically significant 25.0 percent relative\nimprovement over baseline with p less than 0.001. The system maintains median\ninference latency of 1.59ms meeting real-time constraints, while demonstrating\nsuperior robustness with 100 percent success rate under 20 percent label\ncorruption versus baseline degradation to 30.3 percent. Cross-validation\nconfirms stability establishing graph neural networks as viable approach for\nproduction genomics pipelines.", "AI": {"tldr": "RawHash3\u662f\u4e00\u4e2a\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u52a8\u6001\u89c4\u5212\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u7eb3\u7c73\u5b54\u6d4b\u5e8f\u7684\u81ea\u9002\u5e94\u79cd\u5b50\u94fe\u5316\uff0c\u5728\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\u3002", "motivation": "\u7eb3\u7c73\u5b54\u6d4b\u5e8f\u867d\u7136\u80fd\u5b9e\u73b0\u5b9e\u65f6\u957f\u8bfb\u957fDNA\u6d4b\u5e8f\uff0c\u4f4612-15%\u7684\u56fa\u6709\u9519\u8bef\u7387\u7ed9\u8bfb\u6bb5\u6bd4\u5bf9\u5e26\u6765\u4e86\u8ba1\u7b97\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u56fa\u5b9a\u7684\u95f4\u9699\u60e9\u7f5a\u51fd\u6570\uff0c\u65e0\u6cd5\u9002\u5e94\u4e32\u8054\u91cd\u590d\u548c\u7ed3\u6784\u53d8\u5f02\u7b49\u4e0d\u540c\u57fa\u56e0\u7ec4\u73af\u5883\u3002", "method": "\u5c06\u79cd\u5b50\u94fe\u5316\u5f62\u5f0f\u5316\u4e3a\u56fe\u5b66\u4e60\u95ee\u9898\uff0c\u79cd\u5b50\u6784\u6210\u5177\u670912\u7ef4\u7279\u5f81\u5411\u91cf\u7684\u8282\u70b9\uff0c\u8fb9\u7f16\u78018\u7ef4\u7a7a\u95f4\u5173\u7cfb\u3002\u91c7\u7528\u4e09\u5c42EdgeConv\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7ed3\u5408\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u65b9\u6cd5\u9009\u62e9\uff0c\u52a8\u6001\u5207\u6362\u5b66\u4e60\u6307\u5bfc\u548c\u7b97\u6cd5\u56de\u9000\u3002", "result": "\u57281,000\u4e2a\u5408\u6210\u7eb3\u7c73\u5b54\u8bfb\u6bb5\u548c5,200\u4e2a\u6d4b\u8bd5\u79cd\u5b50\u7684\u7efc\u5408\u8bc4\u4f30\u4e2d\uff0cRawHash3\u8fbe\u523099.94%\u7684\u7cbe\u786e\u7387\u548c40.07%\u7684\u53ec\u56de\u7387\uff0c\u76f8\u6bd4\u57fa\u7ebf\u670925.0%\u7684\u76f8\u5bf9\u6539\u8fdb\uff08p<0.001\uff09\u3002\u4e2d\u4f4d\u63a8\u7406\u5ef6\u8fdf\u4e3a1.59ms\uff0c\u572820%\u6807\u7b7e\u635f\u574f\u4e0b\u4fdd\u6301100%\u6210\u529f\u7387\uff0c\u800c\u57fa\u7ebf\u964d\u81f330.3%\u3002", "conclusion": "\u4ea4\u53c9\u9a8c\u8bc1\u786e\u8ba4\u4e86\u7a33\u5b9a\u6027\uff0c\u786e\u7acb\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u751f\u4ea7\u57fa\u56e0\u7ec4\u5b66\u7ba1\u9053\u7684\u53ef\u884c\u65b9\u6cd5\u3002"}}
{"id": "2510.16093", "pdf": "https://arxiv.org/pdf/2510.16093", "abs": "https://arxiv.org/abs/2510.16093", "authors": ["Md. Imtyaz Ahmed", "Md. Delwar Hossain", "Md Mostafizer Rahman", "Md. Ahsan Habib", "Md. Mamunur Rashid", "Md. Selim Reza", "Md Ashad Alam"], "title": "Identifying multi-omics interactions for lung cancer drug targets discovery using Kernel Machine Regression", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "Cancer exhibits diverse and complex phenotypes driven by multifaceted\nmolecular interactions. Recent biomedical research has emphasized the\ncomprehensive study of such diseases by integrating multi-omics datasets\n(genome, proteome, transcriptome, epigenome). This approach provides an\nefficient method for identifying genetic variants associated with cancer and\noffers a deeper understanding of how the disease develops and spreads. However,\nit is challenging to comprehend complex interactions among the features of\nmulti-omics datasets compared to single omics. In this paper, we analyze lung\ncancer multi-omics datasets from The Cancer Genome Atlas (TCGA). Using four\nstatistical methods, LIMMA, the T test, Canonical Correlation Analysis (CCA),\nand the Wilcoxon test, we identified differentially expressed genes across gene\nexpression, DNA methylation, and miRNA expression data. We then integrated\nthese multi-omics data using the Kernel Machine Regression (KMR) approach. Our\nfindings reveal significant interactions among the three omics: gene\nexpression, miRNA expression, and DNA methylation in lung cancer. From our data\nanalysis, we identified 38 genes significantly associated with lung cancer.\nFrom our data analysis, we identified 38 genes significantly associated with\nlung cancer. Among these, eight genes of highest ranking (PDGFRB, PDGFRA,\nSNAI1, ID1, FGF11, TNXB, ITGB1, ZIC1) were highlighted by rigorous statistical\nanalysis. Furthermore, in silico studies identified three top-ranked potential\ncandidate drugs (Selinexor, Orapred, and Capmatinib) that could play a crucial\nrole in the treatment of lung cancer. These proposed drugs are also supported\nby the findings of other independent studies, which underscore their potential\nefficacy in the fight against lung cancer.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u6574\u5408\u591a\u7ec4\u5b66\u6570\u636e\uff08\u57fa\u56e0\u8868\u8fbe\u3001DNA\u7532\u57fa\u5316\u3001miRNA\u8868\u8fbe\uff09\u5206\u6790\u80ba\u764c\uff0c\u4f7f\u7528\u56db\u79cd\u7edf\u8ba1\u65b9\u6cd5\u548c\u6838\u673a\u5668\u56de\u5f52\u65b9\u6cd5\u8bc6\u522b\u51fa38\u4e2a\u4e0e\u80ba\u764c\u663e\u8457\u76f8\u5173\u7684\u57fa\u56e0\uff0c\u5e76\u53d1\u73b0\u4e09\u79cd\u6f5c\u5728\u5019\u9009\u836f\u7269\u3002", "motivation": "\u764c\u75c7\u8868\u73b0\u51fa\u7531\u591a\u65b9\u9762\u5206\u5b50\u76f8\u4e92\u4f5c\u7528\u9a71\u52a8\u7684\u591a\u6837\u5316\u548c\u590d\u6742\u8868\u578b\u3002\u6574\u5408\u591a\u7ec4\u5b66\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u8bc6\u522b\u764c\u75c7\u76f8\u5173\u9057\u4f20\u53d8\u5f02\u548c\u6df1\u5165\u7406\u89e3\u75be\u75c5\u53d1\u5c55\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4f46\u7406\u89e3\u591a\u7ec4\u5b66\u6570\u636e\u7279\u5f81\u95f4\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528\u6bd4\u5355\u7ec4\u5b66\u66f4\u5177\u6311\u6218\u6027\u3002", "method": "\u4f7f\u7528LIMMA\u3001T\u68c0\u9a8c\u3001\u5178\u578b\u76f8\u5173\u5206\u6790\u548cWilcoxon\u68c0\u9a8c\u56db\u79cd\u7edf\u8ba1\u65b9\u6cd5\u5206\u6790TCGA\u7684\u80ba\u764c\u591a\u7ec4\u5b66\u6570\u636e\uff0c\u8bc6\u522b\u5dee\u5f02\u8868\u8fbe\u57fa\u56e0\uff0c\u7136\u540e\u4f7f\u7528\u6838\u673a\u5668\u56de\u5f52\u65b9\u6cd5\u6574\u5408\u591a\u7ec4\u5b66\u6570\u636e\u3002", "result": "\u53d1\u73b0\u57fa\u56e0\u8868\u8fbe\u3001miRNA\u8868\u8fbe\u548cDNA\u7532\u57fa\u5316\u4e09\u4e2a\u7ec4\u5b66\u5728\u80ba\u764c\u4e2d\u5b58\u5728\u663e\u8457\u76f8\u4e92\u4f5c\u7528\uff0c\u8bc6\u522b\u51fa38\u4e2a\u4e0e\u80ba\u764c\u663e\u8457\u76f8\u5173\u7684\u57fa\u56e0\uff0c\u5176\u4e2d8\u4e2a\u6392\u540d\u6700\u9ad8\u7684\u57fa\u56e0\uff08PDGFRB\u3001PDGFRA\u3001SNAI1\u3001ID1\u3001FGF11\u3001TNXB\u3001ITGB1\u3001ZIC1\uff09\u901a\u8fc7\u4e25\u683c\u7edf\u8ba1\u5206\u6790\u7a81\u51fa\u663e\u793a\u3002", "conclusion": "\u901a\u8fc7\u8ba1\u7b97\u673a\u6a21\u62df\u7814\u7a76\u786e\u5b9a\u4e86\u4e09\u79cd\u6392\u540d\u6700\u9ad8\u7684\u6f5c\u5728\u5019\u9009\u836f\u7269\uff08Selinexor\u3001Orapred\u548cCapmatinib\uff09\uff0c\u8fd9\u4e9b\u836f\u7269\u53ef\u80fd\u5728\u80ba\u764c\u6cbb\u7597\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u4e14\u5f97\u5230\u5176\u4ed6\u72ec\u7acb\u7814\u7a76\u7ed3\u679c\u7684\u652f\u6301\u3002"}}
{"id": "2510.16824", "pdf": "https://arxiv.org/pdf/2510.16824", "abs": "https://arxiv.org/abs/2510.16824", "authors": ["Yingxu Wang", "Kunyu Zhang", "Jiaxin Huang", "Nan Yin", "Siwei Liu", "Eran Segal"], "title": "ProtoMol: Enhancing Molecular Property Prediction via Prototype-Guided Multimodal Learning", "categories": ["cs.LG", "q-bio.MN"], "comment": null, "summary": "Multimodal molecular representation learning, which jointly models molecular\ngraphs and their textual descriptions, enhances predictive accuracy and\ninterpretability by enabling more robust and reliable predictions of drug\ntoxicity, bioactivity, and physicochemical properties through the integration\nof structural and semantic information. However, existing multimodal methods\nsuffer from two key limitations: (1) they typically perform cross-modal\ninteraction only at the final encoder layer, thus overlooking hierarchical\nsemantic dependencies; (2) they lack a unified prototype space for robust\nalignment between modalities. To address these limitations, we propose\nProtoMol, a prototype-guided multimodal framework that enables fine-grained\nintegration and consistent semantic alignment between molecular graphs and\ntextual descriptions. ProtoMol incorporates dual-branch hierarchical encoders,\nutilizing Graph Neural Networks to process structured molecular graphs and\nTransformers to encode unstructured texts, resulting in comprehensive\nlayer-wise representations. Then, ProtoMol introduces a layer-wise\nbidirectional cross-modal attention mechanism that progressively aligns\nsemantic features across layers. Furthermore, a shared prototype space with\nlearnable, class-specific anchors is constructed to guide both modalities\ntoward coherent and discriminative representations. Extensive experiments on\nmultiple benchmark datasets demonstrate that ProtoMol consistently outperforms\nstate-of-the-art baselines across a variety of molecular property prediction\ntasks.", "AI": {"tldr": "ProtoMol\u662f\u4e00\u4e2a\u539f\u578b\u5f15\u5bfc\u7684\u591a\u6a21\u6001\u5206\u5b50\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u7f16\u7801\u5668\u548c\u53cc\u5411\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5b9e\u73b0\u5206\u5b50\u56fe\u4e0e\u6587\u672c\u63cf\u8ff0\u7684\u7ec6\u7c92\u5ea6\u6574\u5408\u548c\u8bed\u4e49\u5bf9\u9f50\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a\u4ec5\u5728\u6700\u7ec8\u7f16\u7801\u5c42\u8fdb\u884c\u8de8\u6a21\u6001\u4ea4\u4e92\uff0c\u5ffd\u7565\u4e86\u5206\u5c42\u8bed\u4e49\u4f9d\u8d56\uff1b\u7f3a\u4e4f\u7edf\u4e00\u7684\u539f\u578b\u7a7a\u95f4\u6765\u5b9e\u73b0\u6a21\u6001\u95f4\u7684\u7a33\u5065\u5bf9\u9f50\u3002", "method": "\u91c7\u7528\u53cc\u5206\u652f\u5206\u5c42\u7f16\u7801\u5668\uff08GNN\u5904\u7406\u5206\u5b50\u56fe\uff0cTransformer\u7f16\u7801\u6587\u672c\uff09\uff0c\u5f15\u5165\u5206\u5c42\u53cc\u5411\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6784\u5efa\u5171\u4eab\u539f\u578b\u7a7a\u95f4\u4e0e\u53ef\u5b66\u4e60\u7684\u7c7b\u7279\u5b9a\u951a\u70b9\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cProtoMol\u5728\u5404\u79cd\u5206\u5b50\u6027\u8d28\u9884\u6d4b\u4efb\u52a1\u4e2d\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ProtoMol\u901a\u8fc7\u5206\u5c42\u8de8\u6a21\u6001\u4ea4\u4e92\u548c\u539f\u578b\u5f15\u5bfc\u7684\u8bed\u4e49\u5bf9\u9f50\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5206\u5b50\u8868\u793a\u5b66\u4e60\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.15939", "pdf": "https://arxiv.org/pdf/2510.15939", "abs": "https://arxiv.org/abs/2510.15939", "authors": ["Shreya Gopalan", "Sundar Narayanan"], "title": "Hallucinations in AlphaFold3 for Intrinsically Disordered Proteins with disorder in Biological Process Residues", "categories": ["q-bio.QM"], "comment": "10 pages", "summary": "Protein structure prediction has advanced significantly with the introduction\nof AlphaFold3, a diffusion-based model capable of predicting complex\nbiomolecular interactions across proteins, nucleic acids, small molecules, and\nions. While AlphaFold3 demonstrates high accuracy in folded proteins, its\nperformance on intrinsically disordered proteins (IDPs), which comprise 30 to\n40 percent of the human proteome and play critical roles in transcription,\nsignaling, and disease, remains less explored. This study evaluated\nAlphaFold3's predictions of IDPs with a focus on intrinsically disordered\nregions (IDRs) using 72 proteins curated from the DisProt database. Predictions\nwere generated across multiple random seeds and ensemble outputs, and\nresidue-level pLDDT scores were compared with experimental disorder\nannotations. Our analysis reveals that 32 percent of residues are misaligned\nwith DisProt, with percent representing hallucinations where AlphaFold3\nincorrectly predicts order in disordered regions or vice versa. Additionally,\n10 percent of residues exhibited context-driven misalignment, suggesting that\nAlphaFold3 implicitly incorporates stable structural assumptions. Importantly,\n18 percent of residues associated with biological processes showed\nhallucinations, raising concerns about downstream implications in drug\ndiscovery and disease research. These findings highlight the limitations of\nAlphaFold3 in modeling IDRs, the need for refined hallucination metrics beyond\nthe pLDDT, and the importance of integrating experimental disorder data to\nimprove prediction reliability.", "AI": {"tldr": "AlphaFold3\u5728\u9884\u6d4b\u5185\u5728\u65e0\u5e8f\u86cb\u767d(IDPs)\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c32%\u7684\u6b8b\u57fa\u9884\u6d4b\u4e0e\u5b9e\u9a8c\u6570\u636e\u4e0d\u7b26\uff0c\u5176\u4e2d18%\u6d89\u53ca\u751f\u7269\u8fc7\u7a0b\u7684\u6b8b\u57fa\u51fa\u73b0\u5e7b\u89c9\u9884\u6d4b\uff0c\u53ef\u80fd\u5f71\u54cd\u836f\u7269\u53d1\u73b0\u548c\u75be\u75c5\u7814\u7a76\u3002", "motivation": "\u8bc4\u4f30AlphaFold3\u5728\u5185\u5728\u65e0\u5e8f\u86cb\u767d(IDPs)\u9884\u6d4b\u4e0a\u7684\u8868\u73b0\uff0c\u56e0\u4e3aIDPs\u5360\u4eba\u7c7b\u86cb\u767d\u8d28\u7ec4\u768430-40%\uff0c\u5728\u8f6c\u5f55\u3001\u4fe1\u53f7\u4f20\u5bfc\u548c\u75be\u75c5\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u4f46AlphaFold3\u5728\u8fd9\u65b9\u9762\u7684\u6027\u80fd\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f7f\u7528DisProt\u6570\u636e\u5e93\u4e2d\u768472\u4e2a\u86cb\u767d\u8d28\uff0c\u901a\u8fc7\u591a\u4e2a\u968f\u673a\u79cd\u5b50\u548c\u96c6\u6210\u8f93\u51fa\u751f\u6210\u9884\u6d4b\uff0c\u6bd4\u8f83\u6b8b\u57fa\u7ea7pLDDT\u5206\u6570\u4e0e\u5b9e\u9a8c\u65e0\u5e8f\u6ce8\u91ca\u3002", "result": "32%\u7684\u6b8b\u57fa\u4e0eDisProt\u6570\u636e\u4e0d\u4e00\u81f4\uff0c\u5176\u4e2d10%\u4e3a\u4e0a\u4e0b\u6587\u9a71\u52a8\u7684\u9519\u4f4d\uff0c18%\u4e0e\u751f\u7269\u8fc7\u7a0b\u76f8\u5173\u7684\u6b8b\u57fa\u51fa\u73b0\u5e7b\u89c9\u9884\u6d4b\u3002", "conclusion": "AlphaFold3\u5728\u5efa\u6a21IDRs\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u6539\u8fdb\u5e7b\u89c9\u5ea6\u91cf\u6807\u51c6\u5e76\u6574\u5408\u5b9e\u9a8c\u65e0\u5e8f\u6570\u636e\u4ee5\u63d0\u9ad8\u9884\u6d4b\u53ef\u9760\u6027\u3002"}}
{"id": "2510.16080", "pdf": "https://arxiv.org/pdf/2510.16080", "abs": "https://arxiv.org/abs/2510.16080", "authors": ["Kerem Delikoyun", "Qianyu Chen", "Win Sen Kuan", "John Tshon Yit Soong", "Matthew Edward Cove", "Oliver Hayden"], "title": "TriAgent: Automated Biomarker Discovery with Deep Research Grounding for Triage in Acute Care by LLM-Based Multi-Agent Collaboration", "categories": ["q-bio.QM", "cs.AI"], "comment": null, "summary": "Emergency departments worldwide face rising patient volumes, workforce\nshortages, and variability in triage decisions that threaten the delivery of\ntimely and accurate care. Current triage methods rely primarily on vital signs,\nroutine laboratory values, and clinicians' judgment, which, while effective,\noften miss emerging biological signals that could improve risk prediction for\ninfection typing or antibiotic administration in acute conditions. To address\nthis challenge, we introduce TriAgent, a large language model (LLM)-based\nmulti-agent framework that couples automated biomarker discovery with deep\nresearch for literature-grounded validation and novelty assessment. TriAgent\nemploys a supervisor research agent to generate research topics and delegate\ntargeted queries to specialized sub-agents for evidence retrieval from various\ndata sources. Findings are synthesized to classify biomarkers as either\ngrounded in existing knowledge or flagged as novel candidates, offering\ntransparent justification and highlighting unexplored pathways in acute care\nrisk stratification. Unlike prior frameworks limited to existing routine\nclinical biomarkers, TriAgent aims to deliver an end-to-end framework from data\nanalysis to literature grounding to improve transparency, explainability and\nexpand the frontier of potentially actionable clinical biomarkers. Given a\nuser's clinical query and quantitative triage data, TriAgent achieved a topic\nadherence F1 score of 55.7 +/- 5.0%, surpassing the CoT-ReAct agent by over\n10%, and a faithfulness score of 0.42 +/- 0.39, exceeding all baselines by more\nthan 50%. Across experiments, TriAgent consistently outperformed\nstate-of-the-art LLM-based agentic frameworks in biomarker justification and\nliterature-grounded novelty assessment. We share our repo:\nhttps://github.com/CellFace/TriAgent.", "AI": {"tldr": "TriAgent\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u6025\u8bca\u5206\u8bca\u4e2d\u7684\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u548c\u6587\u732e\u9a8c\u8bc1\uff0c\u65e8\u5728\u63d0\u9ad8\u98ce\u9669\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\u3002", "motivation": "\u89e3\u51b3\u6025\u8bca\u90e8\u95e8\u9762\u4e34\u7684\u65e5\u76ca\u589e\u957f\u7684\u60a3\u8005\u91cf\u3001\u4eba\u5458\u77ed\u7f3a\u4ee5\u53ca\u5206\u8bca\u51b3\u7b56\u53d8\u5f02\u6027\u95ee\u9898\uff0c\u6539\u8fdb\u5f53\u524d\u4e3b\u8981\u4f9d\u8d56\u751f\u547d\u4f53\u5f81\u3001\u5e38\u89c4\u5b9e\u9a8c\u5ba4\u503c\u548c\u4e34\u5e8a\u5224\u65ad\u7684\u5206\u8bca\u65b9\u6cd5\uff0c\u6355\u6349\u53ef\u80fd\u6539\u5584\u611f\u67d3\u7c7b\u578b\u6216\u6297\u751f\u7d20\u4f7f\u7528\u98ce\u9669\u9884\u6d4b\u7684\u65b0\u5174\u751f\u7269\u4fe1\u53f7\u3002", "method": "\u91c7\u7528\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u62ec\u76d1\u7763\u7814\u7a76\u667a\u80fd\u4f53\u751f\u6210\u7814\u7a76\u4e3b\u9898\u5e76\u59d4\u6258\u4e13\u4e1a\u5b50\u667a\u80fd\u4f53\u4ece\u5404\u79cd\u6570\u636e\u6e90\u68c0\u7d22\u8bc1\u636e\uff0c\u7efc\u5408\u53d1\u73b0\u5c06\u751f\u7269\u6807\u5fd7\u7269\u5206\u7c7b\u4e3a\u57fa\u4e8e\u73b0\u6709\u77e5\u8bc6\u6216\u6807\u8bb0\u4e3a\u65b0\u9896\u5019\u9009\uff0c\u63d0\u4f9b\u900f\u660e\u89e3\u91ca\u3002", "result": "TriAgent\u5728\u4e3b\u9898\u9075\u5faaF1\u5f97\u5206\u4e0a\u8fbe\u523055.7\u00b15.0%\uff0c\u6bd4CoT-ReAct\u667a\u80fd\u4f53\u63d0\u9ad8\u8d85\u8fc710%\uff0c\u5fe0\u5b9e\u5ea6\u5f97\u5206\u4e3a0.42\u00b10.39\uff0c\u8d85\u8fc7\u6240\u6709\u57fa\u7ebf50%\u4ee5\u4e0a\uff0c\u5728\u751f\u7269\u6807\u5fd7\u7269\u8bba\u8bc1\u548c\u6587\u732e\u57fa\u7840\u65b0\u9896\u6027\u8bc4\u4f30\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684LLM\u667a\u80fd\u4f53\u6846\u67b6\u3002", "conclusion": "TriAgent\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ece\u6570\u636e\u5206\u6790\u5230\u6587\u732e\u57fa\u7840\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u63d0\u9ad8\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u6269\u5c55\u4e86\u6f5c\u5728\u53ef\u64cd\u4f5c\u4e34\u5e8a\u751f\u7269\u6807\u5fd7\u7269\u7684\u524d\u6cbf\uff0c\u4e3a\u6025\u6027\u62a4\u7406\u98ce\u9669\u5206\u5c42\u63d0\u4f9b\u4e86\u65b0\u7684\u63a2\u7d22\u9014\u5f84\u3002"}}
{"id": "2510.16082", "pdf": "https://arxiv.org/pdf/2510.16082", "abs": "https://arxiv.org/abs/2510.16082", "authors": ["Elias Hossain", "Mehrdad Shoeibi", "Ivan Garibay", "Niloofar Yousefi"], "title": "Interpretable RNA-Seq Clustering with an LLM-Based Agentic Evidence-Grounded Framework", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose CITE V.1, an agentic, evidence-grounded framework that leverages\nLarge Language Models (LLMs) to provide transparent and reproducible\ninterpretations of RNA-seq clusters. Unlike existing enrichment-based\napproaches that reduce results to broad statistical associations and LLM-only\nmodels that risk unsupported claims or fabricated citations, CITE V.1\ntransforms cluster interpretation by producing biologically coherent\nexplanations explicitly anchored in the biomedical literature. The framework\norchestrates three specialized agents: a Retriever that gathers domain\nknowledge from PubMed and UniProt, an Interpreter that formulates functional\nhypotheses, and Critics that evaluate claims, enforce evidence grounding, and\nqualify uncertainty through confidence and reliability indicators. Applied to\nSalmonella enterica RNA-seq data, CITE V.1 generated biologically meaningful\ninsights supported by the literature, while an LLM-only Gemini baseline\nfrequently produced speculative results with false citations. By moving RNA-seq\nanalysis from surface-level enrichment to auditable, interpretable, and\nevidence-based hypothesis generation, CITE V.1 advances the transparency and\nreliability of AI in biomedicine.", "AI": {"tldr": "CITE V.1\u662f\u4e00\u4e2a\u57fa\u4e8e\u8bc1\u636e\u7684\u667a\u80fd\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e3aRNA-seq\u805a\u7c7b\u63d0\u4f9b\u900f\u660e\u53ef\u590d\u73b0\u7684\u89e3\u91ca\uff0c\u901a\u8fc7\u4e09\u4e2a\u4e13\u95e8\u4ee3\u7406\u5b9e\u73b0\u6587\u732e\u652f\u6301\u7684\u751f\u7269\u5b66\u89e3\u91ca\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5bcc\u96c6\u5206\u6790\u65b9\u6cd5\u4ec5\u63d0\u4f9b\u5bbd\u6cdb\u7edf\u8ba1\u5173\u8054\uff0c\u4ee5\u53ca\u7eafLLM\u6a21\u578b\u53ef\u80fd\u4ea7\u751f\u65e0\u652f\u6301\u58f0\u660e\u6216\u4f2a\u9020\u5f15\u7528\u7684\u95ee\u9898\uff0c\u63d0\u5347RNA-seq\u5206\u6790\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528\u4e09\u4e2a\u4e13\u95e8\u4ee3\u7406\uff1a\u68c0\u7d22\u5668\u4ecePubMed\u548cUniProt\u83b7\u53d6\u9886\u57df\u77e5\u8bc6\uff0c\u89e3\u91ca\u5668\u5236\u5b9a\u529f\u80fd\u5047\u8bbe\uff0c\u6279\u8bc4\u5bb6\u8bc4\u4f30\u58f0\u660e\u3001\u5f3a\u5236\u8bc1\u636e\u57fa\u7840\u5e76\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u548c\u53ef\u9760\u6027\u6307\u6807\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5728\u6c99\u95e8\u6c0f\u83ccRNA-seq\u6570\u636e\u4e0a\uff0cCITE V.1\u751f\u6210\u4e86\u6587\u732e\u652f\u6301\u7684\u751f\u7269\u5b66\u89c1\u89e3\uff0c\u800c\u7eafLLM\u7684Gemini\u57fa\u7ebf\u7ecf\u5e38\u4ea7\u751f\u5e26\u6709\u865a\u5047\u5f15\u7528\u7684\u63a8\u6d4b\u6027\u7ed3\u679c\u3002", "conclusion": "CITE V.1\u5c06RNA-seq\u5206\u6790\u4ece\u8868\u9762\u5bcc\u96c6\u63a8\u8fdb\u5230\u53ef\u5ba1\u8ba1\u3001\u53ef\u89e3\u91ca\u548c\u57fa\u4e8e\u8bc1\u636e\u7684\u5047\u8bbe\u751f\u6210\uff0c\u63d0\u5347\u4e86\u751f\u7269\u533b\u5b66\u4e2dAI\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.16130", "pdf": "https://arxiv.org/pdf/2510.16130", "abs": "https://arxiv.org/abs/2510.16130", "authors": ["Jiasen Zhang", "Xi Qiao", "Liangliang Zhang", "Weihong Guo"], "title": "BASIN: Bayesian mAtrix variate normal model with Spatial and sparsIty priors in Non-negative deconvolution", "categories": ["q-bio.QM", "stat.CO"], "comment": "26 pages, 12 figures", "summary": "Spatial transcriptomics allows researchers to visualize and analyze gene\nexpression within the precise location of tissues or cells. It provides\nspatially resolved gene expression data but often lacks cellular resolution,\nnecessitating cell type deconvolution to infer cellular composition at each\nspatial location. In this paper we propose BASIN for cell type deconvolution,\nwhich models deconvolution as a nonnegative matrix factorization (NMF) problem\nincorporating graph Laplacian prior. Rather than find a deterministic optima\nlike other recent methods, we propose a matrix variate Bayesian NMF method with\nnonnegativity and sparsity priors, in which the variables are maintained in\ntheir matrix form to derive a more efficient matrix normal posterior. BASIN\nemploys a Gibbs sampler to approximate the posterior distribution of cell type\nproportions and other parameters, offering a distribution of possible\nsolutions, enhancing robustness and providing inherent uncertainty\nquantification. The performance of BASIN is evaluated on different spatial\ntranscriptomics datasets and outperforms other deconvolution methods in terms\nof accuracy and efficiency. The results also show the effect of the\nincorporated priors and reflect a truncated matrix normal distribution as we\nexpect.", "AI": {"tldr": "BASIN\u662f\u4e00\u79cd\u7528\u4e8e\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u7ec6\u80de\u7c7b\u578b\u53cd\u5377\u79ef\u7684\u8d1d\u53f6\u65af\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fe\u62c9\u666e\u62c9\u65af\u5148\u9a8c\u548c\u5409\u5e03\u65af\u91c7\u6837\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u63d0\u4f9b\u7a7a\u95f4\u5206\u8fa8\u7684\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u4f46\u7f3a\u4e4f\u7ec6\u80de\u5206\u8fa8\u7387\uff0c\u9700\u8981\u7ec6\u80de\u7c7b\u578b\u53cd\u5377\u79ef\u6765\u63a8\u65ad\u6bcf\u4e2a\u7a7a\u95f4\u4f4d\u7f6e\u7684\u7ec6\u80de\u7ec4\u6210\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5bfb\u627e\u786e\u5b9a\u6027\u6700\u4f18\u89e3\uff0c\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "method": "\u5c06\u53cd\u5377\u79ef\u5efa\u6a21\u4e3a\u5305\u542b\u56fe\u62c9\u666e\u62c9\u65af\u5148\u9a8c\u7684\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u95ee\u9898\uff0c\u63d0\u51fa\u77e9\u9635\u53d8\u5206\u8d1d\u53f6\u65afNMF\u65b9\u6cd5\uff0c\u4f7f\u7528\u975e\u8d1f\u6027\u548c\u7a00\u758f\u6027\u5148\u9a8c\uff0c\u901a\u8fc7\u5409\u5e03\u65af\u91c7\u6837\u8fd1\u4f3c\u7ec6\u80de\u7c7b\u578b\u6bd4\u4f8b\u548c\u5176\u4ed6\u53c2\u6570\u7684\u540e\u9a8c\u5206\u5e03\u3002", "result": "\u5728\u4e0d\u540c\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30BASIN\u6027\u80fd\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u53cd\u5377\u79ef\u65b9\u6cd5\uff0c\u7ed3\u679c\u663e\u793a\u4e86\u6240\u7eb3\u5165\u5148\u9a8c\u7684\u6548\u679c\uff0c\u5e76\u53cd\u6620\u4e86\u9884\u671f\u7684\u622a\u65ad\u77e9\u9635\u6b63\u6001\u5206\u5e03\u3002", "conclusion": "BASIN\u901a\u8fc7\u8d1d\u53f6\u65af\u6846\u67b6\u63d0\u4f9b\u7ec6\u80de\u7c7b\u578b\u53cd\u5377\u79ef\u7684\u5206\u5e03\u89e3\uff0c\u589e\u5f3a\u4e86\u9c81\u68d2\u6027\u5e76\u63d0\u4f9b\u4e86\u56fa\u6709\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u5728\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u5206\u6790\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.16536", "pdf": "https://arxiv.org/pdf/2510.16536", "abs": "https://arxiv.org/abs/2510.16536", "authors": ["Niranjana Arun Menon", "Yulong Li", "Iqra Farooq", "Sara Ahmed", "Muhammad Awais", "Imran Razzak"], "title": "Few-Label Multimodal Modeling of SNP Variants and ECG Phenotypes Using Large Language Models for Cardiovascular Risk Stratification", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "Cardiovascular disease (CVD) risk stratification remains a major challenge\ndue to its multifactorial nature and limited availability of high-quality\nlabeled datasets. While genomic and electrophysiological data such as SNP\nvariants and ECG phenotypes are increasingly accessible, effectively\nintegrating these modalities in low-label settings is non-trivial. This\nchallenge arises from the scarcity of well-annotated multimodal datasets and\nthe high dimensionality of biological signals, which limit the effectiveness of\nconventional supervised models. To address this, we present a few-label\nmultimodal framework that leverages large language models (LLMs) to combine\ngenetic and electrophysiological information for cardiovascular risk\nstratification. Our approach incorporates a pseudo-label refinement strategy to\nadaptively distill high-confidence labels from weakly supervised predictions,\nenabling robust model fine-tuning with only a small set of ground-truth\nannotations. To enhance the interpretability, we frame the task as a Chain of\nThought (CoT) reasoning problem, prompting the model to produce clinically\nrelevant rationales alongside predictions. Experimental results demonstrate\nthat the integration of multimodal inputs, few-label supervision, and CoT\nreasoning improves robustness and generalizability across diverse patient\nprofiles. Experimental results using multimodal SNP variants and ECG-derived\nfeatures demonstrated comparable performance to models trained on the full\ndataset, underscoring the promise of LLM-based few-label multimodal modeling\nfor advancing personalized cardiovascular care.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5c11\u6807\u7b7e\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7528\u4e8e\u5fc3\u8840\u7ba1\u75be\u75c5\u98ce\u9669\u5206\u5c42\uff0c\u7ed3\u5408\u9057\u4f20\u548c\u7535\u751f\u7406\u4fe1\u606f\uff0c\u901a\u8fc7\u4f2a\u6807\u7b7e\u7cbe\u70bc\u548c\u601d\u7ef4\u94fe\u63a8\u7406\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5fc3\u8840\u7ba1\u75be\u75c5\u98ce\u9669\u5206\u5c42\u9762\u4e34\u591a\u56e0\u7d20\u6027\u548c\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7684\u6311\u6218\uff0c\u9700\u8981\u6709\u6548\u6574\u5408\u57fa\u56e0\u7ec4\u548c\u7535\u751f\u7406\u6570\u636e\u7b49\u4e0d\u540c\u6a21\u6001\u4fe1\u606f\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6574\u5408SNP\u53d8\u5f02\u548cECG\u7279\u5f81\uff0c\u91c7\u7528\u4f2a\u6807\u7b7e\u7cbe\u70bc\u7b56\u7565\u4ece\u5f31\u76d1\u7763\u9884\u6d4b\u4e2d\u63d0\u53d6\u9ad8\u7f6e\u4fe1\u5ea6\u6807\u7b7e\uff0c\u7ed3\u5408\u601d\u7ef4\u94fe\u63a8\u7406\u751f\u6210\u4e34\u5e8a\u76f8\u5173\u89e3\u91ca\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u591a\u6a21\u6001\u8f93\u5165\u3001\u5c11\u6807\u7b7e\u76d1\u7763\u548c\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u7ed3\u5408\u63d0\u9ad8\u4e86\u6a21\u578b\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u6027\u80fd\u53ef\u4e0e\u5168\u6570\u636e\u96c6\u8bad\u7ec3\u6a21\u578b\u76f8\u5ab2\u7f8e\u3002", "conclusion": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5c11\u6807\u7b7e\u591a\u6a21\u6001\u5efa\u6a21\u5728\u4e2a\u6027\u5316\u5fc3\u8840\u7ba1\u62a4\u7406\u65b9\u9762\u5177\u6709\u5e7f\u9614\u524d\u666f\u3002"}}
{"id": "2510.17273", "pdf": "https://arxiv.org/pdf/2510.17273", "abs": "https://arxiv.org/abs/2510.17273", "authors": ["Akul Sharma", "Anand A. Joshi", "Richard M. Leahy"], "title": "A Tractography Analysis Framework Using Diffusion Maps to Study Thalamic Connectivity in Traumatic Brain Injury", "categories": ["q-bio.QM", "68T07, 62H30 68T07, 62H30 68T07, 62H30", "I.2.10; I.5.4; J.3"], "comment": "Comments: 6 pages, 1 figure. Submitted and Accepted to IEEE\n  Engineering in Medicine and Biology Conference (EMBC) 2025", "summary": "Traumatic brain injury (TBI) disrupts thalamocortical connectivity,\ncontributing to cognitive impairment and post-traumatic epilepsy (PTE). This\nstudy presents a novel tractography-based framework that leverages diffusion\nmaps to capture microstructural and organizational changes in thalamic white\nmatter pathways. By analyzing individual streamline characteristics, we\nidentified significant associations between diffusion map embeddings and\nfunctional outcomes (GOSE scores), highlighting potential biomarkers for injury\nseverity and recovery trajectories. Our findings suggest that fine-grained\ngeometric features of white matter tracts may provide a more sensitive marker\nfor TBI-related alterations.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6269\u6563\u6620\u5c04\u7684\u675f\u8ffd\u8e2a\u6846\u67b6\uff0c\u5206\u6790\u521b\u4f24\u6027\u8111\u635f\u4f24\u540e\u4e18\u8111\u76ae\u8d28\u8fde\u63a5\u7684\u5fae\u89c2\u7ed3\u6784\u548c\u7ec4\u7ec7\u53d8\u5316\uff0c\u53d1\u73b0\u767d\u8d28\u675f\u7684\u51e0\u4f55\u7279\u5f81\u4e0e\u529f\u80fd\u9884\u540e\u76f8\u5173\u3002", "motivation": "\u521b\u4f24\u6027\u8111\u635f\u4f24\u4f1a\u7834\u574f\u4e18\u8111\u76ae\u8d28\u8fde\u63a5\uff0c\u5bfc\u81f4\u8ba4\u77e5\u969c\u788d\u548c\u5916\u4f24\u540e\u766b\u75eb\uff0c\u9700\u8981\u66f4\u654f\u611f\u7684\u6807\u8bb0\u7269\u6765\u8bc4\u4f30\u635f\u4f24\u4e25\u91cd\u7a0b\u5ea6\u548c\u6062\u590d\u8f68\u8ff9\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u6269\u6563\u6620\u5c04\u7684\u675f\u8ffd\u8e2a\u6846\u67b6\uff0c\u5206\u6790\u5355\u4e2a\u6d41\u7ebf\u7279\u5f81\uff0c\u6355\u6349\u4e18\u8111\u767d\u8d28\u901a\u8def\u7684\u5fae\u89c2\u7ed3\u6784\u548c\u7ec4\u7ec7\u53d8\u5316\u3002", "result": "\u53d1\u73b0\u6269\u6563\u6620\u5c04\u5d4c\u5165\u4e0e\u529f\u80fd\u9884\u540e\u8bc4\u5206\u663e\u8457\u76f8\u5173\uff0c\u767d\u8d28\u675f\u7684\u7cbe\u7ec6\u51e0\u4f55\u7279\u5f81\u53ef\u80fd\u6210\u4e3aTBI\u76f8\u5173\u6539\u53d8\u7684\u654f\u611f\u6807\u8bb0\u7269\u3002", "conclusion": "\u767d\u8d28\u675f\u7684\u51e0\u4f55\u7279\u5f81\u4e3a\u521b\u4f24\u6027\u8111\u635f\u4f24\u7684\u4e25\u91cd\u7a0b\u5ea6\u8bc4\u4f30\u548c\u6062\u590d\u8f68\u8ff9\u9884\u6d4b\u63d0\u4f9b\u4e86\u6f5c\u5728\u7684\u751f\u7269\u6807\u8bb0\u7269\u3002"}}
{"id": "2510.16253", "pdf": "https://arxiv.org/pdf/2510.16253", "abs": "https://arxiv.org/abs/2510.16253", "authors": ["Arielle Sanford", "Shuo Sun", "Christian B. Mendl"], "title": "Protein Folding with Neural Ordinary Differential Equations", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.QM", "stat.ML", "I.2.1; J.3"], "comment": null, "summary": "Recent advances in protein structure prediction, such as AlphaFold, have\ndemonstrated the power of deep neural architectures like the Evoformer for\ncapturing complex spatial and evolutionary constraints on protein conformation.\nHowever, the depth of the Evoformer, comprising 48 stacked blocks, introduces\nhigh computational costs and rigid layerwise discretization. Inspired by Neural\nOrdinary Differential Equations (Neural ODEs), we propose a continuous-depth\nformulation of the Evoformer, replacing its 48 discrete blocks with a Neural\nODE parameterization that preserves its core attention-based operations. This\ncontinuous-time Evoformer achieves constant memory cost (in depth) via the\nadjoint method, while allowing a principled trade-off between runtime and\naccuracy through adaptive ODE solvers. Benchmarking on protein structure\nprediction tasks, we find that the Neural ODE-based Evoformer produces\nstructurally plausible predictions and reliably captures certain secondary\nstructure elements, such as alpha-helices, though it does not fully replicate\nthe accuracy of the original architecture. However, our model achieves this\nperformance using dramatically fewer resources, just 17.5 hours of training on\na single GPU, highlighting the promise of continuous-depth models as a\nlightweight and interpretable alternative for biomolecular modeling. This work\nopens new directions for efficient and adaptive protein structure prediction\nframeworks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u7684\u8fde\u7eed\u6df1\u5ea6Evoformer\u6a21\u578b\uff0c\u7528\u795e\u7ecfODE\u53c2\u6570\u5316\u66ff\u4ee3\u4e86AlphaFold\u4e2d48\u4e2a\u79bb\u6563\u5757\uff0c\u5b9e\u73b0\u4e86\u6052\u5b9a\u5185\u5b58\u6210\u672c\u548c\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u3002", "motivation": "AlphaFold\u7b49\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\u6a21\u578b\u867d\u7136\u5f3a\u5927\uff0c\u4f46\u517648\u5c42Evoformer\u67b6\u6784\u5b58\u5728\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u521a\u6027\u79bb\u6563\u5316\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u5c06Evoformer\u768448\u4e2a\u79bb\u6563\u5757\u66ff\u6362\u4e3a\u795e\u7ecfODE\u53c2\u6570\u5316\uff0c\u4fdd\u6301\u6838\u5fc3\u6ce8\u610f\u529b\u64cd\u4f5c\uff0c\u5229\u7528\u4f34\u968f\u65b9\u6cd5\u5b9e\u73b0\u6052\u5b9a\u5185\u5b58\u6210\u672c\uff0c\u901a\u8fc7\u81ea\u9002\u5e94ODE\u6c42\u89e3\u5668\u5e73\u8861\u8fd0\u884c\u65f6\u95f4\u548c\u7cbe\u5ea6\u3002", "result": "\u6a21\u578b\u80fd\u591f\u751f\u6210\u7ed3\u6784\u5408\u7406\u7684\u86cb\u767d\u8d28\u9884\u6d4b\uff0c\u53ef\u9760\u5730\u6355\u6349\u03b1\u87ba\u65cb\u7b49\u4e8c\u7ea7\u7ed3\u6784\u5143\u7d20\uff0c\u4f46\u7cbe\u5ea6\u672a\u5b8c\u5168\u8fbe\u5230\u539f\u59cb\u67b6\u6784\u6c34\u5e73\uff0c\u8bad\u7ec3\u65f6\u95f4\u5927\u5e45\u51cf\u5c11\u81f3\u5355GPU 17.5\u5c0f\u65f6\u3002", "conclusion": "\u8fde\u7eed\u6df1\u5ea6\u6a21\u578b\u4e3a\u751f\u7269\u5206\u5b50\u5efa\u6a21\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u548c\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4e3a\u9ad8\u6548\u81ea\u9002\u5e94\u7684\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\u6846\u67b6\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2510.16304", "pdf": "https://arxiv.org/pdf/2510.16304", "abs": "https://arxiv.org/abs/2510.16304", "authors": ["Qinyu Xu"], "title": "Parameter Identifiability of RNA Dynamics in PDE Transport Models of Fluorescence Recovery After Photobleaching", "categories": ["math.AP", "q-bio.QM"], "comment": "21 pages, 16 figures", "summary": "The transport and localization of RNA molecules, crucial for cellular\nfunction and development, involve a combination of diffusion and active\ntransport mechanisms. Here, we are motivated by understanding the dynamics of\nRNA in Xenopus laevis oocytes. Fluorescence Recovery After Photobleaching\n(FRAP) is an experimental technique that is widely used to investigate the\ndynamics of molecular movement within cells by observing the recovery of\nfluorescence intensity in a photobleached region over time. To advance the\nunderstanding of RNA dynamics, we develop a reaction-diffusion-advection\npartial differential equation (PDE) model integrating both transport and\ndiffusion mechanisms. We propose a pipeline for identifiability analysis to\nassess the model's ability to uniquely determine parameter values from observed\nFRAP data. Based on profile likelihood analysis and reparametrization, we\nexamine the relationship between non- identifiable parameters, which improves\nthe robustness of parameter estimation. We find out that the identifiability of\nthe four parameters of interest is not exactly the same in different regions of\nthe cell. Specifically, transport velocity and diffusion coefficient are\nidentifiable in all regions of the cell, while some combinations of binding\nrate and unbinding rate are found to be identifiable near the nucleus.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408\u6269\u6563\u548c\u4e3b\u52a8\u8fd0\u8f93\u673a\u5236\u7684\u53cd\u5e94-\u6269\u6563-\u5e73\u6d41\u504f\u5fae\u5206\u65b9\u7a0b\u6a21\u578b\uff0c\u7528\u4e8e\u7814\u7a76\u975e\u6d32\u722a\u87fe\u5375\u6bcd\u7ec6\u80de\u4e2dRNA\u7684\u52a8\u529b\u5b66\u3002\u901a\u8fc7\u53ef\u8bc6\u522b\u6027\u5206\u6790\u548c\u53c2\u6570\u91cd\u53c2\u6570\u5316\uff0c\u6539\u8fdb\u4e86FRAP\u6570\u636e\u53c2\u6570\u4f30\u8ba1\u7684\u7a33\u5065\u6027\u3002", "motivation": "\u7406\u89e3\u975e\u6d32\u722a\u87fe\u5375\u6bcd\u7ec6\u80de\u4e2dRNA\u5206\u5b50\u7684\u8fd0\u8f93\u548c\u5b9a\u4f4d\u52a8\u529b\u5b66\uff0c\u8fd9\u4e9b\u8fc7\u7a0b\u5bf9\u7ec6\u80de\u529f\u80fd\u548c\u53d1\u80b2\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f00\u53d1\u53cd\u5e94-\u6269\u6563-\u5e73\u6d41\u504f\u5fae\u5206\u65b9\u7a0b\u6a21\u578b\uff0c\u7ed3\u5408\u53ef\u8bc6\u522b\u6027\u5206\u6790\u7ba1\u9053\uff0c\u5305\u62ec\u8f6e\u5ed3\u4f3c\u7136\u5206\u6790\u548c\u53c2\u6570\u91cd\u53c2\u6570\u5316\uff0c\u8bc4\u4f30\u4eceFRAP\u6570\u636e\u4e2d\u552f\u4e00\u786e\u5b9a\u53c2\u6570\u503c\u7684\u80fd\u529b\u3002", "result": "\u53d1\u73b0\u56db\u4e2a\u611f\u5174\u8da3\u53c2\u6570\u7684\u53ef\u8bc6\u522b\u6027\u5728\u7ec6\u80de\u4e0d\u540c\u533a\u57df\u4e0d\u5b8c\u5168\u76f8\u540c\u3002\u8fd0\u8f93\u901f\u5ea6\u548c\u6269\u6563\u7cfb\u6570\u5728\u6240\u6709\u7ec6\u80de\u533a\u57df\u90fd\u53ef\u8bc6\u522b\uff0c\u800c\u7ed3\u5408\u901f\u7387\u548c\u89e3\u7ed3\u5408\u901f\u7387\u7684\u67d0\u4e9b\u7ec4\u5408\u4ec5\u5728\u7ec6\u80de\u6838\u9644\u8fd1\u53ef\u8bc6\u522b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aRNA\u52a8\u529b\u5b66\u5efa\u6a21\u63d0\u4f9b\u4e86\u6539\u8fdb\u7684\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u7ec6\u80de\u533a\u57df\u53c2\u6570\u53ef\u8bc6\u522b\u6027\u7684\u5dee\u5f02\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u7406\u89e3RNA\u8fd0\u8f93\u673a\u5236\u3002"}}
{"id": "2510.16347", "pdf": "https://arxiv.org/pdf/2510.16347", "abs": "https://arxiv.org/abs/2510.16347", "authors": ["Songyuan Lu", "Jingwen Hui", "Jake Weeks", "David B. Berry", "Fanny Chapelin", "Frank Talke"], "title": "Computer Navigated Spinal Surgery Using Magnetic Resonance Imaging and Augmented Reality", "categories": ["eess.IV", "q-bio.QM"], "comment": null, "summary": "Current spinal pain management procedures, such as radiofrequency ablation\n(RFA) and epidural steroid injection (ESI), rely on fluoroscopy for needle\nplacement which exposes patients and physicians to ionizing radiation. In this\npaper, we investigate a radiation-free surgical navigation system for spinal\npain management procedures that combines magnetic resonance imaging (MRI) with\nfiducial ArUco marker-based augmented reality (AR). High-resolution MRI scans\nof a lumbar spinal phantom were obtained and assembled as a surface mesh.\nLaplacian smoothing algorithms were then applied to smoothen the surface and\nimprove the model fidelity. A commercially available stereo camera (ZED2) was\nused to track single or dual fiducial ArUco markers on the patient to determine\nthe patient's real-time pose. Custom AR software was applied to overlay the MRI\nimage onto the patient, allowing the physician to see not only the outer\nsurface of the patient but also the complete anatomy of the patient below the\nsurface. Needle-insertion trials on a 3D-printed 3-vertebra phantom showed that\ndual-ArUco marker tracking increased the accuracy of needle insertions and\nreduced the average needle misplacement distance compared to single-ArUco\nmarker procedures. The average needle misplacement is comparable to the average\ndeviation of 2 mm for conventional epidural techniques using fluoroscopy. Our\nradiation-free system demonstrates promise to serve as an alternative to\nfluoroscopy by improving image-guided spinal navigation.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7ed3\u5408MRI\u548cAR\u6807\u8bb0\u7684\u65e0\u8f90\u5c04\u810a\u67f1\u75bc\u75db\u7ba1\u7406\u624b\u672f\u5bfc\u822a\u7cfb\u7edf\uff0c\u901a\u8fc7\u53ccArUco\u6807\u8bb0\u8ddf\u8e2a\u63d0\u9ad8\u9488\u5934\u63d2\u5165\u7cbe\u5ea6\uff0c\u4e0e\u4f20\u7edf\u7684\u8367\u5149\u900f\u89c6\u6cd5\u6548\u679c\u76f8\u5f53\u3002", "motivation": "\u5f53\u524d\u810a\u67f1\u75bc\u75db\u7ba1\u7406\u7a0b\u5e8f\uff08\u5982\u5c04\u9891\u6d88\u878d\u548c\u786c\u819c\u5916\u7c7b\u56fa\u9187\u6ce8\u5c04\uff09\u4f9d\u8d56\u8367\u5149\u900f\u89c6\u8fdb\u884c\u9488\u5934\u5b9a\u4f4d\uff0c\u4f7f\u60a3\u8005\u548c\u533b\u751f\u66b4\u9732\u4e8e\u7535\u79bb\u8f90\u5c04\u3002", "method": "\u4f7f\u7528\u9ad8\u5206\u8fa8\u7387MRI\u626b\u63cf\u6784\u5efa\u8170\u690e\u6a21\u578b\uff0c\u5e94\u7528\u62c9\u666e\u62c9\u65af\u5e73\u6ed1\u7b97\u6cd5\u4f18\u5316\u8868\u9762\u3002\u901a\u8fc7\u7acb\u4f53\u76f8\u673a\u8ddf\u8e2aArUco\u6807\u8bb0\u786e\u5b9a\u60a3\u8005\u5b9e\u65f6\u59ff\u6001\uff0c\u5b9a\u5236AR\u8f6f\u4ef6\u5c06MRI\u56fe\u50cf\u53e0\u52a0\u5230\u60a3\u8005\u8eab\u4e0a\u3002", "result": "\u57283D\u6253\u5370\u76843\u690e\u4f53\u6a21\u578b\u4e0a\u8fdb\u884c\u9488\u5934\u63d2\u5165\u8bd5\u9a8c\uff0c\u53ccArUco\u6807\u8bb0\u8ddf\u8e2a\u63d0\u9ad8\u4e86\u9488\u5934\u63d2\u5165\u7cbe\u5ea6\uff0c\u51cf\u5c11\u4e86\u5e73\u5747\u9488\u5934\u9519\u4f4d\u8ddd\u79bb\uff0c\u4e0e\u4f7f\u7528\u8367\u5149\u900f\u89c6\u7684\u4f20\u7edf\u786c\u819c\u5916\u6280\u672f\u5e73\u5747\u504f\u5dee2mm\u76f8\u5f53\u3002", "conclusion": "\u8fd9\u79cd\u65e0\u8f90\u5c04\u7cfb\u7edf\u6709\u671b\u4f5c\u4e3a\u8367\u5149\u900f\u89c6\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u6539\u5584\u56fe\u50cf\u5f15\u5bfc\u7684\u810a\u67f1\u5bfc\u822a\u3002"}}
{"id": "2510.16656", "pdf": "https://arxiv.org/pdf/2510.16656", "abs": "https://arxiv.org/abs/2510.16656", "authors": ["Noah El Rimawi-Fine", "Adam Stecklov", "Lucas Nelson", "Mathieu Blanchette", "Alexander Tong", "Stephen Y. Zhang", "Lazar Atanackovic"], "title": "Simulation-free Structure Learning for Stochastic Dynamics", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Modeling dynamical systems and unraveling their underlying causal\nrelationships is central to many domains in the natural sciences. Various\nphysical systems, such as those arising in cell biology, are inherently\nhigh-dimensional and stochastic in nature, and admit only partial, noisy state\nmeasurements. This poses a significant challenge for addressing the problems of\nmodeling the underlying dynamics and inferring the network structure of these\nsystems. Existing methods are typically tailored either for structure learning\nor modeling dynamics at the population level, but are limited in their ability\nto address both problems together. In this work, we address both problems\nsimultaneously: we present StructureFlow, a novel and principled\nsimulation-free approach for jointly learning the structure and stochastic\npopulation dynamics of physical systems. We showcase the utility of\nStructureFlow for the tasks of structure learning from interventions and\ndynamical (trajectory) inference of conditional population dynamics. We\nempirically evaluate our approach on high-dimensional synthetic systems, a set\nof biologically plausible simulated systems, and an experimental single-cell\ndataset. We show that StructureFlow can learn the structure of underlying\nsystems while simultaneously modeling their conditional population dynamics --\na key step toward the mechanistic understanding of systems behavior.", "AI": {"tldr": "StructureFlow\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u4eff\u771f\u81ea\u7531\u65b9\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u5b66\u4e60\u7269\u7406\u7cfb\u7edf\u7684\u7ed3\u6784\u548c\u968f\u673a\u7fa4\u4f53\u52a8\u529b\u5b66\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5904\u7406\u7ed3\u6784\u5b66\u4e60\u548c\u52a8\u529b\u5b66\u5efa\u6a21\u7684\u95ee\u9898\u3002", "motivation": "\u8bb8\u591a\u81ea\u7136\u7cfb\u7edf\u4e2d\u7684\u7269\u7406\u7cfb\u7edf\uff08\u5982\u7ec6\u80de\u751f\u7269\u5b66\uff09\u5177\u6709\u9ad8\u7ef4\u3001\u968f\u673a\u7279\u6027\uff0c\u4e14\u53ea\u80fd\u83b7\u5f97\u90e8\u5206\u566a\u58f0\u72b6\u6001\u6d4b\u91cf\uff0c\u8fd9\u7ed9\u5efa\u6a21\u7cfb\u7edf\u52a8\u529b\u5b66\u548c\u63a8\u65ad\u7f51\u7edc\u7ed3\u6784\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u53ea\u80fd\u5355\u72ec\u5904\u7406\u7ed3\u6784\u5b66\u4e60\u6216\u7fa4\u4f53\u5c42\u9762\u7684\u52a8\u529b\u5b66\u5efa\u6a21\u3002", "method": "\u63d0\u51fa\u4e86StructureFlow\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u539f\u7406\u7684\u4eff\u771f\u81ea\u7531\u65b9\u6cd5\uff0c\u80fd\u591f\u8054\u5408\u5b66\u4e60\u7269\u7406\u7cfb\u7edf\u7684\u7ed3\u6784\u548c\u968f\u673a\u7fa4\u4f53\u52a8\u529b\u5b66\u3002\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u5e72\u9884\u4e0b\u7684\u7ed3\u6784\u5b66\u4e60\u548c\u6761\u4ef6\u7fa4\u4f53\u52a8\u529b\u5b66\u7684\u8f68\u8ff9\u63a8\u65ad\u4efb\u52a1\u3002", "result": "\u5728\u9ad8\u7ef4\u5408\u6210\u7cfb\u7edf\u3001\u751f\u7269\u6a21\u62df\u7cfb\u7edf\u548c\u5b9e\u9a8c\u5355\u7ec6\u80de\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cStructureFlow\u80fd\u591f\u540c\u65f6\u5b66\u4e60\u5e95\u5c42\u7cfb\u7edf\u7684\u7ed3\u6784\u5e76\u5efa\u6a21\u5176\u6761\u4ef6\u7fa4\u4f53\u52a8\u529b\u5b66\u3002", "conclusion": "StructureFlow\u80fd\u591f\u540c\u65f6\u5b66\u4e60\u7cfb\u7edf\u7ed3\u6784\u548c\u6761\u4ef6\u7fa4\u4f53\u52a8\u529b\u5b66\uff0c\u8fd9\u662f\u7406\u89e3\u7cfb\u7edf\u884c\u4e3a\u673a\u5236\u7684\u5173\u952e\u6b65\u9aa4\u3002"}}
{"id": "2510.16674", "pdf": "https://arxiv.org/pdf/2510.16674", "abs": "https://arxiv.org/abs/2510.16674", "authors": ["Azam Shirali", "Giri Narasimhan"], "title": "Evaluating protein binding interfaces with PUMBA", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Protein-protein docking tools help in studying interactions between proteins,\nand are essential for drug, vaccine, and therapeutic development. However, the\naccuracy of a docking tool depends on a robust scoring function that can\nreliably differentiate between native and non-native complexes. PIsToN is a\nstate-of-the-art deep learning-based scoring function that uses Vision\nTransformers in its architecture. Recently, the Mamba architecture has\ndemonstrated exceptional performance in both natural language processing and\ncomputer vision, often outperforming Transformer-based models in their domains.\nIn this study, we introduce PUMBA (Protein-protein interface evaluation with\nVision Mamba), which improves PIsToN by replacing its Vision Transformer\nbackbone with Vision Mamba. This change allows us to leverage Mamba's efficient\nlong-range sequence modeling for sequences of image patches. As a result, the\nmodel's ability to capture both global and local patterns in protein-protein\ninterface features is significantly improved. Evaluation on several\nwidely-used, large-scale public datasets demonstrates that PUMBA consistently\noutperforms its original Transformer-based predecessor, PIsToN.", "AI": {"tldr": "PUMBA\u662f\u4e00\u4e2a\u6539\u8fdb\u7684\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u5bf9\u63a5\u8bc4\u5206\u51fd\u6570\uff0c\u7528Vision Mamba\u67b6\u6784\u66ff\u4ee3\u4e86PIsToN\u4e2d\u7684Vision Transformer\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u539f\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u5bf9\u63a5\u5de5\u5177\u4f9d\u8d56\u51c6\u786e\u7684\u8bc4\u5206\u51fd\u6570\u6765\u533a\u5206\u5929\u7136\u548c\u975e\u5929\u7136\u590d\u5408\u7269\u3002Vision Mamba\u67b6\u6784\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u6709\u671b\u6539\u8fdb\u73b0\u6709\u7684Transformer-based\u6a21\u578b\u3002", "method": "\u5c06PIsToN\u4e2d\u7684Vision Transformer\u9aa8\u5e72\u7f51\u7edc\u66ff\u6362\u4e3aVision Mamba\u67b6\u6784\uff0c\u5229\u7528Mamba\u5728\u56fe\u50cf\u5757\u5e8f\u5217\u4e0a\u7684\u9ad8\u6548\u957f\u7a0b\u5e8f\u5217\u5efa\u6a21\u80fd\u529b\u3002", "result": "\u5728\u591a\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u5927\u89c4\u6a21\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cPUMBA\u59cb\u7ec8\u4f18\u4e8e\u5176\u57fa\u4e8eTransformer\u7684\u524d\u8eabPIsToN\u3002", "conclusion": "Vision Mamba\u67b6\u6784\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u6355\u6349\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u754c\u9762\u7279\u5f81\u4e2d\u5168\u5c40\u548c\u5c40\u90e8\u6a21\u5f0f\u7684\u80fd\u529b\uff0c\u4e3a\u86cb\u767d\u8d28\u5bf9\u63a5\u8bc4\u5206\u51fd\u6570\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
