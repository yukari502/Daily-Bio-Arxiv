<div id=toc></div>

# Table of Contents

- [q-bio.QM](#q-bio.QM) [Total: 2]
- [cs.LG](#cs.LG) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [1] [ECKO: Explainable Clinical Knowledge for Oncology](https://arxiv.org/abs/2510.18929)
*Marta Contreiras Silva,Daniel Faria,Laura Balbi,Susana Nunes,Ana Filipa Rodrigues,Aleksander Palkowski,Michal Waleron,Emilia Daghir-Wojtkowiak,Ashwin Adrian Kallor,Christophe Battail,Federico Maria Corazza,Manuel Fiorelli,Armando Stellato,Javier Antonio Alfaro,Fabio Massimo Zanzotto,Catia Pesquita*

Main category: q-bio.QM

TL;DR: ECKO是一个可解释的临床知识图谱，整合33个生物医学本体论和多项研究数据，为肿瘤学提供个性化药物推荐和透明解释。


<details>
  <summary>Details</summary>
Motivation: 实现个性化肿瘤学需要整合和解释大量异质生物医学数据，传统方法无法满足这一需求。

Method: 构建ECKO知识图谱，整合33个生物医学本体论，聚合多研究数据，支持个性化药物推荐并提供可解释性。

Result: 创建了统一的知识图谱资源，能够将患者特异性分子数据与药理学知识关联，提供透明解释的药物推荐。

Conclusion: ECKO代表了肿瘤学个性化医学向可解释、可扩展和临床可操作方向的重要进展，在生物标志物发现、治疗优化和转化研究中有应用潜力。

Abstract: Personalized oncology aims to tailor treatment strategies to the unique
molecular and clinical profiles of individual patients, moving beyond the
traditional paradigm of treating the disease not the patient. Achieving this
vision requires the integration and interpretation of vast, heterogeneous
biomedical data within a meaningful scientific framework. Knowledge graphs,
structured according to biomedical ontologies, offer a powerful approach to
contextualize and interconnect diverse datasets, enabling more precise and
informed clinical decision-making.
  We present ECKO (Explainable Clinical Knowledge for Oncology), a
comprehensive knowledge graph that integrates 33 biomedical ontologies and
aggregates data from multiple studies to create a unified resource optimized
for data-driven clinical applications in oncology. Designed to support
personalized drug recommendations, ECKO facilitates the identification of
optimal therapeutic options by linking patient-specific molecular data to
relevant pharmacological knowledge. It provides transparent, interpretable
explanations for drug recommendations, fostering greater trust and
understanding among clinicians and researchers. This resource represents a
significant advancement toward explainable, scalable, and clinically actionable
personalized medicine in oncology, with potential applications in biomarker
discovery, treatment optimization, and translational research.

</details>


### [2] [Interactive visualization of kidney micro-compartmental segmentations and associated pathomics on whole slide images](https://arxiv.org/abs/2510.19499)
*Mark S. Keller,Nicholas Lucarelli,Yijiang Chen,Samuel Border,Andrew Janowczyk,Jonathan Himmelfarb,Matthias Kretzler,Jeffrey Hodgin,Laura Barisoni,Dawit Demeke,Leal Herlitz,Gilbert Moeckel,Avi Z. Rosenberg,Yanli Ding,Pinaki Sarder,Nils Gehlenborg*

Main category: q-bio.QM

TL;DR: 开发了一个基于机器学习的管道，用于在组织学全玻片图像中分割功能性组织单元，并扩展了Vitessce可视化工具来展示多种肾脏结构的分割结果。


<details>
  <summary>Details</summary>
Motivation: 在组织学图像分析中，不仅需要定量分析功能性组织单元，还需要定性检查结果以进行质量控制、探索和沟通。

Method: 构建了应用已验证分割模型的管道，扩展了Vitessce网络可视化工具，并提出了包含多个分割掩码文件的标准表示方法。

Result: 该方法使研究人员和公众能够交互式探索包含多个分割实体和相关特征的数据集，包括KPMP和HuBMAP的肾脏活检数据。

Conclusion: 所提出的方法成功实现了功能性组织单元分割结果的可视化探索，为肾脏形态计量学分析提供了有效工具。

Abstract: Application of machine learning techniques enables segmentation of functional
tissue units in histology whole-slide images (WSIs). We built a pipeline to
apply previously validated segmentation models of kidney structures and extract
quantitative features from these structures. Such quantitative analysis also
requires qualitative inspection of results for quality control, exploration,
and communication. We extend the Vitessce web-based visualization tool to
enable visualization of segmentations of multiple types of functional tissue
units, such as, glomeruli, tubules, arteries/arterioles in the kidney.
Moreover, we propose a standard representation for files containing multiple
segmentation bitmasks, which we define polymorphically, such that existing
formats including OME-TIFF, OME-NGFF, AnnData, MuData, and SpatialData can be
used. We demonstrate that these methods enable researchers and the broader
public to interactively explore datasets containing multiple segmented entities
and associated features, including for exploration of renal morphometry of
biopsies from the Kidney Precision Medicine Project (KPMP) and the Human
Biomolecular Atlas Program (HuBMAP).

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [BATIS: Bayesian Approaches for Targeted Improvement of Species Distribution Models](https://arxiv.org/abs/2510.19749)
*Catherine Villeneuve,Benjamin Akera,Mélisande Teng,David Rolnick*

Main category: cs.LG

TL;DR: 提出了BATIS框架，从贝叶斯角度重新审视深度物种分布模型，通过迭代更新先验预测来改进数据稀缺区域的可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决深度物种分布模型中由数据空间偏差导致的性能限制问题，特别是在数据稀缺区域提高模型可靠性。

Method: 引入BATIS框架，采用贝叶斯深度学习方法，结合先验预测和有限观测数据迭代更新，同时捕捉随机不确定性和认知不确定性。

Result: 在包含eBird平台公民科学观测的新数据集上进行了广泛的不确定性量化方法基准测试，显示贝叶斯深度学习方法能显著提高数据稀缺区域的模型可靠性。

Conclusion: 贝叶斯深度学习方法可以大大改进物种分布模型在数据稀缺位置的可靠性，有助于生态理解和保护工作。

Abstract: Species distribution models (SDMs), which aim to predict species occurrence
based on environmental variables, are widely used to monitor and respond to
biodiversity change. Recent deep learning advances for SDMs have been shown to
perform well on complex and heterogeneous datasets, but their effectiveness
remains limited by spatial biases in the data. In this paper, we revisit deep
SDMs from a Bayesian perspective and introduce BATIS, a novel and practical
framework wherein prior predictions are updated iteratively using limited
observational data. Models must appropriately capture both aleatoric and
epistemic uncertainty to effectively combine fine-grained local insights with
broader ecological patterns. We benchmark an extensive set of uncertainty
quantification approaches on a novel dataset including citizen science
observations from the eBird platform. Our empirical study shows how Bayesian
deep learning approaches can greatly improve the reliability of SDMs in
data-scarce locations, which can contribute to ecological understanding and
conservation efforts.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [4] [Automated Morphological Analysis of Neurons in Fluorescence Microscopy Using YOLOv8](https://arxiv.org/abs/2510.19455)
*Banan Alnemri,Arwa Basbrain*

Main category: eess.IV

TL;DR: 提出基于YOLOv8的神经元实例分割和形态测量管道，在荧光显微镜图像中实现自动化神经元分析，减少人工标注需求。


<details>
  <summary>Details</summary>
Motivation: 荧光显微镜图像中神经元细胞的准确分割和形态分析对神经科学和生物医学成像至关重要，但传统方法劳动密集且耗时。

Method: 使用YOLOv8模型在手动标注的显微镜图像上进行训练，实现神经元实例分割，并提取细胞长度、宽度、面积和灰度强度等形态特征。

Result: 模型分割准确率超过97%，形态测量总体准确率达到75.32%，证明了方法的有效性。

Conclusion: 该集成框架为细胞成像和神经科学研究提供了自动化分析工具，能够实现可扩展的精确神经元形态量化。

Abstract: Accurate segmentation and precise morphological analysis of neuronal cells in
fluorescence microscopy images are crucial steps in neuroscience and biomedical
imaging applications. However, this process is labor-intensive and
time-consuming, requiring significant manual effort and expertise to ensure
reliable outcomes. This work presents a pipeline for neuron instance
segmentation and measurement based on a high-resolution dataset of
stem-cell-derived neurons. The proposed method uses YOLOv8, trained on manually
annotated microscopy images. The model achieved high segmentation accuracy,
exceeding 97%. In addition, the pipeline utilized both ground truth and
predicted masks to extract biologically significant features, including cell
length, width, area, and grayscale intensity values. The overall accuracy of
the extracted morphological measurements reached 75.32%, further supporting the
effectiveness of the proposed approach. This integrated framework offers a
valuable tool for automated analysis in cell imaging and neuroscience research,
reducing the need for manual annotation and enabling scalable, precise
quantification of neuron morphology.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [5] [Learning noisy tissue dynamics across time scales](https://arxiv.org/abs/2510.19090)
*Ming Han,John Devany,Michel Fruchart,Margaret L. Gardel,Vincenzo Vitelli*

Main category: cond-mat.soft

TL;DR: 提出了一种生物模拟机器学习框架，通过图神经网络、归一化流和WaveNet算法直接从实验视频中推断嘈杂的多细胞动态，将组织建模为神经随机微分方程。


<details>
  <summary>Details</summary>
Motivation: 组织动态在从伤口愈合到形态发生的生物过程中至关重要，但这些嘈杂的多细胞动态难以预测。

Method: 结合图神经网络、归一化流和WaveNet算法，将组织表示为神经随机微分方程，其中细胞是演化图的边。

Result: 模型不仅捕捉了随机细胞运动，还预测了细胞分裂周期中的状态演化，并能准确生成发育系统（如果蝇翅膀）和细胞信号过程的实验动态。

Conclusion: 该方法可作为生物工程和临床环境中的数字孪生，为组织动态预测开辟了新途径。

Abstract: Tissue dynamics play a crucial role in biological processes ranging from
wound healing to morphogenesis. However, these noisy multicellular dynamics are
notoriously hard to predict. Here, we introduce a biomimetic machine learning
framework capable of inferring noisy multicellular dynamics directly from
experimental movies. This generative model combines graph neural networks,
normalizing flows and WaveNet algorithms to represent tissues as neural
stochastic differential equations where cells are edges of an evolving graph.
This machine learning architecture reflects the architecture of the underlying
biological tissues, substantially reducing the amount of data needed to train
it compared to convolutional or fully-connected neural networks. Taking
epithelial tissue experiments as a case study, we show that our model not only
captures stochastic cell motion but also predicts the evolution of cell states
in their division cycle. Finally, we demonstrate that our method can accurately
generate the experimental dynamics of developmental systems, such as the fly
wing, and cell signaling processes mediated by stochastic ERK waves, paving the
way for its use as a digital twin in bioengineering and clinical contexts.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [6] [EasyVitessce: auto-magically adding interactivity to Scverse single-cell and spatial biology plots](https://arxiv.org/abs/2510.19532)
*Selena Luo,Mark S. Keller,Tabassum Kakar,Lisa Choy,Nils Gehlenborg*

Main category: cs.HC

TL;DR: EasyVitessce是一个Python包，通过添加一行代码即可将静态的Scanpy和SpatialData绘图转换为交互式可视化


<details>
  <summary>Details</summary>
Motivation: 简化Vitessce的技术配置，增强Scverse Python绘图API的实用性，让用户能够轻松创建交互式可视化

Method: 使用Vitessce内部渲染交互式绘图，抽象化Vitessce配置的技术细节，支持在计算笔记本环境中查看或导出配置用于其他应用

Result: 成功开发出EasyVitessce包，可在PyPI获取，源代码在GitHub公开，采用MIT许可证

Conclusion: EasyVitessce有效提升了静态绘图的交互性，为用户提供了简单易用的交互可视化解决方案

Abstract: EasyVitessce is a Python package that turns existing static Scanpy and
SpatialData plots into interactive visualizations by virtue of adding a single
line of Python code. The package uses Vitessce internally to render interactive
plots, and abstracts away technical details involved with configuration of
Vitessce. The resulting interactive plots can be viewed in computational
notebook environments or their configurations can be exported for usage in
other contexts such as web applications, enhancing the utility of popular
Scverse Python plotting APIs. EasyVitessce is released under the MIT License
and available on the Python Package Index (PyPI). The source code is publicly
available on GitHub.

</details>
