<div id=toc></div>

# Table of Contents

- [q-bio.QM](#q-bio.QM) [Total: 3]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [1] [Ultra-wideband radar to measure in vivo musculoskeletal forces](https://arxiv.org/abs/2510.20866)
*Christopher S. Bird,Antonio P. L. Bo,Wei Lu,Taylor J. M. Dick*

Main category: q-bio.QM

TL;DR: 使用超宽带雷达非侵入式测量肌肉骨骼力，通过检测收缩肌肉的电磁特性变化，在不同肌肉结构、静态/动态条件和疲劳状态下都能准确估计力值。


<details>
  <summary>Details</summary>
Motivation: 直接测量肌肉骨骼力具有高度侵入性，现有估计方法精度有限，需要开发非侵入式的高精度测量技术。

Method: 利用超宽带雷达扫描肌肉，结合机器学习和线性模型，分析肌肉收缩时的电磁特性变化来估计力值。

Result: 在等长和动态膝关节伸展收缩中，测试R²>0.984，误差<3.3%，能够可靠跟踪单羽状和双羽状肌肉的等长力。

Conclusion: 超宽带雷达是一种强大的非侵入式方法，可用于量化体内肌肉骨骼力，在可穿戴辅助技术、生物力学和康复领域具有变革性潜力。

Abstract: Accurate measures of musculoskeletal forces are critical for clinicians,
biomechanists, and engineers, yet direct measurement is highly invasive and
current estimation methods remain limited in accuracy. Here, we demonstrate the
application of ultra-wideband radar to non-invasively estimate musculoskeletal
forces by measuring changes in the electromagnetic properties of contracting
muscles, in muscles with different structural properties, during various static
and dynamic conditions, and in the presence of fatigue. First, we show that
ultra-wideband radar scans of muscle can reliably track isometric force in a
unipennate knee extensor (vastus lateralis) and a bipennate ankle dorsiflexor
(tibialis anterior). Next, we integrate radar signals within machine-learning
and linear models to estimate musculoskeletal forces during fatiguing
isometric, and dynamic knee extension contractions, with exceptional accuracy
(test R2>0.984; errors<3.3%). Finally, we identify frequency-dependent effects
of musculoskeletal forces on ultra-wideband radar signals, that are independent
of physiological and structural features known to influence muscle force.
Together, these findings establish ultra-wideband radar as a powerful,
non-invasive approach for quantifying in vivo musculoskeletal forces, with
transformative potential for wearable assistive technologies, biomechanics, and
rehabilitation.

</details>


### [2] [Physics-Informed Deep Learning for Improved Input Function Estimation in Motion-Blurred Dynamic [${}^{18}$F]FDG PET Images](https://arxiv.org/abs/2510.21281)
*Christian Salomonsen,Kristoffer K. Wickstrøm,Samuel Kuttner,Elisabeth Wetzer*

Main category: q-bio.QM

TL;DR: 提出了一种物理信息深度学习输入函数预测模型(PIDLIF)，直接从PET图像估计动脉输入函数，通过整合动力学建模损失来提高在图像退化情况下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 动力学建模需要准确测定动脉输入函数(AIF)，但传统方法耗时且具有侵入性。深度学习可以预测输入函数，但需要提高在图像退化情况下的鲁棒性。

Method: 使用物理信息深度学习模型，整合动力学建模损失进行训练。基于两组织室模型，在70个小鼠[18F]FDG动态PET图像数据集上进行训练。

Result: 与无物理信息损失的网络性能相当，但在模拟运动模糊导致的图像退化情况下，PIDLIF模型在严重图像退化时仍保持高性能。

Conclusion: PIDLIF模型通过物理约束问题，在因运动模糊导致的严重图像退化情况下，展示了利用生理分布机制指导深度学习AIF预测网络的改进鲁棒性。

Abstract: Kinetic modeling enables \textit{in vivo} quantification of tracer uptake and
glucose metabolism in [${}^{18}$F]Fluorodeoxyglucose ([${}^{18}$F]FDG) dynamic
positron emission tomography (dPET) imaging of mice. However, kinetic modeling
requires the accurate determination of the arterial input function (AIF) during
imaging, which is time-consuming and invasive. Recent studies have shown the
efficacy of using deep learning to directly predict the input function,
surpassing established methods such as the image-derived input function (IDIF).
In this work, we trained a physics-informed deep learning-based input function
prediction model (PIDLIF) to estimate the AIF directly from the PET images,
incorporating a kinetic modeling loss during training. The proposed method uses
a two-tissue compartment model over two regions, the myocardium and brain of
the mice, and is trained on a dataset of 70 [${}^{18}$F]FDG dPET images of mice
accompanied by the measured AIF during imaging. The proposed method had
comparable performance to the network without a physics-informed loss, and when
sudden movement causing blurring in the images was simulated, the PIDLIF model
maintained high performance in severe cases of image degradation. The proposed
physics-informed method exhibits an improved robustness that is promoted by
physically constraining the problem, enforcing consistency for
out-of-distribution samples. In conclusion, the PIDLIF model offers insight
into the effects of leveraging physiological distribution mechanics in mice to
guide a deep learning-based AIF prediction network in images with severe
degradation as a result of blurring due to movement during imaging.

</details>


### [3] [eMZed 3: flexible and interactive development of scalable LC-MS/MS data analysis workflows in Python](https://arxiv.org/abs/2510.21484)
*Uwe Schmitt,Jethro L. Hemmann,Nicola Zamboni,Julia A. Vorholt,Patrick Kiefer*

Main category: q-bio.QM

TL;DR: eMZed 3是一个基于Python 3的现代LC-MS/MS数据分析框架，提供模块化架构、交互式可视化和可扩展的工作流程开发能力。


<details>
  <summary>Details</summary>
Motivation: LC-MS/MS数据分析需要灵活的软件解决方案来满足多样化的分析需求，现有的工具在可扩展性和交互性方面存在局限。

Method: 采用模块化架构分为三个包：emzed（核心功能）、emzed-gui（交互式可视化）和emzed-spyder（集成开发环境），支持SQLite后端和内存外处理，整合OpenMS等成熟库。

Result: eMZed 3支持色谱图数据、提供丰富的交互可视化工具，可在无头Python环境和计算集群中运行，适用于靶向和非靶向代谢组学分析。

Conclusion: eMZed 3支持高效开发可扩展和可重现的LC-MS数据分析流程，适合从新手到高级程序员的不同用户群体。

Abstract: Liquid chromatography-mass spectrometry (LC-MS/MS) data analysis requires
adaptable software solutions to meet diverse analytical needs. We present eMZed
3, a modern Python framework for flexible and interactive analysis of LC-MS/MS
data. eMZed 3 enables users to develop scalable workflows tailored to their
specific requirements while leveraging Python's extensive ecosystem of
libraries. Building on its predecessor, eMZed 3 is now Python 3-based and
includes substantial enhancements, including support for chromatogram-based
LC-MS data, a new SQLite-based backend supporting optional out-of-memory
processing, and rich interactive visualization tools. Compared to the previous
version, eMZed 3 is now split into three packages: emzed (core
functionalities), emzed-gui (interactive data visualization), and emzed-spyder
(an integrated development environment). This modular architecture allows
straightforward integration of the emzed core library into headless Python
environments, including computational notebooks (such as Jupyter) or
high-performance computing clusters. eMZed 3 incorporates well-established
libraries such as OpenMS, and is highly suited for both targeted and untargeted
metabolomics. Overall, eMZed 3 supports the efficient development of scalable
and reproducible LC-MS data analysis and is accessible to both novice and
advanced programmers.
  Availability and Implementation: eMZed 3 and its documentation are freely
available at https://emzed.ethz.ch, the source code is hosted at
https://gitlab.com/groups/emzed3. An online-executable example workflow is
available on Binder at:
https://mybinder.org/v2/gl/emzed3%2Femzed-example-workflow/HEAD?labpath=example.ipynb.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [4] [WhaleVAD-BPN: Improving Baleen Whale Call Detection with Boundary Proposal Networks and Post-processing Optimisation](https://arxiv.org/abs/2510.21280)
*Christiaan M. Geldenhuys,Günther Tonitz,Thomas R. Niesler*

Main category: eess.AS

TL;DR: 提出了边界提议网络(BPN)来改进鲸鱼声音检测系统，通过使用中间潜在表示来减少误报，在精度和少数类检测方面取得显著提升


<details>
  <summary>Details</summary>
Motivation: 解决现有鲸鱼声音检测系统中存在的误报和少数类检测问题

Method: 扩展现有轻量级声音事件检测系统，引入边界提议网络(BPN)，使用中间潜在表示来筛选最终输出，并采用前向搜索和后向搜索两种超参数选择方法

Result: BPN使精度绝对提升16.8%，D类呼叫和BP类呼叫的F1分数分别提升21.3%和9.4%，完整系统F1分数达到0.475，比基线提升9.8%

Conclusion: BPN能有效减少鲸鱼声音检测中的误报，提升少数类检测性能，结合优化的超参数选择方法可显著改善系统性能

Abstract: While recent sound event detection (SED) systems can identify baleen whale
calls in marine audio, challenges related to false positive and minority-class
detection persist. We propose the boundary proposal network (BPN), which
extends an existing lightweight SED system. The BPN is inspired by work in
image object detection and aims to reduce the number of false positive
detections. It achieves this by using intermediate latent representations
computed within the backbone classification model to gate the final output.
When added to an existing SED system, the BPN achieves a 16.8 % absolute
increase in precision, as well as 21.3 % and 9.4 % improvements in the F1-score
for minority-class d-calls and bp-calls, respectively. We further consider two
approaches to the selection of post-processing hyperparameters: a
forward-search and a backward-search. By separately optimising event-level and
frame-level hyperparameters, these two approaches lead to considerable
performance improvements over parameters selected using empirical methods. The
complete WhaleVAD-BPN system achieves a cross-validated development F1-score of
0.475, which is a 9.8 % absolute improvement over the baseline.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [5] [Foundation Models in Dermatopathology: Skin Tissue Classification](https://arxiv.org/abs/2510.21664)
*Riya Gupta,Yiwei Zong,Dennis H. Murphree*

Main category: cs.CV

TL;DR: 评估UNI和Virchow2两种基础模型作为特征提取器在皮肤病理学全玻片图像分类中的性能，Virchow2在大多数分类器中表现优于UNI，逻辑回归达到90%准确率。


<details>
  <summary>Details</summary>
Motivation: 皮肤病理学中全玻片图像的快速生成需要自动化方法进行高效处理和准确分类，本研究旨在评估基础模型在此任务中的表现。

Method: 使用UNI和Virchow2提取补丁级嵌入，通过均值聚合策略聚合成玻片级特征，训练多种机器学习分类器（逻辑回归、梯度提升树、随机森林），并探索数据增强和图像归一化技术。

Result: Virchow2提取的特征在大多数玻片级分类器中优于UNI，逻辑回归对Virchow2达到最高准确率90%，但差异无统计学意义。均值聚合方法提供了可靠的玻片级特征表示。

Conclusion: 基础模型在自动化全玻片图像分类中具有潜力，为皮肤病理学诊断提供了可扩展且有效的方法，并为玻片级表示学习的未来发展铺平了道路。

Abstract: The rapid generation of whole-slide images (WSIs) in dermatopathology
necessitates automated methods for efficient processing and accurate
classification. This study evaluates the performance of two foundation models,
UNI and Virchow2, as feature extractors for classifying WSIs into three
diagnostic categories: melanocytic, basaloid, and squamous lesions. Patch-level
embeddings were aggregated into slide-level features using a mean-aggregation
strategy and subsequently used to train multiple machine learning classifiers,
including logistic regression, gradient-boosted trees, and random forest
models. Performance was assessed using precision, recall, true positive rate,
false positive rate, and the area under the receiver operating characteristic
curve (AUROC) on the test set. Results demonstrate that patch-level features
extracted using Virchow2 outperformed those extracted via UNI across most
slide-level classifiers, with logistic regression achieving the highest
accuracy (90%) for Virchow2, though the difference was not statistically
significant. The study also explored data augmentation techniques and image
normalization to enhance model robustness and generalizability. The
mean-aggregation approach provided reliable slide-level feature
representations. All experimental results and metrics were tracked and
visualized using WandB.ai, facilitating reproducibility and interpretability.
This research highlights the potential of foundation models for automated WSI
classification, providing a scalable and effective approach for
dermatopathological diagnosis while paving the way for future advancements in
slide-level representation learning.

</details>
