{"id": "2510.22008", "pdf": "https://arxiv.org/pdf/2510.22008", "abs": "https://arxiv.org/abs/2510.22008", "authors": ["Md Saiful Islam Sajol", "Magesh Rajasekaran", "Hayden Gemeinhardt", "Adam Bess", "Chris Alvin", "Supratik Mukhopadhyay"], "title": "A Multimodal Human Protein Embeddings Database: DeepDrug Protein Embeddings Bank (DPEB)", "categories": ["cs.LG", "q-bio.MN"], "comment": null, "summary": "Computationally predicting protein-protein interactions (PPIs) is challenging\ndue to the lack of integrated, multimodal protein representations. DPEB is a\ncurated collection of 22,043 human proteins that integrates four embedding\ntypes: structural (AlphaFold2), transformer-based sequence (BioEmbeddings),\ncontextual amino acid patterns (ESM-2: Evolutionary Scale Modeling), and\nsequence-based n-gram statistics (ProtVec]). AlphaFold2 protein structures are\navailable through public databases (e.g., AlphaFold2 Protein Structure\nDatabase), but the internal neural network embeddings are not. DPEB addresses\nthis gap by providing AlphaFold2-derived embeddings for computational modeling.\nOur benchmark evaluations show GraphSAGE with BioEmbedding achieved the highest\nPPI prediction performance (87.37% AUROC, 79.16% accuracy). The framework also\nachieved 77.42% accuracy for enzyme classification and 86.04% accuracy for\nprotein family classification. DPEB supports multiple graph neural network\nmethods for PPI prediction, enabling applications in systems biology, drug\ntarget identification, pathway analysis, and disease mechanism studies.", "AI": {"tldr": "DPE\u662f\u4e00\u4e2a\u6574\u5408\u4e864\u79cd\u5d4c\u5165\u7c7b\u578b\u7684\u4eba\u7c7b\u86cb\u767d\u8d28\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\uff0c\u5176\u4e2dGraphSAGE\u4e0eBioEmbedding\u7ec4\u5408\u5728PPI\u9884\u6d4b\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u6574\u5408\u7684\u591a\u6a21\u6001\u86cb\u767d\u8d28\u8868\u793a\uff0c\u8ba1\u7b97\u9884\u6d4b\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u6574\u5408\u4e864\u79cd\u5d4c\u5165\u7c7b\u578b\uff1a\u7ed3\u6784\u5d4c\u5165\uff08AlphaFold2\uff09\u3001\u57fa\u4e8etransformer\u7684\u5e8f\u5217\u5d4c\u5165\uff08BioEmbeddings\uff09\u3001\u4e0a\u4e0b\u6587\u6c28\u57fa\u9178\u6a21\u5f0f\uff08ESM-2\uff09\u548c\u57fa\u4e8e\u5e8f\u5217\u7684n-gram\u7edf\u8ba1\uff08ProtVec\uff09\u3002\u652f\u6301\u591a\u79cd\u56fe\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u8fdb\u884cPPI\u9884\u6d4b\u3002", "result": "GraphSAGE\u4e0eBioEmbedding\u7ec4\u5408\u5728PPI\u9884\u6d4b\u4e2d\u8868\u73b0\u6700\u4f73\uff0887.37% AUROC\uff0c79.16%\u51c6\u786e\u7387\uff09\u3002\u5728\u9176\u5206\u7c7b\u4e2d\u8fbe\u523077.42%\u51c6\u786e\u7387\uff0c\u5728\u86cb\u767d\u8d28\u5bb6\u65cf\u5206\u7c7b\u4e2d\u8fbe\u523086.04%\u51c6\u786e\u7387\u3002", "conclusion": "DPE\u586b\u8865\u4e86AlphaFold2\u5185\u90e8\u795e\u7ecf\u7f51\u7edc\u5d4c\u5165\u7684\u7a7a\u767d\uff0c\u652f\u6301\u7cfb\u7edf\u751f\u7269\u5b66\u3001\u836f\u7269\u9776\u70b9\u8bc6\u522b\u3001\u901a\u8def\u5206\u6790\u548c\u75be\u75c5\u673a\u5236\u7814\u7a76\u7b49\u5e94\u7528\u3002"}}
{"id": "2510.22167", "pdf": "https://arxiv.org/pdf/2510.22167", "abs": "https://arxiv.org/abs/2510.22167", "authors": ["Chengxuan Li", "August George", "Reece Neff", "Doo Nam Kim", "Trevor Moser", "Kate Baldwin", "Malio Nelson", "Arsam Firoozfar", "James E Evans", "Margaret S Cheung"], "title": "Graph Identification of Proteins in Tomograms (GRIP-Tomo) 2.0: Topologically Aware Classification for Proteins", "categories": ["q-bio.QM", "q-bio.MN"], "comment": null, "summary": "Cryo-electron tomography (cryo-ET) enables structural characterization of\nbiomolecules under near-native conditions. Existing approaches for interpreting\nthe resulting three-dimensional volumes are computationally expensive and have\ndifficulty interpreting density associated with small proteins/complexes. To\nexplore alternate approaches for identifying proteins in cryo-ET data we\npursued a Graph Network and topologically invariant approach. Here, we report\non a fast algorithm that distinguishes volumes containing protein density from\nnoise by searching for nuances of evolutionarily conversed motifs and the\ngeometrical characteristics of protein structure. GRIP-Tomo 2.0 is a\nmachine-learning pipeline that extracts interpretable topological features of\nprotein structures within noisy experimental backgrounds. Compared to version\n1.0, the new pipeline includes three upgrades that significantly improve\nperformance including synthetic tomogram generation simulating realistic noise,\ngraph-based persistent feature extraction as protein fingerprints, and\nhigh-performance computing acceleration. GRIP-Tomo 2.0 achieves over 90%\naccuracy in distinguishing proteins from noise for synthetic datasets and over\n80% accuracy for real datasets, which represents a foundational step toward\nadvancing cryo-ET workflows and empowering automated detection of both small\nand large proteins for visual proteomics.", "AI": {"tldr": "GRIP-Tomo 2.0\u662f\u4e00\u4e2a\u57fa\u4e8e\u56fe\u7f51\u7edc\u548c\u62d3\u6251\u4e0d\u53d8\u91cf\u7684\u673a\u5668\u5b66\u4e60\u7ba1\u9053\uff0c\u7528\u4e8e\u5728\u51b7\u51bb\u7535\u5b50\u65ad\u5c42\u626b\u63cf\u6570\u636e\u4e2d\u5feb\u901f\u533a\u5206\u86cb\u767d\u8d28\u5bc6\u5ea6\u548c\u566a\u58f0\uff0c\u51c6\u786e\u7387\u8d85\u8fc790%\uff08\u5408\u6210\u6570\u636e\u96c6\uff09\u548c80%\uff08\u771f\u5b9e\u6570\u636e\u96c6\uff09\u3002", "motivation": "\u73b0\u6709\u7684\u51b7\u51bb\u7535\u5b50\u65ad\u5c42\u626b\u63cf\u6570\u636e\u89e3\u91ca\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u8bc6\u522b\u5c0f\u86cb\u767d\u8d28/\u590d\u5408\u7269\u7684\u5bc6\u5ea6\uff0c\u9700\u8981\u63a2\u7d22\u66ff\u4ee3\u65b9\u6cd5\u6765\u8bc6\u522b\u86cb\u767d\u8d28\u3002", "method": "\u4f7f\u7528\u56fe\u7f51\u7edc\u548c\u62d3\u6251\u4e0d\u53d8\u65b9\u6cd5\uff0c\u901a\u8fc7\u641c\u7d22\u8fdb\u5316\u4fdd\u5b88\u57fa\u5e8f\u7684\u7ec6\u5fae\u5dee\u522b\u548c\u86cb\u767d\u8d28\u7ed3\u6784\u7684\u51e0\u4f55\u7279\u5f81\uff0c\u5305\u62ec\u5408\u6210\u65ad\u5c42\u56fe\u751f\u6210\u6a21\u62df\u771f\u5b9e\u566a\u58f0\u3001\u57fa\u4e8e\u56fe\u7684\u6301\u4e45\u7279\u5f81\u63d0\u53d6\u4f5c\u4e3a\u86cb\u767d\u8d28\u6307\u7eb9\u3001\u9ad8\u6027\u80fd\u8ba1\u7b97\u52a0\u901f\u3002", "result": "GRIP-Tomo 2.0\u5728\u5408\u6210\u6570\u636e\u96c6\u4e2d\u533a\u5206\u86cb\u767d\u8d28\u4e0e\u566a\u58f0\u7684\u51c6\u786e\u7387\u8d85\u8fc790%\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e2d\u51c6\u786e\u7387\u8d85\u8fc780%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u63a8\u8fdb\u51b7\u51bb\u7535\u5b50\u65ad\u5c42\u626b\u63cf\u5de5\u4f5c\u6d41\u7a0b\u7684\u57fa\u7840\u6b65\u9aa4\uff0c\u80fd\u591f\u81ea\u52a8\u68c0\u6d4b\u5927\u5c0f\u86cb\u767d\u8d28\uff0c\u4e3a\u89c6\u89c9\u86cb\u767d\u8d28\u7ec4\u5b66\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2510.22130", "pdf": "https://arxiv.org/pdf/2510.22130", "abs": "https://arxiv.org/abs/2510.22130", "authors": ["Mushal Zia", "Faisal Suwayyid", "Yuta Hozumi", "JunJie Wee", "Hongsong Feng", "Guo-Wei Wei"], "title": "CAP: Commutative Algebra Prediction of Protein-Nucleic Acid Binding Affinities", "categories": ["q-bio.QM"], "comment": null, "summary": "An accurate prediction of protein-nucleic acid binding affinity is vital for\ndeciphering genomic processes, yet existing approaches often struggle in\nreconciling high accuracy with interpretability and computational efficiency.\nIn this study, we introduce commutative algebra prediction (CAP), which couples\npersistent Stanley-Reisner theory with advanced sequence embedding for\npredicting protein-nucleic acid binding affinities. CAP encodes proteins\nthrough transformer-learned embeddings that retain long-range evolutionary\ncontext and represents DNA and RNA with $\\textit{k}$-mer algebra embeddings\nderived from persistent facet ideals, which capture fine-scale nucleotide\ngeometry. We demonstrate that CAP surpasses the SVSBI protein-nucleic acid\nbenchmark and, in a further test, maintains reasonable performance on newly\ncurated protein-RNA and protein-nucleic acid datasets. Leveraging only primary\nsequences, CAP generalizes to any protein-nucleic acid pair with minimal\npreprocessing, enabling genome-scale analyses without 3D structural data and\npromising faster virtual screening for drug discovery and protein engineering.", "AI": {"tldr": "CAP\u65b9\u6cd5\u7ed3\u5408\u6301\u4e45Stanley-Reisner\u7406\u8bba\u548c\u5e8f\u5217\u5d4c\u5165\u6280\u672f\uff0c\u4ec5\u4f7f\u7528\u4e00\u7ea7\u5e8f\u5217\u5c31\u80fd\u51c6\u786e\u9884\u6d4b\u86cb\u767d\u8d28-\u6838\u9178\u7ed3\u5408\u4eb2\u548c\u529b\uff0c\u65e0\u97003D\u7ed3\u6784\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u540c\u65f6\u6ee1\u8db3\u8fd9\u4e9b\u8981\u6c42\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528transformer\u5b66\u4e60\u7684\u86cb\u767d\u8d28\u5d4c\u5165\u4fdd\u7559\u957f\u7a0b\u8fdb\u5316\u80cc\u666f\uff0cDNA\u548cRNA\u4f7f\u7528\u57fa\u4e8e\u6301\u4e45\u9762\u7406\u60f3\u7684k-mer\u4ee3\u6570\u5d4c\u5165\u6355\u83b7\u6838\u82f7\u9178\u51e0\u4f55\u7ec6\u8282\u3002", "result": "CAP\u8d85\u8d8a\u4e86SVSBI\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5728\u65b0\u6784\u5efa\u7684\u86cb\u767d\u8d28-RNA\u548c\u86cb\u767d\u8d28-\u6838\u9178\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u5408\u7406\u6027\u80fd\u3002", "conclusion": "CAP\u4ec5\u9700\u4e00\u7ea7\u5e8f\u5217\u5373\u53ef\u63a8\u5e7f\u5230\u4efb\u4f55\u86cb\u767d\u8d28-\u6838\u9178\u5bf9\uff0c\u652f\u6301\u57fa\u56e0\u7ec4\u89c4\u6a21\u5206\u6790\uff0c\u6709\u671b\u52a0\u901f\u836f\u7269\u53d1\u73b0\u548c\u86cb\u767d\u8d28\u5de5\u7a0b\u7684\u865a\u62df\u7b5b\u9009\u3002"}}
{"id": "2510.23108", "pdf": "https://arxiv.org/pdf/2510.23108", "abs": "https://arxiv.org/abs/2510.23108", "authors": ["Marlene J E Mayer", "Nicolas B Garnier", "Clara Becker", "Marta C Antonelli", "Silvia M Lobmaier", "Martin G Frasch"], "title": "Heart Rate Variability Patterns Reflect Yoga Intervention in Chronically Stressed Pregnant Women: A Quasi-Randomized Controlled Trial", "categories": ["q-bio.QM"], "comment": null, "summary": "Prenatal maternal stress (PS) is a risk factor for adverse offspring\nneurodevelopment. Heart rate variability (HRV) complexity provides a\nnon-invasive marker of maternal autonomic regulation and may be influenced by\nmind--body interventions such as Yoga. In this quasi-randomized controlled\ntrial, 28 chronically stressed pregnant women were followed from the second\ntrimester until birth: 14 participated in weekly Hatha Yoga with\nelectrocardiogram (ECG) recordings, and 14 received standard obstetric care\nwith monthly ECGs. Group allocation was based on availability, with\nparticipants unaware of their assignment at enrollment. HRV complexity was\nassessed first with Sample Entropy and Entropy Rate and then expanded to 94 HRV\nmetrics spanning temporal, frequency, nonlinear, and information-theoretical\ndomains. All metrics were covariate-adjusted (maternal age, BMI, gestational\nage), standardized, and analyzed using timepoint-specific principal component\nanalysis (PCA). From this, a unified HRV index was derived. Analyses revealed\nthat HRV metric relationships changed dynamically across pregnancy, with PCA\nloadings shifting from frequency toward complexity measures in late gestation.\nThe mixed effects model identified a significant time x group interaction\neffect (p = 0.041). These findings suggest a restructuring of HRV\nsignal-analytical domains with advancing pregnancy attributable to Yoga and\nhighlight the utility of advanced HRV analysis frameworks for future, larger\ntrials.", "AI": {"tldr": "\u745c\u4f3d\u5e72\u9884\u5bf9\u5b55\u671fHRV\u590d\u6742\u6027\u6709\u663e\u8457\u5f71\u54cd\uff0cHRV\u6307\u6807\u5173\u7cfb\u5728\u5b55\u671f\u52a8\u6001\u53d8\u5316\uff0cPCA\u5206\u6790\u663e\u793a\u665a\u671f\u598a\u5a20\u4ece\u9891\u57df\u6307\u6807\u8f6c\u5411\u590d\u6742\u6027\u6307\u6807", "motivation": "\u4ea7\u524d\u6bcd\u4eb2\u538b\u529b\u662f\u5f71\u54cd\u540e\u4ee3\u795e\u7ecf\u53d1\u80b2\u7684\u98ce\u9669\u56e0\u7d20\uff0cHRV\u590d\u6742\u6027\u53ef\u4f5c\u4e3a\u6bcd\u4eb2\u81ea\u4e3b\u795e\u7ecf\u8c03\u8282\u7684\u975e\u4fb5\u5165\u6027\u6807\u8bb0\uff0c\u53ef\u80fd\u53d7\u745c\u4f3d\u7b49\u8eab\u5fc3\u5e72\u9884\u5f71\u54cd", "method": "\u51c6\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\uff0c28\u540d\u6162\u6027\u538b\u529b\u5b55\u5987\u4ece\u5b55\u4e2d\u671f\u968f\u8bbf\u81f3\u5206\u5a29\uff0c14\u4eba\u53c2\u52a0\u6bcf\u5468\u54c8\u4ed6\u745c\u4f3d+ECG\u8bb0\u5f55\uff0c14\u4eba\u63a5\u53d7\u6807\u51c6\u4ea7\u79d1\u62a4\u7406+\u6bcf\u6708ECG\u3002\u4f7f\u752894\u4e2aHRV\u6307\u6807\uff0c\u8fdb\u884c\u534f\u53d8\u91cf\u8c03\u6574\u3001\u6807\u51c6\u5316\u548c\u65f6\u95f4\u70b9\u7279\u5f02\u6027PCA\u5206\u6790", "result": "HRV\u6307\u6807\u5173\u7cfb\u5728\u5b55\u671f\u52a8\u6001\u53d8\u5316\uff0cPCA\u8f7d\u8377\u4ece\u9891\u57df\u6307\u6807\u8f6c\u5411\u590d\u6742\u6027\u6307\u6807\u3002\u6df7\u5408\u6548\u5e94\u6a21\u578b\u663e\u793a\u663e\u8457\u7684\u65f6\u95f4\u00d7\u7ec4\u4ea4\u4e92\u6548\u5e94(p=0.041)", "conclusion": "\u745c\u4f3d\u5bfc\u81f4\u5b55\u671fHRV\u4fe1\u53f7\u5206\u6790\u57df\u7684\u91cd\u7ec4\uff0c\u7a81\u51fa\u4e86\u5148\u8fdbHRV\u5206\u6790\u6846\u67b6\u5728\u66f4\u5927\u89c4\u6a21\u8bd5\u9a8c\u4e2d\u7684\u5b9e\u7528\u6027"}}
{"id": "2510.21980", "pdf": "https://arxiv.org/pdf/2510.21980", "abs": "https://arxiv.org/abs/2510.21980", "authors": ["Starlika Bauskar", "Jade Jiao", "Narayanan Kannan", "Alexander Kimm", "Justin M. Baker", "Matthew J. Tyler", "Andrea L. Bertozzi", "Anne M. Andrews"], "title": "Boltzmann Graph Ensemble Embeddings for Aptamer Libraries", "categories": ["cs.LG", "math.PR", "q-bio.QM", "stat.ML"], "comment": null, "summary": "Machine-learning methods in biochemistry commonly represent molecules as\ngraphs of pairwise intermolecular interactions for property and structure\npredictions. Most methods operate on a single graph, typically the minimal free\nenergy (MFE) structure, for low-energy ensembles (conformations) representative\nof structures at thermodynamic equilibrium. We introduce a thermodynamically\nparameterized exponential-family random graph (ERGM) embedding that models\nmolecules as Boltzmann-weighted ensembles of interaction graphs. We evaluate\nthis embedding on SELEX datasets, where experimental biases (e.g., PCR\namplification or sequencing noise) can obscure true aptamer-ligand affinity,\nproducing anomalous candidates whose observed abundance diverges from their\nactual binding strength. We show that the proposed embedding enables robust\ncommunity detection and subgraph-level explanations for aptamer ligand\naffinity, even in the presence of biased observations. This approach may be\nused to identify low-abundance aptamer candidates for further experimental\nevaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u70ed\u529b\u5b66\u53c2\u6570\u5316\u7684\u6307\u6570\u65cf\u968f\u673a\u56fe\u5d4c\u5165\u65b9\u6cd5\uff0c\u5c06\u5206\u5b50\u5efa\u6a21\u4e3a\u73bb\u5c14\u5179\u66fc\u52a0\u6743\u7684\u76f8\u4e92\u4f5c\u7528\u56fe\u96c6\u5408\uff0c\u7528\u4e8e\u5728\u5b58\u5728\u5b9e\u9a8c\u504f\u5dee\u7684\u60c5\u51b5\u4e0b\u7a33\u5065\u5730\u68c0\u6d4b\u9002\u914d\u4f53-\u914d\u4f53\u4eb2\u548c\u529b\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u5355\u4e00\u6700\u5c0f\u81ea\u7531\u80fd\u7ed3\u6784\u6765\u8868\u793a\u5206\u5b50\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u53cd\u6620\u70ed\u529b\u5b66\u5e73\u8861\u72b6\u6001\u4e0b\u7684\u4f4e\u80fd\u6784\u8c61\u96c6\u5408\u3002\u5b9e\u9a8c\u504f\u5dee\uff08\u5982PCR\u6269\u589e\u6216\u6d4b\u5e8f\u566a\u58f0\uff09\u4f1a\u63a9\u76d6\u771f\u5b9e\u7684\u9002\u914d\u4f53-\u914d\u4f53\u4eb2\u548c\u529b\u3002", "method": "\u5f15\u5165\u70ed\u529b\u5b66\u53c2\u6570\u5316\u7684\u6307\u6570\u65cf\u968f\u673a\u56fe\u5d4c\u5165\uff0c\u5c06\u5206\u5b50\u5efa\u6a21\u4e3a\u73bb\u5c14\u5179\u66fc\u52a0\u6743\u7684\u76f8\u4e92\u4f5c\u7528\u56fe\u96c6\u5408\uff0c\u800c\u4e0d\u662f\u5355\u4e00\u56fe\u7ed3\u6784\u3002", "result": "\u8be5\u65b9\u6cd5\u5728SELEX\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u7a33\u5065\u7684\u793e\u533a\u68c0\u6d4b\u548c\u5b50\u56fe\u7ea7\u89e3\u91ca\uff0c\u5373\u4f7f\u5728\u5b58\u5728\u504f\u5dee\u89c2\u6d4b\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u51c6\u786e\u8bc6\u522b\u9002\u914d\u4f53-\u914d\u4f53\u4eb2\u548c\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u7528\u4e8e\u8bc6\u522b\u4f4e\u4e30\u5ea6\u9002\u914d\u4f53\u5019\u9009\u7269\u8fdb\u884c\u8fdb\u4e00\u6b65\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u4e3a\u5b58\u5728\u5b9e\u9a8c\u504f\u5dee\u7684\u751f\u7269\u5316\u5b66\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.22033", "pdf": "https://arxiv.org/pdf/2510.22033", "abs": "https://arxiv.org/abs/2510.22033", "authors": ["Tianxiang Wang", "Yingtong Ke", "Dhananjay Bhaskar", "Smita Krishnaswamy", "Alexander Cloninger"], "title": "Linearized Optimal Transport for Analysis of High-Dimensional Point-Cloud and Single-Cell Data", "categories": ["cs.LG", "q-bio.QM", "stat.ML", "68T05"], "comment": "11 pages, 5 figures", "summary": "Single-cell technologies generate high-dimensional point clouds of cells,\nenabling detailed characterization of complex patient states and treatment\nresponses. Yet each patient is represented by an irregular point cloud rather\nthan a simple vector, making it difficult to directly quantify and compare\nbiological differences between individuals. Nonlinear methods such as kernels\nand neural networks achieve predictive accuracy but act as black boxes,\noffering little biological interpretability.\n  To address these limitations, we adapt the Linear Optimal Transport (LOT)\nframework to this setting, embedding irregular point clouds into a\nfixed-dimensional Euclidean space while preserving distributional structure.\nThis embedding provides a principled linear representation that preserves\noptimal transport geometry while enabling downstream analysis. It also forms a\nregistration between any two patients, enabling direct comparison of their\ncellular distributions. Within this space, LOT enables: (i) \\textbf{accurate\nand interpretable classification} of COVID-19 patient states, where classifier\nweights map back to specific markers and spatial regions driving predictions;\nand (ii) \\textbf{synthetic data generation} for patient-derived organoids,\nexploiting the linearity of the LOT embedding. LOT barycenters yield averaged\ncellular profiles representing combined conditions or samples, supporting drug\ninteraction testing.\n  Together, these results establish LOT as a unified framework that bridges\npredictive performance, interpretability, and generative modeling. By\ntransforming heterogeneous point clouds into structured embeddings directly\ntraceable to the original data, LOT opens new opportunities for understanding\nimmune variation and treatment effects in high-dimensional biological systems.", "AI": {"tldr": "\u63d0\u51faLinear Optimal Transport\uff08LOT\uff09\u6846\u67b6\uff0c\u5c06\u5355\u7ec6\u80de\u6280\u672f\u751f\u6210\u7684\u9ad8\u7ef4\u70b9\u4e91\u5d4c\u5165\u5230\u56fa\u5b9a\u7ef4\u5ea6\u7684\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u5206\u5e03\u7ed3\u6784\uff0c\u89e3\u51b3\u4e86\u60a3\u8005\u95f4\u751f\u7269\u5dee\u5f02\u96be\u4ee5\u76f4\u63a5\u91cf\u5316\u548c\u6bd4\u8f83\u7684\u95ee\u9898\u3002", "motivation": "\u5355\u7ec6\u80de\u6280\u672f\u751f\u6210\u7684\u60a3\u8005\u6570\u636e\u662f\u4e0d\u89c4\u5219\u7684\u70b9\u4e91\u800c\u975e\u7b80\u5355\u5411\u91cf\uff0c\u4f7f\u5f97\u4e2a\u4f53\u95f4\u751f\u7269\u5dee\u5f02\u96be\u4ee5\u76f4\u63a5\u91cf\u5316\u548c\u6bd4\u8f83\u3002\u975e\u7ebf\u6027\u65b9\u6cd5\u5982\u6838\u65b9\u6cd5\u548c\u795e\u7ecf\u7f51\u7edc\u867d\u7136\u9884\u6d4b\u51c6\u786e\u4f46\u7f3a\u4e4f\u751f\u7269\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u91c7\u7528Linear Optimal Transport\uff08LOT\uff09\u6846\u67b6\uff0c\u5c06\u4e0d\u89c4\u5219\u70b9\u4e91\u5d4c\u5165\u5230\u56fa\u5b9a\u7ef4\u5ea6\u7684\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\uff0c\u4fdd\u6301\u6700\u4f18\u4f20\u8f93\u51e0\u4f55\u7ed3\u6784\uff0c\u5e76\u5f62\u6210\u60a3\u8005\u95f4\u7684\u914d\u51c6\u4ee5\u5b9e\u73b0\u76f4\u63a5\u6bd4\u8f83\u3002", "result": "LOT\u5b9e\u73b0\u4e86\uff1a\uff08i\uff09COVID-19\u60a3\u8005\u72b6\u6001\u7684\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u5206\u7c7b\uff0c\u5206\u7c7b\u5668\u6743\u91cd\u53ef\u6620\u5c04\u56de\u9a71\u52a8\u9884\u6d4b\u7684\u7279\u5b9a\u6807\u8bb0\u548c\u7a7a\u95f4\u533a\u57df\uff1b\uff08ii\uff09\u60a3\u8005\u6765\u6e90\u7c7b\u5668\u5b98\u7684\u5408\u6210\u6570\u636e\u751f\u6210\uff0c\u5229\u7528LOT\u5d4c\u5165\u7684\u7ebf\u6027\u6027\u3002", "conclusion": "LOT\u4f5c\u4e3a\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u6865\u63a5\u4e86\u9884\u6d4b\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u6027\u548c\u751f\u6210\u5efa\u6a21\uff0c\u901a\u8fc7\u5c06\u5f02\u8d28\u70b9\u4e91\u8f6c\u6362\u4e3a\u53ef\u76f4\u63a5\u8ffd\u6eaf\u539f\u59cb\u6570\u636e\u7684\u7ed3\u6784\u5316\u5d4c\u5165\uff0c\u4e3a\u7406\u89e3\u9ad8\u7ef4\u751f\u7269\u7cfb\u7edf\u4e2d\u7684\u514d\u75ab\u53d8\u5f02\u548c\u6cbb\u7597\u6548\u679c\u5f00\u8f9f\u4e86\u65b0\u673a\u4f1a\u3002"}}
{"id": "2510.22239", "pdf": "https://arxiv.org/pdf/2510.22239", "abs": "https://arxiv.org/abs/2510.22239", "authors": ["Jahidul Arafat", "Sanjaya Poudel"], "title": "Synthetic-to-Real Transfer Learning for Chromatin-Sensitive PWS Microscopy", "categories": ["eess.IV", "cs.LG", "q-bio.QM", "68T45, 92C55", "I.4.6; I.2.10; I.5.4"], "comment": "24 pages, 5 figures and 4 tables", "summary": "Chromatin sensitive partial wave spectroscopic (csPWS) microscopy enables\nlabel free detection of nanoscale chromatin packing alterations that occur\nbefore visible cellular transformation. However, manual nuclear segmentation\nlimits population scale analysis needed for biomarker discovery in early cancer\ndetection. The lack of annotated csPWS imaging data prevents direct use of\nstandard deep learning methods. We present CFU Net, a hierarchical segmentation\narchitecture trained with a three stage curriculum on synthetic multimodal\ndata. CFU Net achieves near perfect performance on held out synthetic test data\nthat represent diverse spectroscopic imaging conditions without manual\nannotations (Dice 0.9879, IoU 0.9895). Our approach uses physics based\nrendering that incorporates empirically supported chromatin packing statistics,\nMie scattering models, and modality specific noise, combined with a curriculum\nthat progresses from adversarial RGB pretraining to spectroscopic fine tuning\nand histology validation. CFU Net integrates five architectural elements\n(ConvNeXt backbone, Feature Pyramid Network, UNet plus plus dense connections,\ndual attention, and deep supervision) that together improve Dice over a\nbaseline UNet by 8.3 percent. We demonstrate deployment ready INT8 quantization\nwith 74.9 percent compression and 0.15 second inference, giving a 240 times\nthroughput gain over manual analysis. Applied to more than ten thousand\nautomatically segmented nuclei from synthetic test data, the pipeline extracts\nchromatin biomarkers that distinguish normal from pre cancerous tissue with\nlarge effect sizes (Cohens d between 1.31 and 2.98), reaching 94 percent\nclassification accuracy. This work provides a general framework for synthetic\nto real transfer learning in specialized microscopy and open resources for\ncommunity validation on clinical specimens.", "AI": {"tldr": "\u63d0\u51fa\u4e86CFU Net\uff0c\u4e00\u79cd\u7528\u4e8ecsPWS\u663e\u5fae\u955c\u7684\u5206\u5c42\u5206\u5272\u67b6\u6784\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u8bfe\u7a0b\u5728\u5408\u6210\u591a\u6a21\u6001\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u5b9e\u73b0\u65e0\u6807\u6ce8\u7684\u7ec6\u80de\u6838\u5206\u5272\uff0c\u5e76\u63d0\u53d6\u67d3\u8272\u8d28\u751f\u7269\u6807\u5fd7\u7269\u7528\u4e8e\u65e9\u671f\u764c\u75c7\u68c0\u6d4b\u3002", "motivation": "\u624b\u52a8\u7ec6\u80de\u6838\u5206\u5272\u9650\u5236\u4e86\u5728\u65e9\u671f\u764c\u75c7\u68c0\u6d4b\u4e2d\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u6240\u9700\u7684\u5927\u89c4\u6a21\u7fa4\u4f53\u5206\u6790\uff0c\u4e14\u7f3a\u4e4f\u6807\u6ce8\u7684csPWS\u6210\u50cf\u6570\u636e\u963b\u788d\u4e86\u6807\u51c6\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u4f7f\u7528\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u7269\u7406\u7684\u6e32\u67d3\u65b9\u6cd5\u751f\u6210\u5408\u6210\u591a\u6a21\u6001\u6570\u636e\uff0c\u7ed3\u5408\u7ecf\u9a8c\u652f\u6301\u7684\u67d3\u8272\u8d28\u5305\u88c5\u7edf\u8ba1\u3001Mie\u6563\u5c04\u6a21\u578b\u548c\u6a21\u6001\u7279\u5b9a\u566a\u58f0\uff0c\u91c7\u7528\u4ece\u5bf9\u6297\u6027RGB\u9884\u8bad\u7ec3\u5230\u5149\u8c31\u5fae\u8c03\u548c\u7ec4\u7ec7\u5b66\u9a8c\u8bc1\u7684\u4e09\u9636\u6bb5\u8bfe\u7a0b\u8bad\u7ec3CFU Net\u3002", "result": "CFU Net\u5728\u5408\u6210\u6d4b\u8bd5\u6570\u636e\u4e0a\u8fbe\u5230\u63a5\u8fd1\u5b8c\u7f8e\u7684\u6027\u80fd\uff08Dice 0.9879\uff0cIoU 0.9895\uff09\uff0cINT8\u91cf\u5316\u5b9e\u73b074.9%\u538b\u7f29\u548c0.15\u79d2\u63a8\u7406\uff0c\u5728\u8d85\u8fc7\u4e00\u4e07\u4e2a\u81ea\u52a8\u5206\u5272\u7684\u7ec6\u80de\u6838\u4e2d\u63d0\u53d6\u7684\u67d3\u8272\u8d28\u751f\u7269\u6807\u5fd7\u7269\u533a\u5206\u6b63\u5e38\u4e0e\u764c\u524d\u7ec4\u7ec7\u7684\u51c6\u786e\u7387\u8fbe94%\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4e13\u4e1a\u663e\u5fae\u955c\u4e2d\u7684\u5408\u6210\u5230\u771f\u5b9e\u8fc1\u79fb\u5b66\u4e60\u63d0\u4f9b\u4e86\u901a\u7528\u6846\u67b6\uff0c\u5e76\u4e3a\u4e34\u5e8a\u6837\u672c\u7684\u793e\u533a\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u5f00\u653e\u8d44\u6e90\u3002"}}
{"id": "2510.22293", "pdf": "https://arxiv.org/pdf/2510.22293", "abs": "https://arxiv.org/abs/2510.22293", "authors": ["Mary E. An", "Paul Griffin", "Jonathan G. Stine", "Ramakrishna Balakrishnan", "Ram Sriram", "Soundar Kumara"], "title": "Predicting Metabolic Dysfunction-Associated Steatotic Liver Disease using Machine Learning Methods", "categories": ["cs.LG", "cs.CY", "q-bio.QM"], "comment": null, "summary": "Background: Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD)\naffects ~33% of U.S. adults and is the most common chronic liver disease.\nAlthough often asymptomatic, progression can lead to cirrhosis. Early detection\nis important, as lifestyle interventions can prevent disease progression. We\ndeveloped a fair, rigorous, and reproducible MASLD prediction model and\ncompared it to prior methods using a large electronic health record database.\n  Methods: We evaluated LASSO logistic regression, random forest, XGBoost, and\na neural network for MASLD prediction using clinical feature subsets, including\nthe top 10 SHAP-ranked features. To reduce disparities in true positive rates\nacross racial and ethnic subgroups, we applied an equal opportunity\npostprocessing method.\n  Results: This study included 59,492 patients in the training data, 24,198 in\nthe validating data, and 25,188 in the testing data. The LASSO logistic\nregression model with the top 10 features was selected for its interpretability\nand comparable performance. Before fairness adjustment, the model achieved\nAUROC of 0.84, accuracy of 78%, sensitivity of 72%, specificity of 79%, and\nF1-score of 0.617. After equal opportunity postprocessing, accuracy modestly\nincreased to 81% and specificity to 94%, while sensitivity decreased to 41% and\nF1-score to 0.515, reflecting the fairness trade-off.\n  Conclusions: We developed the MASER prediction model (MASLD Static EHR Risk\nPrediction), a LASSO logistic regression model which achieved competitive\nperformance for MASLD prediction (AUROC 0.836, accuracy 77.6%), comparable to\npreviously reported ensemble and tree-based models. Overall, this approach\ndemonstrates that interpretable models can achieve a balance of predictive\nperformance and fairness in diverse patient populations.", "AI": {"tldr": "\u5f00\u53d1\u4e86MASER\u9884\u6d4b\u6a21\u578b\uff0c\u4f7f\u7528LASSO\u903b\u8f91\u56de\u5f52\u9884\u6d4b\u4ee3\u8c22\u529f\u80fd\u969c\u788d\u76f8\u5173\u8102\u80aa\u809d\u75c5\uff0c\u5728\u5927\u578b\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\u5e93\u4e2d\u5b9e\u73b0\u4e860.836\u7684AUROC\u548c77.6%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u901a\u8fc7\u516c\u5e73\u6027\u540e\u5904\u7406\u51cf\u5c11\u4e86\u79cd\u65cf\u548c\u6c11\u65cf\u4e9a\u7ec4\u95f4\u7684\u5dee\u5f02\u3002", "motivation": "MASLD\u5f71\u54cd\u7ea633%\u7684\u7f8e\u56fd\u6210\u5e74\u4eba\uff0c\u662f\u6700\u5e38\u89c1\u7684\u6162\u6027\u809d\u75c5\u3002\u65e9\u671f\u68c0\u6d4b\u5f88\u91cd\u8981\uff0c\u56e0\u4e3a\u751f\u6d3b\u65b9\u5f0f\u5e72\u9884\u53ef\u4ee5\u9884\u9632\u75be\u75c5\u8fdb\u5c55\u3002\u9700\u8981\u5f00\u53d1\u516c\u5e73\u3001\u4e25\u8c28\u4e14\u53ef\u91cd\u590d\u7684\u9884\u6d4b\u6a21\u578b\u3002", "method": "\u8bc4\u4f30\u4e86LASSO\u903b\u8f91\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\u3001XGBoost\u548c\u795e\u7ecf\u7f51\u7edc\uff0c\u4f7f\u7528\u4e34\u5e8a\u7279\u5f81\u5b50\u96c6\uff08\u5305\u62ec\u524d10\u4e2aSHAP\u6392\u540d\u7279\u5f81\uff09\u3002\u5e94\u7528\u673a\u4f1a\u5747\u7b49\u540e\u5904\u7406\u65b9\u6cd5\u4ee5\u51cf\u5c11\u79cd\u65cf\u548c\u6c11\u65cf\u4e9a\u7ec4\u95f4\u7684\u771f\u9633\u6027\u7387\u5dee\u5f02\u3002", "result": "\u8bad\u7ec3\u6570\u636e59,492\u4eba\uff0c\u9a8c\u8bc1\u6570\u636e24,198\u4eba\uff0c\u6d4b\u8bd5\u6570\u636e25,188\u4eba\u3002\u9009\u62e9\u524d10\u4e2a\u7279\u5f81\u7684LASSO\u903b\u8f91\u56de\u5f52\u6a21\u578b\uff0c\u516c\u5e73\u8c03\u6574\u524dAUROC\u4e3a0.84\uff0c\u51c6\u786e\u738778%\uff1b\u8c03\u6574\u540e\u51c6\u786e\u7387\u589e\u81f381%\uff0c\u7279\u5f02\u6027\u589e\u81f394%\uff0c\u4f46\u654f\u611f\u6027\u964d\u81f341%\u3002", "conclusion": "MASER\u9884\u6d4b\u6a21\u578b\u5728MASLD\u9884\u6d4b\u4e2d\u5b9e\u73b0\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u4e0e\u5148\u524d\u62a5\u544a\u7684\u96c6\u6210\u548c\u57fa\u4e8e\u6811\u7684\u6a21\u578b\u76f8\u5f53\u3002\u53ef\u89e3\u91ca\u6a21\u578b\u53ef\u4ee5\u5728\u591a\u6837\u5316\u60a3\u8005\u7fa4\u4f53\u4e2d\u5b9e\u73b0\u9884\u6d4b\u6027\u80fd\u548c\u516c\u5e73\u6027\u7684\u5e73\u8861\u3002"}}
{"id": "2510.22364", "pdf": "https://arxiv.org/pdf/2510.22364", "abs": "https://arxiv.org/abs/2510.22364", "authors": ["Samir Damji", "Simrut Kurry", "Shazia'Ayn Babul", "Joydeep Bhattacharya", "Naznin Virji-Babul"], "title": "Tuned for Creativity? Graph-Theoretical Mapping of Resting-State EEG Reveals Neural Signatures of Creativity", "categories": ["q-bio.NC", "eess.SP", "q-bio.QM"], "comment": "27 pages, 6 figures, 2 tables", "summary": "Understanding how creativity is represented in the brain's intrinsic\nfunctional architecture remains a central challenge in cognitive neuroscience.\nWhile resting-state fMRI studies have revealed large-scale network correlates\nof creative potential, electroencephalography (EEG) offers a temporally precise\nand scalable approach to capture the fast oscillatory dynamics that underlie\nspontaneous neural organization. In this study, we used a data-driven network\napproach to examine whether resting-state EEG connectivity patterns\ndifferentiate individuals according to their creative abilities. Creativity was\nevaluated by: The Inventory of Creative Activities and Achievements (ICAA), The\nDivergent Association Task (DAT), The Matchstick Arithmetic Puzzles Task (MAPT)\nand Self-rating (SR) of creative ability in 30 healthy young adults.\nGraph-theoretical analyses were applied to functional connectivity matrices and\nclustered based on graph similarity. Two distinct participant clusters emerged,\ndiffering systematically across multiple dimensions of creativity. Cluster 1,\ncharacterized by consistently higher performance across multiple creativity\nvariables (ICAA, DAT, MAPT and SR), showed broad alpha-band hypoconnectivity,\nrelatively preserved left frontal connectivity and greater network modularity.\nCluster 0, associated with lower creativity scores, exhibited stronger overall\nconnectivity strength, reduced modularity and higher local clustering. These\nfindings suggest that resting-state EEG connectivity patterns can index stable\ncognitive traits such as creativity. More broadly, they point to an intrinsic\nneural signature of adaptive brain function marked by efficient yet flexible\nnetwork organization that may support creative and adaptive cognition.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u9759\u606f\u6001EEG\u548c\u7f51\u7edc\u5206\u6790\u65b9\u6cd5\uff0c\u53d1\u73b0\u9ad8\u521b\u9020\u529b\u4e2a\u4f53\u8868\u73b0\u51faalpha\u9891\u6bb5\u8fde\u63a5\u6027\u964d\u4f4e\u3001\u5de6\u524d\u989d\u8fde\u63a5\u6027\u4fdd\u6301\u548c\u66f4\u9ad8\u7f51\u7edc\u6a21\u5757\u5316\uff0c\u800c\u4f4e\u521b\u9020\u529b\u4e2a\u4f53\u5219\u663e\u793a\u66f4\u5f3a\u7684\u6574\u4f53\u8fde\u63a5\u6027\u548c\u66f4\u4f4e\u7684\u6a21\u5757\u5316\u3002", "motivation": "\u7406\u89e3\u521b\u9020\u529b\u5728\u5927\u8111\u5185\u5728\u529f\u80fd\u67b6\u6784\u4e2d\u7684\u8868\u5f81\u662f\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u7684\u6838\u5fc3\u6311\u6218\uff0cEEG\u63d0\u4f9b\u4e86\u65f6\u95f4\u7cbe\u5ea6\u9ad8\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u6355\u6349\u652f\u6301\u81ea\u53d1\u795e\u7ecf\u7ec4\u7ec7\u7684\u5feb\u901f\u632f\u8361\u52a8\u6001\u3002", "method": "\u5bf930\u540d\u5065\u5eb7\u5e74\u8f7b\u4eba\u8fdb\u884c\u521b\u9020\u529b\u8bc4\u4f30\uff08ICAA\u3001DAT\u3001MAPT\u548c\u81ea\u8bc4\uff09\uff0c\u5e94\u7528\u56fe\u8bba\u5206\u6790\u529f\u80fd\u8fde\u63a5\u77e9\u9635\uff0c\u5e76\u57fa\u4e8e\u56fe\u76f8\u4f3c\u6027\u8fdb\u884c\u805a\u7c7b\u5206\u6790\u3002", "result": "\u51fa\u73b0\u4e86\u4e24\u4e2a\u4e0d\u540c\u7684\u53c2\u4e0e\u8005\u805a\u7c7b\uff0c\u5728\u591a\u4e2a\u521b\u9020\u529b\u7ef4\u5ea6\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\u3002\u9ad8\u521b\u9020\u529b\u805a\u7c7b\u663e\u793a\u5e7f\u6cdb\u7684alpha\u9891\u6bb5\u4f4e\u8fde\u63a5\u6027\u3001\u76f8\u5bf9\u4fdd\u6301\u7684\u5de6\u524d\u989d\u8fde\u63a5\u6027\u548c\u66f4\u9ad8\u7684\u7f51\u7edc\u6a21\u5757\u5316\u3002", "conclusion": "\u9759\u606f\u6001EEG\u8fde\u63a5\u6a21\u5f0f\u53ef\u4ee5\u7d22\u5f15\u7a33\u5b9a\u7684\u8ba4\u77e5\u7279\u8d28\u5982\u521b\u9020\u529b\uff0c\u6307\u5411\u4e00\u79cd\u4ee5\u9ad8\u6548\u800c\u7075\u6d3b\u7684\u7f51\u7edc\u7ec4\u7ec7\u4e3a\u6807\u5fd7\u7684\u9002\u5e94\u6027\u5927\u8111\u529f\u80fd\u7684\u5185\u5728\u795e\u7ecf\u7279\u5f81\u3002"}}
{"id": "2510.23273", "pdf": "https://arxiv.org/pdf/2510.23273", "abs": "https://arxiv.org/abs/2510.23273", "authors": ["Runjie Zheng", "Zhen Wang", "Anjie Qiao", "Jiancong Xie", "Jiahua Rao", "Yuedong Yang"], "title": "A Novel Framework for Multi-Modal Protein Representation Learning", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": "35 pages, 5 figures, 4 tables", "summary": "Accurate protein function prediction requires integrating heterogeneous\nintrinsic signals (e.g., sequence and structure) with noisy extrinsic contexts\n(e.g., protein-protein interactions and GO term annotations). However, two key\nchallenges hinder effective fusion: (i) cross-modal distributional mismatch\namong embeddings produced by pre-trained intrinsic encoders, and (ii) noisy\nrelational graphs of extrinsic data that degrade GNN-based information\naggregation. We propose Diffused and Aligned Multi-modal Protein Embedding\n(DAMPE), a unified framework that addresses these through two core mechanisms.\nFirst, we propose Optimal Transport (OT)-based representation alignment that\nestablishes correspondence between intrinsic embedding spaces of different\nmodalities, effectively mitigating cross-modal heterogeneity. Second, we\ndevelop a Conditional Graph Generation (CGG)-based information fusion method,\nwhere a condition encoder fuses the aligned intrinsic embeddings to provide\ninformative cues for graph reconstruction. Meanwhile, our theoretical analysis\nimplies that the CGG objective drives this condition encoder to absorb\ngraph-aware knowledge into its produced protein representations. Empirically,\nDAMPE outperforms or matches state-of-the-art methods such as DPFunc on\nstandard GO benchmarks, achieving AUPR gains of 0.002-0.013 pp and Fmax gains\n0.004-0.007 pp. Ablation studies further show that OT-based alignment\ncontributes 0.043-0.064 pp AUPR, while CGG-based fusion adds 0.005-0.111 pp\nFmax. Overall, DAMPE offers a scalable and theoretically grounded approach for\nrobust multi-modal protein representation learning, substantially enhancing\nprotein function prediction.", "AI": {"tldr": "DAMPE\u662f\u4e00\u4e2a\u7528\u4e8e\u86cb\u767d\u8d28\u529f\u80fd\u9884\u6d4b\u7684\u591a\u6a21\u6001\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u4f18\u4f20\u8f93\u5bf9\u9f50\u548c\u6761\u4ef6\u56fe\u751f\u6210\u89e3\u51b3\u8de8\u6a21\u6001\u5206\u5e03\u4e0d\u5339\u914d\u548c\u566a\u58f0\u56fe\u6570\u636e\u95ee\u9898\u3002", "motivation": "\u86cb\u767d\u8d28\u529f\u80fd\u9884\u6d4b\u9700\u8981\u6574\u5408\u5f02\u8d28\u7684\u5185\u5728\u4fe1\u53f7\uff08\u5e8f\u5217\u3001\u7ed3\u6784\uff09\u548c\u566a\u58f0\u7684\u5916\u5728\u4e0a\u4e0b\u6587\uff08\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u3001GO\u6ce8\u91ca\uff09\uff0c\u4f46\u5b58\u5728\u8de8\u6a21\u6001\u5206\u5e03\u4e0d\u5339\u914d\u548c\u566a\u58f0\u56fe\u6570\u636e\u805a\u5408\u4e24\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u6700\u4f18\u4f20\u8f93\uff08OT\uff09\u8868\u793a\u5bf9\u9f50\u6765\u7f13\u89e3\u8de8\u6a21\u6001\u5f02\u8d28\u6027\uff0c\u4ee5\u53ca\u6761\u4ef6\u56fe\u751f\u6210\uff08CGG\uff09\u4fe1\u606f\u878d\u5408\u65b9\u6cd5\uff0c\u5176\u4e2d\u6761\u4ef6\u7f16\u7801\u5668\u878d\u5408\u5bf9\u9f50\u7684\u5185\u5728\u5d4c\u5165\u4e3a\u56fe\u91cd\u5efa\u63d0\u4f9b\u4fe1\u606f\u7ebf\u7d22\u3002", "result": "\u5728\u6807\u51c6GO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDAMPE\u4f18\u4e8e\u6216\u5339\u914dDPFunc\u7b49\u6700\u5148\u8fdb\u65b9\u6cd5\uff0cAUPR\u63d0\u53470.002-0.013pp\uff0cFmax\u63d0\u53470.004-0.007pp\u3002\u6d88\u878d\u7814\u7a76\u663e\u793aOT\u5bf9\u9f50\u8d21\u732e0.043-0.064pp AUPR\uff0cCGG\u878d\u5408\u8d21\u732e0.005-0.111pp Fmax\u3002", "conclusion": "DAMPE\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u7406\u8bba\u57fa\u7840\u624e\u5b9e\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u9c81\u68d2\u7684\u591a\u6a21\u6001\u86cb\u767d\u8d28\u8868\u793a\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u86cb\u767d\u8d28\u529f\u80fd\u9884\u6d4b\u6027\u80fd\u3002"}}
