<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 2]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [PanDelos-plus: A parallel algorithm for computing sequence homology in pangenomic analysis](https://arxiv.org/abs/2510.23679)
*Simone Colli,Emiliano Maresi,Vincenzo Bonnici*

Main category: q-bio.GN

TL;DR: PanDelos-plus是PanDelos的并行化版本，通过数据分解和线程池策略优化计算密集型阶段，在保持准确性的同时实现14倍加速和96%内存使用减少。


<details>
  <summary>Details</summary>
Motivation: 随着基因组数据量的增加，需要能够高效扩展到更大数据集的工具。PanDelos-plus旨在解决PanDelos在处理大规模数据集时的性能瓶颈。

Method: 采用全并行、基因中心的重设计，通过数据分解和线程池策略并行化最佳命中检测和双向最佳命中提取阶段，并使用轻量级数据结构减少内存使用。

Result: 在合成数据集上的基准测试显示，PanDelos-plus实现高达14倍的执行加速和高达96%的内存使用减少，同时保持准确性。

Conclusion: 这些改进使得种群规模的比较基因组学能够在标准多核工作站上执行，使大规模细菌泛基因组分析在日常研究中可常规使用。

Abstract: The identification of homologous gene families across multiple genomes is a
central task in bacterial pangenomics traditionally requiring computationally
demanding all-against-all comparisons. PanDelos addresses this challenge with
an alignment-free and parameter-free approach based on k-mer profiles,
combining high speed, ease of use, and competitive accuracy with
state-of-the-art methods. However, the increasing availability of genomic data
requires tools that can scale efficiently to larger datasets. To address this
need, we present PanDelos-plus, a fully parallel, gene-centric redesign of
PanDelos. The algorithm parallelizes the most computationally intensive phases
(Best Hit detection and Bidirectional Best Hit extraction) through data
decomposition and a thread pool strategy, while employing lightweight data
structures to reduce memory usage. Benchmarks on synthetic datasets show that
PanDelos-plus achieves up to 14x faster execution and reduces memory usage by
up to 96%, while maintaining accuracy. These improvements enable
population-scale comparative genomics to be performed on standard multicore
workstations, making large-scale bacterial pangenome analysis accessible for
routine use in everyday research.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [2] [Gut decisions based on the liver: A radiomics approach to boost colorectal cancer screening](https://arxiv.org/abs/2510.23687)
*Anna Hinterberger,Jonas Bohn,Dasha Trofimova,Nicolas Knabe,Julia Dettling,Tobias Norajitra,Fabian Isensee,Johannes Betge,Stefan O. Schönberg,Dominik Nörenberg,Sergio Grosu,Sonja Loges,Ralf Floca,Jakob Nikolas Kather,Klaus Maier-Hein,Freba Grawe*

Main category: q-bio.QM

TL;DR: 通过从常规腹部CT图像中提取肝脏放射组学特征，利用肠道-肝脏轴预测结直肠肿瘤，为结直肠癌筛查提供了一种新的机会性筛查方法。


<details>
  <summary>Details</summary>
Motivation: 非侵入性结直肠癌筛查是提高结肠镜检查参与率和降低结直肠癌死亡率的关键机会。本研究探索通过常规CT图像中肝脏来源的放射组学特征来预测结直肠肿瘤的潜力。

Method: 回顾性分析1997名接受结肠镜和腹部CT检查的患者数据。使用放射组学处理工具包从3D肝脏分割中提取特征，通过5折交叉验证训练5种机器学习模型，选择基于验证AUROC的最佳模型集成。

Result: 最佳放射组学XGBoost模型在测试集上达到AUROC 0.810，明显优于最佳临床模型（AUROC 0.457）。结直肠癌与腺瘤亚分类准确度较低（AUROC 0.674）。

Conclusion: 研究证实了从常规腹部CT中提取的肝脏放射组学特征可以预测结直肠肿瘤，为结直肠癌筛查提供了实用、广泛可及的辅助方法，并揭示了肠道-肝脏轴作为新型生物标志物来源的潜力。

Abstract: Non-invasive colorectal cancer (CRC) screening represents a key opportunity
to improve colonoscopy participation rates and reduce CRC mortality. This study
explores the potential of the gut-liver axis for predicting colorectal
neoplasia through liver-derived radiomic features extracted from routine CT
images as a novel opportunistic screening approach. In this retrospective
study, we analyzed data from 1,997 patients who underwent colonoscopy and
abdominal CT. Patients either had no colorectal neoplasia (n=1,189) or
colorectal neoplasia (n_total=808; adenomas n=423, CRC n=385). Radiomics
features were extracted from 3D liver segmentations using the Radiomics
Processing ToolKit (RPTK), which performed feature extraction, filtering, and
classification. The dataset was split into training (n=1,397) and test (n=600)
cohorts. Five machine learning models were trained with 5-fold cross-validation
on the 20 most informative features, and the best model ensemble was selected
based on the validation AUROC. The best radiomics-based XGBoost model achieved
a test AUROC of 0.810, clearly outperforming the best clinical-only model (test
AUROC: 0.457). Subclassification between colorectal cancer and adenoma showed
lower accuracy (test AUROC: 0.674). Our findings establish proof-of-concept
that liver-derived radiomics from routine abdominal CT can predict colorectal
neoplasia. Beyond offering a pragmatic, widely accessible adjunct to CRC
screening, this approach highlights the gut-liver axis as a novel biomarker
source for opportunistic screening and sparks new mechanistic hypotheses for
future translational research.

</details>


### [3] [Machine learning approaches for interpretable antibody property prediction using structural data](https://arxiv.org/abs/2510.23975)
*Kevin Michalewicz,Mauricio Barahona,Barbara Bravi*

Main category: q-bio.QM

TL;DR: 本章综述了整合抗体序列和结构信息的机器学习方法，介绍了ANTIPASTI和INFUSSE两个框架，分别用于预测抗体结合亲和力和残基灵活性。


<details>
  <summary>Details</summary>
Motivation: 当前基于序列的机器学习模型在预测抗体特性方面取得进展，但缺乏结构信息的整合，无法深入理解分子机制。

Method: 使用图表示编码结构数据，结合神经网络预测抗体特性：ANTIPASTI预测全局结合亲和力，INFUSSE预测局部残基灵活性。

Result: 开发了两个能够整合结构信息的机器学习框架，能够提取生物学相关的统计信号，揭示分子决定因素。

Conclusion: 整合结构信息的机器学习方法不仅能提高预测性能，还能提供对分子机制的深入理解，有助于抗体治疗和工具的设计。

Abstract: Understanding the relationship between antibody sequence, structure and
function is essential for the design of antibody-based therapeutics and
research tools. Recently, machine learning (ML) models mostly based on the
application of large language models to sequence information have been
developed to predict antibody properties. Yet there are open directions to
incorporate structural information, not only to enhance prediction but also to
offer insights into the underlying molecular mechanisms. This chapter provides
an overview of these approaches and describes two ML frameworks that integrate
structural data (via graph representations) with neural networks to predict
properties of antibodies: ANTIPASTI predicts binding affinity (a global
property) whereas INFUSSE predicts residue flexibility (a local property). We
survey the principles underpinning these models; the ways in which they encode
structural knowledge; and the strategies that can be used to extract
biologically relevant statistical signals that can help discover and
disentangle molecular determinants of the properties of interest.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [4] [An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine](https://arxiv.org/abs/2510.24359)
*Pedram Fard,Alaleh Azhir,Neguine Rezaii,Jiazi Tian,Hossein Estiri*

Main category: cs.AI

TL;DR: 提出了一种多智能体生态系统用于N-of-1决策支持，旨在解决传统医疗AI系统对边缘患者（罕见变异、多病共存、代表性不足人群）表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 传统医疗AI系统为平均患者设计，在大型数据集上最小化错误，但对边缘患者表现不佳，损害了公平性和信任。需要一种更关注个体患者的方法。

Method: 构建多智能体生态系统，按器官系统、患者群体和分析模式分组的智能体共享模型库和证据合成工具，通过协调层整合结果，考虑可靠性、不确定性和数据密度。

Result: 系统提供包含风险估计、置信区间、异常标志和关联证据的决策支持包，验证重点从群体平均转向个体可靠性，包括低密度区域错误、小样本校准和风险-覆盖权衡。

Conclusion: 通过从单一模型转向协调智能，该方法旨在使医疗AI与医学第一原则保持一致：提供透明、公平且以个体为中心的护理。

Abstract: Artificial intelligence in medicine is built to serve the average patient. By
minimizing error across large datasets, most systems deliver strong aggregate
accuracy yet falter at the margins: patients with rare variants,
multimorbidity, or underrepresented demographics. This average patient fallacy
erodes both equity and trust. We propose a different design: a multi-agent
ecosystem for N-of-1 decision support. In this environment, agents clustered by
organ systems, patient populations, and analytic modalities draw on a shared
library of models and evidence synthesis tools. Their results converge in a
coordination layer that weighs reliability, uncertainty, and data density
before presenting the clinician with a decision-support packet: risk estimates
bounded by confidence ranges, outlier flags, and linked evidence. Validation
shifts from population averages to individual reliability, measured by error in
low-density regions, calibration in the small, and risk--coverage trade-offs.
Anticipated challenges include computational demands, automation bias, and
regulatory fit, addressed through caching strategies, consensus checks, and
adaptive trial frameworks. By moving from monolithic models to orchestrated
intelligence, this approach seeks to align medical AI with the first principle
of medicine: care that is transparent, equitable, and centered on the
individual.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Integrating Genomics into Multimodal EHR Foundation Models](https://arxiv.org/abs/2510.23639)
*Jonathan Amar,Edward Liu,Alessandra Breschi,Liangliang Zhang,Pouya Kheradpour,Sylvia Li,Lisa Soleymani Lehmann,Alessandro Giulianelli,Matt Edwards,Yugang Jia,David Nola,Raghav Mani,Pankaj Vats,Jesse Tetreault,T. J. Chen,Cory Y. McLean*

Main category: cs.LG

TL;DR: 提出了一种整合多基因风险评分(PRS)的电子健康记录(EHR)基础模型，超越传统EHR方法构建更全面的健康档案，在All of Us数据集上验证了对2型糖尿病等疾病的预测价值。


<details>
  <summary>Details</summary>
Motivation: 传统EHR方法局限于临床数据，缺乏遗传风险信息。本研究旨在整合PRS和EHR数据，构建更全面的健康档案，改善疾病预测和个性化医疗。

Method: 利用All of Us研究项目的多样化数据，开发多模态框架，结合生成式AI技术，学习临床数据与遗传易感性之间的复杂关系。

Result: 在All of Us数据上验证了模型对多种疾病(特别是2型糖尿病)的预测价值，展示了PRS与EHR数据的相互作用，并通过迁移学习证明了架构的通用性。

Conclusion: 该方法为疾病预测、主动健康管理、风险分层和个性化治疗策略提供了新见解，为医疗领域更个性化、公平和可操作的真实世界证据生成奠定了基础。

Abstract: This paper introduces an innovative Electronic Health Record (EHR) foundation
model that integrates Polygenic Risk Scores (PRS) as a foundational data
modality, moving beyond traditional EHR-only approaches to build more holistic
health profiles. Leveraging the extensive and diverse data from the All of Us
(AoU) Research Program, this multimodal framework aims to learn complex
relationships between clinical data and genetic predispositions. The
methodology extends advancements in generative AI to the EHR foundation model
space, enhancing predictive capabilities and interpretability. Evaluation on
AoU data demonstrates the model's predictive value for the onset of various
conditions, particularly Type 2 Diabetes (T2D), and illustrates the interplay
between PRS and EHR data. The work also explores transfer learning for custom
classification tasks, showcasing the architecture's versatility and efficiency.
This approach is pivotal for unlocking new insights into disease prediction,
proactive health management, risk stratification, and personalized treatment
strategies, laying the groundwork for more personalized, equitable, and
actionable real-world evidence generation in healthcare.

</details>


### [6] [Low-N Protein Activity Optimization with FolDE](https://arxiv.org/abs/2510.24053)
*Jacob B. Roberts,Catherine R. Ji,Isaac Donnell,Thomas D. Young,Allison N. Pearson,Graham A. Hudson,Leah S. Keiser,Mia Wesselkamper,Peter H. Winegar,Janik Ludwig,Sarah H. Klass,Isha V. Sheth,Ezechinyere C. Ukabiala,Maria C. T. Astolfi,Benjamin Eysenbach,Jay D. Keasling*

Main category: cs.LG

TL;DR: FolDE是一种主动学习辅助定向进化方法，通过自然性预热启动和恒定谎言批量选择器，在蛋白质优化中比现有方法发现更多顶级突变体。


<details>
  <summary>Details</summary>
Motivation: 传统蛋白质优化方法成本高昂，现有主动学习方法存在训练数据同质化问题，导致后续预测模型不准确。

Method: FolDE采用自然性预热启动（利用蛋白质语言模型输出增强有限活性测量）和恒定谎言批量选择器（提高批量多样性）。

Result: 在20个蛋白质靶点的模拟中，FolDE比最佳基线方法多发现23%的前10%突变体，找到前1%突变体的可能性高55%。

Conclusion: FolDE显著提高了蛋白质优化的效率，完整的开源工作流程使高效蛋白质优化对任何实验室都可及。

Abstract: Proteins are traditionally optimized through the costly construction and
measurement of many mutants. Active Learning-assisted Directed Evolution (ALDE)
alleviates that cost by predicting the best improvements and iteratively
testing mutants to inform predictions. However, existing ALDE methods face a
critical limitation: selecting the highest-predicted mutants in each round
yields homogeneous training data insufficient for accurate prediction models in
subsequent rounds. Here we present FolDE, an ALDE method designed to maximize
end-of-campaign success. In simulations across 20 protein targets, FolDE
discovers 23% more top 10% mutants than the best baseline ALDE method (p=0.005)
and is 55% more likely to find top 1% mutants. FolDE achieves this primarily
through naturalness-based warm-starting, which augments limited activity
measurements with protein language model outputs to improve activity
prediction. We also introduce a constant-liar batch selector, which improves
batch diversity; this is important in multi-mutation campaigns but had limited
effect in our benchmarks. The complete workflow is freely available as
open-source software, making efficient protein optimization accessible to any
laboratory.

</details>


### [7] [Pearl: A Foundation Model for Placing Every Atom in the Right Location](https://arxiv.org/abs/2510.24670)
*Genesis Research Team,Alejandro Dobles,Nina Jovic,Kenneth Leidal,Pranav Murugan,David C. Williams,Drausin Wulsin,Nate Gruver,Christina X. Ji,Korrawat Pruegsanusak,Gianluca Scarpellini,Ansh Sharma,Wojciech Swiderski,Andrea Bootsma,Richard Strong Bowen,Charlotte Chen,Jamin Chen,Marc André Dämgen,Roy Tal Dew,Benjamin DiFrancesco,J. D. Fishman,Alla Ivanova,Zach Kagin,David Li-Bland,Zuli Liu,Igor Morozov,Jeffrey Ouyang-Zhang,Frank C. Pickard IV,Kushal S. Shah,Ben Shor,Gabriel Monteiro da Silva,Maxx Tessmer,Carl Tilbury,Cyr Vetcher,Daniel Zeng,Maruan Al-Shedivat,Aleksandra Faust,Evan N. Feinberg,Michael V. LeVine,Matteus Pan*

Main category: cs.LG

TL;DR: Pearl是一个用于蛋白质-配体共折叠的基础模型，通过大规模合成数据训练、SO(3)等变扩散架构和可控推理，在蛋白质-配体复合物结构预测方面实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 准确预测蛋白质-配体复合物的三维结构是计算药物发现中的基本挑战，现有深度学习方法的性能受到实验数据稀缺、架构效率低、物理无效构象和推理时无法充分利用辅助信息的限制。

Method: Pearl采用三个关键创新：(1)包含大规模合成数据的训练方案；(2)集成SO(3)等变扩散模块的架构，尊重3D旋转对称性；(3)可控推理，包括支持蛋白质和非聚合组件的多链模板系统，以及无条件/条件双模式。

Result: 在生成准确(RMSD < 2Å)且物理有效构象的关键指标上，Pearl在公开基准测试中分别比AlphaFold 3和其他开源基线提高了14.5%和14.2%。在口袋条件共折叠机制下，在更严格的RMSD < 1Å阈值下，对专有挑战性药物靶点实现了3.6倍的改进。

Conclusion: Pearl在蛋白质-配体共折叠方面建立了新的最先进性能，模型性能与训练中使用的合成数据集大小直接相关。

Abstract: Accurately predicting the three-dimensional structures of protein-ligand
complexes remains a fundamental challenge in computational drug discovery that
limits the pace and success of therapeutic design. Deep learning methods have
recently shown strong potential as structural prediction tools, achieving
promising accuracy across diverse biomolecular systems. However, their
performance and utility are constrained by scarce experimental data,
inefficient architectures, physically invalid poses, and the limited ability to
exploit auxiliary information available at inference. To address these issues,
we introduce Pearl (Placing Every Atom in the Right Location), a foundation
model for protein-ligand cofolding at scale. Pearl addresses these challenges
with three key innovations: (1) training recipes that include large-scale
synthetic data to overcome data scarcity; (2) architectures that incorporate an
SO(3)-equivariant diffusion module to inherently respect 3D rotational
symmetries, improving generalization and sample efficiency, and (3)
controllable inference, including a generalized multi-chain templating system
supporting both protein and non-polymeric components as well as dual
unconditional/conditional modes. Pearl establishes a new state-of-the-art
performance in protein-ligand cofolding. On the key metric of generating
accurate (RMSD < 2 \r{A}) and physically valid poses, Pearl surpasses AlphaFold
3 and other open source baselines on the public Runs N' Poses and PoseBusters
benchmarks, delivering 14.5% and 14.2% improvements, respectively, over the
next best model. In the pocket-conditional cofolding regime, Pearl delivers
$3.6\times$ improvement on a proprietary set of challenging, real-world drug
targets at the more rigorous RMSD < 1 \r{A} threshold. Finally, we demonstrate
that model performance correlates directly with synthetic dataset size used in
training.

</details>
