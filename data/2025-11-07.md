<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 5]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.CV](#cs.CV) [Total: 1]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [Advancing Risk Gene Discovery Across the Allele Frequency Spectrum](https://arxiv.org/abs/2511.04637)
*Madison Caballero,Behrang Mahjani*

Main category: q-bio.GN

TL;DR: 论文探讨了遗传风险基因发现中的'缺失中间地带'问题，即中等频率和中等效应大小的变异在现有方法中统计功效有限，导致基因发现滞后。


<details>
  <summary>Details</summary>
Motivation: 尽管测序和生物库资源呈指数级增长，但新基因发现的步伐已经放缓，现有方法主要针对罕见高外显率变异和常见低效应变异，而中等频率变异成为关键盲点。

Method: 通过按变异频率类别组织风险基因识别策略，分析各尺度的方法优势和限制，并整合变异注释、联合建模、表型细化和基于网络推理等创新方法。

Result: 提出了一个以频率谱为统一轴的概念框架，展示了当前能力、局限性和向更全面风险基因发现的新兴方向。

Conclusion: 通过整合跨领域经验和方法创新，可以扩展发现到中等频率范围，实现更全面的风险基因识别。

Abstract: The discovery of genetic risk factors has transformed human genetics, yet the
pace of new gene identification has slowed despite the exponential expansion of
sequencing and biobank resources. Current approaches are optimized for the
extremes of the allele frequency spectrum: rare, high-penetrance variants
identified through burden testing, and common, low-effect variants mapped by
genome-wide association studies. Between these extremes lies variants of
intermediate frequency and effect size where statistical power is limited,
pathogenicity is often misclassified, and gene discovery lags behind empirical
evidence of heritable contribution. This 'missing middle' represents a critical
blind spot across disease areas, from neurodevelopmental and psychiatric
disorders to cancer and aging. In this review, we organize strategies for risk
gene identification by variant frequency class, highlighting methodological
strengths and constraints at each scale. We draw on lessons across fields to
illustrate how innovations in variant annotation, joint modeling, phenotype
refinement, and network-based inference can extend discovery into the
intermediate range. By framing the frequency spectrum as a unifying axis, we
provide a conceptual map of current capabilities, their limitations, and
emerging directions toward more comprehensive risk gene discovery.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [2] [Attention-based ROI Discovery in 3D Tissue Images](https://arxiv.org/abs/2511.03751)
*Hossein Fathollahian,Siyuan Zhao,Nafiul Nipu,G. Elisabeta Marai*

Main category: q-bio.QM

TL;DR: 提出了一种基于自监督多层图注意力网络(SSGAT)的方法，用于自动识别3D显微镜数据中的感兴趣区域，无需专家手动标注。


<details>
  <summary>Details</summary>
Motivation: 高维组织成像生成包含多个生物标志物的复杂3D数据，在没有专家手动标注感兴趣区域的情况下，识别生物相关区域具有挑战性。

Method: 使用自监督多层图注意力网络(SSGAT)，结合对抗性自监督学习目标，通过标记物相互作用识别有意义的免疫微环境，并开发了基于Vitessce的React交互界面。

Result: 该方法能够揭示复杂的空间生物反应，可以直观评估其在组织中的分布。

Conclusion: SSGAT方法为自动识别3D显微镜数据中的感兴趣区域提供了一种有效的自监督解决方案，能够发现复杂的空间生物相互作用。

Abstract: High-dimensional tissue imaging generates highly complex 3D data containing
multiple biomarkers, making it challenging to identify biologically relevant
regions without an expert user specifying manual labels for regions of
interest. We introduce an approach to automatically identifying regions of
interest (ROIs) in the 3D microscopy data. Our approach is based on a novel
self-supervised multi-layer graph attention network (SSGAT), coupled with a
React interactive interface wrapped around Vitessce. SSGAT employs an
adversarial self-supervised learning objective to identify meaningful immune
microenvironments through marker interactions. Our method reveals complex
spatial bioreactions that can be visually assessed to assess their distribution
across tissue. Index Terms: Biomedical visualization, graph attention
networks,self-supervised learning, spatial interaction analysis.

</details>


### [3] [Phenotype discovery of traumatic brain injury segmentations from heterogeneous multi-site data](https://arxiv.org/abs/2511.03767)
*Adam M. Saunders,Michael E. Kim,Gaurav Rudravaram,Lucas W. Remedios,Chloe Cho,Elyssa M. McMaster,Daniel R. Gillis,Yihao Liu,Lianrui Zuo,Bennett A. Landman,Tonia S. Rex*

Main category: q-bio.QM

TL;DR: 该研究利用FITBIR数据库的大规模多中心MRI数据，通过图像处理和统计分析，识别了创伤性脑损伤(TBI)患者与对照组在37个脑区体积上的显著差异，并揭示了TBI损伤的三种主要模式。


<details>
  <summary>Details</summary>
Motivation: 创伤性脑损伤具有高度异质性，临床结果测量方法难以捕捉这种多样性，使得将结构损伤与功能缺陷联系起来变得困难。研究旨在通过大规模多中心MRI数据分析，揭示TBI的共同损伤通路。

Method: 使用FITBIR数据库的25项研究、7,693个MRI会话数据，首先进行图像协调处理，分割132个感兴趣脑区，进行质量保证和体积计算，通过z-score标准化，使用多元线性回归控制性别、年龄和总脑体积的影响，最后通过独立成分分析和聚类分析识别损伤模式。

Result: 发现TBI患者与对照组在37个脑区体积上存在显著差异(p<0.05，经FDR校正)，这些差异主要分布在三个区域：1)脑干、枕极和眶后结构；2)皮层下灰质和岛叶皮层；3)大脑和小脑白质。

Conclusion: 研究成功识别了TBI的共享损伤通路，为理解TBI的病理机制提供了重要见解，这些发现有助于开发更精确的诊断和治疗方法。

Abstract: Traumatic brain injury (TBI) is intrinsically heterogeneous, and typical
clinical outcome measures like the Glasgow Coma Scale complicate this
diversity. The large variability in severity and patient outcomes render it
difficult to link structural damage to functional deficits. The Federal
Interagency Traumatic Brain Injury Research (FITBIR) repository contains
large-scale multi-site magnetic resonance imaging data of varying resolutions
and acquisition parameters (25 shared studies with 7,693 sessions that have
age, sex and TBI status defined - 5,811 TBI and 1,882 controls). To reveal
shared pathways of injury of TBI through imaging, we analyzed T1-weighted
images from these sessions by first harmonizing to a local dataset and
segmenting 132 regions of interest (ROIs) in the brain. After running quality
assurance, calculating the volumes of the ROIs, and removing outliers, we
calculated the z-scores of volumes for all participants relative to the mean
and standard deviation of the controls. We regressed out sex, age, and total
brain volume with a multivariate linear regression, and we found significant
differences in 37 ROIs between subjects with TBI and controls (p < 0.05 with
independent t-tests with false discovery rate correction). We found that
differences originated in 1) the brainstem, occipital pole and structures
posterior to the orbit, 2) subcortical gray matter and insular cortex, and 3)
cerebral and cerebellar white matter using independent component analysis and
clustering the component loadings of those with TBI.

</details>


### [4] [Climbing the label tree: Hierarchy-preserving contrastive learning for medical imaging](https://arxiv.org/abs/2511.03771)
*Alif Elham Khan*

Main category: q-bio.QM

TL;DR: 提出了一种保持层次结构的对比学习框架，将医学图像标签的树状结构作为训练信号和评估目标，通过层次加权对比和层次感知边距两个目标函数，在多个基准测试中提高了表示质量并更好地尊重了分类学结构。


<details>
  <summary>Details</summary>
Motivation: 医学图像标签通常按分类学（如器官-组织-亚型）组织，但标准的自监督学习忽略了这种层次结构。需要一种能够保留标签树结构的表示学习方法。

Method: 提出了层次保持对比学习框架，包含两个插件目标：层次加权对比（HWC）通过共享祖先缩放正负对强度来促进父级内一致性；层次感知边距（LAM）通过原型边距在不同层次上分离祖先组。该框架与几何无关，适用于欧几里得和双曲嵌入。

Result: 在多个基准测试（包括乳腺组织病理学）中，所提出的目标函数在强自监督学习基线基础上持续提高了表示质量，同时更好地尊重了分类学。使用层次忠实性指标（HF1、H-Acc、父距离违反率）和top-1准确率进行评估。

Conclusion: 该方法为学习尊重标签树的医学图像表示提供了一个简单通用的方案，在层次丰富的领域中推进了性能和可解释性。

Abstract: Medical image labels are often organized by taxonomies (e.g., organ - tissue
- subtype), yet standard self-supervised learning (SSL) ignores this structure.
We present a hierarchy-preserving contrastive framework that makes the label
tree a first-class training signal and an evaluation target. Our approach
introduces two plug-in objectives: Hierarchy-Weighted Contrastive (HWC), which
scales positive/negative pair strengths by shared ancestors to promote
within-parent coherence, and Level-Aware Margin (LAM), a prototype margin that
separates ancestor groups across levels. The formulation is geometry-agnostic
and applies to Euclidean and hyperbolic embeddings without architectural
changes. Across several benchmarks, including breast histopathology, the
proposed objectives consistently improve representation quality over strong SSL
baselines while better respecting the taxonomy. We evaluate with metrics
tailored to hierarchy faithfulness: HF1 (hierarchical F1), H-Acc
(tree-distance-weighted accuracy), and parent-distance violation rate. We also
report top-1 accuracy for completeness. Ablations show that HWC and LAM are
effective even without curvature, and combining them yields the most
taxonomy-aligned representations. Taken together, these results provide a
simple, general recipe for learning medical image representations that respect
the label tree and advance both performance and interpretability in
hierarchy-rich domains.

</details>


### [5] [CORE - A Cell-Level Coarse-to-Fine Image Registration Engine for Multi-stain Image Alignment](https://arxiv.org/abs/2511.03826)
*Esha Sadia Nasir,Behnaz Elhaminia,Mark Eastwood,Catherine King,Owen Cain,Lorraine Harper,Paul Moss,Dimitrios Chanouzas,David Snead,Nasir Rajpoot,Adam Shephard,Shan E Ahmed Raza*

Main category: q-bio.QM

TL;DR: 提出了一种名为CORE的从粗到细的框架，用于多模态全玻片图像中精确的细胞核级配准，包括粗配准、细粒度刚性配准和细胞级非刚性配准三个阶段。


<details>
  <summary>Details</summary>
Motivation: 全玻片图像的准确高效配准对于多染色组织切片的高分辨率、细胞核级分析至关重要。

Method: 使用基于提示的组织掩码提取进行粗配准，然后进行全局对齐和加速密集特征匹配。从粗对齐的切片中检测细胞核质心，使用形状感知点集配准模型进行细粒度刚性配准，最后使用相干点漂移估计非线性位移场实现细胞级非刚性对齐。

Result: 在三个公开WSI配准数据集和两个私有数据集上评估，CORE在明场和免疫荧光显微镜WSI中优于当前最先进方法，具有更好的泛化性、精度和鲁棒性。

Conclusion: CORE框架通过从粗到细的配准策略和自动生成的细胞核，在多模态全玻片图像配准中实现了高精度的细胞核级对应。

Abstract: Accurate and efficient registration of whole slide images (WSIs) is essential
for high-resolution, nuclei-level analysis in multi-stained tissue slides. We
propose a novel coarse-to-fine framework CORE for accurate nuclei-level
registration across diverse multimodal whole-slide image (WSI) datasets. The
coarse registration stage leverages prompt-based tissue mask extraction to
effectively filter out artefacts and non-tissue regions, followed by global
alignment using tissue morphology and ac- celerated dense feature matching with
a pre-trained feature extractor. From the coarsely aligned slides, nuclei
centroids are detected and subjected to fine-grained rigid registration using a
custom, shape-aware point-set registration model. Finally, non-rigid alignment
at the cellular level is achieved by estimating a non-linear dis- placement
field using Coherent Point Drift (CPD). Our approach benefits from
automatically generated nuclei that enhance the accuracy of deformable
registra- tion and ensure precise nuclei-level correspondence across
modalities. The pro- posed model is evaluated on three publicly available WSI
registration datasets, and two private datasets. We show that CORE outperforms
current state-of-the-art methods in terms of generalisability, precision, and
robustness in bright-field and immunofluorescence microscopy WSIs

</details>


### [6] [Infrared Microscopy of Biochemistry and Metabolism in Single Living Eukaryotic Cells](https://arxiv.org/abs/2511.04143)
*Luca Quaroni*

Main category: q-bio.QM

TL;DR: 本文综述了红外显微镜在活细胞分析中的应用，重点关注代谢周转的定量研究，为代谢组学、毒理学和药理学研究提供补充方法。


<details>
  <summary>Details</summary>
Motivation: 利用红外光谱技术研究活细胞的分子信息，提供从整体样本中无法获得的单个细胞信息，实现对实时生化过程的监测。

Method: 使用红外显微镜对单个活细胞进行光谱分析，通过检测特定生物分子及其反应性来量化代谢周转。

Result: 过去几年在方法学上取得了进展，完成了概念验证实验，证明了该技术在检测特定生物分子及其反应性方面的可行性。

Conclusion: 红外显微镜在活细胞分析中具有潜力，但仍存在局限性，未来需要进一步发展和完善该技术。

Abstract: The turn of the millennium has seen a growing interest in the study of live
cells by infrared (IR) spectroscopy, driven by the versatility, wealth of
molecular information, and potential for high-throughput screening of the
technique. Measurements on individual cells, either isolated or within a
multi-cellular structure, provide information that is not available from
ensemble samples. The present review discusses the use of infrared (IR)
microscopy to analyse live single cells from a biochemical perspective, seeking
information on real-time processes. The emphasis is on the use of the technique
to quantify metabolic turnover, with the aim of providing a complementary
method for metabolomics, and for toxicological and pharmacological studies. The
present work highlights the methodological advances and proof-of-concept
experiments that took place over the past few years in this direction. It
discusses current advantages and limitations of the technique, including the
possibility of detecting specific biomolecules and their reactivity, and it
concludes with a brief outline of future perspectives.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [7] [PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction](https://arxiv.org/abs/2511.03976)
*Xu Zou*

Main category: cs.LG

TL;DR: PETRA是一种基于进化轨迹而非原始RNA序列的Transformer方法，通过系统发育树构建进化轨迹，有效减轻测序噪声并捕捉病毒进化的层次结构，在预测SARS-CoV-2未来突变方面表现出色。


<details>
  <summary>Details</summary>
Motivation: SARS-CoV-2具有快速且不可预测的进化轨迹，持续出现免疫逃逸变种，对公共卫生和疫苗开发构成挑战。现有的大规模生成预训练Transformer直接应用于嘈杂的病毒基因组序列存在局限性。

Method: 提出PETRA方法，基于系统发育树构建进化轨迹而非原始RNA序列，采用加权训练框架解决全球序列数据的地理和时间不平衡问题。

Result: PETRA在预测SARS-CoV-2未来突变方面表现优异，核苷酸突变的加权召回率@1达到9.45%，刺突蛋白氨基酸突变为17.10%，显著优于基线方法。

Conclusion: PETRA能够有效预测SARS-CoV-2的未来突变，包括主要分支如24F(XEC)和25A(LP.8.1)的实时突变预测，为病毒进化监测提供有力工具。

Abstract: Since its emergence, SARS-CoV-2 has demonstrated a rapid and unpredictable
evolutionary trajectory, characterized by the continual emergence of
immune-evasive variants. This poses persistent challenges to public health and
vaccine development.
  While large-scale generative pre-trained transformers (GPTs) have
revolutionized the modeling of sequential data, their direct applications to
noisy viral genomic sequences are limited. In this paper, we introduce
PETRA(Pretrained Evolutionary TRAnsformer), a novel transformer approach based
on evolutionary trajectories derived from phylogenetic trees rather than raw
RNA sequences. This method effectively mitigates sequencing noise and captures
the hierarchical structure of viral evolution.
  With a weighted training framework to address substantial geographical and
temporal imbalances in global sequence data, PETRA excels in predicting future
SARS-CoV-2 mutations, achieving a weighted recall@1 of 9.45% for nucleotide
mutations and 17.10\% for spike amino-acid mutations, compared to 0.49% and
6.64% respectively for the best baseline. PETRA also demonstrates its ability
to aid in the real-time mutation prediction of major clades like 24F(XEC) and
25A(LP.8.1). The code is open sourced on https://github.com/xz-keg/PETra

</details>


### [8] [Use of Continuous Glucose Monitoring with Machine Learning to Identify Metabolic Subphenotypes and Inform Precision Lifestyle Changes](https://arxiv.org/abs/2511.03986)
*Ahmed A. Metwally,Heyjun Park,Yue Wu,Tracey McLaughlin,Michael P. Snyder*

Main category: cs.LG

TL;DR: 本文综述了利用连续血糖监测和可穿戴技术从静态血糖阈值转向动态代谢表型分析的新范式，通过机器学习模型预测胰岛素抵抗和β细胞功能，实现个性化代谢亚型识别和精准干预。


<details>
  <summary>Details</summary>
Motivation: 传统基于静态血糖阈值的糖尿病和前驱糖尿病分类方法掩盖了病理生理学上的异质性，无法反映胰岛素抵抗、β细胞功能障碍和肠促胰岛素缺乏等核心代谢缺陷的个体差异。

Method: 采用连续血糖监测和可穿戴技术收集高分辨率血糖数据，结合机器学习模型分析家庭口服葡萄糖耐量测试数据，预测肌肉胰岛素抵抗和β细胞功能，并整合饮食、睡眠和体力活动等可穿戴数据。

Result: 研究表明机器学习模型能准确预测金标准代谢指标，个体对标准化餐食的餐后血糖反应可作为代谢亚型生物标志物，生活方式模式的时序特征与特定代谢功能障碍相关，饮食干预效果具有表型依赖性。

Conclusion: 连续血糖监测技术能够将早期血糖异常的复杂性分解为可操作的亚表型，超越简单的血糖控制，为针对个体核心代谢缺陷的精准营养、行为和药物干预策略开辟了新途径。

Abstract: The classification of diabetes and prediabetes by static glucose thresholds
obscures the pathophysiological dysglycemia heterogeneity, primarily driven by
insulin resistance (IR), beta-cell dysfunction, and incretin deficiency. This
review demonstrates that continuous glucose monitoring and wearable
technologies enable a paradigm shift towards non-invasive, dynamic metabolic
phenotyping. We show evidence that machine learning models can leverage
high-resolution glucose data from at-home, CGM-enabled oral glucose tolerance
tests to accurately predict gold-standard measures of muscle IR and beta-cell
function. This personalized characterization extends to real-world nutrition,
where an individual's unique postprandial glycemic response (PPGR) to
standardized meals, such as the relative glucose spike to potatoes versus
grapes, could serve as a biomarker for their metabolic subtype. Moreover,
integrating wearable data reveals that habitual diet, sleep, and physical
activity patterns, particularly their timing, are uniquely associated with
specific metabolic dysfunctions, informing precision lifestyle interventions.
The efficacy of dietary mitigators in attenuating PPGR is also shown to be
phenotype-dependent. Collectively, this evidence demonstrates that CGM can
deconstruct the complexity of early dysglycemia into distinct, actionable
subphenotypes. This approach moves beyond simple glycemic control, paving the
way for targeted nutritional, behavioral, and pharmacological strategies
tailored to an individual's core metabolic defects, thereby paving the way for
a new era of precision diabetes prevention.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [9] [SILVI: Simple Interface for Labeling Video Interactions](https://arxiv.org/abs/2511.03819)
*Ozan Kanbertay,Richard Vogg,Elif Karakoc,Peter M. Kappeler,Claudia Fichtel,Alexander S. Ecker*

Main category: cs.CV

TL;DR: SILVI是一个开源标注软件，填补了现有工具在动物行为交互标注方面的空白，支持在视频数据中直接标注行为和交互，为计算机视觉模型训练提供结构化输出。


<details>
  <summary>Details</summary>
Motivation: 现有开源标注工具要么支持行为标注但不定位个体，要么支持定位但不能捕捉交互。为了理解社会化和个体化动物行为，需要能够检测和标注交互的工具。

Method: 开发SILVI开源标注软件，集成行为标注和交互标注功能，允许研究者在视频数据中直接标注行为和交互。

Result: SILVI能够生成适合训练和验证计算机视觉模型的结构化输出，连接行为生态学和计算机视觉，促进精细行为分析的自动化方法开发。

Conclusion: SILVI填补了动物行为交互标注工具的空白，虽然主要针对动物行为开发，但也可用于标注其他需要提取动态场景图的人类交互视频。

Abstract: Computer vision methods are increasingly used for the automated analysis of
large volumes of video data collected through camera traps, drones, or direct
observations of animals in the wild. While recent advances have focused
primarily on detecting individual actions, much less work has addressed the
detection and annotation of interactions -- a crucial aspect for understanding
social and individualized animal behavior. Existing open-source annotation
tools support either behavioral labeling without localization of individuals,
or localization without the capacity to capture interactions. To bridge this
gap, we present SILVI, an open-source labeling software that integrates both
functionalities. SILVI enables researchers to annotate behaviors and
interactions directly within video data, generating structured outputs suitable
for training and validating computer vision models. By linking behavioral
ecology with computer vision, SILVI facilitates the development of automated
approaches for fine-grained behavioral analyses. Although developed primarily
in the context of animal behavior, SILVI could be useful more broadly to
annotate human interactions in other videos that require extracting dynamic
scene graphs. The software, along with documentation and download instructions,
is available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app.

</details>
