<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 5]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [Advancing Risk Gene Discovery Across the Allele Frequency Spectrum](https://arxiv.org/abs/2511.04637)
*Madison Caballero,Behrang Mahjani*

Main category: q-bio.GN

TL;DR: 本文综述了遗传风险基因发现中的'缺失中间区域'问题，即中等频率和中等效应大小的变异，这些变异在当前方法中统计功效有限，病原性常被错误分类，基因发现滞后于遗传贡献的经验证据。


<details>
  <summary>Details</summary>
Motivation: 尽管测序和生物库资源呈指数级增长，但新基因识别的速度已经放缓。当前方法主要针对极端等位基因频率谱：罕见高外显率变异和常见低效应变异，而中等频率和效应大小的变异成为关键盲点。

Method: 通过按变异频率类别组织风险基因识别策略，强调每个尺度上的方法优势和限制。利用变异注释、联合建模、表型细化和基于网络推理的创新来扩展中间区域的发现。

Result: 通过将频率谱作为统一轴，提供了当前能力、其局限性以及朝着更全面风险基因发现的新兴方向的概念图。

Conclusion: 通过跨领域经验整合创新方法，可以填补中等频率变异这一关键盲点，推动更全面的风险基因发现。

Abstract: The discovery of genetic risk factors has transformed human genetics, yet the
pace of new gene identification has slowed despite the exponential expansion of
sequencing and biobank resources. Current approaches are optimized for the
extremes of the allele frequency spectrum: rare, high-penetrance variants
identified through burden testing, and common, low-effect variants mapped by
genome-wide association studies. Between these extremes lies variants of
intermediate frequency and effect size where statistical power is limited,
pathogenicity is often misclassified, and gene discovery lags behind empirical
evidence of heritable contribution. This 'missing middle' represents a critical
blind spot across disease areas, from neurodevelopmental and psychiatric
disorders to cancer and aging. In this review, we organize strategies for risk
gene identification by variant frequency class, highlighting methodological
strengths and constraints at each scale. We draw on lessons across fields to
illustrate how innovations in variant annotation, joint modeling, phenotype
refinement, and network-based inference can extend discovery into the
intermediate range. By framing the frequency spectrum as a unifying axis, we
provide a conceptual map of current capabilities, their limitations, and
emerging directions toward more comprehensive risk gene discovery.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [2] [Attention-based ROI Discovery in 3D Tissue Images](https://arxiv.org/abs/2511.03751)
*Hossein Fathollahian,Siyuan Zhao,Nafiul Nipu,G. Elisabeta Marai*

Main category: q-bio.QM

TL;DR: 提出了一种自动识别3D显微镜数据中感兴趣区域的方法，基于自监督多层图注意力网络(SSGAT)和React交互界面，无需专家手动标注即可识别生物相关区域。


<details>
  <summary>Details</summary>
Motivation: 高维组织成像生成包含多个生物标志物的复杂3D数据，在没有专家手动标注感兴趣区域的情况下，识别生物相关区域具有挑战性。

Method: 使用自监督多层图注意力网络(SSGAT)，结合对抗性自监督学习目标，通过标记物相互作用识别有意义的免疫微环境，并开发了基于Vitessce的React交互界面。

Result: 该方法能够揭示复杂的空间生物反应，可以视觉评估其在组织中的分布情况。

Conclusion: 提出的SSGAT方法能够自动识别3D显微镜数据中的感兴趣区域，有效解决了高维组织成像数据分析的挑战。

Abstract: High-dimensional tissue imaging generates highly complex 3D data containing
multiple biomarkers, making it challenging to identify biologically relevant
regions without an expert user specifying manual labels for regions of
interest. We introduce an approach to automatically identifying regions of
interest (ROIs) in the 3D microscopy data. Our approach is based on a novel
self-supervised multi-layer graph attention network (SSGAT), coupled with a
React interactive interface wrapped around Vitessce. SSGAT employs an
adversarial self-supervised learning objective to identify meaningful immune
microenvironments through marker interactions. Our method reveals complex
spatial bioreactions that can be visually assessed to assess their distribution
across tissue. Index Terms: Biomedical visualization, graph attention
networks,self-supervised learning, spatial interaction analysis.

</details>


### [3] [Phenotype discovery of traumatic brain injury segmentations from heterogeneous multi-site data](https://arxiv.org/abs/2511.03767)
*Adam M. Saunders,Michael E. Kim,Gaurav Rudravaram,Lucas W. Remedios,Chloe Cho,Elyssa M. McMaster,Daniel R. Gillis,Yihao Liu,Lianrui Zuo,Bennett A. Landman,Tonia S. Rex*

Main category: q-bio.QM

TL;DR: 该研究通过分析FITBIR数据库中7,693个MRI会话，识别了创伤性脑损伤(TBI)患者与对照组在37个脑区体积上的显著差异，揭示了TBI的三个主要损伤模式。


<details>
  <summary>Details</summary>
Motivation: 创伤性脑损伤具有高度异质性，临床结果测量难以将结构损伤与功能缺陷联系起来，需要在大规模多中心数据中揭示共享的损伤通路。

Method: 使用FITBIR数据库的T1加权图像，先进行数据协调和132个脑区分割，计算体积z分数，回归性别、年龄和总脑体积，通过独立t检验和错误发现率校正识别差异区域。

Result: 发现TBI患者与对照组在37个脑区存在显著体积差异，通过独立成分分析识别出三个主要损伤模式：脑干/枕叶区域、皮层下灰质/岛叶皮层、以及大脑和小脑白质。

Conclusion: 研究成功在大规模多中心数据中识别了TBI的共享损伤通路，为理解TBI的异质性提供了重要见解。

Abstract: Traumatic brain injury (TBI) is intrinsically heterogeneous, and typical
clinical outcome measures like the Glasgow Coma Scale complicate this
diversity. The large variability in severity and patient outcomes render it
difficult to link structural damage to functional deficits. The Federal
Interagency Traumatic Brain Injury Research (FITBIR) repository contains
large-scale multi-site magnetic resonance imaging data of varying resolutions
and acquisition parameters (25 shared studies with 7,693 sessions that have
age, sex and TBI status defined - 5,811 TBI and 1,882 controls). To reveal
shared pathways of injury of TBI through imaging, we analyzed T1-weighted
images from these sessions by first harmonizing to a local dataset and
segmenting 132 regions of interest (ROIs) in the brain. After running quality
assurance, calculating the volumes of the ROIs, and removing outliers, we
calculated the z-scores of volumes for all participants relative to the mean
and standard deviation of the controls. We regressed out sex, age, and total
brain volume with a multivariate linear regression, and we found significant
differences in 37 ROIs between subjects with TBI and controls (p < 0.05 with
independent t-tests with false discovery rate correction). We found that
differences originated in 1) the brainstem, occipital pole and structures
posterior to the orbit, 2) subcortical gray matter and insular cortex, and 3)
cerebral and cerebellar white matter using independent component analysis and
clustering the component loadings of those with TBI.

</details>


### [4] [Climbing the label tree: Hierarchy-preserving contrastive learning for medical imaging](https://arxiv.org/abs/2511.03771)
*Alif Elham Khan*

Main category: q-bio.QM

TL;DR: 提出了一种保持层次结构的对比学习框架，将医学图像标签的树状结构作为训练信号和评估目标，通过层次加权对比和层级感知边界两个目标函数，在多个基准测试中提升了表示质量并更好地保持了分类层次结构。


<details>
  <summary>Details</summary>
Motivation: 医学图像标签通常按层次结构组织（如器官-组织-亚型），但标准的自监督学习方法忽略了这种结构信息。

Method: 引入两个插件式目标函数：层次加权对比（HWC）通过共享祖先缩放正负对强度，促进同父节点内的连贯性；层级感知边界（LAM）通过原型边界在不同层级分离祖先组。该框架与几何结构无关，适用于欧几里得和双曲嵌入。

Result: 在多个基准测试（包括乳腺组织病理学）中，所提出的目标函数持续改进了表示质量，同时更好地保持了分类层次结构。使用层次忠实度指标（HF1、H-Acc、父距离违规率）进行评估，也报告了top-1准确率。

Conclusion: 该方法提供了一个简单通用的方案，用于学习尊重标签树结构的医学图像表示，在层次丰富的领域中既提升了性能又增强了可解释性。

Abstract: Medical image labels are often organized by taxonomies (e.g., organ - tissue
- subtype), yet standard self-supervised learning (SSL) ignores this structure.
We present a hierarchy-preserving contrastive framework that makes the label
tree a first-class training signal and an evaluation target. Our approach
introduces two plug-in objectives: Hierarchy-Weighted Contrastive (HWC), which
scales positive/negative pair strengths by shared ancestors to promote
within-parent coherence, and Level-Aware Margin (LAM), a prototype margin that
separates ancestor groups across levels. The formulation is geometry-agnostic
and applies to Euclidean and hyperbolic embeddings without architectural
changes. Across several benchmarks, including breast histopathology, the
proposed objectives consistently improve representation quality over strong SSL
baselines while better respecting the taxonomy. We evaluate with metrics
tailored to hierarchy faithfulness: HF1 (hierarchical F1), H-Acc
(tree-distance-weighted accuracy), and parent-distance violation rate. We also
report top-1 accuracy for completeness. Ablations show that HWC and LAM are
effective even without curvature, and combining them yields the most
taxonomy-aligned representations. Taken together, these results provide a
simple, general recipe for learning medical image representations that respect
the label tree and advance both performance and interpretability in
hierarchy-rich domains.

</details>


### [5] [CORE - A Cell-Level Coarse-to-Fine Image Registration Engine for Multi-stain Image Alignment](https://arxiv.org/abs/2511.03826)
*Esha Sadia Nasir,Behnaz Elhaminia,Mark Eastwood,Catherine King,Owen Cain,Lorraine Harper,Paul Moss,Dimitrios Chanouzas,David Snead,Nasir Rajpoot,Adam Shephard,Shan E Ahmed Raza*

Main category: q-bio.QM

TL;DR: 提出了一种名为CORE的从粗到细的框架，用于多模态全玻片图像（WSI）的精确细胞核级配准，包括粗配准、细粒度刚性配准和非刚性对齐三个阶段。


<details>
  <summary>Details</summary>
Motivation: 全玻片图像的准确高效配准对于多染色组织切片的高分辨率、细胞核级分析至关重要。

Method: 采用从粗到细的框架：粗配准阶段使用基于提示的组织掩码提取过滤伪影和非组织区域，然后进行全局对齐；细粒度刚性配准使用形状感知点集配准模型；最后通过相干点漂移（CPD）实现细胞级的非刚性对齐。

Result: 在三个公开WSI配准数据集和两个私有数据集上评估，CORE在明场和免疫荧光显微镜WSI中，在泛化性、精度和鲁棒性方面优于当前最先进方法。

Conclusion: CORE框架通过自动生成的细胞核增强了可变形配准的准确性，确保了跨模态的精确细胞核级对应关系。

Abstract: Accurate and efficient registration of whole slide images (WSIs) is essential
for high-resolution, nuclei-level analysis in multi-stained tissue slides. We
propose a novel coarse-to-fine framework CORE for accurate nuclei-level
registration across diverse multimodal whole-slide image (WSI) datasets. The
coarse registration stage leverages prompt-based tissue mask extraction to
effectively filter out artefacts and non-tissue regions, followed by global
alignment using tissue morphology and ac- celerated dense feature matching with
a pre-trained feature extractor. From the coarsely aligned slides, nuclei
centroids are detected and subjected to fine-grained rigid registration using a
custom, shape-aware point-set registration model. Finally, non-rigid alignment
at the cellular level is achieved by estimating a non-linear dis- placement
field using Coherent Point Drift (CPD). Our approach benefits from
automatically generated nuclei that enhance the accuracy of deformable
registra- tion and ensure precise nuclei-level correspondence across
modalities. The pro- posed model is evaluated on three publicly available WSI
registration datasets, and two private datasets. We show that CORE outperforms
current state-of-the-art methods in terms of generalisability, precision, and
robustness in bright-field and immunofluorescence microscopy WSIs

</details>


### [6] [Infrared Microscopy of Biochemistry and Metabolism in Single Living Eukaryotic Cells](https://arxiv.org/abs/2511.04143)
*Luca Quaroni*

Main category: q-bio.QM

TL;DR: 本文综述了红外显微镜在活体单细胞分析中的应用，重点关注代谢周转的量化，为代谢组学、毒理学和药理学研究提供补充方法。


<details>
  <summary>Details</summary>
Motivation: 由于红外光谱技术的多功能性、丰富的分子信息和高通量筛选潜力，千禧年以来对活细胞红外光谱研究的兴趣日益增长。单细胞测量能提供群体样本无法获得的信息。

Method: 使用红外显微镜分析活体单细胞，从生化角度研究实时过程，特别强调量化代谢周转的技术应用。

Result: 综述了过去几年在该方向上的方法学进展和概念验证实验，讨论了当前技术的优势和局限性，包括检测特定生物分子及其反应性的可能性。

Conclusion: 文章最后简要概述了未来的发展前景，表明该技术在活细胞分析领域具有持续发展的潜力。

Abstract: The turn of the millennium has seen a growing interest in the study of live
cells by infrared (IR) spectroscopy, driven by the versatility, wealth of
molecular information, and potential for high-throughput screening of the
technique. Measurements on individual cells, either isolated or within a
multi-cellular structure, provide information that is not available from
ensemble samples. The present review discusses the use of infrared (IR)
microscopy to analyse live single cells from a biochemical perspective, seeking
information on real-time processes. The emphasis is on the use of the technique
to quantify metabolic turnover, with the aim of providing a complementary
method for metabolomics, and for toxicological and pharmacological studies. The
present work highlights the methodological advances and proof-of-concept
experiments that took place over the past few years in this direction. It
discusses current advantages and limitations of the technique, including the
possibility of detecting specific biomolecules and their reactivity, and it
concludes with a brief outline of future perspectives.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [7] [SILVI: Simple Interface for Labeling Video Interactions](https://arxiv.org/abs/2511.03819)
*Ozan Kanbertay,Richard Vogg,Elif Karakoc,Peter M. Kappeler,Claudia Fichtel,Alexander S. Ecker*

Main category: cs.CV

TL;DR: SILVI是一个开源标注软件，用于在视频数据中标注行为和交互，填补了现有工具在交互检测方面的空白。


<details>
  <summary>Details</summary>
Motivation: 现有开源标注工具要么支持行为标注但不定位个体，要么支持定位但不能捕捉交互，缺乏同时支持两者的工具。

Method: 开发了SILVI软件，集成行为和交互标注功能，直接在视频数据中标注，生成结构化输出用于计算机视觉模型训练。

Result: SILVI能够有效标注行为和交互，为细粒度行为分析提供自动化方法。

Conclusion: SILVI连接了行为生态学和计算机视觉，促进了自动化的细粒度行为分析方法开发，虽然主要用于动物行为，但也可用于标注人类交互。

Abstract: Computer vision methods are increasingly used for the automated analysis of
large volumes of video data collected through camera traps, drones, or direct
observations of animals in the wild. While recent advances have focused
primarily on detecting individual actions, much less work has addressed the
detection and annotation of interactions -- a crucial aspect for understanding
social and individualized animal behavior. Existing open-source annotation
tools support either behavioral labeling without localization of individuals,
or localization without the capacity to capture interactions. To bridge this
gap, we present SILVI, an open-source labeling software that integrates both
functionalities. SILVI enables researchers to annotate behaviors and
interactions directly within video data, generating structured outputs suitable
for training and validating computer vision models. By linking behavioral
ecology with computer vision, SILVI facilitates the development of automated
approaches for fine-grained behavioral analyses. Although developed primarily
in the context of animal behavior, SILVI could be useful more broadly to
annotate human interactions in other videos that require extracting dynamic
scene graphs. The software, along with documentation and download instructions,
is available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [8] [PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction](https://arxiv.org/abs/2511.03976)
*Xu Zou*

Main category: cs.LG

TL;DR: PETRA是一种基于进化轨迹的Transformer方法，通过系统发育树而非原始RNA序列来预测SARS-CoV-2的未来突变，有效缓解测序噪声并捕捉病毒进化的层次结构。


<details>
  <summary>Details</summary>
Motivation: SARS-CoV-2的快速进化轨迹和免疫逃逸变体的持续出现对公共卫生和疫苗开发构成挑战，而现有大型生成预训练Transformer直接应用于嘈杂的病毒基因组序列存在局限性。

Method: 提出PETRA方法，基于系统发育树推导的进化轨迹而非原始RNA序列，采用加权训练框架处理全球序列数据的地理和时间不平衡问题。

Result: 在预测SARS-CoV-2未来突变方面表现优异，核苷酸突变的加权召回率@1达到9.45%，刺突蛋白氨基酸突变为17.10%，显著优于基线方法（分别为0.49%和6.64%）。

Conclusion: PETRA能够有效预测SARS-CoV-2的未来突变，包括主要分支如24F(XEC)和25A(LP.8.1)的实时突变预测，为公共卫生应对提供支持。

Abstract: Since its emergence, SARS-CoV-2 has demonstrated a rapid and unpredictable
evolutionary trajectory, characterized by the continual emergence of
immune-evasive variants. This poses persistent challenges to public health and
vaccine development.
  While large-scale generative pre-trained transformers (GPTs) have
revolutionized the modeling of sequential data, their direct applications to
noisy viral genomic sequences are limited. In this paper, we introduce
PETRA(Pretrained Evolutionary TRAnsformer), a novel transformer approach based
on evolutionary trajectories derived from phylogenetic trees rather than raw
RNA sequences. This method effectively mitigates sequencing noise and captures
the hierarchical structure of viral evolution.
  With a weighted training framework to address substantial geographical and
temporal imbalances in global sequence data, PETRA excels in predicting future
SARS-CoV-2 mutations, achieving a weighted recall@1 of 9.45% for nucleotide
mutations and 17.10\% for spike amino-acid mutations, compared to 0.49% and
6.64% respectively for the best baseline. PETRA also demonstrates its ability
to aid in the real-time mutation prediction of major clades like 24F(XEC) and
25A(LP.8.1). The code is open sourced on https://github.com/xz-keg/PETra

</details>


### [9] [Use of Continuous Glucose Monitoring with Machine Learning to Identify Metabolic Subphenotypes and Inform Precision Lifestyle Changes](https://arxiv.org/abs/2511.03986)
*Ahmed A. Metwally,Heyjun Park,Yue Wu,Tracey McLaughlin,Michael P. Snyder*

Main category: cs.LG

TL;DR: 论文提出使用连续血糖监测和可穿戴技术进行动态代谢表型分析，通过机器学习模型从高分辨率血糖数据预测胰岛素抵抗和β细胞功能，实现个性化糖尿病预防策略。


<details>
  <summary>Details</summary>
Motivation: 传统基于静态血糖阈值的糖尿病和糖尿病前期分类方法掩盖了病理生理性血糖异常的异质性，主要受胰岛素抵抗、β细胞功能障碍和肠促胰岛素缺乏驱动。

Method: 利用连续血糖监测和可穿戴技术收集高分辨率血糖数据，通过机器学习模型分析家庭CGM口服葡萄糖耐量测试数据，预测肌肉胰岛素抵抗和β细胞功能。

Result: 研究表明机器学习模型能准确预测金标准胰岛素抵抗和β细胞功能指标，餐后血糖反应可作为代谢亚型的生物标志物，生活方式模式与特定代谢功能障碍相关。

Conclusion: CGM技术可将早期血糖异常复杂性分解为可操作的亚表型，超越简单血糖控制，为针对个体核心代谢缺陷的精准营养、行为和药物干预策略开辟新途径。

Abstract: The classification of diabetes and prediabetes by static glucose thresholds
obscures the pathophysiological dysglycemia heterogeneity, primarily driven by
insulin resistance (IR), beta-cell dysfunction, and incretin deficiency. This
review demonstrates that continuous glucose monitoring and wearable
technologies enable a paradigm shift towards non-invasive, dynamic metabolic
phenotyping. We show evidence that machine learning models can leverage
high-resolution glucose data from at-home, CGM-enabled oral glucose tolerance
tests to accurately predict gold-standard measures of muscle IR and beta-cell
function. This personalized characterization extends to real-world nutrition,
where an individual's unique postprandial glycemic response (PPGR) to
standardized meals, such as the relative glucose spike to potatoes versus
grapes, could serve as a biomarker for their metabolic subtype. Moreover,
integrating wearable data reveals that habitual diet, sleep, and physical
activity patterns, particularly their timing, are uniquely associated with
specific metabolic dysfunctions, informing precision lifestyle interventions.
The efficacy of dietary mitigators in attenuating PPGR is also shown to be
phenotype-dependent. Collectively, this evidence demonstrates that CGM can
deconstruct the complexity of early dysglycemia into distinct, actionable
subphenotypes. This approach moves beyond simple glycemic control, paving the
way for targeted nutritional, behavioral, and pharmacological strategies
tailored to an individual's core metabolic defects, thereby paving the way for
a new era of precision diabetes prevention.

</details>
