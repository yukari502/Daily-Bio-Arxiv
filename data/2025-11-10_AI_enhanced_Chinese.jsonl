{"id": "2511.05183", "pdf": "https://arxiv.org/pdf/2511.05183", "abs": "https://arxiv.org/abs/2511.05183", "authors": ["Gregory Verghese", "Anthony Baptista", "Chima Eke", "Holly Rafique", "Mengyuan Li", "Fathima Mohamed", "Ananya Bhalla", "Lucy Ryan", "Michael Pitcher", "Enrico Parisini", "Concetta Piazzese", "Liz Ing-Simmons", "Anita Grigoriadis"], "title": "PySlyde: A Lightweight, Open-Source Toolkit for Pathology Preprocessing", "categories": ["q-bio.QM", "cs.CV", "eess.IV"], "comment": null, "summary": "The integration of artificial intelligence (AI) into pathology is advancing\nprecision medicine by improving diagnosis, treatment planning, and patient\noutcomes. Digitised whole-slide images (WSIs) capture rich spatial and\nmorphological information vital for understanding disease biology, yet their\ngigapixel scale and variability pose major challenges for standardisation and\nanalysis. Robust preprocessing, covering tissue detection, tessellation, stain\nnormalisation, and annotation parsing is critical but often limited by\nfragmented and inconsistent workflows. We present PySlyde, a lightweight,\nopen-source Python toolkit built on OpenSlide to simplify and standardise WSI\npreprocessing. PySlyde provides an intuitive API for slide loading, annotation\nmanagement, tissue detection, tiling, and feature extraction, compatible with\nmodern pathology foundation models. By unifying these processes, it streamlines\nWSI preprocessing, enhances reproducibility, and accelerates the generation of\nAI-ready datasets, enabling researchers to focus on model development and\ndownstream analysis.", "AI": {"tldr": "PySlyde\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5f00\u6e90Python\u5de5\u5177\u5305\uff0c\u57fa\u4e8eOpenSlide\u6784\u5efa\uff0c\u7528\u4e8e\u7b80\u5316\u548c\u6807\u51c6\u5316\u5168\u73bb\u7247\u56fe\u50cf(WSI)\u7684\u9884\u5904\u7406\u6d41\u7a0b\u3002", "motivation": "\u6570\u5b57\u5316\u7684\u5168\u73bb\u7247\u56fe\u50cf\u5305\u542b\u4e30\u5bcc\u7684\u7a7a\u95f4\u548c\u5f62\u6001\u5b66\u4fe1\u606f\uff0c\u4f46\u5176\u5343\u5146\u50cf\u7d20\u89c4\u6a21\u548c\u53d8\u5f02\u6027\u7ed9\u6807\u51c6\u5316\u548c\u5206\u6790\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\uff0c\u73b0\u6709\u9884\u5904\u7406\u5de5\u4f5c\u6d41\u7a0b\u5206\u6563\u4e14\u4e0d\u4e00\u81f4\u3002", "method": "PySlyde\u63d0\u4f9b\u76f4\u89c2\u7684API\uff0c\u652f\u6301\u73bb\u7247\u52a0\u8f7d\u3001\u6ce8\u91ca\u7ba1\u7406\u3001\u7ec4\u7ec7\u68c0\u6d4b\u3001\u5206\u5757\u548c\u7279\u5f81\u63d0\u53d6\uff0c\u4e0e\u73b0\u4ee3\u75c5\u7406\u5b66\u57fa\u7840\u6a21\u578b\u517c\u5bb9\u3002", "result": "\u901a\u8fc7\u7edf\u4e00\u8fd9\u4e9b\u6d41\u7a0b\uff0cPySlyde\u7b80\u5316\u4e86WSI\u9884\u5904\u7406\uff0c\u589e\u5f3a\u4e86\u53ef\u91cd\u590d\u6027\uff0c\u5e76\u52a0\u901f\u4e86AI\u5c31\u7eea\u6570\u636e\u96c6\u7684\u751f\u6210\u3002", "conclusion": "PySlyde\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u4e13\u6ce8\u4e8e\u6a21\u578b\u5f00\u53d1\u548c\u4e0b\u6e38\u5206\u6790\uff0c\u63a8\u52a8\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u75c5\u7406\u5b66\u4e2d\u7684\u96c6\u6210\u548c\u7cbe\u51c6\u533b\u5b66\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.04825", "pdf": "https://arxiv.org/pdf/2511.04825", "abs": "https://arxiv.org/abs/2511.04825", "authors": ["Luigi Caputi", "Nicholas Meadows", "Henri Riihim\u00e4ki"], "title": "Persistent reachability homology in machine learning applications", "categories": ["cs.LG", "math.AT", "q-bio.QM"], "comment": "19 pages; any comments welcome", "summary": "We explore the recently introduced persistent reachability homology (PRH) of\ndigraph data, i.e. data in the form of directed graphs. In particular, we study\nthe effectiveness of PRH in network classification task in a key neuroscience\nproblem: epilepsy detection. PRH is a variation of the persistent homology of\ndigraphs, more traditionally based on the directed flag complex (DPH). A main\nadvantage of PRH is that it considers the condensations of the digraphs\nappearing in the persistent filtration and thus is computed from smaller\ndigraphs. We compare the effectiveness of PRH to that of DPH and we show that\nPRH outperforms DPH in the classification task. We use the Betti curves and\ntheir integrals as topological features and implement our pipeline on support\nvector machine.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6301\u4e45\u53ef\u8fbe\u6027\u540c\u8c03\uff08PRH\uff09\u5728\u6709\u5411\u56fe\u6570\u636e\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u5728\u766b\u75eb\u68c0\u6d4b\u8fd9\u4e00\u795e\u7ecf\u79d1\u5b66\u95ee\u9898\u4e2d\u7684\u7f51\u7edc\u5206\u7c7b\u4efb\u52a1\u6548\u679c\u3002PRH\u76f8\u6bd4\u4f20\u7edf\u7684\u57fa\u4e8e\u6709\u5411\u65d7\u590d\u5f62\uff08DPH\uff09\u7684\u6301\u4e45\u540c\u8c03\u65b9\u6cd5\uff0c\u8003\u8651\u4e86\u8fc7\u6ee4\u8fc7\u7a0b\u4e2d\u6709\u5411\u56fe\u7684\u51dd\u805a\uff0c\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002", "motivation": "\u63a2\u7d22PRH\u5728\u6709\u5411\u56fe\u6570\u636e\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u766b\u75eb\u68c0\u6d4b\u8fd9\u4e00\u91cd\u8981\u795e\u7ecf\u79d1\u5b66\u95ee\u9898\u4e0a\uff0c\u5bfb\u6c42\u6bd4\u4f20\u7edfDPH\u65b9\u6cd5\u66f4\u4f18\u7684\u62d3\u6251\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6301\u4e45\u53ef\u8fbe\u6027\u540c\u8c03\uff08PRH\uff09\u4f5c\u4e3a\u62d3\u6251\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\uff0c\u4e0e\u57fa\u4e8e\u6709\u5411\u65d7\u590d\u5f62\uff08DPH\uff09\u7684\u4f20\u7edf\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002\u91c7\u7528Betti\u66f2\u7ebf\u53ca\u5176\u79ef\u5206\u4f5c\u4e3a\u62d3\u6251\u7279\u5f81\uff0c\u5e76\u5728\u652f\u6301\u5411\u91cf\u673a\u4e0a\u5b9e\u73b0\u5206\u7c7b\u7ba1\u9053\u3002", "result": "\u5728\u766b\u75eb\u68c0\u6d4b\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cPRH\u65b9\u6cd5\u7684\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u7684DPH\u65b9\u6cd5\u3002", "conclusion": "\u6301\u4e45\u53ef\u8fbe\u6027\u540c\u8c03\uff08PRH\uff09\u662f\u4e00\u79cd\u6709\u6548\u7684\u6709\u5411\u56fe\u62d3\u6251\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\uff0c\u5728\u795e\u7ecf\u79d1\u5b66\u6570\u636e\u5206\u7c7b\u4efb\u52a1\u4e2d\u5177\u6709\u4f18\u52bf\uff0c\u7279\u522b\u662f\u901a\u8fc7\u8003\u8651\u6709\u5411\u56fe\u51dd\u805a\u6765\u51cf\u5c11\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2511.04854", "pdf": "https://arxiv.org/pdf/2511.04854", "abs": "https://arxiv.org/abs/2511.04854", "authors": ["Alvaro Prat", "Leo Zhang", "Charlotte M. Deane", "Yee Whye Teh", "Garrett M. Morris"], "title": "SigmaDock: Untwisting Molecular Docking With Fragment-Based SE(3) Diffusion", "categories": ["cs.LG", "q-bio.QM"], "comment": "Preprint", "summary": "Determining the binding pose of a ligand to a protein, known as molecular\ndocking, is a fundamental task in drug discovery. Generative approaches promise\nfaster, improved, and more diverse pose sampling than physics-based methods,\nbut are often hindered by chemically implausible outputs, poor\ngeneralisability, and high computational cost. To address these challenges, we\nintroduce a novel fragmentation scheme, leveraging inductive biases from\nstructural chemistry, to decompose ligands into rigid-body fragments. Building\non this decomposition, we present SigmaDock, an SE(3) Riemannian diffusion\nmodel that generates poses by learning to reassemble these rigid bodies within\nthe binding pocket. By operating at the level of fragments in SE(3), SigmaDock\nexploits well-established geometric priors while avoiding overly complex\ndiffusion processes and unstable training dynamics. Experimentally, we show\nSigmaDock achieves state-of-the-art performance, reaching Top-1 success rates\n(RMSD<2 & PB-valid) above 79.9% on the PoseBusters set, compared to 12.7-30.8%\nreported by recent deep learning approaches, whilst demonstrating consistent\ngeneralisation to unseen proteins. SigmaDock is the first deep learning\napproach to surpass classical physics-based docking under the PB train-test\nsplit, marking a significant leap forward in the reliability and feasibility of\ndeep learning for molecular modelling.", "AI": {"tldr": "SigmaDock\u662f\u4e00\u79cd\u57fa\u4e8eSE(3)\u9ece\u66fc\u6269\u6563\u6a21\u578b\u7684\u5206\u5b50\u5bf9\u63a5\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u914d\u4f53\u5206\u89e3\u4e3a\u521a\u6027\u7247\u6bb5\u5e76\u5728\u7ed3\u5408\u53e3\u888b\u4e2d\u91cd\u65b0\u7ec4\u88c5\u6765\u751f\u6210\u7ed3\u5408\u6784\u8c61\uff0c\u5728PoseBusters\u6570\u636e\u96c6\u4e0a\u8fbe\u523079.9%\u7684Top-1\u6210\u529f\u7387\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7269\u7406\u65b9\u6cd5\u548c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u751f\u6210\u5f0f\u5206\u5b50\u5bf9\u63a5\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u5316\u5b66\u4e0d\u5408\u7406\u8f93\u51fa\u3001\u6cdb\u5316\u6027\u5dee\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5229\u7528\u7ed3\u6784\u5316\u5b66\u7684\u5f52\u7eb3\u504f\u7f6e\u6765\u6539\u8fdb\u914d\u4f53\u7ed3\u5408\u6784\u8c61\u7684\u751f\u6210\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u7247\u6bb5\u5316\u65b9\u6848\uff0c\u5c06\u914d\u4f53\u5206\u89e3\u4e3a\u521a\u6027\u7247\u6bb5\uff0c\u7136\u540e\u4f7f\u7528SE(3)\u9ece\u66fc\u6269\u6563\u6a21\u578b\u5b66\u4e60\u5728\u7ed3\u5408\u53e3\u888b\u4e2d\u91cd\u65b0\u7ec4\u88c5\u8fd9\u4e9b\u521a\u6027\u7247\u6bb5\u3002", "result": "\u5728PoseBusters\u6570\u636e\u96c6\u4e0a\u8fbe\u523079.9%\u7684Top-1\u6210\u529f\u7387\uff08RMSD<2\u4e14PB\u6709\u6548\uff09\uff0c\u8fdc\u8d85\u8fd1\u671f\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0812.7-30.8%\uff09\uff0c\u5e76\u5c55\u73b0\u51fa\u5bf9\u672a\u89c1\u86cb\u767d\u8d28\u7684\u4e00\u81f4\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SigmaDock\u662f\u9996\u4e2a\u5728PB\u8bad\u7ec3-\u6d4b\u8bd5\u5206\u5272\u4e0b\u8d85\u8d8a\u7ecf\u5178\u7269\u7406\u57fa\u5bf9\u63a5\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u6807\u5fd7\u7740\u6df1\u5ea6\u5b66\u4e60\u5728\u5206\u5b50\u5efa\u6a21\u53ef\u9760\u6027\u548c\u53ef\u884c\u6027\u65b9\u9762\u7684\u91cd\u5927\u7a81\u7834\u3002"}}
{"id": "2511.04998", "pdf": "https://arxiv.org/pdf/2511.04998", "abs": "https://arxiv.org/abs/2511.04998", "authors": ["Daniel S. Lee", "Mayra S. Haedo-Cruz", "Chen Jiang", "Oshin Miranda", "LiRong Wang"], "title": "BiPETE: A Bi-Positional Embedding Transformer Encoder for Risk Assessment of Alcohol and Substance Use Disorder with Electronic Health Records", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": "20 pages, 2 figures, 6 tables, 2 supplementary figures, 4\n  supplementary tables, submitted to Journal of Biomedical Informatics on 6\n  Nov, 2025", "summary": "Transformer-based deep learning models have shown promise for disease risk\nprediction using electronic health records(EHRs), but modeling temporal\ndependencies remains a key challenge due to irregular visit intervals and lack\nof uniform structure. We propose a Bi-Positional Embedding Transformer Encoder\nor BiPETE for single-disease prediction, which integrates rotary positional\nembeddings to encode relative visit timing and sinusoidal embeddings to\npreserve visit order. Without relying on large-scale pretraining, BiPETE is\ntrained on EHR data from two mental health cohorts-depressive disorder and\npost-traumatic stress disorder (PTSD)-to predict the risk of alcohol and\nsubstance use disorders (ASUD). BiPETE outperforms baseline models, improving\nthe area under the precision-recall curve (AUPRC) by 34% and 50% in the\ndepression and PTSD cohorts, respectively. An ablation study further confirms\nthe effectiveness of the dual positional encoding strategy. We apply the\nIntegrated Gradients method to interpret model predictions, identifying key\nclinical features associated with ASUD risk and protection, such as abnormal\ninflammatory, hematologic, and metabolic markers, as well as specific\nmedications and comorbidities. Overall, these key clinical features identified\nby the attribution methods contribute to a deeper understanding of the risk\nassessment process and offer valuable clues for mitigating potential risks. In\nsummary, our study presents a practical and interpretable framework for disease\nrisk prediction using EHR data, which can achieve strong performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86BiPETE\u6a21\u578b\uff0c\u7ed3\u5408\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\u548c\u6b63\u5f26\u5d4c\u5165\u6765\u5904\u7406\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u5728\u6291\u90c1\u548cPTSD\u961f\u5217\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u9152\u7cbe\u548c\u7269\u8d28\u4f7f\u7528\u969c\u788d\u98ce\u9669\u7684\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u57fa\u4e8eTransformer\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u75be\u75c5\u98ce\u9669\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u5c31\u8bca\u95f4\u9694\u4e0d\u89c4\u5219\u548c\u7f3a\u4e4f\u7edf\u4e00\u7ed3\u6784\uff0c\u5efa\u6a21\u65f6\u95f4\u4f9d\u8d56\u6027\u4ecd\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86Bi-Positional Embedding Transformer Encoder (BiPETE)\u6a21\u578b\uff0c\u96c6\u6210\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\u7f16\u7801\u76f8\u5bf9\u5c31\u8bca\u65f6\u95f4\uff0c\u6b63\u5f26\u5d4c\u5165\u4fdd\u6301\u5c31\u8bca\u987a\u5e8f\uff0c\u5728\u4e24\u4e2a\u5fc3\u7406\u5065\u5eb7\u961f\u5217\u4e0a\u8bad\u7ec3\u9884\u6d4bASUD\u98ce\u9669\u3002", "result": "BiPETE\u5728\u6291\u90c1\u548cPTSD\u961f\u5217\u4e2d\u5206\u522b\u5c06AUPRC\u63d0\u9ad8\u4e8634%\u548c50%\uff0c\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e86\u53cc\u4f4d\u7f6e\u7f16\u7801\u7b56\u7565\u7684\u6709\u6548\u6027\u3002\u901a\u8fc7\u96c6\u6210\u68af\u5ea6\u65b9\u6cd5\u8bc6\u522b\u51fa\u4e0eASUD\u98ce\u9669\u76f8\u5173\u7684\u5173\u952e\u4e34\u5e8a\u7279\u5f81\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u75be\u75c5\u98ce\u9669\u9884\u6d4b\u6846\u67b6\uff0c\u80fd\u591f\u5b9e\u73b0\u5f3a\u5927\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u4e3a\u98ce\u9669\u7f13\u89e3\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u7ebf\u7d22\u3002"}}
