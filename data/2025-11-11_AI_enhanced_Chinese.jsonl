{"id": "2511.05529", "pdf": "https://arxiv.org/pdf/2511.05529", "abs": "https://arxiv.org/abs/2511.05529", "authors": ["Jophy Lin"], "title": "Selective Diabetic Retinopathy Screening with Accuracy-Weighted Deep Ensembles and Entropy-Guided Abstention", "categories": ["q-bio.QM", "cs.AI", "cs.CV"], "comment": null, "summary": "Diabetic retinopathy (DR), a microvascular complication of diabetes and a leading cause of preventable blindness, is projected to affect more than 130 million individuals worldwide by 2030. Early identification is essential to reduce irreversible vision loss, yet current diagnostic workflows rely on methods such as fundus photography and expert review, which remain costly and resource-intensive. This, combined with DR's asymptomatic nature, results in its underdiagnosis rate of approximately 25 percent. Although convolutional neural networks (CNNs) have demonstrated strong performance in medical imaging tasks, limited interpretability and the absence of uncertainty quantification restrict clinical reliability. Therefore, in this study, a deep ensemble learning framework integrated with uncertainty estimation is introduced to improve robustness, transparency, and scalability in DR detection. The ensemble incorporates seven CNN architectures-ResNet-50, DenseNet-121, MobileNetV3 (Small and Large), and EfficientNet (B0, B2, B3)- whose outputs are fused through an accuracy-weighted majority voting strategy. A probability-weighted entropy metric quantifies prediction uncertainty, enabling low-confidence samples to be excluded or flagged for additional review. Training and validation on 35,000 EyePACS retinal fundus images produced an unfiltered accuracy of 93.70 percent (F1 = 0.9376). Uncertainty-filtering later was conducted to remove unconfident samples, resulting in maximum-accuracy of 99.44 percent (F1 = 0.9932). The framework shows that uncertainty-aware, accuracy-weighted ensembling improves reliability without hindering performance. With confidence-calibrated outputs and a tunable accuracy-coverage trade-off, it offers a generalizable paradigm for deploying trustworthy AI diagnostics in high-risk care.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u96c6\u6210\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u6765\u6539\u8fdb\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\u3001\u900f\u660e\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\u662f\u5168\u7403\u53ef\u9884\u9632\u6027\u5931\u660e\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u4f46\u5f53\u524d\u8bca\u65ad\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u8d44\u6e90\u5bc6\u96c6\uff0c\u4e14\u5b58\u5728\u7ea625%\u7684\u6f0f\u8bca\u7387\u3002\u867d\u7136CNN\u5728\u533b\u5b66\u5f71\u50cf\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u6709\u9650\u7684\u53ef\u89e3\u91ca\u6027\u548c\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u9650\u5236\u4e86\u5176\u4e34\u5e8a\u53ef\u9760\u6027\u3002", "method": "\u96c6\u6210\u4e03\u4e2aCNN\u67b6\u6784\uff08ResNet-50\u3001DenseNet-121\u3001MobileNetV3\u5c0f/\u5927\u3001EfficientNet B0/B2/B3\uff09\uff0c\u901a\u8fc7\u7cbe\u5ea6\u52a0\u6743\u591a\u6570\u6295\u7968\u7b56\u7565\u878d\u5408\u8f93\u51fa\u3002\u4f7f\u7528\u6982\u7387\u52a0\u6743\u71b5\u5ea6\u91cf\u91cf\u5316\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u80fd\u591f\u6392\u9664\u6216\u6807\u8bb0\u4f4e\u7f6e\u4fe1\u5ea6\u6837\u672c\u3002", "result": "\u572835,000\u5f20EyePACS\u89c6\u7f51\u819c\u773c\u5e95\u56fe\u50cf\u4e0a\u8bad\u7ec3\u9a8c\u8bc1\uff0c\u672a\u8fc7\u6ee4\u51c6\u786e\u7387\u4e3a93.70%\uff08F1=0.9376\uff09\u3002\u4e0d\u786e\u5b9a\u6027\u8fc7\u6ee4\u540e\uff0c\u6700\u9ad8\u51c6\u786e\u7387\u8fbe\u523099.44%\uff08F1=0.9932\uff09\u3002", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u7cbe\u5ea6\u52a0\u6743\u96c6\u6210\u5728\u4e0d\u5f71\u54cd\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u53ef\u9760\u6027\u3002\u5177\u6709\u7f6e\u4fe1\u5ea6\u6821\u51c6\u8f93\u51fa\u548c\u53ef\u8c03\u7cbe\u5ea6-\u8986\u76d6\u6743\u8861\uff0c\u4e3a\u9ad8\u98ce\u9669\u62a4\u7406\u4e2d\u90e8\u7f72\u53ef\u4fe1AI\u8bca\u65ad\u63d0\u4f9b\u4e86\u901a\u7528\u8303\u4f8b\u3002"}}
{"id": "2511.06426", "pdf": "https://arxiv.org/pdf/2511.06426", "abs": "https://arxiv.org/abs/2511.06426", "authors": ["Kaikwan Lau", "Gary P. T. Choi"], "title": "Geometric and statistical analysis of avian skull morphology", "categories": ["q-bio.QM"], "comment": null, "summary": "Understanding the growth and form of shapes is one of the most fundamental problems in biology. While many prior works have analyzed the beak shapes of Darwin's finches, other cranial features are relatively less explored. In this work, we develop geometric and statistical methods for analyzing the skull morphology of Darwin's finches and their relatives, focusing on the relationship between their skull dimensions, orbit curvature, and neurocranial geometries. Specifically, by utilizing tools in computational geometry, differential geometry, and numerical optimization, we develop efficient algorithms for quantifying various key geometric features of the skull. We then perform a statistical analysis and discover a strong correlation between skull size and orbit curvature. Based on our findings, we further establish a predictive model that can estimate the orbit curvature using easily obtainable linear skull measurements. Our results show that the predictive model is highly effective and is capable of explaining 85.48\\% of the variance (R-squared) in curvature with an average prediction error of only 6.35\\%. Altogether, our work provides a quantitative foundation for understanding the functional and evolutionary pressures that shape avian skulls, thereby offering a validated framework for future studies in comparative anatomy and evolutionary biology.", "AI": {"tldr": "\u5f00\u53d1\u51e0\u4f55\u548c\u7edf\u8ba1\u65b9\u6cd5\u5206\u6790\u8fbe\u5c14\u6587\u96c0\u53ca\u5176\u4eb2\u5c5e\u7684\u5934\u9aa8\u5f62\u6001\uff0c\u53d1\u73b0\u5934\u9aa8\u5927\u5c0f\u4e0e\u773c\u7736\u66f2\u7387\u5b58\u5728\u5f3a\u76f8\u5173\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u57fa\u4e8e\u7ebf\u6027\u5934\u9aa8\u6d4b\u91cf\u9884\u6d4b\u773c\u7736\u66f2\u7387\u7684\u6709\u6548\u6a21\u578b\u3002", "motivation": "\u7406\u89e3\u751f\u7269\u5f62\u72b6\u7684\u751f\u957f\u548c\u5f62\u6001\u662f\u751f\u7269\u5b66\u4e2d\u6700\u57fa\u672c\u7684\u95ee\u9898\u4e4b\u4e00\u3002\u867d\u7136\u5df2\u6709\u8bb8\u591a\u7814\u7a76\u5206\u6790\u4e86\u8fbe\u5c14\u6587\u96c0\u7684\u5599\u5f62\uff0c\u4f46\u5176\u4ed6\u9885\u9aa8\u7279\u5f81\u76f8\u5bf9\u8f83\u5c11\u63a2\u7d22\u3002", "method": "\u5229\u7528\u8ba1\u7b97\u51e0\u4f55\u3001\u5fae\u5206\u51e0\u4f55\u548c\u6570\u503c\u4f18\u5316\u5de5\u5177\uff0c\u5f00\u53d1\u9ad8\u6548\u7b97\u6cd5\u91cf\u5316\u5934\u9aa8\u7684\u5173\u952e\u51e0\u4f55\u7279\u5f81\uff0c\u7136\u540e\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u5e76\u5efa\u7acb\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u53d1\u73b0\u5934\u9aa8\u5927\u5c0f\u4e0e\u773c\u7736\u66f2\u7387\u5b58\u5728\u5f3a\u76f8\u5173\u6027\uff0c\u5efa\u7acb\u7684\u9884\u6d4b\u6a21\u578b\u80fd\u591f\u89e3\u91ca85.48%\u7684\u66f2\u7387\u65b9\u5dee\uff0c\u5e73\u5747\u9884\u6d4b\u8bef\u5dee\u4ec5\u4e3a6.35%\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u5851\u9020\u9e1f\u7c7b\u5934\u9aa8\u7684\u529f\u80fd\u548c\u8fdb\u5316\u538b\u529b\u63d0\u4f9b\u4e86\u5b9a\u91cf\u57fa\u7840\uff0c\u4e3a\u6bd4\u8f83\u89e3\u5256\u5b66\u548c\u8fdb\u5316\u751f\u7269\u5b66\u7684\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u9a8c\u8bc1\u6846\u67b6\u3002"}}
{"id": "2511.06662", "pdf": "https://arxiv.org/pdf/2511.06662", "abs": "https://arxiv.org/abs/2511.06662", "authors": ["Franklin Lee", "Tengfei Ma"], "title": "Dual-Pathway Fusion of EHRs and Knowledge Graphs for Predicting Unseen Drug-Drug Interactions", "categories": ["cs.LG", "q-bio.QM"], "comment": "ML4H 2025 Findings", "summary": "Drug-drug interactions (DDIs) remain a major source of preventable harm, and many clinically important mechanisms are still unknown. Existing models either rely on pharmacologic knowledge graphs (KGs), which fail on unseen drugs, or on electronic health records (EHRs), which are noisy, temporal, and site-dependent. We introduce, to our knowledge, the first system that conditions KG relation scoring on patient-level EHR context and distills that reasoning into an EHR-only model for zero-shot inference. A fusion \"Teacher\" learns mechanism-specific relations for drug pairs represented in both sources, while a distilled \"Student\" generalizes to new or rarely used drugs without KG access at inference. Both operate under a shared ontology (set) of pharmacologic mechanisms (drug relations) to produce interpretable, auditable alerts rather than opaque risk scores. Trained on a multi-institution EHR corpus paired with a curated DrugBank DDI graph, and evaluated using a clinically aligned, decision-focused protocol with leakage-safe negatives that avoid artificially easy pairs, the system maintains precision across multi-institutuion test data, produces mechanism-specific, clinically consistent predictions, reduces false alerts (higher precision) at comparable overall detection performance (F1), and misses fewer true interactions compared to prior methods. Case studies further show zero-shot identification of clinically recognized CYP-mediated and pharmacodynamic mechanisms for drugs absent from the KG, supporting real-world use in clinical decision support and pharmacovigilance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u548c\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u6559\u5e08-\u5b66\u751f\u84b8\u998f\u6846\u67b6\u5b9e\u73b0\u96f6\u6837\u672cDDI\u9884\u6d4b\uff0c\u80fd\u591f\u5728\u672a\u89c1\u836f\u7269\u4e0a\u4ea7\u751f\u53ef\u89e3\u91ca\u7684\u673a\u5236\u7279\u5f02\u6027\u8b66\u62a5", "motivation": "\u73b0\u6709DDI\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u672a\u89c1\u836f\u7269\uff0c\u57fa\u4e8e\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7684\u65b9\u6cd5\u5b58\u5728\u566a\u58f0\u3001\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u7ad9\u70b9\u4f9d\u8d56\u6027\u95ee\u9898", "method": "\u4f7f\u7528\u878d\u5408\u6559\u5e08\u6a21\u578b\u5b66\u4e60\u77e5\u8bc6\u56fe\u8c31\u548c\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u7684\u836f\u7269\u5173\u7cfb\uff0c\u7136\u540e\u84b8\u998f\u5230\u4ec5\u4f7f\u7528\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7684\u5b66\u751f\u6a21\u578b\uff0c\u5171\u4eab\u836f\u7406\u5b66\u673a\u5236\u672c\u4f53\u4ee5\u4ea7\u751f\u53ef\u89e3\u91ca\u7684\u8b66\u62a5", "result": "\u5728\u591a\u4e2a\u673a\u6784\u6570\u636e\u4e0a\u4fdd\u6301\u7cbe\u5ea6\uff0c\u4ea7\u751f\u673a\u5236\u7279\u5f02\u6027\u9884\u6d4b\uff0c\u51cf\u5c11\u8bef\u62a5\uff0c\u5728\u53ef\u6bd4\u68c0\u6d4b\u6027\u80fd\u4e0b\u6f0f\u62a5\u66f4\u5c11\u771f\u5b9e\u76f8\u4e92\u4f5c\u7528", "conclusion": "\u7cfb\u7edf\u80fd\u591f\u96f6\u6837\u672c\u8bc6\u522b\u77e5\u8bc6\u56fe\u8c31\u4e2d\u672a\u89c1\u836f\u7269\u7684\u4e34\u5e8a\u8ba4\u53ef\u673a\u5236\uff0c\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u548c\u836f\u7269\u8b66\u6212\u7684\u5b9e\u9645\u5e94\u7528"}}
