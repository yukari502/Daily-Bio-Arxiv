<div id=toc></div>

# Table of Contents

- [q-bio.QM](#q-bio.QM) [Total: 2]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [stat.AP](#stat.AP) [Total: 1]


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [1] [Bio AI Agent: A Multi-Agent Artificial Intelligence System for Autonomous CAR-T Cell Therapy Development with Integrated Target Discovery, Toxicity Prediction, and Rational Molecular Design](https://arxiv.org/abs/2511.08649)
*Yi Ni,Liwei Zhu,Shuai Li*

Main category: q-bio.QM

TL;DR: Bio AI Agent是一个基于大语言模型的多智能体AI系统，能够通过协作的专门化智能体实现自主CAR-T开发，解决靶点选择、安全性评估和分子优化等关键效率问题。


<details>
  <summary>Details</summary>
Motivation: CAR-T疗法开发周期长（8-12年）且临床失败率高（40-60%），在靶点选择、安全性评估和分子优化方面存在关键效率问题，需要更智能的系统来加速免疫疗法开发。

Method: 系统包含六个自主智能体：靶点选择智能体（多参数抗原优先排序）、毒性预测智能体（整合组织表达图谱和药物警戒数据库）、分子设计智能体（理性CAR工程）、专利情报智能体（自由操作分析）、临床转化智能体（监管合规）和决策编排智能体（多智能体协调）。

Result: 回顾性验证显示系统能自主识别高风险靶点（如FcRH5的肝毒性、CD229的脱靶毒性）、CD38+SLAMF7组合的专利侵权风险，并生成全面的开发路线图。

Conclusion: Bio AI Agent通过并行处理、专门化推理和自主决策，解决了精准肿瘤学开发中的关键差距，有潜力加速下一代免疫疗法从发现到临床的转化。

Abstract: Chimeric antigen receptor T-cell (CAR-T) therapy represents a paradigm shift in cancer treatment, yet development timelines of 8-12 years and clinical attrition rates exceeding 40-60% highlight critical inefficiencies in target selection, safety assessment, and molecular optimization. We present Bio AI Agent, a multi-agent artificial intelligence system powered by large language models that enables autonomous CAR-T development through collaborative specialized agents. The system comprises six autonomous agents: Target Selection Agent for multi-parametric antigen prioritization across >10,000 cancer-associated targets, Toxicity Prediction Agent for comprehensive safety profiling integrating tissue expression atlases and pharmacovigilance databases, Molecular Design Agent for rational CAR engineering, Patent Intelligence Agent for freedom-to-operate analysis, Clinical Translation Agent for regulatory compliance, and Decision Orchestration Agent for multi-agent coordination. Retrospective validation demonstrated autonomous identification of high-risk targets including FcRH5 (hepatotoxicity) and CD229 (off-tumor toxicity), patent infringement risks for CD38+SLAMF7 combinations, and generation of comprehensive development roadmaps. By enabling parallel processing, specialized reasoning, and autonomous decision-making superior to monolithic AI systems, Bio AI Agent addresses critical gaps in precision oncology development and has potential to accelerate translation of next-generation immunotherapies from discovery to clinic.

</details>


### [2] [OMOP ETL Framework for Semi-Structured Health Data](https://arxiv.org/abs/2511.09017)
*Jacob Desmond,Ryan Wartmann,Chng Wei Lau,Steven Thomas,Paul M. Middleton,Jeewani Anupama Ginige*

Main category: q-bio.QM

TL;DR: 提出了一个支持关系型数据库和文档型数据库的医疗数据标准化框架，能够将异构医疗数据转换为OMOP-CDM标准格式，并验证了其在270万患者记录上的有效性。


<details>
  <summary>Details</summary>
Motivation: 医疗数据格式多样，难以跨机构和研究复用，需要标准化以实现大规模分析。OMOP-CDM是广泛采用的标准，但需要支持多种数据源的转换方案。

Method: 扩展现有文献，使用人类可读的YAML规范实现模式无关的转换，支持MSSQL和MongoDB数据源，包含溯源感知映射和增量更新等生产就绪特性。

Result: 使用6家医院20年间的270万患者记录和2700万次就诊记录验证，生成的OMOP-CDM数据集在OHDSI数据质量仪表板检查中达到97%的总体通过率。

Conclusion: 该工作为大规模数据协调提供了可复用的蓝图，直接支持真实世界医学数据研究。

Abstract: Healthcare data are generated in many different formats, which makes it difficult to integrate and reuse across institutions and studies. Standardisation is required to enable consistent large-scale analysis. The OMOP-CDM, developed by the OHDSI community, provides one widely adopted standard. Our framework achieves schema-agnostic transformation by extending upon existing literature in using human-readable YAML specification to support both relational (Microsoft SQL Server (MSSQL)) and document-based (MongoDB) data sources. It also incorporates critical production readiness features: provenance-aware mapping and support for incremental updates. We validated the pipeline using 2.7 million patient records and 27 million encounters across six hospitals spanning two decades of records. The resulting OMOP-CDM dataset demonstrated an acceptable level of data quality with a 97% overall passing rate based on the OHDSI Data Quality Dashboard check. Our work provides a reusable blueprint for large-scale data harmonisation, directly supporting real-world medical data research.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [3] [Measuring irreversibility in stochastic systems by categorizing single-molecule displacements](https://arxiv.org/abs/2511.09183)
*Alvaro Lanza,Inés Martínez-Martín,Rafael Tapia-Rojo,Stefano Bo*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种量化随机朗之万系统不可逆性的物理量，通过观测单个分子位移来测量不可逆性，无需了解系统的力和波动幅度。


<details>
  <summary>Details</summary>
Motivation: 量化非平衡过程的不可逆性和耗散对于理解其行为、评估能力和表征效率至关重要。

Method: 基于分子初始和最终位置将位移分类为几个组别，通过条件涨落定理与熵产生关联，提供平均熵产生的下界估计。

Result: 在单分子力谱实验中验证了该方法，证明不可逆性对蛋白质折叠动力学能量景观的细节特征敏感。

Conclusion: 该方法可用于揭示蛋白质折叠过程的关键特性，为研究非平衡系统提供了无模型估计工具。

Abstract: Quantifying the irreversibility and dissipation of non-equilibrium processes is crucial to understanding their behavior, assessing their possible capabilities, and characterizing their efficiency. We introduce a physical quantity that quantifies the irreversibility of stochastic Langevin systems from the observation of individual molecules' displacements. Categorizing these displacements into a few groups based on their initial and final position allows us to measure irreversibility precisely without the need to know the forces and magnitude of the fluctuations acting on the system. Our model-free estimate of irreversibility is related to entropy production by a conditional fluctuation theorem and provides a lower bound to the average entropy production. We validate the method on single-molecule force spectroscopy experiments of proteins subject to force ramps. We show that irreversibility is sensitive to detailed features of the energy landscape underlying the protein folding dynamics and suggest how our methods can be employed to unveil key properties of protein folding processes.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [DeepDR: an integrated deep-learning model web server for drug repositioning](https://arxiv.org/abs/2511.08921)
*Shuting Jin,Yi Jiang,Yimin Liu,Tengfei Ma,Dongsheng Cao,Leyi Wei,Xiangrong Liu,Xiangxiang Zeng*

Main category: cs.LG

TL;DR: DeepDR是一个集成多种深度学习模型的首个药物重定位平台，无需编程技能即可使用，整合了15个网络和包含590万边的关系知识图谱，覆盖药物、疾病、蛋白质等107种关系类型。


<details>
  <summary>Details</summary>
Motivation: 药物重定位是一个复杂耗时的过程，需要药理学、临床数据和计算方法的深入知识。深度学习虽能准确预测，但实施需要专业领域知识和编程技能。

Method: 整合多种已建立的深度学习模型，构建包含590万边的关系知识图谱，覆盖药物、疾病、蛋白质、通路等107种关系类型，从6个现有数据库和2400万PubMed文献中提取数据。

Result: 开发出首个集成深度学习模型的药物重定位平台，能够推荐候选药物并提供详细描述，通过知识图谱可视化关键模式，具有可解释性。

Conclusion: DeepDR是一个免费开放的平台，无需注册，为实验和计算科学家提供易用、系统、高精度且计算自动化的药物重定位解决方案。

Abstract: Background: Identifying new indications for approved drugs is a complex and time-consuming process that requires extensive knowledge of pharmacology, clinical data, and advanced computational methods. Recently, deep learning (DL) methods have shown their capability for the accurate prediction of drug repositioning. However, implementing DL-based modeling requires in-depth domain knowledge and proficient programming skills. Results: In this application, we introduce DeepDR, the first integrated platform that combines a variety of established DL-based models for disease- and target-specific drug repositioning tasks. DeepDR leverages invaluable experience to recommend candidate drugs, which covers more than 15 networks and a comprehensive knowledge graph that includes 5.9 million edges across 107 types of relationships connecting drugs, diseases, proteins/genes, pathways, and expression from six existing databases and a large scientific corpus of 24 million PubMed publications. Additionally, the recommended results include detailed descriptions of the recommended drugs and visualize key patterns with interpretability through a knowledge graph. Conclusion: DeepDR is free and open to all users without the requirement of registration. We believe it can provide an easy-to-use, systematic, highly accurate, and computationally automated platform for both experimental and computational scientists.

</details>


### [5] [Controllable protein design through Feynman-Kac steering](https://arxiv.org/abs/2511.09216)
*Erik Hartman,Jonas Wallin,Johan Malmström,Jimmy Olsson*

Main category: cs.LG

TL;DR: 该论文将Feynman-Kac（FK）引导框架扩展到基于扩散的蛋白质设计，通过在推理时控制来引导蛋白质结构生成朝向特定的功能或生化目标，如结合亲和力或序列组成。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的蛋白质结构生成模型虽然能产生真实多样的结构，但难以主动引导结果朝向特定的功能或生化目标，如结合亲和力或序列组成。

Method: 将FK引导框架与结构生成耦合，在保持底层扩散过程多样性的同时，引导采样朝向理想的结构或能量特征。为了同时生成序列和结构属性，在通过ProteinMPNN和全原子松弛精炼的模型上计算奖励。

Result: 应用于结合剂设计时，FK引导在不同目标上一致改善了预测的界面能量学，且计算开销最小。

Conclusion: 推理时FK控制将基于扩散的蛋白质设计推广到任意、不可微分和奖励不可知的目标，为引导分子生成提供了一个统一且模型无关的框架。

Abstract: Diffusion-based models have recently enabled the generation of realistic and diverse protein structures, yet they remain limited in their ability to steer outcomes toward specific functional or biochemical objectives, such as binding affinity or sequence composition. Here we extend the Feynman-Kac (FK) steering framework, an inference-time control approach, to diffusion-based protein design. By coupling FK steering with structure generation, the method guides sampling toward desirable structural or energetic features while maintaining the diversity of the underlying diffusion process. To enable simultaneous generation of both sequence and structure properties, rewards are computed on models refined through ProteinMPNN and all-atom relaxation. Applied to binder design, FK steering consistently improves predicted interface energetics across diverse targets with minimal computational overhead. More broadly, this work demonstrates that inference-time FK control generalizes diffusion-based protein design to arbitrary, non-differentiable, and reward-agnostic objectives, providing a unified and model-independent framework for guided molecular generation.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [6] [Backcasting biodiversity at high spatiotemporal resolution using flexible site-occupancy models for opportunistically sampled citizen science data](https://arxiv.org/abs/2511.08802)
*Maxime Fajgenblat,Marc Herremans,Pieter Vanormelingen,Kristijn Swinnen,Dirk Maes,Robby Stoks,Luc De Meester,Christel Faes,Thomas Neyens*

Main category: stat.AP

TL;DR: 提出了一种灵活的贝叶斯时空站点占用模型，用于分析公民科学数据，能够进行高分辨率的时空回溯预测和丰富的生物学推断。


<details>
  <summary>Details</summary>
Motivation: 现有的站点占用模型往往忽略检测过程的重要方面，未能充分利用公民科学数据集中的信息，无法进行精细的时空回溯预测。

Method: 开发了灵活的贝叶斯时空站点占用模型，模拟公民科学数据生成过程，应用于比利时超过300万条蝴蝶观测记录。

Result: 该方法能够进行高分辨率的时空回溯预测，推断年度分布趋势、范围动态、栖息地偏好、物候模式、检测模式和观察者异质性。

Conclusion: 该模型可以提高自然学家和公民科学家机会性收集数据的价值，帮助理解缺乏严格收集数据的物种的时空动态。

Abstract: For many taxonomic groups, online biodiversity portals used by naturalists and citizen scientists constitute the primary source of distributional information. Over the last decade, site-occupancy models have been advanced as a promising framework to analyse such loosely structured, opportunistically collected datasets. Current approaches often ignore important aspects of the detection process and do not fully capitalise on the information present in these datasets, leaving opportunities for fine-grained spatiotemporal backcasting untouched. We propose a flexible Bayesian spatiotemporal site-occupancy model that aims to mimic the data-generating process that underlies common citizen science datasets sourced from public biodiversity portals, and yields rich biological output. We illustrate the use of the model to a dataset containing over 3M butterfly records in Belgium, collected through the citizen science data portal Observations.be. We show that the proposed approach enables retrospective predictions on the occupancy of species through time and space at high resolution, as well as inference on inter-annual distributional trends, range dynamics, habitat preferences, phenological patterns, detection patterns and observer heterogeneity. The proposed model can be used to increase the value of opportunistically collected data by naturalists and citizen scientists, and can aid the understanding of spatiotemporal dynamics of species for which rigorously collected data are absent or too costly to collect.

</details>
