{"id": "2511.09571", "pdf": "https://arxiv.org/pdf/2511.09571", "abs": "https://arxiv.org/abs/2511.09571", "authors": ["Margaret R. Martin", "Soha Hassoun"], "title": "General Intelligence-based Fragmentation (GIF): A framework for peak-labeled spectra simulation", "categories": ["q-bio.QM", "cs.AI"], "comment": null, "summary": "Despite growing reference libraries and advanced computational tools, progress in the field of metabolomics remains constrained by low rates of annotating measured spectra. The recent developments of large language models (LLMs) have led to strong performance across a wide range of generation and reasoning tasks, spurring increased interest in LLMs' application to domain-specific scientific challenges, such as mass spectra annotation. Here, we present a novel framework, General Intelligence-based Fragmentation (GIF), that guides pretrained LLMs through spectra simulation using structured prompting and reasoning. GIF utilizes tagging, structured inputs/outputs, system prompts, instruction-based prompts, and iterative refinement. Indeed, GIF offers a structured alternative to ad hoc prompting, underscoring the need for systematic guidance of LLMs on complex scientific tasks. Using GIF, we evaluate current generalist LLMs' ability to use reasoning towards fragmentation and to perform intensity prediction after fine-tuning. We benchmark performance on a novel QA dataset, the MassSpecGym QA-sim dataset, that we derive from the MassSpecGym dataset. Through these implementations of GIF, we find that GPT-4o and GPT-4o-mini achieve a cosine similarity of 0.36 and 0.35 between the simulated and true spectra, respectively, outperforming other pretrained models including GPT-5, Llama-3.1, and ChemDFM, despite GPT-5's recency and ChemDFM's domain specialization. GIF outperforms several deep learning baselines. Our evaluation of GIF highlights the value of using LLMs not only for spectra simulation but for enabling human-in-the-loop workflows and structured, explainable reasoning in molecular fragmentation.", "AI": {"tldr": "GIF\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u548c\u63a8\u7406\u6307\u5bfc\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8d28\u8c31\u6a21\u62df\uff0c\u5728\u8d28\u8c31\u6ce8\u91ca\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u6709\u4e0d\u65ad\u589e\u957f\u7684\u53c2\u8003\u5e93\u548c\u5148\u8fdb\u8ba1\u7b97\u5de5\u5177\uff0c\u4ee3\u8c22\u7ec4\u5b66\u9886\u57df\u4ecd\u53d7\u9650\u4e8e\u8d28\u8c31\u6ce8\u91ca\u7387\u4f4e\u7684\u95ee\u9898\u3002\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u548c\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u4f18\u5f02\u8868\u73b0\u6fc0\u53d1\u4e86\u5c06\u5176\u5e94\u7528\u4e8e\u8d28\u8c31\u6ce8\u91ca\u7b49\u79d1\u5b66\u6311\u6218\u7684\u5174\u8da3\u3002", "method": "GIF\u6846\u67b6\u4f7f\u7528\u6807\u8bb0\u3001\u7ed3\u6784\u5316\u8f93\u5165/\u8f93\u51fa\u3001\u7cfb\u7edf\u63d0\u793a\u3001\u57fa\u4e8e\u6307\u4ee4\u7684\u63d0\u793a\u548c\u8fed\u4ee3\u4f18\u5316\u6765\u6307\u5bfc\u9884\u8bad\u7ec3LLMs\u8fdb\u884c\u8d28\u8c31\u6a21\u62df\u3002\u5728MassSpecGym QA-sim\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "GPT-4o\u548cGPT-4o-mini\u5728\u6a21\u62df\u8c31\u4e0e\u771f\u5b9e\u8c31\u4e4b\u95f4\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5206\u522b\u8fbe\u52300.36\u548c0.35\uff0c\u4f18\u4e8eGPT-5\u3001Llama-3.1\u548cChemDFM\u7b49\u6a21\u578b\uff0c\u4e5f\u4f18\u4e8e\u591a\u4e2a\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "GIF\u6846\u67b6\u4e0d\u4ec5\u53ef\u7528\u4e8e\u8d28\u8c31\u6a21\u62df\uff0c\u8fd8\u80fd\u5b9e\u73b0\u4eba\u673a\u534f\u4f5c\u5de5\u4f5c\u6d41\u7a0b\u548c\u5206\u5b50\u788e\u7247\u5316\u7684\u7ed3\u6784\u5316\u3001\u53ef\u89e3\u91ca\u63a8\u7406\uff0c\u7a81\u663e\u4e86\u5728\u590d\u6742\u79d1\u5b66\u4efb\u52a1\u4e2d\u7cfb\u7edf\u6307\u5bfcLLMs\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.09576", "pdf": "https://arxiv.org/pdf/2511.09576", "abs": "https://arxiv.org/abs/2511.09576", "authors": ["Abraham Francisco Arellano Tavara", "Umesh Kumar", "Jathurshan Pradeepkumar", "Jimeng Sun"], "title": "Prostate-VarBench: A Benchmark with Interpretable TabNet Framework for Prostate Cancer Variant Classification", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "Variants of Uncertain Significance (VUS) limit the clinical utility of prostate cancer genomics by delaying diagnosis and therapy when evidence for pathogenicity or benignity is incomplete. Progress is further limited by inconsistent annotations across sources and the absence of a prostate-specific benchmark for fair comparison. We introduce Prostate-VarBench, a curated pipeline for creating prostate-specific benchmarks that integrates COSMIC (somatic cancer mutations), ClinVar (expert-curated clinical variants), and TCGA-PRAD (prostate tumor genomics from The Cancer Genome Atlas) into a harmonized dataset of 193,278 variants supporting patient- or gene-aware splits to prevent data leakage. To ensure data integrity, we corrected a Variant Effect Predictor (VEP) issue that merged multiple transcript records, introducing ambiguity in clinical significance fields. We then standardized 56 interpretable features across eight clinically relevant tiers, including population frequency, variant type, and clinical context. AlphaMissense pathogenicity scores were incorporated to enhance missense variant classification and reduce VUS uncertainty. Building on this resource, we trained an interpretable TabNet model to classify variant pathogenicity, whose step-wise sparse masks provide per-case rationales consistent with molecular tumor board review practices. On the held-out test set, the model achieved 89.9% accuracy with balanced class metrics, and the VEP correction yields an 6.5% absolute reduction in VUS.", "AI": {"tldr": "\u5f00\u53d1\u4e86Prostate-VarBench\uff0c\u4e00\u4e2a\u524d\u5217\u817a\u764c\u7279\u5f02\u6027\u57fa\u56e0\u7ec4\u53d8\u5f02\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6574\u5408\u4e86\u591a\u4e2a\u6570\u636e\u5e93\u7684193,278\u4e2a\u53d8\u5f02\uff0c\u5e76\u8bad\u7ec3\u4e86\u53ef\u89e3\u91ca\u7684TabNet\u6a21\u578b\u7528\u4e8e\u53d8\u5f02\u81f4\u75c5\u6027\u5206\u7c7b\uff0c\u51c6\u786e\u7387\u8fbe89.9%\uff0cVUS\u51cf\u5c116.5%\u3002", "motivation": "\u89e3\u51b3\u524d\u5217\u817a\u764c\u57fa\u56e0\u7ec4\u5b66\u4e2d\u610f\u4e49\u672a\u660e\u53d8\u5f02(VUS)\u95ee\u9898\uff0c\u8fd9\u4e9b\u53d8\u5f02\u56e0\u81f4\u75c5\u6027\u6216\u826f\u6027\u8bc1\u636e\u4e0d\u5b8c\u6574\u800c\u5ef6\u8fdf\u8bca\u65ad\u548c\u6cbb\u7597\uff0c\u540c\u65f6\u7f3a\u4e4f\u524d\u5217\u817a\u7279\u5f02\u6027\u57fa\u51c6\u548c\u4e00\u81f4\u6ce8\u91ca\u9650\u5236\u4e86\u8fdb\u5c55\u3002", "method": "\u521b\u5efa\u524d\u5217\u817a\u7279\u5f02\u6027\u57fa\u51c6\u7ba1\u9053\uff0c\u6574\u5408COSMIC\u3001ClinVar\u548cTCGA-PRAD\u6570\u636e\uff1b\u4fee\u6b63VEP\u8f6c\u5f55\u672c\u5408\u5e76\u95ee\u9898\uff1b\u6807\u51c6\u531656\u4e2a\u53ef\u89e3\u91ca\u7279\u5f81\uff1b\u7eb3\u5165AlphaMissense\u81f4\u75c5\u6027\u8bc4\u5206\uff1b\u8bad\u7ec3\u53ef\u89e3\u91caTabNet\u6a21\u578b\u8fdb\u884c\u53d8\u5f02\u5206\u7c7b\u3002", "result": "\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u523089.9%\u51c6\u786e\u7387\uff0cVEP\u4fee\u6b63\u4f7fVUS\u7edd\u5bf9\u51cf\u5c116.5%\uff1b\u6784\u5efa\u4e86\u5305\u542b193,278\u4e2a\u53d8\u5f02\u7684\u524d\u5217\u817a\u7279\u5f02\u6027\u57fa\u51c6\u6570\u636e\u96c6\u3002", "conclusion": "Prostate-VarBench\u4e3a\u524d\u5217\u817a\u764c\u53d8\u5f02\u5206\u7c7b\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u57fa\u51c6\uff0cTabNet\u6a21\u578b\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u9010\u6b65\u7a00\u758f\u63a9\u7801\u63d0\u4f9b\u4e34\u5e8a\u76f8\u5173\u7406\u7531\uff0c\u663e\u8457\u51cf\u5c11\u4e86VUS\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2511.09583", "pdf": "https://arxiv.org/pdf/2511.09583", "abs": "https://arxiv.org/abs/2511.09583", "authors": ["Dmytro Leontiev", "Abicumaran Uthamacumaran", "Riya Nagar", "Hector Zenil"], "title": "Exhaustive Investigation of CBC-Derived Biomarker Ratios for Clinical Outcome Prediction: The RDW-to-MCHC Ratio as a Novel Mortality Predictor in Critical Care", "categories": ["q-bio.QM"], "comment": "26 pages with Appendix", "summary": "Ratios of common biomarkers and blood analytes are well established for early detection and predictive purposes. Early risk stratification in critical care is often limited by the delayed availability of complex severity scores. Complete blood count (CBC) parameters, available within hours of admission, may enable rapid prognostication. We conducted an exhaustive and systematic evaluation of CBC-derived ratios for mortality prediction to identify robust, accessible, and generalizable biomarkers. We generated all feasible two-parameter CBC ratios with unit checks and plausibility filters on more than 90,000 ICU admissions (MIMIC-IV). Discrimination was assessed via cross-validated and external AUC, calibration via isotonic regression, and clinical utility with decision-curve analysis. Retrospective validation was performed on eICU-CRD (n = 156530) participants. The ratio of Red Cell Distribution Width (RDW) to Mean Corpuscular Hemoglobin Concentration (MCHC), denoted RDW:MCHC, emerged as the top biomarker (AUC = 0.699 discovery; 0.662 validation), outperforming RDW and NLR. It achieved near-universal availability (99.9\\% vs.\\ 35.0\\% for NLR), excellent calibration (Hosmer--Lemeshow $p = 1.0$; $\\mathrm{ECE} < 0.001$), and preserved performance across diagnostic groups, with only modest attenuation in respiratory cases. Expressed as a logistic odds ratio, each one standard deviation increase in RDW:MCHC nearly quadrupled 30-day mortality odds (OR = 3.81, 95\\% CI [3.70, 3.95]). Decision-curve analysis showed positive net benefit at high-risk triage thresholds. A simple, widely available CBC-derived feature (RDW:MCHC) provides consistent, externally validated signal for early mortality risk. While not a substitute for multivariable scores, it offers a pragmatic adjunct for rapid triage when full scoring is impractical.", "AI": {"tldr": "RDW:MCHC\u6bd4\u503c\u662f\u4ece\u8840\u5e38\u89c4\u53c2\u6570\u4e2d\u7b5b\u9009\u51fa\u7684\u6700\u4f73\u6b7b\u4ea1\u7387\u9884\u6d4b\u751f\u7269\u6807\u5fd7\u7269\uff0c\u5728ICU\u60a3\u8005\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u9884\u6d4b\u6027\u80fd\u3001\u901a\u7528\u6027\u548c\u6821\u51c6\u6027\u3002", "motivation": "\u91cd\u75c7\u76d1\u62a4\u4e2d\u65e9\u671f\u98ce\u9669\u5206\u5c42\u5e38\u53d7\u9650\u4e8e\u590d\u6742\u8bc4\u5206\u7cfb\u7edf\u7684\u5ef6\u8fdf\u53ef\u7528\u6027\uff0c\u800c\u8840\u5e38\u89c4\u53c2\u6570\u5728\u5165\u9662\u51e0\u5c0f\u65f6\u5185\u5373\u53ef\u83b7\u5f97\uff0c\u53ef\u80fd\u5b9e\u73b0\u5feb\u901f\u9884\u540e\u8bc4\u4f30\u3002", "method": "\u5bf9\u8d85\u8fc79\u4e07\u4f8bICU\u5165\u9662\u60a3\u8005\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u751f\u6210\u6240\u6709\u53ef\u884c\u7684\u4e24\u53c2\u6570\u8840\u5e38\u89c4\u6bd4\u503c\uff0c\u901a\u8fc7\u4ea4\u53c9\u9a8c\u8bc1\u548c\u5916\u90e8\u9a8c\u8bc1\u8bc4\u4f30\u533a\u5206\u5ea6\u3001\u6821\u51c6\u548c\u4e34\u5e8a\u6548\u7528\u3002", "result": "RDW:MCHC\u6bd4\u503c\u5728\u53d1\u73b0\u961f\u5217\u4e2dAUC\u4e3a0.699\uff0c\u9a8c\u8bc1\u961f\u5217\u4e2d\u4e3a0.662\uff0c\u4f18\u4e8eRDW\u548cNLR\uff0c\u4e14\u53ef\u7528\u6027\u9ad8\u8fbe99.9%\uff0c\u6821\u51c6\u826f\u597d\uff0cOR=3.81\u3002", "conclusion": "RDW:MCHC\u6bd4\u503c\u662f\u4e00\u4e2a\u7b80\u5355\u3001\u5e7f\u6cdb\u53ef\u7528\u7684\u8840\u5e38\u89c4\u884d\u751f\u7279\u5f81\uff0c\u4e3a\u65e9\u671f\u6b7b\u4ea1\u98ce\u9669\u63d0\u4f9b\u4e00\u81f4\u4e14\u5916\u90e8\u9a8c\u8bc1\u7684\u4fe1\u53f7\uff0c\u53ef\u4f5c\u4e3a\u5feb\u901f\u5206\u8bca\u7684\u5b9e\u7528\u8f85\u52a9\u5de5\u5177\u3002"}}
{"id": "2511.10014", "pdf": "https://arxiv.org/pdf/2511.10014", "abs": "https://arxiv.org/abs/2511.10014", "authors": ["Guofeng Meng", "Li Shen", "Qiuyan Zhong", "Wei Wang", "Haizhou Zhang", "Xiaozhen Wang"], "title": "fastbmRAG: A Fast Graph-Based RAG Framework for Efficient Processing of Large-Scale Biomedical Literature", "categories": ["q-bio.QM", "cs.AI"], "comment": "8 pages, 2 figure, 1 table", "summary": "Large language models (LLMs) are rapidly transforming various domains, including biomedicine and healthcare, and demonstrate remarkable potential from scientific research to new drug discovery. Graph-based retrieval-augmented generation (RAG) systems, as a useful application of LLMs, can improve contextual reasoning through structured entity and relationship identification from long-context knowledge, e.g. biomedical literature. Even though many advantages over naive RAGs, most of graph-based RAGs are computationally intensive, which limits their application to large-scale dataset. To address this issue, we introduce fastbmRAG, an fast graph-based RAG optimized for biomedical literature. Utilizing well organized structure of biomedical papers, fastbmRAG divides the construction of knowledge graph into two stages, first drafting graphs using abstracts; and second, refining them using main texts guided by vector-based entity linking, which minimizes redundancy and computational load. Our evaluations demonstrate that fastbmRAG is over 10x faster than existing graph-RAG tools and achieve superior coverage and accuracy to input knowledge. FastbmRAG provides a fast solution for quickly understanding, summarizing, and answering questions about biomedical literature on a large scale. FastbmRAG is public available in https://github.com/menggf/fastbmRAG.", "AI": {"tldr": "fastbmRAG\u662f\u4e00\u4e2a\u9488\u5bf9\u751f\u7269\u533b\u5b66\u6587\u732e\u4f18\u5316\u7684\u5feb\u901f\u56fe\u57fa\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\uff08\u6458\u8981\u8349\u7a3f+\u6b63\u6587\u7cbe\u70bc\uff09\u5b9e\u73b010\u500d\u901f\u5ea6\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8986\u76d6\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u56fe\u57faRAG\u7cfb\u7edf\u5728\u751f\u7269\u533b\u5b66\u9886\u57df\u8ba1\u7b97\u5bc6\u96c6\uff0c\u9650\u5236\u4e86\u5176\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5e94\u7528\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u751f\u7269\u533b\u5b66\u8bba\u6587\u7ed3\u6784\u7279\u70b9\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\uff1a\u5148\u7528\u6458\u8981\u6784\u5efa\u8349\u7a3f\u56fe\uff0c\u518d\u7528\u6b63\u6587\u901a\u8fc7\u5411\u91cf\u5b9e\u4f53\u94fe\u63a5\u8fdb\u884c\u7cbe\u70bc\uff0c\u51cf\u5c11\u5197\u4f59\u548c\u8ba1\u7b97\u8d1f\u62c5\u3002", "result": "fastbmRAG\u6bd4\u73b0\u6709\u56fe\u57faRAG\u5de5\u5177\u5feb10\u500d\u4ee5\u4e0a\uff0c\u5728\u77e5\u8bc6\u8986\u76d6\u7387\u548c\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "fastbmRAG\u4e3a\u5927\u89c4\u6a21\u751f\u7269\u533b\u5b66\u6587\u732e\u7684\u5feb\u901f\u7406\u89e3\u3001\u603b\u7ed3\u548c\u95ee\u7b54\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.10223", "pdf": "https://arxiv.org/pdf/2511.10223", "abs": "https://arxiv.org/abs/2511.10223", "authors": ["David F. Anderson", "Aidan S. Howells", "Diego Rojas La Luz"], "title": "Stochastic Reaction Networks Within Interacting Compartments with Content-Dependent Fragmentation", "categories": ["math.PR", "q-bio.MN"], "comment": "23 pages", "summary": "Stochastic reaction networks with mass-action kinetics provide a useful framework for understanding processes -- biochemical and otherwise -- in homogeneous environments. However, cellular reactions are often compartmentalized, either at the cell level or within cells, and hence non-homogeneous. A general framework for compartmentalized chemistry with dynamic compartments was proposed in (Duso and Zechner, PNAS, 2020), and the special case where the compartment dynamics do not depend on their contents was studied mathematically in (Anderson and Howells, Bull. Math. Biol., 2023). In the present paper, we investigate the case in which the rate of fragmentation of a compartment depends on the abundance of some designated species inside that compartment. The main focus of this work is on providing general conditions for (positive) recurrence and non-explosivity of the models. In particular, we demonstrate that the explosivity characterization from (Anderson and Howells, Bull. Math. Biol., 2023) fails in this setting and provide new sufficient conditions for non-explosivity and positive recurrence, under the assumption that the underlying CRN admits a linear Lyapunov function. These results extend the theoretical foundation for modeling content-mediated compartment dynamics, with implications for systems such as cell division and intracellular transport.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5185\u5bb9\u4ecb\u5bfc\u7684\u533a\u5ba4\u52a8\u529b\u5b66\uff0c\u5176\u4e2d\u533a\u5ba4\u5206\u88c2\u901f\u7387\u53d6\u51b3\u4e8e\u5176\u5185\u90e8\u7279\u5b9a\u7269\u79cd\u7684\u4e30\u5ea6\uff0c\u63d0\u4f9b\u4e86\u975e\u7206\u70b8\u6027\u548c\u6b63\u9012\u5f52\u6027\u7684\u5145\u5206\u6761\u4ef6\u3002", "motivation": "\u7ec6\u80de\u53cd\u5e94\u901a\u5e38\u5728\u533a\u5ba4\u5316\u73af\u5883\u4e2d\u8fdb\u884c\uff0c\u73b0\u6709\u6a21\u578b\u5047\u8bbe\u533a\u5ba4\u52a8\u529b\u5b66\u72ec\u7acb\u4e8e\u5176\u5185\u5bb9\u7269\uff0c\u4f46\u5b9e\u9645\u4e2d\u533a\u5ba4\u5206\u88c2\u5f80\u5f80\u53d7\u5185\u90e8\u7269\u79cd\u5f71\u54cd\uff0c\u9700\u8981\u5efa\u7acb\u66f4\u4e00\u822c\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5728\u5047\u8bbe\u57fa\u7840\u5316\u5b66\u53cd\u5e94\u7f51\u7edc\u5b58\u5728\u7ebf\u6027Lyapunov\u51fd\u6570\u7684\u524d\u63d0\u4e0b\uff0c\u5efa\u7acb\u6570\u5b66\u6a21\u578b\u5206\u6790\u5185\u5bb9\u4f9d\u8d56\u578b\u533a\u5ba4\u5206\u88c2\u7684\u968f\u673a\u52a8\u529b\u5b66\u884c\u4e3a\u3002", "result": "\u8bc1\u660e\u4e86Anderson\u548cHowells\u7684\u7206\u70b8\u6027\u7279\u5f81\u5316\u5728\u6b64\u8bbe\u7f6e\u4e0b\u5931\u6548\uff0c\u5e76\u63d0\u4f9b\u4e86\u65b0\u7684\u975e\u7206\u70b8\u6027\u548c\u6b63\u9012\u5f52\u6027\u5145\u5206\u6761\u4ef6\u3002", "conclusion": "\u6269\u5c55\u4e86\u5185\u5bb9\u4ecb\u5bfc\u533a\u5ba4\u52a8\u529b\u5b66\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5bf9\u7ec6\u80de\u5206\u88c2\u548c\u7ec6\u80de\u5185\u8fd0\u8f93\u7b49\u7cfb\u7edf\u5efa\u6a21\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.09574", "pdf": "https://arxiv.org/pdf/2511.09574", "abs": "https://arxiv.org/abs/2511.09574", "authors": ["Alexander Ingold", "Richard G. Baird", "Dasmeet Kaur", "Nidhi Dwivedi", "Reed Sorenson", "Leslie Sieburth", "Chang-Jun Liu", "Rajesh Menon"], "title": "HAMscope: a snapshot Hyperspectral Autofluorescence Miniscope for real-time molecular imaging", "categories": ["physics.optics", "eess.IV", "q-bio.QM"], "comment": null, "summary": "We introduce HAMscope, a compact, snapshot hyperspectral autofluorescence miniscope that enables real-time, label-free molecular imaging in a wide range of biological systems. By integrating a thin polymer diffuser into a widefield miniscope, HAMscope spectrally encodes each frame and employs a probabilistic deep learning framework to reconstruct 30-channel hyperspectral stacks (452 to 703 nm) or directly infer molecular composition maps from single images. A scalable multi-pass U-Net architecture with transformer-based attention and per-pixel uncertainty estimation enables high spatio-spectral fidelity (mean absolute error ~ 0.0048) at video rates. While initially demonstrated in plant systems, including lignin, chlorophyll, and suberin imaging in intact poplar and cork tissues, the platform is readily adaptable to other applications such as neural activity mapping, metabolic profiling, and histopathology. We show that the system generalizes to out-of-distribution tissue types and supports direct molecular mapping without the need for spectral unmixing. HAMscope establishes a general framework for compact, uncertainty-aware spectral imaging that combines minimal optics with advanced deep learning, offering broad utility for real-time biochemical imaging across neuroscience, environmental monitoring, and biomedicine.", "AI": {"tldr": "HAMscope\u662f\u4e00\u79cd\u7d27\u51d1\u578b\u5feb\u7167\u5f0f\u9ad8\u5149\u8c31\u81ea\u53d1\u8367\u5149\u5fae\u578b\u663e\u5fae\u955c\uff0c\u901a\u8fc7\u96c6\u6210\u805a\u5408\u7269\u6269\u6563\u5668\u548c\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5b9e\u73b0\u5b9e\u65f6\u65e0\u6807\u8bb0\u5206\u5b50\u6210\u50cf\uff0c\u53ef\u91cd\u5efa30\u901a\u9053\u9ad8\u5149\u8c31\u6570\u636e\u6216\u76f4\u63a5\u63a8\u65ad\u5206\u5b50\u7ec4\u6210\u56fe\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5b9e\u65f6\u8fdb\u884c\u65e0\u6807\u8bb0\u5206\u5b50\u6210\u50cf\u7684\u7d27\u51d1\u578b\u9ad8\u5149\u8c31\u663e\u5fae\u955c\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u751f\u7269\u7cfb\u7edf\uff0c\u89e3\u51b3\u4f20\u7edf\u9ad8\u5149\u8c31\u6210\u50cf\u8bbe\u5907\u4f53\u79ef\u5e9e\u5927\u3001\u6210\u672c\u9ad8\u6602\u7684\u95ee\u9898\u3002", "method": "\u5728\u5bbd\u573a\u5fae\u578b\u663e\u5fae\u955c\u4e2d\u96c6\u6210\u8584\u805a\u5408\u7269\u6269\u6563\u5668\u8fdb\u884c\u5149\u8c31\u7f16\u7801\uff0c\u91c7\u7528\u6982\u7387\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u5177\u6709transformer\u6ce8\u610f\u529b\u548c\u9010\u50cf\u7d20\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u53ef\u6269\u5c55\u591a\u901a\u9053U-Net\u67b6\u6784\u3002", "result": "\u5b9e\u73b0\u4e86\u9ad8\u65f6\u7a7a\u5149\u8c31\u4fdd\u771f\u5ea6\uff08\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u7ea60.0048\uff09\uff0c\u89c6\u9891\u901f\u7387\u6210\u50cf\uff0c\u5728\u690d\u7269\u7cfb\u7edf\u4e2d\u6210\u529f\u6210\u50cf\u6728\u8d28\u7d20\u3001\u53f6\u7eff\u7d20\u548c\u6728\u6813\u8d28\uff0c\u7cfb\u7edf\u53ef\u6cdb\u5316\u5230\u5206\u5e03\u5916\u7ec4\u7ec7\u7c7b\u578b\uff0c\u652f\u6301\u65e0\u9700\u5149\u8c31\u89e3\u6df7\u7684\u76f4\u63a5\u5206\u5b50\u6620\u5c04\u3002", "conclusion": "HAMscope\u5efa\u7acb\u4e86\u4e00\u4e2a\u7d27\u51d1\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u5149\u8c31\u6210\u50cf\u901a\u7528\u6846\u67b6\uff0c\u7ed3\u5408\u6700\u5c0f\u5316\u5149\u5b66\u5668\u4ef6\u548c\u5148\u8fdb\u6df1\u5ea6\u5b66\u4e60\uff0c\u4e3a\u795e\u7ecf\u79d1\u5b66\u3001\u73af\u5883\u76d1\u6d4b\u548c\u751f\u7269\u533b\u5b66\u4e2d\u7684\u5b9e\u65f6\u751f\u5316\u6210\u50cf\u63d0\u4f9b\u5e7f\u6cdb\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.10337", "pdf": "https://arxiv.org/pdf/2511.10337", "abs": "https://arxiv.org/abs/2511.10337", "authors": ["D. Evan Piephoff", "Jianshu Cao"], "title": "Stochastic Thermodynamics of Cooperative Biomolecular Machines: Fluctuation Relations and Hidden Detailed Balance Breaking", "categories": ["cond-mat.stat-mech", "physics.bio-ph", "physics.chem-ph", "q-bio.MN"], "comment": null, "summary": "We examine a biomolecular machine involving a driven, observable process coupled to a hidden process in a kinetically cooperative manner. A stochastic thermodynamics framework is employed to analyze a fluctuation theorem for the first-passage time of the observable process under nonequilibrium steady-state conditions. Based on a generic kinetic model, we demonstrate that, along first-passage trajectories, entropy production remains constant when the changes in stochastic entropy and free energy of the machine are balanced, which corresponds to zero net hidden flux through the initial state manifold. Under this condition, which we define quite generally, this first-passage time fluctuation theorem can be established, with its violation serving as an experimentally detectable signature of hidden detailed balance breaking (which we subsequently characterize). In addition, using an enzymatic model, we show that the violation of our first-passage time fluctuation theorem can be thought of as a consequence of the breakdown of local detailed balance in the steps linking coarse-grained states that correspond to the initial and intermediate state manifolds. In the absence of hidden current, the fluctuation theorem is restored, and a mesoscopic local detailed balance condition can be established, which has implications for the thermodynamic analysis of driven, coarse-grained systems. This work sheds significant light on the unique connections between stochastic thermodynamic quantities and kinetic measurements in complex cooperative networks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u751f\u7269\u5206\u5b50\u673a\u5668\uff0c\u5176\u4e2d\u53ef\u89c2\u6d4b\u8fc7\u7a0b\u4e0e\u9690\u85cf\u8fc7\u7a0b\u5728\u52a8\u529b\u5b66\u4e0a\u8026\u5408\u3002\u901a\u8fc7\u968f\u673a\u70ed\u529b\u5b66\u6846\u67b6\uff0c\u5206\u6790\u4e86\u975e\u5e73\u8861\u7a33\u6001\u6761\u4ef6\u4e0b\u53ef\u89c2\u6d4b\u8fc7\u7a0b\u9996\u6b21\u901a\u8fc7\u65f6\u95f4\u7684\u6da8\u843d\u5b9a\u7406\u3002", "motivation": "\u7814\u7a76\u590d\u6742\u5408\u4f5c\u7f51\u7edc\u4e2d\u968f\u673a\u70ed\u529b\u5b66\u91cf\u4e0e\u52a8\u529b\u5b66\u6d4b\u91cf\u4e4b\u95f4\u7684\u72ec\u7279\u8054\u7cfb\uff0c\u7279\u522b\u662f\u5f53\u53ef\u89c2\u6d4b\u8fc7\u7a0b\u4e0e\u9690\u85cf\u8fc7\u7a0b\u8026\u5408\u65f6\uff0c\u9996\u6b21\u901a\u8fc7\u65f6\u95f4\u6da8\u843d\u5b9a\u7406\u7684\u884c\u4e3a\u3002", "method": "\u91c7\u7528\u968f\u673a\u70ed\u529b\u5b66\u6846\u67b6\uff0c\u57fa\u4e8e\u901a\u7528\u52a8\u529b\u5b66\u6a21\u578b\u5206\u6790\u9996\u6b21\u901a\u8fc7\u65f6\u95f4\u7684\u6da8\u843d\u5b9a\u7406\uff0c\u5e76\u901a\u8fc7\u9176\u6a21\u578b\u9a8c\u8bc1\u7406\u8bba\u7ed3\u679c\u3002", "result": "\u5f53\u71b5\u4ea7\u751f\u4fdd\u6301\u6052\u5b9a\uff08\u5373\u968f\u673a\u71b5\u548c\u673a\u5668\u81ea\u7531\u80fd\u53d8\u5316\u5e73\u8861\uff09\u65f6\uff0c\u9996\u6b21\u901a\u8fc7\u65f6\u95f4\u6da8\u843d\u5b9a\u7406\u6210\u7acb\uff1b\u8fdd\u53cd\u8be5\u5b9a\u7406\u53ef\u4f5c\u4e3a\u9690\u85cf\u8be6\u7ec6\u5e73\u8861\u7834\u574f\u7684\u5b9e\u9a8c\u53ef\u68c0\u6d4b\u7279\u5f81\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63ed\u793a\u4e86\u590d\u6742\u5408\u4f5c\u7f51\u7edc\u4e2d\u968f\u673a\u70ed\u529b\u5b66\u91cf\u4e0e\u52a8\u529b\u5b66\u6d4b\u91cf\u4e4b\u95f4\u7684\u91cd\u8981\u8054\u7cfb\uff0c\u4e3a\u9a71\u52a8\u7c97\u7c92\u5316\u7cfb\u7edf\u7684\u70ed\u529b\u5b66\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2511.09581", "pdf": "https://arxiv.org/pdf/2511.09581", "abs": "https://arxiv.org/abs/2511.09581", "authors": ["Phillip Sloan", "Edwin Simpson", "Majid Mirmehdi"], "title": "Clinically-aligned Multi-modal Chest X-ray Classification", "categories": ["eess.IV", "q-bio.QM"], "comment": "9 Pages, 2 Figures, 3 Tables & 2 Supplementary Tables in Appendix. Accepted to ML4H 2025 (Proceedings)", "summary": "Radiology is essential to modern healthcare, yet rising demand and staffing shortages continue to pose major challenges. Recent advances in artificial intelligence have the potential to support radiologists and help address these challenges. Given its widespread use and clinical importance, chest X-ray classification is well suited to augment radiologists' workflows. However, most existing approaches rely solely on single-view, image-level inputs, ignoring the structured clinical information and multi-image studies available at the time of reporting. In this work, we introduce CaMCheX, a multimodal transformer-based framework that aligns multi-view chest X-ray studies with structured clinical data to better reflect how clinicians make diagnostic decisions. Our architecture employs view-specific ConvNeXt encoders for frontal and lateral chest radiographs, whose features are fused with clinical indications, history, and vital signs using a transformer fusion module. This design enables the model to generate context-aware representations that mirror reasoning in clinical practice. Our results exceed the state of the art for both the original MIMIC-CXR dataset and the more recent CXR-LT benchmarks, highlighting the value of clinically grounded multimodal alignment for advancing chest X-ray classification.", "AI": {"tldr": "CaMCheX\u662f\u4e00\u4e2a\u591a\u6a21\u6001Transformer\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u591a\u89c6\u56fe\u80f8\u90e8X\u5149\u7814\u7a76\u4e0e\u7ed3\u6784\u5316\u4e34\u5e8a\u6570\u636e\u5bf9\u9f50\uff0c\u63d0\u5347\u80f8\u90e8X\u5149\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u80f8\u90e8X\u5149\u5206\u7c7b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5355\u89c6\u56fe\u56fe\u50cf\u7ea7\u8f93\u5165\uff0c\u5ffd\u7565\u4e86\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u53ef\u7528\u7684\u7ed3\u6784\u5316\u4e34\u5e8a\u4fe1\u606f\u548c\u591a\u56fe\u50cf\u7814\u7a76\uff0c\u65e0\u6cd5\u53cd\u6620\u4e34\u5e8a\u533b\u751f\u7684\u8bca\u65ad\u51b3\u7b56\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528\u89c6\u56fe\u7279\u5b9a\u7684ConvNeXt\u7f16\u7801\u5668\u5904\u7406\u6b63\u9762\u548c\u4fa7\u9762\u80f8\u7247\uff0c\u901a\u8fc7Transformer\u878d\u5408\u6a21\u5757\u5c06\u56fe\u50cf\u7279\u5f81\u4e0e\u4e34\u5e8a\u6307\u5f81\u3001\u75c5\u53f2\u548c\u751f\u547d\u4f53\u5f81\u7b49\u7ed3\u6784\u5316\u6570\u636e\u878d\u5408\u3002", "result": "\u5728\u539f\u59cbMIMIC-CXR\u6570\u636e\u96c6\u548c\u66f4\u65b0\u7684CXR-LT\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u8d85\u8d8a\u4e86\u73b0\u6709\u6280\u672f\u6c34\u5e73\u3002", "conclusion": "\u57fa\u4e8e\u4e34\u5e8a\u7684\u591a\u6a21\u6001\u5bf9\u9f50\u5bf9\u4e8e\u63a8\u8fdb\u80f8\u90e8X\u5149\u5206\u7c7b\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u80fd\u591f\u751f\u6210\u53cd\u6620\u4e34\u5e8a\u5b9e\u8df5\u63a8\u7406\u7684\u60c5\u5883\u611f\u77e5\u8868\u793a\u3002"}}
{"id": "2511.10609", "pdf": "https://arxiv.org/pdf/2511.10609", "abs": "https://arxiv.org/abs/2511.10609", "authors": ["Praneet Nandan", "Beatriz Pascual-Escudero", "Diego Rojas La Luz"], "title": "Multistationarity in semi-open Phosphorylation-Dephosphorylation Cycles", "categories": ["math.DS", "q-bio.MN"], "comment": "24 pages", "summary": "Multistationarity, underlies biochemical switching and cellular decision-making. We study how multistationarity in the sequential n-site phosphorylation-dephosphorylation cycle is affected when only some species are open, meaning allowed to exchange with the environment (so-called semi-open networks). Working under mass action kinetics, we obtain two complementary structural results for every $n\\geq 2$. First, opening any nonempty subset of the substrate species preserves the network's capacity for nondegenerate multistationarity. Second, opening the enzyme species (both kinase and phosphatase), possibly together with any subset of substrates, always destroys multistationarity. The latter result is proved by a general reduction framework combining the detection of absolute concentration robustness (ACR) with projection onto the remaining species; when the projection is monostationary, the full semi-open system is monostationary. We also illustrate the general method on multi-layer cascade variants and discuss biological implications: opening enzymes acts as a robust switch that converts a potentially multistationary phosphorylation module into a monostationary one, while substrate exchange preserves switching capacity and thus the ability to couple cycles to downstream processes.", "AI": {"tldr": "\u7814\u7a76\u534a\u5f00\u653e\u7f51\u7edc\u4e2dn\u4f4d\u70b9\u987a\u5e8f\u78f7\u9178\u5316-\u53bb\u78f7\u9178\u5316\u5faa\u73af\u7684\u591a\u7a33\u6001\u6027\uff0c\u53d1\u73b0\u5f00\u653e\u5e95\u7269\u7269\u79cd\u4fdd\u7559\u591a\u7a33\u6001\u80fd\u529b\uff0c\u800c\u5f00\u653e\u9176\u7269\u79cd\u4f1a\u7834\u574f\u591a\u7a33\u6001\u6027\u3002", "motivation": "\u591a\u7a33\u6001\u6027\u662f\u751f\u5316\u5f00\u5173\u548c\u7ec6\u80de\u51b3\u7b56\u7684\u57fa\u7840\uff0c\u7814\u7a76\u5728\u90e8\u5206\u7269\u79cd\u5141\u8bb8\u4e0e\u73af\u5883\u4ea4\u6362\u7684\u534a\u5f00\u653e\u7f51\u7edc\u4e2d\uff0c\u591a\u7a33\u6001\u6027\u5982\u4f55\u53d7\u5230\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u8d28\u91cf\u4f5c\u7528\u52a8\u529b\u5b66\uff0c\u901a\u8fc7\u7ed3\u5408\u7edd\u5bf9\u6d53\u5ea6\u7a33\u5065\u6027\u68c0\u6d4b\u548c\u5269\u4f59\u7269\u79cd\u6295\u5f71\u7684\u901a\u7528\u7b80\u5316\u6846\u67b6\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5f00\u653e\u4efb\u4f55\u975e\u7a7a\u5e95\u7269\u5b50\u96c6\u4fdd\u7559\u975e\u9000\u5316\u591a\u7a33\u6001\u6027\uff1b\u5f00\u653e\u9176\u7269\u79cd\uff08\u6fc0\u9176\u548c\u78f7\u9178\u9176\uff09\u603b\u662f\u7834\u574f\u591a\u7a33\u6001\u6027\u3002", "conclusion": "\u9176\u5f00\u653e\u4f5c\u4e3a\u7a33\u5065\u5f00\u5173\u5c06\u6f5c\u5728\u591a\u7a33\u6001\u78f7\u9178\u5316\u6a21\u5757\u8f6c\u6362\u4e3a\u5355\u7a33\u6001\uff0c\u800c\u5e95\u7269\u4ea4\u6362\u4fdd\u7559\u5207\u6362\u80fd\u529b\uff0c\u4fbf\u4e8e\u4e0e\u4e0b\u6e38\u8fc7\u7a0b\u8026\u5408\u3002"}}
{"id": "2511.09588", "pdf": "https://arxiv.org/pdf/2511.09588", "abs": "https://arxiv.org/abs/2511.09588", "authors": ["Vincenzo Marcian\u00f2", "Hava Chaptoukaev", "Virginia Fernandez", "M. Jorge Cardoso", "S\u00e9bastien Ourselin", "Michela Antonelli", "Maria A. Zuluaga"], "title": "Diffusion-Based Quality Control of Medical Image Segmentations across Organs", "categories": ["eess.IV", "q-bio.QM"], "comment": null, "summary": "Medical image segmentation using deep learning (DL) has enabled the development of automated analysis pipelines for large-scale population studies. However, state-of-the-art DL methods are prone to hallucinations, which can result in anatomically implausible segmentations. With manual correction impractical at scale, automated quality control (QC) techniques have to address the challenge. While promising, existing QC methods are organ-specific, limiting their generalizability and usability beyond their original intended task. To overcome this limitation, we propose no-new Quality Control (nnQC), a robust QC framework based on a diffusion-generative paradigm that self-adapts to any input organ dataset. Central to nnQC is a novel Team of Experts (ToE) architecture, where two specialized experts independently encode 3D spatial awareness, represented by the relative spatial position of an axial slice, and anatomical information derived from visual features from the original image. A weighted conditional module dynamically combines the pair of independent embeddings, or opinions to condition the sampling mechanism within a diffusion process, enabling the generation of a spatially aware pseudo-ground truth for predicting QC scores. Within its framework, nnQC integrates fingerprint adaptation to ensure adaptability across organs, datasets, and imaging modalities. We evaluated nnQC on seven organs using twelve publicly available datasets. Our results demonstrate that nnQC consistently outperforms state-of-the-art methods across all experiments, including cases where segmentation masks are highly degraded or completely missing, confirming its versatility and effectiveness across different organs.", "AI": {"tldr": "\u63d0\u51fa\u4e86nnQC\u6846\u67b6\uff0c\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u751f\u6210\u8303\u5f0f\u7684\u81ea\u9002\u5e94\u8d28\u91cf\u63a7\u5236\u7cfb\u7edf\uff0c\u80fd\u591f\u5904\u7406\u4efb\u4f55\u8f93\u5165\u5668\u5b98\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4e13\u5bb6\u56e2\u961f\u67b6\u6784\u7ed3\u5408\u7a7a\u95f4\u548c\u89c6\u89c9\u4fe1\u606f\u751f\u6210\u4f2a\u771f\u5b9e\u6807\u7b7e\u6765\u9884\u6d4b\u8d28\u91cf\u5206\u6570\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u533b\u5b66\u56fe\u50cf\u5206\u5272\u65b9\u6cd5\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\u5bfc\u81f4\u89e3\u5256\u5b66\u4e0a\u4e0d\u5408\u7406\u7684\u5206\u5272\u7ed3\u679c\uff0c\u800c\u73b0\u6709\u8d28\u91cf\u63a7\u5236\u65b9\u6cd5\u90fd\u662f\u5668\u5b98\u7279\u5b9a\u7684\uff0c\u7f3a\u4e4f\u901a\u7528\u6027\u548c\u53ef\u7528\u6027\u3002", "method": "\u63d0\u51fannQC\u6846\u67b6\uff0c\u91c7\u7528\u4e13\u5bb6\u56e2\u961f\u67b6\u6784\uff0c\u4e24\u4e2a\u4e13\u5bb6\u5206\u522b\u7f16\u78013D\u7a7a\u95f4\u610f\u8bc6\u548c\u89e3\u5256\u4fe1\u606f\uff0c\u901a\u8fc7\u52a0\u6743\u6761\u4ef6\u6a21\u5757\u52a8\u6001\u7ed3\u5408\u8fd9\u4e9b\u4fe1\u606f\uff0c\u5728\u6269\u6563\u8fc7\u7a0b\u4e2d\u751f\u6210\u7a7a\u95f4\u611f\u77e5\u7684\u4f2a\u771f\u5b9e\u6807\u7b7e\u6765\u9884\u6d4b\u8d28\u91cf\u5206\u6570\u3002", "result": "\u57287\u4e2a\u5668\u5b98\u768412\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cnnQC\u5728\u6240\u6709\u5b9e\u9a8c\u4e2d\u4e00\u81f4\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5305\u62ec\u5206\u5272\u63a9\u7801\u4e25\u91cd\u9000\u5316\u6216\u5b8c\u5168\u7f3a\u5931\u7684\u60c5\u51b5\u3002", "conclusion": "nnQC\u6846\u67b6\u5177\u6709\u8de8\u5668\u5b98\u3001\u6570\u636e\u96c6\u548c\u6210\u50cf\u6a21\u6001\u7684\u9002\u5e94\u80fd\u529b\uff0c\u8bc1\u5b9e\u4e86\u5176\u5728\u4e0d\u540c\u5668\u5b98\u95f4\u7684\u591a\u529f\u80fd\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2511.09592", "pdf": "https://arxiv.org/pdf/2511.09592", "abs": "https://arxiv.org/abs/2511.09592", "authors": ["Himashi Peiris", "Sizhe Wang", "Gary Egan", "Mehrtash Harandi", "Meng Law", "Zhaolin Chen"], "title": "Segment Any Tumour: An Uncertainty-Aware Vision Foundation Model for Whole-Body Analysis", "categories": ["eess.IV", "q-bio.QM"], "comment": null, "summary": "Prompt-driven vision foundation models, such as the Segment Anything Model, have recently demonstrated remarkable adaptability in computer vision. However, their direct application to medical imaging remains challenging due to heterogeneous tissue structures, imaging artefacts, and low-contrast boundaries, particularly in tumours and cancer primaries leading to suboptimal segmentation in ambiguous or overlapping lesion regions. Here, we present Segment Any Tumour 3D (SAT3D), a lightweight volumetric foundation model designed to enable robust and generalisable tumour segmentation across diverse medical imaging modalities. SAT3D integrates a shifted-window vision transformer for hierarchical volumetric representation with an uncertainty-aware training pipeline that explicitly incorporates uncertainty estimates as prompts to guide reliable boundary prediction in low-contrast regions. Adversarial learning further enhances model performance for the ambiguous pathological regions. We benchmark SAT3D against three recent vision foundation models and nnUNet across 11 publicly available datasets, encompassing 3,884 tumour and cancer cases for training and 694 cases for in-distribution evaluation. Trained on 17,075 3D volume-mask pairs across multiple modalities and cancer primaries, SAT3D demonstrates strong generalisation and robustness. To facilitate practical use and clinical translation, we developed a 3D Slicer plugin that enables interactive, prompt-driven segmentation and visualisation using the trained SAT3D model. Extensive experiments highlight its effectiveness in improving segmentation accuracy under challenging and out-of-distribution scenarios, underscoring its potential as a scalable foundation model for medical image analysis.", "AI": {"tldr": "SAT3D\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea73D\u4f53\u79ef\u57fa\u7840\u6a21\u578b\uff0c\u4e13\u95e8\u7528\u4e8e\u533b\u5b66\u5f71\u50cf\u4e2d\u7684\u80bf\u7624\u5206\u5272\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8bad\u7ec3\u548c\u5bf9\u6297\u5b66\u4e60\u89e3\u51b3\u533b\u5b66\u5f71\u50cf\u4e2d\u7ec4\u7ec7\u5f02\u8d28\u6027\u3001\u4f2a\u5f71\u548c\u4f4e\u5bf9\u6bd4\u5ea6\u8fb9\u754c\u7b49\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9\u57fa\u7840\u6a21\u578b\uff08\u5982Segment Anything Model\uff09\u76f4\u63a5\u5e94\u7528\u4e8e\u533b\u5b66\u5f71\u50cf\u5b58\u5728\u6311\u6218\uff0c\u5305\u62ec\u7ec4\u7ec7\u5f02\u8d28\u6027\u3001\u6210\u50cf\u4f2a\u5f71\u548c\u4f4e\u5bf9\u6bd4\u5ea6\u8fb9\u754c\uff0c\u7279\u522b\u662f\u5728\u80bf\u7624\u548c\u764c\u75c7\u539f\u53d1\u7076\u533a\u57df\uff0c\u5bfc\u81f4\u5728\u6a21\u7cca\u6216\u91cd\u53e0\u75c5\u53d8\u533a\u57df\u7684\u5206\u5272\u6548\u679c\u4e0d\u4f73\u3002", "method": "SAT3D\u96c6\u6210\u4e86shifted-window\u89c6\u89c9\u53d8\u6362\u5668\u8fdb\u884c\u5206\u5c42\u4f53\u79ef\u8868\u793a\uff0c\u91c7\u7528\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8bad\u7ec3\u7ba1\u9053\uff0c\u5c06\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4f5c\u4e3a\u63d0\u793a\u6765\u6307\u5bfc\u4f4e\u5bf9\u6bd4\u5ea6\u533a\u57df\u7684\u53ef\u9760\u8fb9\u754c\u9884\u6d4b\uff0c\u5e76\u901a\u8fc7\u5bf9\u6297\u5b66\u4e60\u589e\u5f3a\u6a21\u578b\u5728\u6a21\u7cca\u75c5\u7406\u533a\u57df\u7684\u6027\u80fd\u3002", "result": "\u572811\u4e2a\u516c\u5f00\u6570\u636e\u96c6\uff083,884\u4e2a\u8bad\u7ec3\u75c5\u4f8b\u548c694\u4e2a\u5206\u5e03\u5185\u8bc4\u4f30\u75c5\u4f8b\uff09\u4e0a\uff0cSAT3D\u76f8\u6bd4\u4e09\u4e2a\u6700\u8fd1\u7684\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u548cnnUNet\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\uff0c\u5728\u6311\u6218\u6027\u548c\u5206\u5e03\u5916\u573a\u666f\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u5272\u51c6\u786e\u6027\u3002", "conclusion": "SAT3D\u5c55\u793a\u4e86\u4f5c\u4e3a\u533b\u5b66\u5f71\u50cf\u5206\u6790\u53ef\u6269\u5c55\u57fa\u7840\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u5e76\u5f00\u53d1\u4e863D Slicer\u63d2\u4ef6\u4ee5\u4fc3\u8fdb\u5b9e\u9645\u4f7f\u7528\u548c\u4e34\u5e8a\u8f6c\u5316\uff0c\u5b9e\u73b0\u4ea4\u4e92\u5f0f\u3001\u63d0\u793a\u9a71\u52a8\u7684\u5206\u5272\u548c\u53ef\u89c6\u5316\u3002"}}
{"id": "2511.09605", "pdf": "https://arxiv.org/pdf/2511.09605", "abs": "https://arxiv.org/abs/2511.09605", "authors": ["Johannes Kiechle", "Stefan M. Fischer", "Daniel M. Lang", "Cosmin I. Bercea", "Matthew J. Nyflot", "Lina Felsner", "Julia A. Schnabel", "Jan C. Peeken"], "title": "TomoGraphView: 3D Medical Image Classification with Omnidirectional Slice Representations and Graph Neural Networks", "categories": ["eess.IV", "cs.AI", "cs.LG", "q-bio.QM"], "comment": "Preprint submitted to Medical Image Analysis (MedIA)", "summary": "The growing number of medical tomography examinations has necessitated the development of automated methods capable of extracting comprehensive imaging features to facilitate downstream tasks such as tumor characterization, while assisting physicians in managing their growing workload. However, 3D medical image classification remains a challenging task due to the complex spatial relationships and long-range dependencies inherent in volumetric data. Training models from scratch suffers from low data regimes, and the absence of 3D large-scale multimodal datasets has limited the development of 3D medical imaging foundation models. Recent studies, however, have highlighted the potential of 2D vision foundation models, originally trained on natural images, as powerful feature extractors for medical image analysis. Despite these advances, existing approaches that apply 2D models to 3D volumes via slice-based decomposition remain suboptimal. Conventional volume slicing strategies, which rely on canonical planes such as axial, sagittal, or coronal, may inadequately capture the spatial extent of target structures when these are misaligned with standardized viewing planes. Furthermore, existing slice-wise aggregation strategies rarely account for preserving the volumetric structure, resulting in a loss of spatial coherence across slices. To overcome these limitations, we propose TomoGraphView, a novel framework that integrates omnidirectional volume slicing with spherical graph-based feature aggregation. We publicly share our accessible code base at http://github.com/compai-lab/2025-MedIA-kiechle and provide a user-friendly library for omnidirectional volume slicing at https://pypi.org/project/OmniSlicer.", "AI": {"tldr": "\u63d0\u51fa\u4e86TomoGraphView\u6846\u67b6\uff0c\u901a\u8fc7\u5168\u5411\u4f53\u79ef\u5207\u7247\u548c\u7403\u5f62\u56fe\u7279\u5f81\u805a\u5408\u6765\u89e3\u51b33D\u533b\u5b66\u56fe\u50cf\u5206\u7c7b\u4e2d\u4f20\u7edf\u5207\u7247\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "3D\u533b\u5b66\u56fe\u50cf\u5206\u7c7b\u9762\u4e34\u590d\u6742\u7a7a\u95f4\u5173\u7cfb\u548c\u957f\u7a0b\u4f9d\u8d56\u7684\u6311\u6218\uff0c\u73b0\u6709\u57fa\u4e8e2D\u57fa\u7840\u6a21\u578b\u7684\u65b9\u6cd5\u901a\u8fc7\u6807\u51c6\u5e73\u9762\u5207\u7247\u65e0\u6cd5\u5145\u5206\u6355\u6349\u76ee\u6807\u7ed3\u6784\u7684\u7a7a\u95f4\u8303\u56f4\uff0c\u4e14\u5207\u7247\u805a\u5408\u7b56\u7565\u4f1a\u635f\u5931\u7a7a\u95f4\u8fde\u8d2f\u6027\u3002", "method": "\u7ed3\u5408\u5168\u5411\u4f53\u79ef\u5207\u7247\u548c\u7403\u5f62\u56fe\u7279\u5f81\u805a\u5408\uff0c\u901a\u8fc7\u591a\u65b9\u5411\u5207\u7247\u66f4\u597d\u5730\u6355\u6349\u7a7a\u95f4\u7ed3\u6784\uff0c\u5e76\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u4fdd\u6301\u5207\u7247\u95f4\u7684\u7a7a\u95f4\u8fde\u8d2f\u6027\u3002", "result": "\u5f00\u53d1\u4e86\u5f00\u6e90\u4ee3\u7801\u5e93\u548c\u7528\u6237\u53cb\u597d\u7684\u5168\u5411\u5207\u7247\u5de5\u5177\u5305\uff0c\u63d0\u4f9b\u4e86\u53ef\u8bbf\u95ee\u7684\u5b9e\u73b0\u65b9\u6848\u3002", "conclusion": "TomoGraphView\u6846\u67b6\u80fd\u591f\u66f4\u6709\u6548\u5730\u5904\u74063D\u533b\u5b66\u56fe\u50cf\uff0c\u514b\u670d\u4f20\u7edf\u5207\u7247\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u4e3a\u533b\u5b66\u56fe\u50cf\u5206\u6790\u63d0\u4f9b\u66f4\u597d\u7684\u7279\u5f81\u63d0\u53d6\u65b9\u6848\u3002"}}
{"id": "2511.10165", "pdf": "https://arxiv.org/pdf/2511.10165", "abs": "https://arxiv.org/abs/2511.10165", "authors": ["Yuancheng Sun", "Yuxuan Ren", "Zhaoming Chen", "Xu Han", "Kang Liu", "Qiwei Ye"], "title": "EPO: Diverse and Realistic Protein Ensemble Generation via Energy Preference Optimization", "categories": ["cs.LG", "q-bio.QM"], "comment": "Accepted as AAAI 2026 Poster", "summary": "Accurate exploration of protein conformational ensembles is essential for uncovering function but remains hard because molecular-dynamics (MD) simulations suffer from high computational costs and energy-barrier trapping. This paper presents Energy Preference Optimization (EPO), an online refinement algorithm that turns a pretrained protein ensemble generator into an energy-aware sampler without extra MD trajectories. Specifically, EPO leverages stochastic differential equation sampling to explore the conformational landscape and incorporates a novel energy-ranking mechanism based on list-wise preference optimization. Crucially, EPO introduces a practical upper bound to efficiently approximate the intractable probability of long sampling trajectories in continuous-time generative models, making it easily adaptable to existing pretrained generators. On Tetrapeptides, ATLAS, and Fast-Folding benchmarks, EPO successfully generates diverse and physically realistic ensembles, establishing a new state-of-the-art in nine evaluation metrics. These results demonstrate that energy-only preference signals can efficiently steer generative models toward thermodynamically consistent conformational ensembles, providing an alternative to long MD simulations and widening the applicability of learned potentials in structural biology and drug discovery.", "AI": {"tldr": "EPO\u662f\u4e00\u79cd\u5728\u7ebf\u4f18\u5316\u7b97\u6cd5\uff0c\u5c06\u9884\u8bad\u7ec3\u7684\u86cb\u767d\u8d28\u6784\u8c61\u96c6\u6210\u751f\u6210\u5668\u8f6c\u5316\u4e3a\u80fd\u91cf\u611f\u77e5\u91c7\u6837\u5668\uff0c\u65e0\u9700\u989d\u5916MD\u8f68\u8ff9\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u6613\u9677\u5165\u80fd\u91cf\u9677\u9631\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u63a2\u7d22\u86cb\u767d\u8d28\u6784\u8c61\u96c6\u6210\u3002", "method": "\u4f7f\u7528\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u91c7\u6837\u63a2\u7d22\u6784\u8c61\u7a7a\u95f4\uff0c\u7ed3\u5408\u57fa\u4e8e\u5217\u8868\u504f\u597d\u4f18\u5316\u7684\u80fd\u91cf\u6392\u5e8f\u673a\u5236\uff0c\u5f15\u5165\u5b9e\u7528\u4e0a\u754c\u8fd1\u4f3c\u8fde\u7eed\u65f6\u95f4\u751f\u6210\u6a21\u578b\u4e2d\u96be\u4ee5\u5904\u7406\u7684\u6982\u7387\u3002", "result": "\u5728Tetrapeptides\u3001ATLAS\u548cFast-Folding\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEPO\u5728\u4e5d\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u751f\u6210\u591a\u6837\u4e14\u7269\u7406\u771f\u5b9e\u7684\u6784\u8c61\u96c6\u6210\u3002", "conclusion": "\u4ec5\u4f7f\u7528\u80fd\u91cf\u504f\u597d\u4fe1\u53f7\u5c31\u80fd\u6709\u6548\u5f15\u5bfc\u751f\u6210\u6a21\u578b\u4ea7\u751f\u70ed\u529b\u5b66\u4e00\u81f4\u7684\u6784\u8c61\u96c6\u6210\uff0c\u4e3a\u957fMD\u6a21\u62df\u63d0\u4f9b\u4e86\u66ff\u4ee3\u65b9\u6848\uff0c\u6269\u5c55\u4e86\u5b66\u4e60\u52bf\u80fd\u5728\u7ed3\u6784\u751f\u7269\u5b66\u548c\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2511.10432", "pdf": "https://arxiv.org/pdf/2511.10432", "abs": "https://arxiv.org/abs/2511.10432", "authors": ["Willem Bonnaff\u00e9", "Yang Hu", "Andrea Chatrian", "Mengran Fan", "Stefano Malacrino", "Sandy Figiel", "CRUK ICGC Prostate Group", "Srinivasa R. Rao", "Richard Colling", "Richard J. Bryant", "Freddie C. Hamdy", "Dan J. Woodcock", "Ian G. Mills", "Clare Verrill", "Jens Rittscher"], "title": "Histology-informed tiling of whole tissue sections improves the interpretability and predictability of cancer relapse and genetic alterations", "categories": ["cs.CV", "q-bio.QM", "q-bio.TO"], "comment": "26 pages, 6 figures", "summary": "Histopathologists establish cancer grade by assessing histological structures, such as glands in prostate cancer. Yet, digital pathology pipelines often rely on grid-based tiling that ignores tissue architecture. This introduces irrelevant information and limits interpretability. We introduce histology-informed tiling (HIT), which uses semantic segmentation to extract glands from whole slide images (WSIs) as biologically meaningful input patches for multiple-instance learning (MIL) and phenotyping. Trained on 137 samples from the ProMPT cohort, HIT achieved a gland-level Dice score of 0.83 +/- 0.17. By extracting 380,000 glands from 760 WSIs across ICGC-C and TCGA-PRAD cohorts, HIT improved MIL models AUCs by 10% for detecting copy number variation (CNVs) in genes related to epithelial-mesenchymal transitions (EMT) and MYC, and revealed 15 gland clusters, several of which were associated with cancer relapse, oncogenic mutations, and high Gleason. Therefore, HIT improved the accuracy and interpretability of MIL predictions, while streamlining computations by focussing on biologically meaningful structures during feature extraction.", "AI": {"tldr": "\u63d0\u51faHIT\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bed\u4e49\u5206\u5272\u4ece\u5168\u5207\u7247\u56fe\u50cf\u4e2d\u63d0\u53d6\u817a\u4f53\u4f5c\u4e3a\u751f\u7269\u610f\u4e49\u8f93\u5165\uff0c\u63d0\u5347\u591a\u5b9e\u4f8b\u5b66\u4e60\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027", "motivation": "\u4f20\u7edf\u6570\u5b57\u75c5\u7406\u5b66\u57fa\u4e8e\u7f51\u683c\u5207\u5206\u5ffd\u7565\u7ec4\u7ec7\u7ed3\u6784\uff0c\u5f15\u5165\u65e0\u5173\u4fe1\u606f\u4e14\u9650\u5236\u53ef\u89e3\u91ca\u6027", "method": "\u4f7f\u7528\u8bed\u4e49\u5206\u5272\u63d0\u53d6\u817a\u4f53\u4f5c\u4e3a\u8f93\u5165\u8865\u4e01\uff0c\u5e94\u7528\u4e8e\u591a\u5b9e\u4f8b\u5b66\u4e60\u548c\u8868\u578b\u5206\u6790", "result": "\u817a\u4f53\u5206\u5272Dice\u5f97\u52060.83\uff0c\u5728760\u4e2aWSI\u4e2d\u63d0\u53d638\u4e07\u4e2a\u817a\u4f53\uff0cMIL\u6a21\u578bAUC\u63d0\u534710%\uff0c\u8bc6\u522b\u51fa15\u4e2a\u817a\u4f53\u7c07\u4e0e\u764c\u75c7\u590d\u53d1\u76f8\u5173", "conclusion": "HIT\u901a\u8fc7\u805a\u7126\u751f\u7269\u610f\u4e49\u7ed3\u6784\uff0c\u63d0\u9ad8\u4e86MIL\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u7b80\u5316\u4e86\u8ba1\u7b97"}}
