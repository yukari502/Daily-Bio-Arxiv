<div id=toc></div>

# Table of Contents

- [q-bio.QM](#q-bio.QM) [Total: 3]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]
- [physics.bio-ph](#physics.bio-ph) [Total: 1]


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [1] [MOSAIC: Codon Harmonization of Monte Carlo-Based Simulated Annealing for Linked Codons in Heterologous Protein Expression](https://arxiv.org/abs/2511.10708)
*Yoonho Jeong,Chengcheng Yang,Jihoo Kim,Eok Kyun Lee,Younghoon Lee,Won June Kim,Seung Seo Lee,Insung S. Choi*

Main category: q-bio.QM

TL;DR: 提出了一种基于蒙特卡洛的密码子优化算法MOSAIC，专注于关联密码子集的协调优化，在核糖体蛋白上表现出优异性能，显著提高了蛋白质表达量和可溶性。


<details>
  <summary>Details</summary>
Motivation: 密码子使用偏好对翻译效率和共翻译折叠有重要影响，特别是对于异源重组蛋白表达。密码子协调对于翻译速率敏感的蛋白质尤其重要，因为它可以复制天然翻译速度，保持正确折叠和蛋白质活性。

Method: 开发了MOSAIC算法（基于蒙特卡洛的关联密码子模拟退火），专注于关联密码子集的协调优化，而不是传统的单个密码子优化。

Result: 在核糖体蛋白（S18、S15、S10和L11）模型系统上表现出最先进性能。协调后的RP S18基因表达产生了更大数量的蛋白质，其中可溶性蛋白含量也很显著。

Conclusion: 关联密码子协调方法有潜力增强敏感蛋白质的表达和功能，为各种生物技术和制药应用中更高效生产重组蛋白奠定了基础。

Abstract: Codon usage bias has a crucial impact on the translation efficiency and co-translational folding of proteins, necessitating the algorithmic development of codon optimization/harmonization methods, particularly for heterologous recombinant protein expression. Codon harmonization is especially valuable for proteins sensitive to translation rates, because it can potentially replicate native translation speeds, preserving proper folding and maintaining protein activity. This work proposes a Monte Carlo-based codon harmonization algorithm, MOSAIC (Monte Carlo-based Simulated Annealing for Linked Codons), for the harmonization of a set of linked codons, which differs from conventional codon harmonization, by focusing on the codon sets rather than individual ones. Our MOSAIC demonstrates state-of-the-art performance on ribosomal proteins (S18, S15, S10, and L11) as model systems. Among them, the harmonized gene of RP S18 was expressed and compared with the expression of the wild-type gene. The harmonized gene clearly yielded a larger quantity of the protein, from which the amount of the soluble protein was also significant. These results underscore the potential of the linked codon harmonization approach to enhance the expression and functionality of sensitive proteins, setting the stage for more efficient production of recombinant proteins in various biotechnological and pharmaceutical applications.

</details>


### [2] [Synergy vs. Noise: Performance-Guided Multimodal Fusion For Biochemical Recurrence-Free Survival in Prostate Cancer](https://arxiv.org/abs/2511.11452)
*Seth Alain Chang,Muhammad Mueez Amjad,Noorul Wahab,Ethar Alzaid,Nasir Rajpoot,Adam Shephard*

Main category: q-bio.QM

TL;DR: 多模态深度学习在计算病理学中表现优异，但研究发现并非所有模态组合都能提升性能。只有高性能模态的组合才能带来优势，而整合低性能模态反而会降低预测准确性。


<details>
  <summary>Details</summary>
Motivation: 检验多模态深度学习中的假设——组合模态是否能自动提升性能，研究模态性能质量对多模态增益的影响。

Method: 使用前列腺癌数据集，整合组织病理学、放射学和临床数据，预测生化复发时间，分析不同模态组合的性能表现。

Result: 高性能模态组合确实优于单模态方法，但将低性能模态与其他高性能模态整合会降低预测准确性。

Conclusion: 多模态获益需要基于性能的选择性整合，而非不加区分的模态组合，这对计算病理学和医学成像中的多模态深度学习设计具有重要意义。

Abstract: Multimodal deep learning (MDL) has emerged as a transformative approach in computational pathology. By integrating complementary information from multiple data sources, MDL models have demonstrated superior predictive performance across diverse clinical tasks compared to unimodal models. However, the assumption that combining modalities inherently improves performance remains largely unexamined. We hypothesise that multimodal gains depend critically on the predictive quality of individual modalities, and that integrating weak modalities may introduce noise rather than complementary information. We test this hypothesis on a prostate cancer dataset with histopathology, radiology, and clinical data to predict time-to-biochemical recurrence. Our results confirm that combining high-performing modalities yield superior performance compared to unimodal approaches. However, integrating a poor-performing modality with other higher-performing modalities degrades predictive accuracy. These findings demonstrate that multimodal benefit requires selective, performance-guided integration rather than indiscriminate modality combination, with implications for MDL design across computational pathology and medical imaging.

</details>


### [3] [PEtab-GUI: A graphical user interface to create, edit and inspect PEtab parameter estimation problems](https://arxiv.org/abs/2511.11515)
*Paul Jonas Jost,Frank T Bergmann,Daniel Weindl,Jan Hasenauer*

Main category: q-bio.QM

TL;DR: PEtab-GUI是一个开源Python应用程序，通过直观的图形界面简化PEtab参数估计问题的创建、编辑和验证。


<details>
  <summary>Details</summary>
Motivation: 参数估计是系统生物学中数据驱动建模的基石，但构建可重现且易于访问的问题仍然具有挑战性。PEtab格式已成为编码参数估计问题的强大社区标准，但其依赖多个互连文件且通常手动编辑，可能引入不一致性，新用户也常常难以掌握。

Method: PEtab-GUI将所有PEtab组件（包括SBML模型和表格文件）集成到单一环境中，具有实时错误检查和可自定义默认值。提供交互式可视化和模拟功能，使用户能够检查模型与数据之间的关系。

Result: 开发了一个开源Python应用程序，代码采用模块化和可扩展设计，托管在GitHub上，可从PyPI安装，使用3-Clause BSD许可证。

Conclusion: PEtab-GUI降低了指定标准化参数估计问题的入门门槛，使动态建模更加易于访问，特别是在教育和跨学科环境中。

Abstract: Motivation: Parameter estimation is a cornerstone of data-driven modeling in systems biology. Yet, constructing such problems in a reproducible and accessible manner remains challenging. The PEtab format has established itself as a powerful community standard to encode parameter estimation problems, promoting interoperability and reusability. However, its reliance on multiple interlinked files - often edited manually - can introduce inconsistencies, and new users often struggle to navigate them. Here, we present PEtab-GUI, an open-source Python application designed to streamline the creation, editing, and validation of PEtab problems through an intuitive graphical user interface. PEtab-GUI integrates all PEtab components, including SBML models and tabular files, into a single environment with live error-checking and customizable defaults. Interactive visualization and simulation capabilities enable users to inspect the relationship between the model and the data. PEtab-GUI lowers the barrier to entry for specifying standardized parameter estimation problems, making dynamic modeling more accessible, especially in educational and interdisciplinary settings.
  Availability and Implementation: PEtab-GUI is implemented in Python, open-source under a 3-Clause BSD license. The code, designed to be modular and extensible, is hosted on https://github.com/PEtab-dev/PEtab-GUI and can be installed from PyPI.
  Key words: Parameter Estimation, Python, Graphical User Interface, Systems Biology

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Toward Scalable Early Cancer Detection: Evaluating EHR-Based Predictive Models Against Traditional Screening Criteria](https://arxiv.org/abs/2511.11293)
*Jiheum Park,Chao Pang,Tristan Y. Lee,Jeong Yun Yang,Jacob Berkowitz,Alexander Z. Wei,Nicholas Tatonetti*

Main category: cs.LG

TL;DR: 基于电子健康记录（EHR）的预测模型在识别癌症高风险个体方面显著优于传统风险因素，能够实现3-6倍的真实癌症病例富集，支持更精确和可扩展的早期检测策略。


<details>
  <summary>Details</summary>
Motivation: 当前癌症筛查指南仅覆盖少数癌症类型，且依赖年龄或单一风险因素等狭窄标准。基于EHR的预测模型可能通过捕捉微妙的癌症前诊断信号，更有效地识别高风险群体。

Method: 使用All of Us研究项目中865,000多名参与者的EHR、基因组和调查数据，系统评估EHR预测模型与传统风险因素在八种主要癌症中的临床效用。

Result: 即使使用基线建模方法，EHR模型在识别为高风险的个体中，真实癌症病例的富集度比单独使用传统风险因素高3-6倍。EHR基础模型进一步提高了26种癌症类型的预测性能。

Conclusion: 基于EHR的预测建模具有临床潜力，可以支持更精确和可扩展的早期检测策略，显著优于当前筛查指南中使用的传统风险因素。

Abstract: Current cancer screening guidelines cover only a few cancer types and rely on narrowly defined criteria such as age or a single risk factor like smoking history, to identify high-risk individuals. Predictive models using electronic health records (EHRs), which capture large-scale longitudinal patient-level health information, may provide a more effective tool for identifying high-risk groups by detecting subtle prediagnostic signals of cancer. Recent advances in large language and foundation models have further expanded this potential, yet evidence remains limited on how useful HER-based models are compared with traditional risk factors currently used in screening guidelines. We systematically evaluated the clinical utility of EHR-based predictive models against traditional risk factors, including gene mutations and family history of cancer, for identifying high-risk individuals across eight major cancers (breast, lung, colorectal, prostate, ovarian, liver, pancreatic, and stomach), using data from the All of Us Research Program, which integrates EHR, genomic, and survey data from over 865,000 participants. Even with a baseline modeling approach, EHR-based models achieved a 3- to 6-fold higher enrichment of true cancer cases among individuals identified as high risk compared with traditional risk factors alone, whether used as a standalone or complementary tool. The EHR foundation model, a state-of-the-art approach trained on comprehensive patient trajectories, further improved predictive performance across 26 cancer types, demonstrating the clinical potential of EHR-based predictive modeling to support more precise and scalable early detection strategies.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [5] [Multimodal Posterior Sampling-based Uncertainty in PD-L1 Segmentation from H&E Images](https://arxiv.org/abs/2511.11486)
*Roman Kinakh,Gonzalo R. Ríos-Muñoz,Arrate Muñoz-Barrutia*

Main category: cs.CV

TL;DR: nnUNet-B是一个贝叶斯分割框架，通过多模态后验采样直接从H&E染色组织学图像推断PD-L1表达，提供准确分割和认知不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 当前基于免疫组织化学的PD-L1表达评估方法资源密集，需要更高效、可扩展的解决方案。

Method: 基于nnUNet-v2构建，在循环训练期间采样多样化模型检查点来近似后验分布，通过熵和标准差实现不确定性估计。

Result: 在肺鳞状细胞癌数据集上，平均Dice分数0.805，平均IoU 0.709，性能与现有基线相当，并提供像素级不确定性图。

Conclusion: 基于H&E的不确定性感知PD-L1预测是向临床工作流程中可扩展、可解释生物标志物评估迈出的有希望的一步。

Abstract: Accurate assessment of PD-L1 expression is critical for guiding immunotherapy, yet current immunohistochemistry (IHC) based methods are resource-intensive. We present nnUNet-B: a Bayesian segmentation framework that infers PD-L1 expression directly from H&E-stained histology images using Multimodal Posterior Sampling (MPS). Built upon nnUNet-v2, our method samples diverse model checkpoints during cyclic training to approximate the posterior, enabling both accurate segmentation and epistemic uncertainty estimation via entropy and standard deviation. Evaluated on a dataset of lung squamous cell carcinoma, our approach achieves competitive performance against established baselines with mean Dice Score and mean IoU of 0.805 and 0.709, respectively, while providing pixel-wise uncertainty maps. Uncertainty estimates show strong correlation with segmentation error, though calibration remains imperfect. These results suggest that uncertainty-aware H&E-based PD-L1 prediction is a promising step toward scalable, interpretable biomarker assessment in clinical workflows.

</details>


<div id='physics.bio-ph'></div>

# physics.bio-ph [[Back]](#toc)

### [6] [Advanced Data Analysis of Spontaneous Biophoton Emission: A Multi-Method Approach](https://arxiv.org/abs/2511.11080)
*M. Benfatto,L. De Paolis,L. Tonello,P. Grigolini*

Main category: physics.bio-ph

TL;DR: 本文建立了一个全面的光子计数时间序列分析框架，结合多种熵分析和波动分析方法，用于区分生物驱动的光子发射相关性与非生物随机效应。


<details>
  <summary>Details</summary>
Motivation: 超弱光子发射被认为反映了生物系统的自组织和长程协调性，但需要可靠的方法来区分生物相关性与非生物随机效应。

Method: 结合分布熵分析、Rényi熵、去趋势波动分析、多重分形去趋势波动分析和尾部统计特征，使用泊松过程、分数高斯噪声和幂律等待时间更新过程构建替代信号进行验证。

Result: 所有方法都恢复了一致的动力学层次结构，实验暗计数数据和衰减相干激光发射确认了泊松行为，为UPE研究建立了统计基线。

Conclusion: 这种多分辨率方法可靠地区分了平凡光子计数统计与结构化长程组织，为未来生物UPE测量提供了验证的方法学基础。

Abstract: Ultra-weak photon emission (UPE) from living systems is widely hypothesized to reflect un-derlying self-organization and long-range coordination in biological dynamics. However, distin-guishing biologically driven correlations from trivial stochastic or instrumental effects requires a robust, multi-method framework. In this work, we establish and benchmark a comprehensive anal-ysis pipeline for photon-count time series, combining Distribution Entropy Analysis, Rényi entro-py, Detrended Fluctuation Analysis, its generalization Multifractal Detrended Fluctuation Analysis, and tail-statistics characterization. Surrogate signals constructed from Poisson processes, Fractional Gaussian Noise, and Renewal Processes with power-law waiting times are used to validate sensitivity to memory, intermittency, and multifractality. Across all methods, a coherent hierarchy of dynamical regimes is recovered, demonstrating internal methodological consistency. Application to experimental dark-count data and attenuated coherent-laser emission confirm Poisson-like behavior, establishing an essential statistical baseline for UPE studies. The combined results show that this multi-resolution approach reliably separates trivial photon-counting statistics from struc-tured long-range organization, providing a validated methodological foundation for future biological UPE measurements and their interpretation in the context of non-equilibrium statistical physics, information dynamics, and prospective markers of biological coherence.

</details>
