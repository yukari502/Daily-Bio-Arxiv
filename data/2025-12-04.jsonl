{"id": "2512.03111", "pdf": "https://arxiv.org/pdf/2512.03111", "abs": "https://arxiv.org/abs/2512.03111", "authors": ["Xiaoshui Huang", "Tianlin Zhu", "Yifan Zuo", "Xue Xia", "Zonghan Wu", "Jiebin Yan", "Dingli Hua", "Zongyi Xu", "Yuming Fang", "Jian Zhang"], "title": "PanFoMa: A Lightweight Foundation Model and Benchmark for Pan-Cancer", "categories": ["q-bio.GN", "cs.AI", "cs.CV"], "comment": "Accepted by AAAI 2026", "summary": "Single-cell RNA sequencing (scRNA-seq) is essential for decoding tumor heterogeneity. However, pan-cancer research still faces two key challenges: learning discriminative and efficient single-cell representations, and establishing a comprehensive evaluation benchmark. In this paper, we introduce PanFoMa, a lightweight hybrid neural network that combines the strengths of Transformers and state-space models to achieve a balance between performance and efficiency. PanFoMa consists of a front-end local-context encoder with shared self-attention layers to capture complex, order-independent gene interactions; and a back-end global sequential feature decoder that efficiently integrates global context using a linear-time state-space model. This modular design preserves the expressive power of Transformers while leveraging the scalability of Mamba to enable transcriptome modeling, effectively capturing both local and global regulatory signals. To enable robust evaluation, we also construct a large-scale pan-cancer single-cell benchmark, PanFoMaBench, containing over 3.5 million high-quality cells across 33 cancer subtypes, curated through a rigorous preprocessing pipeline. Experimental results show that PanFoMa outperforms state-of-the-art models on our pan-cancer benchmark (+4.0\\%) and across multiple public tasks, including cell type annotation (+7.4\\%), batch integration (+4.0\\%) and multi-omics integration (+3.1\\%). The code is available at https://github.com/Xiaoshui-Huang/PanFoMa."}
{"id": "2512.03098", "pdf": "https://arxiv.org/pdf/2512.03098", "abs": "https://arxiv.org/abs/2512.03098", "authors": ["Benoit L. Marteau", "Andrew Hornback", "Shaun Q. Tan", "Christian Lowson", "Jason Woloff", "May D. Wang"], "title": "An AI Implementation Science Study to Improve Trustworthy Data in a Large Healthcare System", "categories": ["q-bio.QM", "cs.LG"], "comment": "Submitted and Accepted to the IEEE International Conference on Biomedical and Health Informatics (BHI) 2025", "summary": "The rapid growth of Artificial Intelligence (AI) in healthcare has sparked interest in Trustworthy AI and AI Implementation Science, both of which are essential for accelerating clinical adoption. However, strict regulations, gaps between research and clinical settings, and challenges in evaluating AI systems continue to hinder real-world implementation. This study presents an AI implementation case study within Shriners Childrens (SC), a large multisite pediatric system, showcasing the modernization of SCs Research Data Warehouse (RDW) to OMOP CDM v5.4 within a secure Microsoft Fabric environment. We introduce a Python-based data quality assessment tool compatible with SCs infrastructure, extending OHDsi's R/Java-based Data Quality Dashboard (DQD) and integrating Trustworthy AI principles using the METRIC framework. This extension enhances data quality evaluation by addressing informative missingness, redundancy, timeliness, and distributional consistency. We also compare systematic and case-specific AI implementation strategies for Craniofacial Microsomia (CFM) using the FHIR standard. Our contributions include a real-world evaluation of AI implementations, integration of Trustworthy AI principles into data quality assessment, and insights into hybrid implementation strategies that blend systematic infrastructure with use-case-driven approaches to advance AI in healthcare."}
{"id": "2512.03110", "pdf": "https://arxiv.org/pdf/2512.03110", "abs": "https://arxiv.org/abs/2512.03110", "authors": ["Steven Mascaro", "Owen Woodberry", "Charlie McLeod", "Mitch Messer", "Hiran Selvadurai", "Yue Wu", "Andre Schultz", "Thomas L Snelling"], "title": "The BEAT-CF Causal Model: A model for guiding the design of trials and observational analyses of cystic fibrosis exacerbations", "categories": ["q-bio.QM", "cs.AI"], "comment": "12 pages (8 pages in appendices)", "summary": "Loss of lung function in cystic fibrosis (CF) occurs progressively, punctuated by acute pulmonary exacerbations (PEx) in which abrupt declines in lung function are not fully recovered. A key component of CF management over the past half century has been the treatment of PEx to slow lung function decline. This has been credited with improvements in survival for people with CF (PwCF), but there is no consensus on the optimal approach to PEx management. BEAT-CF (Bayesian evidence-adaptive treatment of CF) was established to build an evidence-informed knowledge base for CF management. The BEAT-CF causal model is a directed acyclic graph (DAG) and Bayesian network (BN) for PEx that aims to inform the design and analysis of clinical trials comparing the effectiveness of alternative approaches to PEx management. The causal model describes relationships between background risk factors, treatments, and pathogen colonisation of the airways that affect the outcome of an individual PEx episode. The key factors, outcomes, and causal relationships were elicited from CF clinical experts and together represent current expert understanding of the pathophysiology of a PEx episode, guiding the design of data collection and studies and enabling causal inference. Here, we present the DAG that documents this understanding, along with the processes used in its development, providing transparency around our trial design and study processes, as well as a reusable framework for others."}
{"id": "2512.03122", "pdf": "https://arxiv.org/pdf/2512.03122", "abs": "https://arxiv.org/abs/2512.03122", "authors": ["Piotr Gwiazda", "Alexey Kazarnikov", "Anna Marciniak-Czochra", "Zuzanna Szymańska"], "title": "Beyond Bayesian Inference: The Correlation Integral Likelihood Framework and Gradient Flow Methods for Deterministic Sampling", "categories": ["q-bio.QM"], "comment": null, "summary": "Calibrating mathematical models of biological processes is essential for achieving predictive accuracy and gaining mechanistic insight. However, this task remains challenging due to limited and noisy data, significant biological variability, and the computational complexity of the models themselves. In this method's article, we explore a range of approaches for parameter inference in partial differential equation (PDE) models of biological systems. We introduce a unified mathematical framework, the Correlation Integral Likelihood (CIL) method, for parameter estimation in systems exhibiting heterogeneous or chaotic dynamics, encompassing both pattern formation models and individual-based models. Departing from classical Bayesian inverse problem methodologies, we motivate the development of the CIL method, demonstrate its versatility, and highlight illustrative applications within mathematical biology. Furthermore, we compare stochastic sampling strategies, such as Markov Chain Monte Carlo (MCMC), with deterministic gradient flow approaches, highlighting how these methods can be integrated within the proposed framework to enhance inference performance. Our work provides a practical and theoretically grounded toolbox for researchers seeking to calibrate complex biological models using incomplete, noisy, or heterogeneous data, thereby advancing both the predictive capability and mechanistic understanding of such systems."}
{"id": "2512.03286", "pdf": "https://arxiv.org/pdf/2512.03286", "abs": "https://arxiv.org/abs/2512.03286", "authors": ["Min Huang", "Rishikesan Kamaleswaran"], "title": "SpikGPT: A High-Accuracy and Interpretable Spiking Attention Framework for Single-Cell Annotation", "categories": ["q-bio.QM", "q-bio.GN"], "comment": null, "summary": "Accurate and scalable cell type annotation remains a challenge in single-cell transcriptomics, especially when datasets exhibit strong batch effects or contain previously unseen cell populations. Here we introduce SpikGPT, a hybrid deep learning framework that integrates scGPT-derived cell embeddings with a spiking Transformer architecture to achieve efficient and robust annotation. scGPT provides biologically informed dense representations of each cell, which are further processed by a multi-head Spiking Self-Attention mechanism for energy-efficient feature extraction. Across multiple benchmark datasets, SpikGPT consistently matches or exceeds the performance of leading annotation tools. Notably, SpikGPT uniquely identifies unseen cell types by assigning low-confidence predictions to an \"Unknown\" category, allowing accurate rejection of cell states absent from the training reference. Together, these results demonstrate that SpikGPT is a versatile and reliable annotation tool capable of generalizing across datasets, resolving complex cellular heterogeneity, and facilitating discovery of novel or disease-associated cell populations."}
{"id": "2512.03460", "pdf": "https://arxiv.org/pdf/2512.03460", "abs": "https://arxiv.org/abs/2512.03460", "authors": ["Johnny Peng", "Thanh Tung Khuat", "Ellen Otte", "Katarzyna Musial", "Bogdan Gabrys"], "title": "Learning From Limited Data and Feedback for Cell Culture Process Monitoring: A Comparative Study", "categories": ["q-bio.QM", "cs.AI", "cs.CE", "cs.LG"], "comment": "This is a pre-print for submitting to computers & chemical engineering journal", "summary": "In cell culture bioprocessing, real-time batch process monitoring (BPM) refers to the continuous tracking and analysis of key process variables such as viable cell density, nutrient levels, metabolite concentrations, and product titer throughout the duration of a batch run. This enables early detection of deviations and supports timely control actions to ensure optimal cell growth and product quality. BPM plays a critical role in ensuring the quality and regulatory compliance of biopharmaceutical manufacturing processes. However, the development of accurate soft sensors for BPM is hindered by key challenges, including limited historical data, infrequent feedback, heterogeneous process conditions, and high-dimensional sensory inputs. This study presents a comprehensive benchmarking analysis of machine learning (ML) methods designed to address these challenges, with a focus on learning from historical data with limited volume and relevance in the context of bioprocess monitoring. We evaluate multiple ML approaches including feature dimensionality reduction, online learning, and just-in-time learning across three datasets, one in silico dataset and two real-world experimental datasets. Our findings highlight the importance of training strategies in handling limited data and feedback, with batch learning proving effective in homogeneous settings, while just-in-time learning and online learning demonstrate superior adaptability in cold-start scenarios. Additionally, we identify key meta-features, such as feed media composition and process control strategies, that significantly impact model transferability. The results also suggest that integrating Raman-based predictions with lagged offline measurements enhances monitoring accuracy, offering a promising direction for future bioprocess soft sensor development."}
{"id": "2512.03497", "pdf": "https://arxiv.org/pdf/2512.03497", "abs": "https://arxiv.org/abs/2512.03497", "authors": ["Xiangzheng Cheng", "Haili Huang", "Ye Su", "Qing Nie", "Xiufen Zou", "Suoqin Jin"], "title": "Cell-cell communication inference and analysis: biological mechanisms, computational approaches, and future opportunities", "categories": ["q-bio.QM", "cs.AI", "q-bio.CB"], "comment": null, "summary": "In multicellular organisms, cells coordinate their activities through cell-cell communication (CCC), which are crucial for development, tissue homeostasis, and disease progression. Recent advances in single-cell and spatial omics technologies provide unprecedented opportunities to systematically infer and analyze CCC from these omics data, either by integrating prior knowledge of ligand-receptor interactions (LRIs) or through de novo approaches. A variety of computational methods have been developed, focusing on methodological innovations, accurate modeling of complex signaling mechanisms, and investigation of broader biological questions. These advances have greatly enhanced our ability to analyze CCC and generate biological hypotheses. Here, we introduce the biological mechanisms and modeling strategies of CCC, and provide a focused overview of more than 140 computational methods for inferring CCC from single-cell and spatial transcriptomic data, emphasizing the diversity in methodological frameworks and biological questions. Finally, we discuss the current challenges and future opportunities in this rapidly evolving field."}
{"id": "2512.03880", "pdf": "https://arxiv.org/pdf/2512.03880", "abs": "https://arxiv.org/abs/2512.03880", "authors": ["John Rick Manzanares", "Richard Leslie Abel", "Paweł Dłotko"], "title": "Leveraging topological data analysis to estimate bone strength from micro-CT as a surrogate for advanced imaging", "categories": ["q-bio.QM"], "comment": null, "summary": "Accurate bone strength prediction is essential for assessing fracture risk, particularly in aging populations and individuals with osteoporosis. Bone imaging has evolved from X-rays and DXA to clinical computed tomography (CT), and now to advanced modalities such as high-resolution peripheral quantitative CT and synchrotron radiation CT, which offer unprecedented resolution of bone microarchitecture. However, analytical methods have not kept pace with these imaging advances. This study applied topological data analysis (TDA) to extract biomechanically relevant features from high-resolution bone images, offering a new framework for bone strength prediction. We extracted topological features, specifically those derived from persistent homology, and combined them with standard bone morphometric descriptors to train machine learning models for apparent strength prediction. Models based solely on topological features outperformed those using traditional morphometrics, highlighting TDA's ability to capture biomechanically relevant structure. In particular, internal voids, often dismissed as imaging noise, proved to be the most predictive. While limited by dataset size and class imbalance, these results suggest that TDA offers a promising approach for advancing osteoporosis risk assessment."}
{"id": "2512.03092", "pdf": "https://arxiv.org/pdf/2512.03092", "abs": "https://arxiv.org/abs/2512.03092", "authors": ["Maxwell H Wang", "Till Hoffmann", "Jukka-Pekka Onnela"], "title": "Approximate Bayesian Inference on Mechanisms of Network Growth and Evolution", "categories": ["cs.SI", "q-bio.QM"], "comment": "24 pages, 8 figures", "summary": "Mechanistic models can provide an intuitive and interpretable explanation of network growth by specifying a set of generative rules. These rules can be defined by domain knowledge about real-world mechanisms governing network growth or may be designed to facilitate the appearance of certain network motifs. In the formation of real-world networks, multiple mechanisms may be simultaneously involved; it is then important to understand the relative contribution of each of these mechanisms. In this paper, we propose the use of a conditional density estimator, augmented with a graph neural network, to perform inference on a flexible mixture of network-forming mechanisms. This event-wise mixture-of-mechanisms model assigns mechanisms to each edge formation event rather than stipulating node-level mechanisms, thus allowing for an explanation of the network generation process, as well as the dynamic evolution of the network over time. We demonstrate that our approximate Bayesian approach yields valid inferences for the relative weights of the mechanisms in our model, and we utilize this method to investigate the mechanisms behind the formation of a variety of real-world networks."}
