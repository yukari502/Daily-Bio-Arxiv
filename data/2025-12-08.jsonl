{"id": "2512.05208", "pdf": "https://arxiv.org/pdf/2512.05208", "abs": "https://arxiv.org/abs/2512.05208", "authors": ["Alex Zhavoronkov", "Dominika Wilczok"], "title": "Peakspan: Defining, Quantifying and Extending the Boundaries of Peak Productive Lifespan", "categories": ["q-bio.QM", "econ.GN"], "comment": null, "summary": "The unprecedented extension of the human lifespan necessitates a parallel evolution in how we quantify the quality of aging and its socioeconomic impact. Traditional metrics focusing on Healthspan (years free of disease) overlook the gradual erosion of physiological capacity that occurs even in the absence of illness, leading to declines in productivity and eventual lack of capacity to work. To address this critical gap, we introduce Peakspan: the age interval during which an individual maintains at least 90% of their peak functional performance in a specific physiological or cognitive domain. Our multi-system analysis reveals a profound misalignment: most biological systems reach maximal capacity in early adulthood, resulting in a Peakspan that is remarkably short relative to the total lifespan. This dissociation means humans now spend the majority of their adult lives in a \"healthy but declined\" state, characterized by a significant functional gap. We argue that extending Peakspan and developing strategies to restore function in post-peak individuals is the functional manifestation of rejuvenative biomedical progress and is essential for sustained economic growth in aging societies. Recognizing and tracking Peakspan, increasingly facilitated by artificial intelligence and foundational models of biological aging, is crucial for developing strategies to compress functional morbidity and maximize human potential across the life course."}
{"id": "2512.05649", "pdf": "https://arxiv.org/pdf/2512.05649", "abs": "https://arxiv.org/abs/2512.05649", "authors": ["Khayrul Islam", "Mehedi Hasan", "Yaling Liu"], "title": "Physics-Guided Surrogate Modeling for Machine Learning-Driven DLD Design Optimization", "categories": ["q-bio.QM"], "comment": "33 pages, 5 figures", "summary": "Sorting cells based on their mechanical properties is essential for applications in disease diagnostics, cell therapy, and biomedical research. Deterministic Lateral Displacement (DLD) devices provide a label-free method for achieving such sorting, but their performance is highly sensitive to cell size and deformability. Designing effective DLD geometries often demands extensive trial-and-error experimentation, as even small variations in cellular mechanical traits can cause significant changes in migration behavior. To address this challenge, we propose a simulation-driven machine learning (ML) framework that predicts suitable DLD design candidates for a given cell type. Our approach integrates high-fidelity particle-based simulations to model cell deformation and migration through microfluidic pillar arrays with supervised ML models trained to estimate optimal geometries. By mapping mechanical parameters such as bending rigidity and shear modulus to deformation index and migration angle, the framework enables rapid, data-informed design of DLD systems. We also demonstrate a deployable web interface to make this tool accessible for real-world device prototyping."}
{"id": "2512.05247", "pdf": "https://arxiv.org/pdf/2512.05247", "abs": "https://arxiv.org/abs/2512.05247", "authors": ["Spencer Gibson", "Yun William Yu"], "title": "Incorporating indel channels into average-case analysis of seed-chain-extend", "categories": ["cs.DS", "q-bio.QM"], "comment": "25 pages (10 page main text + 2 page biblio + 13 page appendix); conference submission", "summary": "Given a sequence $s_1$ of $n$ letters drawn i.i.d. from an alphabet of size $σ$ and a mutated substring $s_2$ of length $m < n$, we often want to recover the mutation history that generated $s_2$ from $s_1$. Modern sequence aligners are widely used for this task, and many employ the seed-chain-extend heuristic with $k$-mer seeds. Previously, Shaw and Yu showed that optimal linear-gap cost chaining can produce a chain with $1 - O\\left(\\frac{1}{\\sqrt{m}}\\right)$ recoverability, the proportion of the mutation history that is recovered, in $O\\left(mn^{2.43θ} \\log n\\right)$ expected time, where $θ< 0.206$ is the mutation rate under a substitution-only channel and $s_1$ is assumed to be uniformly random. However, a gap remains between theory and practice, since real genomic data includes insertions and deletions (indels), and yet seed-chain-extend remains effective. In this paper, we generalize those prior results by introducing mathematical machinery to deal with the two new obstacles introduced by indel channels: the dependence of neighboring anchors and the presence of anchors that are only partially correct. We are thus able\n  to prove that the expected recoverability of an optimal chain is $\\ge 1 - O\\Bigl(\\frac{1}{\\sqrt{m}}\\Bigr)$ and the expected runtime is $O(mn^{3.15 \\cdot θ_T}\\log n)$, when the total mutation rate given by the sum of the substitution, insertion, and deletion mutation rates ($θ_T = θ_i + θ_d + θ_s$) is less than $0.159$."}
{"id": "2512.05256", "pdf": "https://arxiv.org/pdf/2512.05256", "abs": "https://arxiv.org/abs/2512.05256", "authors": ["Ivan Makohon", "Mohamad Najafi", "Jian Wu", "Mathias Brochhausen", "Yaohang Li"], "title": "Enhancing Clinical Note Generation with ICD-10, Clinical Ontology Knowledge Graphs, and Chain-of-Thought Prompting Using GPT-4", "categories": ["cs.CL", "q-bio.QM"], "comment": null, "summary": "In the past decade a surge in the amount of electronic health record (EHR) data in the United States, attributed to a favorable policy environment created by the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and the 21st Century Cures Act of 2016. Clinical notes for patients' assessments, diagnoses, and treatments are captured in these EHRs in free-form text by physicians, who spend a considerable amount of time entering and editing them. Manually writing clinical notes takes a considerable amount of a doctor's valuable time, increasing the patient's waiting time and possibly delaying diagnoses. Large language models (LLMs) possess the ability to generate news articles that closely resemble human-written ones. We investigate the usage of Chain-of-Thought (CoT) prompt engineering to improve the LLM's response in clinical note generation. In our prompts, we use as input International Classification of Diseases (ICD) codes and basic patient information. We investigate a strategy that combines the traditional CoT with semantic search results to improve the quality of generated clinical notes. Additionally, we infuse a knowledge graph (KG) built from clinical ontology to further enrich the domain-specific knowledge of generated clinical notes. We test our prompting technique on six clinical cases from the CodiEsp test dataset using GPT-4 and our results show that it outperformed the clinical notes generated by standard one-shot prompts."}
{"id": "2512.05346", "pdf": "https://arxiv.org/pdf/2512.05346", "abs": "https://arxiv.org/abs/2512.05346", "authors": ["Neil H. Kim", "Xiao-Liu Chu", "Joseph B. DeGrandchamp", "Matthew R. Foreman"], "title": "Hypothesis-Based Particle Detection for Accurate Nanoparticle Counting and Digital Diagnostics", "categories": ["physics.comp-ph", "physics.med-ph", "physics.optics", "q-bio.QM"], "comment": "Main text (14 pages, 5 figures, 1 table) and supplementary information (5 pages, 3 figures, 2 tables). Supporting code at https://github.com/Optical-Theory-Group/Hypothesis-Test-Based-Particle-Detection", "summary": "Digital assays represent a shift from traditional diagnostics and enable the precise detection of low-abundance analytes, critical for early disease diagnosis and personalized medicine, through discrete counting of biomolecular reporters. Within this paradigm, we present a particle counting algorithm for nanoparticle based imaging assays, formulated as a multiple-hypothesis statistical test under an explicit image-formation model and evaluated using a penalized likelihood rule. In contrast to thresholding or machine learning methods, this approach requires no training data or empirical parameter tuning, and its outputs remain interpretable through direct links to imaging physics and statistical decision theory.\n  Through numerical simulations we demonstrate robust count accuracy across weak signals, variable backgrounds, magnification changes and moderate PSF mismatch. Particle resolvability tests further reveal characteristic error modes, including under-counting at very small separations and localized over-counting near the resolution limit. Practically, we also confirm the algorithm's utility, through application to experimental dark-field images comprising a nanoparticle-based assay for detection of DNA biomarkers derived from SARS-CoV-2. Statistically significant differences in particle count distributions are observed between control and positive samples. Full count statistics obtained further exhibit consistent over-dispersion, and provide insight into non-specific and target-induced particle aggregation. These results establish our method as a reliable framework for nanoparticle-based detection assays in digital molecular diagnostics."}
{"id": "2512.05365", "pdf": "https://arxiv.org/pdf/2512.05365", "abs": "https://arxiv.org/abs/2512.05365", "authors": ["Zag ElSayed", "Craig Erickson", "Ernest Pedapati"], "title": "MCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare", "categories": ["cs.AI", "q-bio.QM"], "comment": "6 pages, 4 figures", "summary": "Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state management, and human-verifiable workflows into a cohesive framework. This paper introduces a completely innovative architecture and concept: combining the Model Context Protocol (MCP) with a specific clinical application, known as MCP-AI. This integration allows intelligent agents to reason over extended periods, collaborate securely, and adhere to authentic clinical logic, representing a significant shift away from traditional Clinical Decision Support Systems (CDSS) and prompt-based Large Language Models (LLMs). As healthcare systems become more complex, the need for autonomous, context-aware clinical reasoning frameworks has become urgent. We present MCP-AI, a novel architecture for explainable medical decision-making built upon the Model Context Protocol (MCP) a modular, executable specification for orchestrating generative and descriptive AI agents in real-time workflows. Each MCP file captures clinical objectives, patient context, reasoning state, and task logic, forming a reusable and auditable memory object. Unlike conventional CDSS or stateless prompt-based AI systems, MCP-AI supports adaptive, longitudinal, and collaborative reasoning across care settings. MCP-AI is validated through two use cases: (1) diagnostic modeling of Fragile X Syndrome with comorbid depression, and (2) remote coordination for Type 2 Diabetes and hypertension. In either scenario, the protocol facilitates physician-in-the-loop validation, streamlines clinical processes, and guarantees secure transitions of AI responsibilities between healthcare providers. The system connects with HL7/FHIR interfaces and adheres to regulatory standards, such as HIPAA and FDA SaMD guidelines. MCP-AI provides a scalable basis for interpretable, composable, and safety-oriented AI within upcoming clinical environments."}
{"id": "2512.05462", "pdf": "https://arxiv.org/pdf/2512.05462", "abs": "https://arxiv.org/abs/2512.05462", "authors": ["Yan-Shiun Wu", "Nathan A. Morin"], "title": "Model Gateway: Model Management Platform for Model-Driven Drug Discovery", "categories": ["cs.SE", "cs.DC", "cs.LG", "q-bio.QM"], "comment": "7 pages, 7 figures", "summary": "This paper presents the Model Gateway, a management platform for managing machine learning (ML) and scientific computational models in the drug discovery pipeline. The platform supports Large Language Model (LLM) Agents and Generative AI-based tools to perform ML model management tasks in our Machine Learning operations (MLOps) pipelines, such as the dynamic consensus model, a model that aggregates several scientific computational models, registration and management, retrieving model information, asynchronous submission/execution of models, and receiving results once the model complete executions. The platform includes a Model Owner Control Panel, Platform Admin Tools, and Model Gateway API service for interacting with the platform and tracking model execution. The platform achieves a 0% failure rate when testing scaling beyond 10k simultaneous application clients consume models. The Model Gateway is a fundamental part of our model-driven drug discovery pipeline. It has the potential to significantly accelerate the development of new drugs with the maturity of our MLOps infrastructure and the integration of LLM Agents and Generative AI tools."}
{"id": "2512.05573", "pdf": "https://arxiv.org/pdf/2512.05573", "abs": "https://arxiv.org/abs/2512.05573", "authors": ["Fei Zhang", "Weixiong Zhang"], "title": "Refined HLA Linkage Disequilibrium Architectures of World Populations by a Novel Allelic Correlation Measure", "categories": ["q-bio.GN", "q-bio.QM"], "comment": null, "summary": "Numerous diseases, particularly autoimmune disorders, are associated with the human leukocyte antigen (HLA), a small genomic region located on human chromosome 6. Adequate characterization of linkage disequilibrium (LD) in the HLA across populations is crucial for identifying genetic markers associated with specific traits and phenotypes. However, current LD measures often fail to capture HLA's structural complexity due to methodological limitations and sensitivity to low-frequency variants, marginal allele frequencies, and haplotype composition. To address these challenges, we introduced the Conditional Informatics Correlation Coefficient (CICC), which integrates conditional probability, information content, and haplotype-aware XOR logic to quantify LD robustly. When applied to high-resolution haploid genomes from the Human Pangenome Reference Consortium (HPRC), CICC revealed 10 novel high-LD regions in HLA. Further analyses using the 1000 Genomes Project and Genome Asia datasets identified nine strongly linked regions shared across five global populations-five in Class I and four in Class II. These results demonstrate CICC's ability to capture complex HLA LD structures across populations, highlighting its broad potential for disease gene mapping, population genomics, and guiding precision medicine."}
{"id": "2512.05794", "pdf": "https://arxiv.org/pdf/2512.05794", "abs": "https://arxiv.org/abs/2512.05794", "authors": ["Rebonto Haque", "Oliver M. Turnbull", "Anisha Parsan", "Nithin Parsan", "John J. Yang", "Charlotte M. Deane"], "title": "Mechanistic Interpretability of Antibody Language Models Using SAEs", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "Sparse autoencoders (SAEs) are a mechanistic interpretability technique that have been used to provide insight into learned concepts within large protein language models. Here, we employ TopK and Ordered SAEs to investigate an autoregressive antibody language model, p-IgGen, and steer its generation. We show that TopK SAEs can reveal biologically meaningful latent features, but high feature concept correlation does not guarantee causal control over generation. In contrast, Ordered SAEs impose an hierarchical structure that reliably identifies steerable features, but at the expense of more complex and less interpretable activation patterns. These findings advance the mechanistic interpretability of domain-specific protein language models and suggest that, while TopK SAEs are sufficient for mapping latent features to concepts, Ordered SAEs are preferable when precise generative steering is required."}
