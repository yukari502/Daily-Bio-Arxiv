<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 1]
- [q-bio.MN](#q-bio.MN) [Total: 3]
- [cs.LG](#cs.LG) [Total: 1]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [Development of an Agentic AI Model for NGS Downstream Analysis Targeting Researchers with Limited Biological Background](https://arxiv.org/abs/2512.09964)
*Donghyeon Lee,Dongseok Kim,Seokhwan Ko,Seo-Young Park,Junghwan Cho*

Main category: q-bio.GN

TL;DR: 开发基于Llama 3 70B LLM和RAG框架的AI代理系统，自动化NGS下游分析，为缺乏计算生物学背景的研究者提供文献支持的生物解释和高级分析方法推荐。


<details>
  <summary>Details</summary>
Motivation: NGS下游分析复杂，现有AI代理大多只关注通用流程，缺乏针对新手的定制化解释和指导，需要开发能自动化分析并提供文献支持解释的系统。

Method: 基于Llama 3 70B大语言模型和检索增强生成(RAG)框架，集成Biopython、GSEApy、gProfiler等生物信息学工具，通过Streamlit部署为交互式Web应用，利用RAG查询PubMed文献进行假设验证。

Result: 在癌症数据集案例中，成功识别显著差异表达基因，可视化临床相关性，获得基于证据的生物学见解（如BRAF突变与预后的关联），并能根据用户选择执行高级生存建模。

Conclusion: 该框架通过使研究者从基础数据处理无缝过渡到高级假设检验和验证，实现了生物信息学的民主化，特别适合计算和生物学背景有限的研究人员。

Abstract: Next-Generation Sequencing (NGS) has become a cornerstone of genomic research, yet the complexity of downstream analysis-ranging from differential expression gene (DEG) identification to biological interpretations-remains a significant barrier for researchers lacking specialized computational and biological expertise. While recent studies have introduced AI agents for RNA-seq analysis, most focus on general workflows without offering tailored interpretations or guidance for novices. To address this gap, we developed an Agentic AI model designed to automate NGS downstream analysis, provide literature-backed interpretations, and autonomously recommend advanced analytical methods. Built on the Llama 3 70B Large Language Model (LLM) and a Retrieval-Augmented Generation (RAG) framework, the model is deployed as an interactive Streamlit web application. The system integrates standard bioinformatics tools (Biopython, GSEApy, gProfiler) to execute core analyses, including DEG identification, clustering, and pathway enrichment. Uniquely, the agent utilizes RAG to query PubMed via Entrez, synthesizing biological insights and validating hypotheses with current literature. In a case study using cancer-related dataset, the model successfully identified significant DEGs, visualized clinical correlations, and derived evidence-based insights (e.g., linking BRAF mutations to prognosis), subsequently executing advanced survival modeling upon user selection. This framework democratizes bioinformatics by enabling researchers with limited backgrounds to seamlessly transition from basic data processing to advanced hypothesis testing and validation.

</details>


<div id='q-bio.MN'></div>

# q-bio.MN [[Back]](#toc)

### [2] [Tracking large chemical reaction networks and rare events by neural networks](https://arxiv.org/abs/2512.10309)
*Jiayu Weng,Xinyi Zhu,Jing Liu,Linyuan Lü,Pan Zhang,Ying Tang*

Main category: q-bio.MN

TL;DR: 本文提出了一种改进的神经网络方法，通过自然梯度下降和时间依赖变分原理实现5-22倍加速，并利用增强采样策略捕捉罕见事件，成功应用于大型生物网络和二维反应扩散系统。


<details>
  <summary>Details</summary>
Motivation: 化学主方程在求解化学动力学、系统生物学和流行病学中的随机动力学时面临状态空间指数增长的挑战。现有的自回归神经网络方法效率有限，特别是在高维系统和罕见事件场景下。

Method: 采用自然梯度下降和时间依赖变分原理等快速优化方法实现加速，结合增强采样策略捕捉罕见事件，将神经网络方法扩展到二维反应扩散系统。

Result: 相比之前的神经网络方法，实现了5-22倍的速度提升和更高的精度，成功处理了MAPK级联网络（迄今最大的生物网络），并扩展到二维Schlögl模型反应扩散系统。

Conclusion: 该方法显著提升了神经网络求解化学主方程的效率和能力，能够高效建模一般化学反应网络，包括高维系统和罕见事件场景。

Abstract: Chemical reaction networks are widely used to model stochastic dynamics in chemical kinetics, systems biology and epidemiology. Solving the chemical master equation that governs these systems poses a significant challenge due to the large state space exponentially growing with system sizes. The development of autoregressive neural networks offers a flexible framework for this problem; however, its efficiency is limited especially for high-dimensional systems and in scenarios with rare events. Here, we push the frontier of neural-network approach by exploiting faster optimizations such as natural gradient descent and time-dependent variational principle, achieving a 5- to 22-fold speedup, and by leveraging enhanced-sampling strategies to capture rare events. We demonstrate reduced computational cost and higher accuracy over the previous neural-network method in challenging reaction networks, including the mitogen-activated protein kinase (MAPK) cascade network, the hitherto largest biological network handled by the previous approaches of solving the chemical master equation. We further apply the approach to spatially extended reaction-diffusion systems, the Schlögl model with rare events, on two-dimensional lattices, beyond the recent tensor-network approach that handles one-dimensional lattices. The present approach thus enables efficient modeling of chemical reaction networks in general.

</details>


### [3] [Why a chloroplast needs its own genome tethered to the thylakoid membrane -- Co-location for Redox Regulation](https://arxiv.org/abs/2512.10588)
*John F. Allen*

Main category: q-bio.MN

TL;DR: 本文提出CoRR假说，解释为什么叶绿体保留自身基因组：光合电子传递的氧化还原调控需要基因与产物共定位，以实现蛋白质组成的自我调节。


<details>
  <summary>Details</summary>
Motivation: 探索叶绿体为何保留自身基因组，而不是将所有蛋白质编码转移到细胞核中。研究光合作用电子传递链中蛋白质合成的不同位点（叶绿体vs细胞核）背后的选择压力。

Method: 提出CoRR假说（共定位氧化还原调控），认为光合电子传递本身调控其组分的基因表达：叶绿体基因与其产物共定位允许氧化还原调控基因表达，从而响应环境变化自我调节蛋白质化学计量。

Result: 氧化还原调控影响叶绿体基因表达的所有阶段，这种整合控制由叶绿体间体或核样结构介导，该结构将叶绿体DNA锚定在类囊体膜上。

Conclusion: 叶绿体保留基因组的主要原因是CoRR机制，即基因与产物共定位允许氧化还原调控基因表达，使光合电子传递链能够响应环境变化自我调节蛋白质组成，这一机制也适用于呼吸作用的线粒体。

Abstract: A chloroplast is a subcellular organelle of photosynthesis in plant and algal cells. A chloroplast genome encodes proteins of the photosynthetic electron transport chain and ribosomal proteins required to express them. Chloroplast-encoded photosynthetic proteins are mostly intrinsic to the chloroplast thylakoid membrane where they drive vectorial electron and proton transport. There they function in close contact with proteins whose precursors are encoded in the cell nucleus for cytosolic synthesis, subsequent processing, and import into the chloroplast. The protein complexes of photosynthetic electron transport thus contain subunits with one of two quite different sites of synthesis. If most chloroplast proteins result from expression of nuclear genes then why not all? What selective pressure accounts for the persistence of the chloroplast genome? One proposal is that photosynthetic electron transport itself governs expression of genes for its own components: co-location of chloroplast genes with their gene products allows redox regulation of gene expression, thereby resulting in self-adjustment of protein stoichiometry in response to environmental change. This hypothesis posits Co-Location for Redox Regulation, termed CoRR, as the primary reason for the retention of genomes in both photosynthetic chloroplasts and respiring mitochondria. I propose that redox regulation affects all stages of chloroplast gene expression and that this integrated control is mediated by a chloroplast mesosome or nucleoid - a structure that tethers chloroplast DNA to the thylakoid.

</details>


### [4] [Saturation-Based Atom Provenance Tracing in Chemical Reaction Networks](https://arxiv.org/abs/2512.10708)
*Marcel Friedrichs,Daniel Merkle*

Main category: q-bio.MN

TL;DR: 提出基于饱和度的标记模式枚举框架，直接基于原子-原子映射，无需通量数据或实验测量，避免组合爆炸问题


<details>
  <summary>Details</summary>
Motivation: 现有计算方法要么简化标记相关性，要么面临组合爆炸问题，需要一种能够精确追踪标记原子在生化反应网络中命运的方法

Method: 使用幂集单子中的Kleisli态射建模反应语义，通过反应规则的迭代饱和枚举所有可能的标记分子配置，包括多重性和重用

Result: 方法能够完全自动重现已知标记模式并发现稳态标记行为，在三羧酸循环和糖酵解途径中得到验证

Conclusion: 该框架为同位素异构体建模和实验设计提供了可扩展、机制透明且可推广的基础

Abstract: Atom tracing is essential for understanding the fate of labeled atoms in biochemical reaction networks, yet existing computational methods either simplify label correlations or suffer from combinatorial explosion. We introduce a saturation-based framework for enumerating labeling patterns that directly operates on atom-atom maps without requiring flux data or experimental measurements. The approach models reaction semantics using Kleisli morphisms in the powerset monad, allowing for compositional propagation of atom provenance through reaction networks. By iteratively saturating all possible educt combinations of reaction rules, the method exhaustively enumerates labeled molecular configurations, including multiplicities and reuse. Allowing arbitrary initial labeling patterns - including identical or distinct labels - the method expands only isotopomers reachable from these inputs, keeping the configuration space as small as necessary and avoids the full combinatorial growth characteristic of previous approaches. In principle, even every atom could carry a distinct identifier (e.g., tracing all carbon atoms individually), illustrating the generality of the framework beyond practical experimental limitations. The resulting template instance hypergraph captures the complete flow of atoms between compounds and supports projections tailored to experimental targets. Customizable labeling sets significantly reduce generated network sizes, providing efficient and exact atom traces focused on specific compounds or available isotopes. Applications to the tricarboxylic acid cycle, and glycolytic pathways demonstrate that the method fully automatically reproduces known labeling patterns and discovers steady-state labeling behavior. The framework offers a scalable, mechanistically transparent, and generalizable foundation for isotopomer modeling and experiment design.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Murmur2Vec: A Hashing Based Solution For Embedding Generation Of COVID-19 Spike Sequences](https://arxiv.org/abs/2512.10147)
*Sarwan Ali,Taslim Murad*

Main category: cs.LG

TL;DR: 提出一种基于哈希的SARS-CoV-2刺突蛋白序列嵌入方法，用于高效的大规模病毒谱系分类，相比现有方法显著提升效率


<details>
  <summary>Details</summary>
Motivation: COVID-19早期检测和特征分析对临床响应和公共卫生规划至关重要。现有方法存在局限性：基于系统发育树的方法计算密集，无法扩展到数百万序列的数据集；现有嵌入方法要么依赖序列比对，要么预测性能不佳且运行成本高，阻碍大规模分析

Method: 针对SARS-CoV-2刺突蛋白区域的最常见谱系，提出可扩展的嵌入方法，利用哈希技术生成紧凑的低维序列表示，然后用这些嵌入训练多种机器学习模型进行监督谱系分类

Result: 与多种基线方法和最先进的生物序列嵌入方法相比，所提嵌入方法在效率上有显著改进，达到86.4%的分类准确率，同时将嵌入生成时间减少高达99.81%

Conclusion: 该方法作为快速、有效且可扩展的大规模病毒序列分析解决方案具有巨大潜力，能够克服现有方法的计算瓶颈

Abstract: Early detection and characterization of coronavirus disease (COVID-19), caused by SARS-CoV-2, remain critical for effective clinical response and public-health planning. The global availability of large-scale viral sequence data presents significant opportunities for computational analysis; however, existing approaches face notable limitations. Phylogenetic tree-based methods are computationally intensive and do not scale efficiently to today's multi-million-sequence datasets. Similarly, current embedding-based techniques often rely on aligned sequences or exhibit suboptimal predictive performance and high runtime costs, creating barriers to practical large-scale analysis. In this study, we focus on the most prevalent SARS-CoV-2 lineages associated with the spike protein region and introduce a scalable embedding method that leverages hashing to generate compact, low-dimensional representations of spike sequences. These embeddings are subsequently used to train a variety of machine learning models for supervised lineage classification. We conduct an extensive evaluation comparing our approach with multiple baseline and state-of-the-art biological sequence embedding methods across diverse metrics. Our results demonstrate that the proposed embeddings offer substantial improvements in efficiency, achieving up to 86.4\% classification accuracy while reducing embedding generation time by as much as 99.81\%. This highlights the method's potential as a fast, effective, and scalable solution for large-scale viral sequence analysis.

</details>
