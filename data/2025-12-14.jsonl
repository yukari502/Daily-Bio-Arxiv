{"id": "2512.09964", "pdf": "https://arxiv.org/pdf/2512.09964", "abs": "https://arxiv.org/abs/2512.09964", "authors": ["Donghyeon Lee", "Dongseok Kim", "Seokhwan Ko", "Seo-Young Park", "Junghwan Cho"], "title": "Development of an Agentic AI Model for NGS Downstream Analysis Targeting Researchers with Limited Biological Background", "categories": ["q-bio.GN"], "comment": null, "summary": "Next-Generation Sequencing (NGS) has become a cornerstone of genomic research, yet the complexity of downstream analysis-ranging from differential expression gene (DEG) identification to biological interpretations-remains a significant barrier for researchers lacking specialized computational and biological expertise. While recent studies have introduced AI agents for RNA-seq analysis, most focus on general workflows without offering tailored interpretations or guidance for novices. To address this gap, we developed an Agentic AI model designed to automate NGS downstream analysis, provide literature-backed interpretations, and autonomously recommend advanced analytical methods. Built on the Llama 3 70B Large Language Model (LLM) and a Retrieval-Augmented Generation (RAG) framework, the model is deployed as an interactive Streamlit web application. The system integrates standard bioinformatics tools (Biopython, GSEApy, gProfiler) to execute core analyses, including DEG identification, clustering, and pathway enrichment. Uniquely, the agent utilizes RAG to query PubMed via Entrez, synthesizing biological insights and validating hypotheses with current literature. In a case study using cancer-related dataset, the model successfully identified significant DEGs, visualized clinical correlations, and derived evidence-based insights (e.g., linking BRAF mutations to prognosis), subsequently executing advanced survival modeling upon user selection. This framework democratizes bioinformatics by enabling researchers with limited backgrounds to seamlessly transition from basic data processing to advanced hypothesis testing and validation."}
{"id": "2512.10147", "pdf": "https://arxiv.org/pdf/2512.10147", "abs": "https://arxiv.org/abs/2512.10147", "authors": ["Sarwan Ali", "Taslim Murad"], "title": "Murmur2Vec: A Hashing Based Solution For Embedding Generation Of COVID-19 Spike Sequences", "categories": ["cs.LG", "q-bio.GN"], "comment": null, "summary": "Early detection and characterization of coronavirus disease (COVID-19), caused by SARS-CoV-2, remain critical for effective clinical response and public-health planning. The global availability of large-scale viral sequence data presents significant opportunities for computational analysis; however, existing approaches face notable limitations. Phylogenetic tree-based methods are computationally intensive and do not scale efficiently to today's multi-million-sequence datasets. Similarly, current embedding-based techniques often rely on aligned sequences or exhibit suboptimal predictive performance and high runtime costs, creating barriers to practical large-scale analysis. In this study, we focus on the most prevalent SARS-CoV-2 lineages associated with the spike protein region and introduce a scalable embedding method that leverages hashing to generate compact, low-dimensional representations of spike sequences. These embeddings are subsequently used to train a variety of machine learning models for supervised lineage classification. We conduct an extensive evaluation comparing our approach with multiple baseline and state-of-the-art biological sequence embedding methods across diverse metrics. Our results demonstrate that the proposed embeddings offer substantial improvements in efficiency, achieving up to 86.4\\% classification accuracy while reducing embedding generation time by as much as 99.81\\%. This highlights the method's potential as a fast, effective, and scalable solution for large-scale viral sequence analysis."}
{"id": "2512.10309", "pdf": "https://arxiv.org/pdf/2512.10309", "abs": "https://arxiv.org/abs/2512.10309", "authors": ["Jiayu Weng", "Xinyi Zhu", "Jing Liu", "Linyuan Lü", "Pan Zhang", "Ying Tang"], "title": "Tracking large chemical reaction networks and rare events by neural networks", "categories": ["q-bio.MN", "cs.LG", "physics.bio-ph"], "comment": null, "summary": "Chemical reaction networks are widely used to model stochastic dynamics in chemical kinetics, systems biology and epidemiology. Solving the chemical master equation that governs these systems poses a significant challenge due to the large state space exponentially growing with system sizes. The development of autoregressive neural networks offers a flexible framework for this problem; however, its efficiency is limited especially for high-dimensional systems and in scenarios with rare events. Here, we push the frontier of neural-network approach by exploiting faster optimizations such as natural gradient descent and time-dependent variational principle, achieving a 5- to 22-fold speedup, and by leveraging enhanced-sampling strategies to capture rare events. We demonstrate reduced computational cost and higher accuracy over the previous neural-network method in challenging reaction networks, including the mitogen-activated protein kinase (MAPK) cascade network, the hitherto largest biological network handled by the previous approaches of solving the chemical master equation. We further apply the approach to spatially extended reaction-diffusion systems, the Schlögl model with rare events, on two-dimensional lattices, beyond the recent tensor-network approach that handles one-dimensional lattices. The present approach thus enables efficient modeling of chemical reaction networks in general."}
{"id": "2512.10588", "pdf": "https://arxiv.org/pdf/2512.10588", "abs": "https://arxiv.org/abs/2512.10588", "authors": ["John F. Allen"], "title": "Why a chloroplast needs its own genome tethered to the thylakoid membrane -- Co-location for Redox Regulation", "categories": ["q-bio.MN"], "comment": "15 pages, 1 figure", "summary": "A chloroplast is a subcellular organelle of photosynthesis in plant and algal cells. A chloroplast genome encodes proteins of the photosynthetic electron transport chain and ribosomal proteins required to express them. Chloroplast-encoded photosynthetic proteins are mostly intrinsic to the chloroplast thylakoid membrane where they drive vectorial electron and proton transport. There they function in close contact with proteins whose precursors are encoded in the cell nucleus for cytosolic synthesis, subsequent processing, and import into the chloroplast. The protein complexes of photosynthetic electron transport thus contain subunits with one of two quite different sites of synthesis. If most chloroplast proteins result from expression of nuclear genes then why not all? What selective pressure accounts for the persistence of the chloroplast genome? One proposal is that photosynthetic electron transport itself governs expression of genes for its own components: co-location of chloroplast genes with their gene products allows redox regulation of gene expression, thereby resulting in self-adjustment of protein stoichiometry in response to environmental change. This hypothesis posits Co-Location for Redox Regulation, termed CoRR, as the primary reason for the retention of genomes in both photosynthetic chloroplasts and respiring mitochondria. I propose that redox regulation affects all stages of chloroplast gene expression and that this integrated control is mediated by a chloroplast mesosome or nucleoid - a structure that tethers chloroplast DNA to the thylakoid."}
{"id": "2512.10708", "pdf": "https://arxiv.org/pdf/2512.10708", "abs": "https://arxiv.org/abs/2512.10708", "authors": ["Marcel Friedrichs", "Daniel Merkle"], "title": "Saturation-Based Atom Provenance Tracing in Chemical Reaction Networks", "categories": ["q-bio.MN", "cs.DM"], "comment": null, "summary": "Atom tracing is essential for understanding the fate of labeled atoms in biochemical reaction networks, yet existing computational methods either simplify label correlations or suffer from combinatorial explosion. We introduce a saturation-based framework for enumerating labeling patterns that directly operates on atom-atom maps without requiring flux data or experimental measurements. The approach models reaction semantics using Kleisli morphisms in the powerset monad, allowing for compositional propagation of atom provenance through reaction networks. By iteratively saturating all possible educt combinations of reaction rules, the method exhaustively enumerates labeled molecular configurations, including multiplicities and reuse. Allowing arbitrary initial labeling patterns - including identical or distinct labels - the method expands only isotopomers reachable from these inputs, keeping the configuration space as small as necessary and avoids the full combinatorial growth characteristic of previous approaches. In principle, even every atom could carry a distinct identifier (e.g., tracing all carbon atoms individually), illustrating the generality of the framework beyond practical experimental limitations. The resulting template instance hypergraph captures the complete flow of atoms between compounds and supports projections tailored to experimental targets. Customizable labeling sets significantly reduce generated network sizes, providing efficient and exact atom traces focused on specific compounds or available isotopes. Applications to the tricarboxylic acid cycle, and glycolytic pathways demonstrate that the method fully automatically reproduces known labeling patterns and discovers steady-state labeling behavior. The framework offers a scalable, mechanistically transparent, and generalizable foundation for isotopomer modeling and experiment design."}
