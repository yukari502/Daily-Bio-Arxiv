<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 1]
- [q-bio.MN](#q-bio.MN) [Total: 3]
- [cs.LG](#cs.LG) [Total: 1]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [Development of an Agentic AI Model for NGS Downstream Analysis Targeting Researchers with Limited Biological Background](https://arxiv.org/abs/2512.09964)
*Donghyeon Lee,Dongseok Kim,Seokhwan Ko,Seo-Young Park,Junghwan Cho*

Main category: q-bio.GN

TL;DR: 开发基于Llama 3 70B LLM和RAG框架的AI代理系统，自动化NGS下游分析并提供文献支持的生物学解释，降低生物信息学分析门槛


<details>
  <summary>Details</summary>
Motivation: NGS下游分析复杂度高，现有AI代理大多关注通用流程而缺乏针对新手的定制化解释和指导，需要开发能提供文献支持解释的自动化系统

Method: 基于Llama 3 70B大型语言模型和检索增强生成(RAG)框架，集成标准生物信息学工具(Biopython, GSEApy, gProfiler)，通过Entrez查询PubMed文献，部署为交互式Streamlit网络应用

Result: 在癌症相关数据集案例中，成功识别显著差异表达基因，可视化临床相关性，获得基于证据的生物学见解(如BRAF突变与预后的关联)，并能根据用户选择执行高级生存建模

Conclusion: 该框架通过使背景有限的研究人员能够从基础数据处理无缝过渡到高级假设检验和验证，实现了生物信息学的民主化

Abstract: Next-Generation Sequencing (NGS) has become a cornerstone of genomic research, yet the complexity of downstream analysis-ranging from differential expression gene (DEG) identification to biological interpretations-remains a significant barrier for researchers lacking specialized computational and biological expertise. While recent studies have introduced AI agents for RNA-seq analysis, most focus on general workflows without offering tailored interpretations or guidance for novices. To address this gap, we developed an Agentic AI model designed to automate NGS downstream analysis, provide literature-backed interpretations, and autonomously recommend advanced analytical methods. Built on the Llama 3 70B Large Language Model (LLM) and a Retrieval-Augmented Generation (RAG) framework, the model is deployed as an interactive Streamlit web application. The system integrates standard bioinformatics tools (Biopython, GSEApy, gProfiler) to execute core analyses, including DEG identification, clustering, and pathway enrichment. Uniquely, the agent utilizes RAG to query PubMed via Entrez, synthesizing biological insights and validating hypotheses with current literature. In a case study using cancer-related dataset, the model successfully identified significant DEGs, visualized clinical correlations, and derived evidence-based insights (e.g., linking BRAF mutations to prognosis), subsequently executing advanced survival modeling upon user selection. This framework democratizes bioinformatics by enabling researchers with limited backgrounds to seamlessly transition from basic data processing to advanced hypothesis testing and validation.

</details>


<div id='q-bio.MN'></div>

# q-bio.MN [[Back]](#toc)

### [2] [Tracking large chemical reaction networks and rare events by neural networks](https://arxiv.org/abs/2512.10309)
*Jiayu Weng,Xinyi Zhu,Jing Liu,Linyuan Lü,Pan Zhang,Ying Tang*

Main category: q-bio.MN

TL;DR: 该论文提出了一种改进的神经网络方法，通过自然梯度下降和时间依赖变分原理实现5-22倍加速，并利用增强采样策略捕捉稀有事件，成功应用于高维反应网络和二维反应扩散系统。


<details>
  <summary>Details</summary>
Motivation: 化学主方程在求解化学动力学、系统生物学和流行病学中的随机动力学时面临状态空间随系统规模指数增长的挑战。现有自回归神经网络方法效率有限，特别是在高维系统和稀有事件场景下。

Method: 采用更快的优化方法（自然梯度下降和时间依赖变分原理）实现加速，并利用增强采样策略来捕捉稀有事件。将方法应用于包括MAPK级联网络在内的挑战性反应网络，以及二维反应扩散系统。

Result: 相比之前的神经网络方法，实现了5-22倍的速度提升，计算成本降低且精度更高。成功处理了迄今为止最大的生物网络（MAPK级联），并扩展到二维反应扩散系统（Schlögl模型），超越了最近仅能处理一维系统的张量网络方法。

Conclusion: 该方法为化学反应网络的高效建模提供了通用解决方案，能够处理高维系统、稀有事件和空间扩展系统，显著推进了神经网络在化学主方程求解中的应用前沿。

Abstract: Chemical reaction networks are widely used to model stochastic dynamics in chemical kinetics, systems biology and epidemiology. Solving the chemical master equation that governs these systems poses a significant challenge due to the large state space exponentially growing with system sizes. The development of autoregressive neural networks offers a flexible framework for this problem; however, its efficiency is limited especially for high-dimensional systems and in scenarios with rare events. Here, we push the frontier of neural-network approach by exploiting faster optimizations such as natural gradient descent and time-dependent variational principle, achieving a 5- to 22-fold speedup, and by leveraging enhanced-sampling strategies to capture rare events. We demonstrate reduced computational cost and higher accuracy over the previous neural-network method in challenging reaction networks, including the mitogen-activated protein kinase (MAPK) cascade network, the hitherto largest biological network handled by the previous approaches of solving the chemical master equation. We further apply the approach to spatially extended reaction-diffusion systems, the Schlögl model with rare events, on two-dimensional lattices, beyond the recent tensor-network approach that handles one-dimensional lattices. The present approach thus enables efficient modeling of chemical reaction networks in general.

</details>


### [3] [Why a chloroplast needs its own genome tethered to the thylakoid membrane -- Co-location for Redox Regulation](https://arxiv.org/abs/2512.10588)
*John F. Allen*

Main category: q-bio.MN

TL;DR: 叶绿体基因组持续存在的主要原因是"共定位用于氧化还原调控"假说，即光合电子传递本身调控其自身组分的基因表达，通过氧化还原信号实现蛋白质化学计量的自我调整。


<details>
  <summary>Details</summary>
Motivation: 探讨为什么叶绿体基因组在大多数叶绿体蛋白由核基因编码的情况下仍然持续存在，寻找其进化保留的选择压力。

Method: 提出CoRR假说（共定位用于氧化还原调控），认为光合电子传递通过氧化还原信号调控叶绿体基因表达，实现蛋白质化学计量的环境响应性调整。

Result: 氧化还原调控影响叶绿体基因表达的所有阶段，这种整合控制由叶绿体中体或类核结构介导，该结构将叶绿体DNA锚定在类囊体膜上。

Conclusion: 叶绿体基因组持续存在的主要原因是CoRR机制，这同样适用于呼吸线粒体基因组的保留，为细胞器基因组的进化保留提供了统一解释。

Abstract: A chloroplast is a subcellular organelle of photosynthesis in plant and algal cells. A chloroplast genome encodes proteins of the photosynthetic electron transport chain and ribosomal proteins required to express them. Chloroplast-encoded photosynthetic proteins are mostly intrinsic to the chloroplast thylakoid membrane where they drive vectorial electron and proton transport. There they function in close contact with proteins whose precursors are encoded in the cell nucleus for cytosolic synthesis, subsequent processing, and import into the chloroplast. The protein complexes of photosynthetic electron transport thus contain subunits with one of two quite different sites of synthesis. If most chloroplast proteins result from expression of nuclear genes then why not all? What selective pressure accounts for the persistence of the chloroplast genome? One proposal is that photosynthetic electron transport itself governs expression of genes for its own components: co-location of chloroplast genes with their gene products allows redox regulation of gene expression, thereby resulting in self-adjustment of protein stoichiometry in response to environmental change. This hypothesis posits Co-Location for Redox Regulation, termed CoRR, as the primary reason for the retention of genomes in both photosynthetic chloroplasts and respiring mitochondria. I propose that redox regulation affects all stages of chloroplast gene expression and that this integrated control is mediated by a chloroplast mesosome or nucleoid - a structure that tethers chloroplast DNA to the thylakoid.

</details>


### [4] [Saturation-Based Atom Provenance Tracing in Chemical Reaction Networks](https://arxiv.org/abs/2512.10708)
*Marcel Friedrichs,Daniel Merkle*

Main category: q-bio.MN

TL;DR: 提出基于饱和的框架，用于枚举标记模式，直接操作原子-原子映射，无需通量数据或实验测量，避免组合爆炸问题。


<details>
  <summary>Details</summary>
Motivation: 现有计算方法要么简化标记相关性，要么面临组合爆炸问题，需要一种能够精确追踪标记原子在生化反应网络中命运的方法。

Method: 使用幂集单子中的Kleisli态射建模反应语义，通过反应规则的迭代饱和枚举所有可能的标记分子配置，包括多重性和重用。

Result: 该方法能够自动重现已知标记模式，发现稳态标记行为，生成可定制的模板实例超图，显著减少网络规模，提供高效精确的原子追踪。

Conclusion: 该框架为同位素异构体建模和实验设计提供了可扩展、机制透明且可推广的基础，超越了实际实验限制。

Abstract: Atom tracing is essential for understanding the fate of labeled atoms in biochemical reaction networks, yet existing computational methods either simplify label correlations or suffer from combinatorial explosion. We introduce a saturation-based framework for enumerating labeling patterns that directly operates on atom-atom maps without requiring flux data or experimental measurements. The approach models reaction semantics using Kleisli morphisms in the powerset monad, allowing for compositional propagation of atom provenance through reaction networks. By iteratively saturating all possible educt combinations of reaction rules, the method exhaustively enumerates labeled molecular configurations, including multiplicities and reuse. Allowing arbitrary initial labeling patterns - including identical or distinct labels - the method expands only isotopomers reachable from these inputs, keeping the configuration space as small as necessary and avoids the full combinatorial growth characteristic of previous approaches. In principle, even every atom could carry a distinct identifier (e.g., tracing all carbon atoms individually), illustrating the generality of the framework beyond practical experimental limitations. The resulting template instance hypergraph captures the complete flow of atoms between compounds and supports projections tailored to experimental targets. Customizable labeling sets significantly reduce generated network sizes, providing efficient and exact atom traces focused on specific compounds or available isotopes. Applications to the tricarboxylic acid cycle, and glycolytic pathways demonstrate that the method fully automatically reproduces known labeling patterns and discovers steady-state labeling behavior. The framework offers a scalable, mechanistically transparent, and generalizable foundation for isotopomer modeling and experiment design.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Murmur2Vec: A Hashing Based Solution For Embedding Generation Of COVID-19 Spike Sequences](https://arxiv.org/abs/2512.10147)
*Sarwan Ali,Taslim Murad*

Main category: cs.LG

TL;DR: 提出一种基于哈希的可扩展嵌入方法，用于SARS-CoV-2刺突蛋白序列分析，显著提高分类效率和准确性


<details>
  <summary>Details</summary>
Motivation: COVID-19早期检测和特征分析对临床响应和公共卫生规划至关重要。现有方法存在计算量大、扩展性差、性能不佳等问题，难以处理数百万序列的大规模数据集

Method: 针对SARS-CoV-2刺突蛋白区域的主要谱系，开发基于哈希的可扩展嵌入方法，生成紧凑的低维序列表示，然后训练多种机器学习模型进行谱系分类

Result: 与多种基线方法相比，提出的嵌入方法在效率上显著提升，达到86.4%的分类准确率，同时将嵌入生成时间减少高达99.81%

Conclusion: 该方法为大规模病毒序列分析提供了一个快速、有效且可扩展的解决方案，具有实际应用潜力

Abstract: Early detection and characterization of coronavirus disease (COVID-19), caused by SARS-CoV-2, remain critical for effective clinical response and public-health planning. The global availability of large-scale viral sequence data presents significant opportunities for computational analysis; however, existing approaches face notable limitations. Phylogenetic tree-based methods are computationally intensive and do not scale efficiently to today's multi-million-sequence datasets. Similarly, current embedding-based techniques often rely on aligned sequences or exhibit suboptimal predictive performance and high runtime costs, creating barriers to practical large-scale analysis. In this study, we focus on the most prevalent SARS-CoV-2 lineages associated with the spike protein region and introduce a scalable embedding method that leverages hashing to generate compact, low-dimensional representations of spike sequences. These embeddings are subsequently used to train a variety of machine learning models for supervised lineage classification. We conduct an extensive evaluation comparing our approach with multiple baseline and state-of-the-art biological sequence embedding methods across diverse metrics. Our results demonstrate that the proposed embeddings offer substantial improvements in efficiency, achieving up to 86.4\% classification accuracy while reducing embedding generation time by as much as 99.81\%. This highlights the method's potential as a fast, effective, and scalable solution for large-scale viral sequence analysis.

</details>
