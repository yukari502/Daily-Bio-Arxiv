{"id": "2512.10995", "pdf": "https://arxiv.org/pdf/2512.10995", "abs": "https://arxiv.org/abs/2512.10995", "authors": ["Muhammad Usamah Shahid", "Muddassar Farooq"], "title": "Boosted Random Forests for Predicting Treatment Failure of Chemotherapy Regimens", "categories": ["q-bio.QM", "cs.LG"], "comment": "International Conference on Artificial Intelligence in Medicine. Cham: Springer Nature Switzerland, 2023", "summary": "Cancer patients may undergo lengthy and painful chemotherapy treatments, comprising several successive regimens or plans. Treatment inefficacy and other adverse events can lead to discontinuation (or failure) of these plans, or prematurely changing them, which results in a significant amount of physical, financial, and emotional toxicity to the patients and their families. In this work, we build treatment failure models based on the Real World Evidence (RWE) gathered from patients' profiles available in our oncology EMR/EHR system. We also describe our feature engineering pipeline, experimental methods, and valuable insights obtained about treatment failures from trained models. We report our findings on five primary cancer types with the most frequent treatment failures (or discontinuations) to build unique and novel feature vectors from the clinical notes, diagnoses, and medications that are available in our oncology EMR. After following a novel three axes - performance, complexity and explainability - design exploration framework, boosted random forests are selected because they provide a baseline accuracy of 80% and an F1 score of 75%, with reduced model complexity, thus making them more interpretable to and usable by oncologists."}
{"id": "2512.11075", "pdf": "https://arxiv.org/pdf/2512.11075", "abs": "https://arxiv.org/abs/2512.11075", "authors": ["Junmin Zhong", "Jon F. Harrison", "Jennie Si", "Jun Chen"], "title": "Fast, accurate measurement of the worker populations of honey bee colonies using deep learning", "categories": ["q-bio.QM", "cs.AI"], "comment": null, "summary": "Honey bees play a crucial role in pollination, contributing significantly to global agriculture and ecosystems. Accurately estimating hive populations is essential for understanding the effects of environmental factors on bee colonies, yet traditional methods of counting bees are time-consuming, labor-intensive, and prone to human error, particularly in large-scale studies. In this paper, we present a deep learning-based solution for automating bee population counting using CSRNet and introduce ASUBEE, the FIRST high-resolution dataset specifically designed for this task. Our method employs density map estimation to predict bee populations, effectively addressing challenges such as occlusion and overlapping bees that are common in hive monitoring. We demonstrate that CSRNet achieves superior performance in terms of time efficiency, with a computation time of just 1 second per image, while delivering accurate counts even in complex and densely populated hive scenarios. Our findings show that deep learning approaches like CSRNet can dramatically enhance the efficiency of hive population assessments, providing a valuable tool for researchers and beekeepers alike. This work marks a significant advancement in applying AI technologies to ecological research, offering scalable and precise monitoring solutions for honey bee populations."}
{"id": "2512.11101", "pdf": "https://arxiv.org/pdf/2512.11101", "abs": "https://arxiv.org/abs/2512.11101", "authors": ["B. G. Gutiérrez-Gutiérrez", "J. L. Luquin-Arce", "J. Padilla-Lepe", "G. Nieves Hernández", "P. J. Y. Oropeza Gutiérrez", "J. A. Vázquez-García"], "title": "Agave villalobosii (sección Ditepalae, Agavaceae), una especie nueva de la meseta central Mexicana de aguascalientes y zacatecas", "categories": ["q-bio.QM", "q-bio.PE"], "comment": "10 paginas, in Spanish language, 5 figuras, 1 cuadro", "summary": "Agave villalobosii sp. nov. (sect. Ditepalae, Agavaceae, Asparagales) from the Mexican central plain in Aguascalientes and southern Zacatecas, Mexico, is described and illustrated. It resembles A. flexispina in terms of color and the general appearance of its rosettes. However, it differs from the latter in having fewer leaves with more widely spaced teeth, more compact and shorter panicles with more inclined lateral branches with respect to the horizontal plane, and subglobose to broadly ellipsoid capsules. A distribution map for both species is provided. The species was preliminary assessed as critically endangered."}
{"id": "2512.11511", "pdf": "https://arxiv.org/pdf/2512.11511", "abs": "https://arxiv.org/abs/2512.11511", "authors": ["Kaijie Wang", "Le Yin", "Aodi Tian", "Zhiqiang Wei", "Zai Yang", "Min Han", "Qichun Wei", "Sheng Wang"], "title": "DREAM-B3P: Dual-Stream Transformer Network Enhanced by Feedback Diffusion Model for Blood-Brain Barrier Penetrating Peptide Prediction", "categories": ["q-bio.QM"], "comment": null, "summary": "Introduction: The blood-brain barrier (BBB) protects the central nervous system but prevents most neurotherapeutics from reaching effective concentrations in the brain. BBB-penetrating peptides (BBBPs) offer a promising strategy for brain drug delivery; however, the scarcity of positive samples and severe class imbalance hinder the reliable identification of BBBPs.\n  Objectives: Our goal is to alleviate class imbalance in BBBP prediction and to develop an accurate, interpretable classifier for BBBP prediction.\n  Methods: We propose DREAM-B3P, which couples a feedback diffusion model (FB-Diffusion) for data augmentation with a dual-stream Transformer for classification. FB-Diffusion learns the BBBP distribution via iterative denoising and uses an external analyzer to provide feedback, generating high-quality pseudo-BBBPs. The classifier contains a sequence stream that extracts structural features from peptide sequences and a physicochemical stream that captures physicochemical features such as hydrophobic surface area, molecular charge, number of rotatable bonds, and polarizability. Combining the two features leads to superior BBBP predictive performance.\n  Results: On a benchmark test set containing equal numbers of BBBPs and non-BBBPs, DREAM-B3P surpasses baseline methods (Deep-B3P, B3Pred, BBPpredict and Augur), improving AUC/ACC/MCC by 4.3\\%/17.8\\%/14.9\\%, respectively, over the second-best method.\n  Conclusion: By integrating feedback diffusion with a dual-stream Transformer classifier, DREAM-B3P effectively mitigates data scarcity and imbalance and achieves state-of-the-art performance."}
{"id": "2512.11605", "pdf": "https://arxiv.org/pdf/2512.11605", "abs": "https://arxiv.org/abs/2512.11605", "authors": ["Walter Polilli", "Alessio Antonini", "Cristiano Platani", "Fabio Stagnari", "Angelica Galieni"], "title": "Enhancing Robustness in Plant Water Stress Classification based on Morpho-Kinematic via Biological Sectoring and Adaptive Linear Opinion Pooling", "categories": ["q-bio.QM"], "comment": "35 pages, 6 figures, to be submitted to Computers and Electronics in Agriculture COMPAG", "summary": "Precise irrigation management requires robust classification of plant water stress. We expanded a morpho-kinematic (MK) framework that derives canopy-movement features from RGB time-lapse imaging evaluating how methodological refinements affect robustness and fine discrimination across four irrigation treatments representing distinct stress histories. The study tested both a biological (Agg) versus an isogonal (Unif) sectoring of the canopy image, within an additive scheme where to the baseline (i.e. flattened MK features, A0) were sequentially added non-linear descriptors (A1), irrigation-context variables (i.e. dry time, A2), and their interactions with baseline (A3). The multi-class problem was decomposed in biologically meaningful binary tasks, and the final classification confronted an adaptive - to the performance obtained in the out-of-fold predictions inside the leave-one-sample-out validation framework - linear opinion pooling (ALOP) ensemble, evaluated across its full parameter space, against hierarchical cascades (HCC). In our combined dataset from two sequential Lactuca sativa experiments (144 sample-days) ALOP median outperformed HCC in every configuration, while non-linear and contextual enrichments (A1-A2) produced consistent improvements in terms of prediction stability, variability (for ALOP), and balanced accuracy (BA). The highest balanced accuracy (median BA = 0.96) was reached under Unif scheme in A3, yet the Agg configuration in A2 achieved the best compromise between accuracy (median BA approx 0.91) and robustness. Concluding, this study identifies methodological pathways that strengthen resilience and transferability of movement-based water-stress classification, establishing a solid foundation for generalizable, low-cost phenotyping."}
{"id": "2512.10991", "pdf": "https://arxiv.org/pdf/2512.10991", "abs": "https://arxiv.org/abs/2512.10991", "authors": ["Zhanpeng Chen", "Weihao Gao", "Shunyu Wang", "Yanan Zhu", "Hong Meng", "Yuexian Zou"], "title": "MolSculpt: Sculpting 3D Molecular Geometries from Chemical Syntax", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "q-bio.QM"], "comment": null, "summary": "Generating precise 3D molecular geometries is crucial for drug discovery and material science. While prior efforts leverage 1D representations like SELFIES to ensure molecular validity, they fail to fully exploit the rich chemical knowledge entangled within 1D models, leading to a disconnect between 1D syntactic generation and 3D geometric realization. To bridge this gap, we propose MolSculpt, a novel framework that \"sculpts\" 3D molecular geometries from chemical syntax. MolSculpt is built upon a frozen 1D molecular foundation model and a 3D molecular diffusion model. We introduce a set of learnable queries to extract inherent chemical knowledge from the foundation model, and a trainable projector then injects this cross-modal information into the conditioning space of the diffusion model to guide the 3D geometry generation. In this way, our model deeply integrates 1D latent chemical knowledge into the 3D generation process through end-to-end optimization. Experiments demonstrate that MolSculpt achieves state-of-the-art (SOTA) performance in \\textit{de novo} 3D molecule generation and conditional 3D molecule generation, showing superior 3D fidelity and stability on both the GEOM-DRUGS and QM9 datasets. Code is available at https://github.com/SakuraTroyChen/MolSculpt."}
