{"id": "2512.13724", "pdf": "https://arxiv.org/pdf/2512.13724", "abs": "https://arxiv.org/abs/2512.13724", "authors": ["Ayush Noori", "Joaqu\u00edn Polonuer", "Katharina Meyer", "Bogdan Budnik", "Shad Morton", "Xinyuan Wang", "Sumaiya Nazeen", "Yingnan He", "I\u00f1aki Arango", "Lucas Vittor", "Matthew Woodworth", "Richard C. Krolewski", "Michelle M. Li", "Ninning Liu", "Tushar Kamath", "Evan Macosko", "Dylan Ritter", "Jalwa Afroz", "Alexander B. H. Henderson", "Lorenz Studer", "Samuel G. Rodriques", "Andrew White", "Noa Dagan", "David A. Clifton", "George M. Church", "Sudeshna Das", "Jenny M. Tam", "Vikram Khurana", "Marinka Zitnik"], "title": "Graph AI generates neurological hypotheses validated in molecular, organoid, and clinical systems", "categories": ["q-bio.QM", "cs.AI", "q-bio.NC"], "comment": null, "summary": "Neurological diseases are the leading global cause of disability, yet most lack disease-modifying treatments. We present PROTON, a heterogeneous graph transformer that generates testable hypotheses across molecular, organoid, and clinical systems. To evaluate PROTON, we apply it to Parkinson's disease (PD), bipolar disorder (BD), and Alzheimer's disease (AD). In PD, PROTON linked genetic risk loci to genes essential for dopaminergic neuron survival and predicted pesticides toxic to patient-derived neurons, including the insecticide endosulfan, which ranked within the top 1.29% of predictions. In silico screens performed by PROTON reproduced six genome-wide $\u03b1$-synuclein experiments, including a split-ubiquitin yeast two-hybrid system (normalized enrichment score [NES] = 2.30, FDR-adjusted $p < 1 \\times 10^{-4}$), an ascorbate peroxidase proximity labeling assay (NES = 2.16, FDR $< 1 \\times 10^{-4}$), and a high-depth targeted exome sequencing study in 496 synucleinopathy patients (NES = 2.13, FDR $< 1 \\times 10^{-4}$). In BD, PROTON predicted calcitriol as a candidate drug that reversed proteomic alterations observed in cortical organoids derived from BD patients. In AD, we evaluated PROTON predictions in health records from $n = 610,524$ patients at Mass General Brigham, confirming that five PROTON-predicted drugs were associated with reduced seven-year dementia risk (minimum hazard ratio = 0.63, 95% CI: 0.53-0.75, $p < 1 \\times 10^{-7}$). PROTON generated neurological hypotheses that were evaluated across molecular, organoid, and clinical systems, defining a path for AI-driven discovery in neurological disease.", "AI": {"tldr": "PROTON\u662f\u4e00\u4e2a\u5f02\u6784\u56fe\u53d8\u6362\u5668\uff0c\u7528\u4e8e\u751f\u6210\u8de8\u5206\u5b50\u3001\u7c7b\u5668\u5b98\u548c\u4e34\u5e8a\u7cfb\u7edf\u7684\u53ef\u6d4b\u8bd5\u5047\u8bf4\uff0c\u5e94\u7528\u4e8e\u5e15\u91d1\u68ee\u75c5\u3001\u53cc\u76f8\u60c5\u611f\u969c\u788d\u548c\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff0c\u6210\u529f\u9884\u6d4b\u4e86\u836f\u7269\u9776\u70b9\u548c\u6cbb\u7597\u5019\u9009\u7269\u3002", "motivation": "\u795e\u7ecf\u7cfb\u7edf\u75be\u75c5\u662f\u5168\u7403\u81f4\u6b8b\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u4f46\u5927\u591a\u6570\u7f3a\u4e4f\u75be\u75c5\u4fee\u9970\u6cbb\u7597\u65b9\u6cd5\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6574\u5408\u591a\u5c3a\u5ea6\u6570\u636e\u5e76\u751f\u6210\u53ef\u6d4b\u8bd5\u5047\u8bf4\u7684AI\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86PROTON\uff0c\u4e00\u4e2a\u5f02\u6784\u56fe\u53d8\u6362\u5668\uff0c\u80fd\u591f\u6574\u5408\u5206\u5b50\u3001\u7c7b\u5668\u5b98\u548c\u4e34\u5e8a\u7cfb\u7edf\u6570\u636e\uff0c\u751f\u6210\u8de8\u5c3a\u5ea6\u7684\u53ef\u6d4b\u8bd5\u5047\u8bf4\u3002", "result": "\u5728\u5e15\u91d1\u68ee\u75c5\u4e2d\uff0cPROTON\u6210\u529f\u8fde\u63a5\u9057\u4f20\u98ce\u9669\u4f4d\u70b9\u4e0e\u591a\u5df4\u80fa\u80fd\u795e\u7ecf\u5143\u751f\u5b58\u5fc5\u9700\u57fa\u56e0\uff0c\u9884\u6d4b\u4e86\u5305\u62ec\u786b\u4e39\u5728\u5185\u7684\u6709\u6bd2\u519c\u836f\uff1b\u5728\u53cc\u76f8\u60c5\u611f\u969c\u788d\u4e2d\uff0c\u9884\u6d4b\u4e86\u9aa8\u5316\u4e09\u9187\u4f5c\u4e3a\u5019\u9009\u836f\u7269\uff1b\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u4e2d\uff0c\u9884\u6d4b\u76845\u79cd\u836f\u7269\u4e0e610,524\u540d\u60a3\u8005\u76847\u5e74\u75f4\u5446\u98ce\u9669\u964d\u4f4e\u76f8\u5173\u3002", "conclusion": "PROTON\u80fd\u591f\u751f\u6210\u5728\u5206\u5b50\u3001\u7c7b\u5668\u5b98\u548c\u4e34\u5e8a\u7cfb\u7edf\u4e2d\u5f97\u5230\u9a8c\u8bc1\u7684\u795e\u7ecf\u7cfb\u7edf\u75be\u75c5\u5047\u8bf4\uff0c\u4e3aAI\u9a71\u52a8\u7684\u795e\u7ecf\u7cfb\u7edf\u75be\u75c5\u53d1\u73b0\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2512.12101", "pdf": "https://arxiv.org/pdf/2512.12101", "abs": "https://arxiv.org/abs/2512.12101", "authors": ["Swarn S. Warshaneyan", "Maksims Ivanovs", "Bla\u017e Cugmas", "Inese B\u0113rzi\u0146a", "Laura Goldberga", "Mindaugas Tamosiunas", "Roberts Kadi\u0137is"], "title": "AI-Augmented Pollen Recognition in Optical and Holographic Microscopy for Veterinary Imaging", "categories": ["cs.CV", "cs.LG", "q-bio.QM"], "comment": "10 pages, 10 figures, 2 tables, 22 references. Journal submission undergoing peer review", "summary": "We present a comprehensive study on fully automated pollen recognition across both conventional optical and digital in-line holographic microscopy (DIHM) images of sample slides. Visually recognizing pollen in unreconstructed holographic images remains challenging due to speckle noise, twin-image artifacts and substantial divergence from bright-field appearances. We establish the performance baseline by training YOLOv8s for object detection and MobileNetV3L for classification on a dual-modality dataset of automatically annotated optical and affinely aligned DIHM images. On optical data, detection mAP50 reaches 91.3% and classification accuracy reaches 97%, whereas on DIHM data, we achieve only 8.15% for detection mAP50 and 50% for classification accuracy. Expanding the bounding boxes of pollens in DIHM images over those acquired in aligned optical images achieves 13.3% for detection mAP50 and 54% for classification accuracy. To improve object detection in DIHM images, we employ a Wasserstein GAN with spectral normalization (WGAN-SN) to create synthetic DIHM images, yielding an FID score of 58.246. Mixing real-world and synthetic data at the 1.0 : 1.5 ratio for DIHM images improves object detection up to 15.4%. These results demonstrate that GAN-based augmentation can reduce the performance divide, bringing fully automated DIHM workflows for veterinary imaging a small but important step closer to practice.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u4f20\u7edf\u5149\u5b66\u663e\u5fae\u955c\u548c\u6570\u5b57\u5728\u7ebf\u5168\u606f\u663e\u5fae\u955c(DIHM)\u5728\u82b1\u7c89\u81ea\u52a8\u8bc6\u522b\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u53d1\u73b0DIHM\u56fe\u50cf\u8bc6\u522b\u6548\u679c\u8f83\u5dee\uff0c\u901a\u8fc7GAN\u751f\u6210\u5408\u6210DIHM\u56fe\u50cf\u8fdb\u884c\u6570\u636e\u589e\u5f3a\uff0c\u5c06\u68c0\u6d4b\u6027\u80fd\u4ece8.15%\u63d0\u5347\u523015.4%\u3002", "motivation": "\u5168\u606f\u663e\u5fae\u955c\u56fe\u50cf\u4e2d\u7684\u82b1\u7c89\u8bc6\u522b\u9762\u4e34\u6311\u6218\uff0c\u5305\u62ec\u6563\u6591\u566a\u58f0\u3001\u5b6a\u751f\u50cf\u4f2a\u5f71\u4ee5\u53ca\u4e0e\u660e\u573a\u56fe\u50cf\u7684\u663e\u8457\u5dee\u5f02\uff0c\u9700\u8981\u5efa\u7acb\u6027\u80fd\u57fa\u51c6\u5e76\u63a2\u7d22\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528YOLOv8s\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u548cMobileNetV3L\u8fdb\u884c\u5206\u7c7b\uff0c\u5728\u53cc\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff1b\u91c7\u7528Wasserstein GAN with spectral normalization\u751f\u6210\u5408\u6210DIHM\u56fe\u50cf\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u3002", "result": "\u5149\u5b66\u6570\u636e\u68c0\u6d4bmAP50\u8fbe91.3%\uff0c\u5206\u7c7b\u51c6\u786e\u738797%\uff1bDIHM\u6570\u636e\u68c0\u6d4bmAP50\u4ec58.15%\uff0c\u5206\u7c7b\u51c6\u786e\u738750%\uff1b\u901a\u8fc7GAN\u6570\u636e\u589e\u5f3a\uff0cDIHM\u68c0\u6d4b\u6027\u80fd\u63d0\u5347\u81f315.4%\u3002", "conclusion": "GAN\u6570\u636e\u589e\u5f3a\u80fd\u7f29\u5c0f\u5149\u5b66\u4e0e\u5168\u606f\u663e\u5fae\u955c\u56fe\u50cf\u8bc6\u522b\u6027\u80fd\u5dee\u8ddd\uff0c\u4e3a\u517d\u533b\u5f71\u50cf\u7684\u5b8c\u5168\u81ea\u52a8\u5316DIHM\u5de5\u4f5c\u6d41\u7a0b\u5411\u5b9e\u9645\u5e94\u7528\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2512.13720", "pdf": "https://arxiv.org/pdf/2512.13720", "abs": "https://arxiv.org/abs/2512.13720", "authors": ["Serhii V Marchenko"], "title": "Absement: Quantitative Assessment of Metabolic Cost during Quasi-Isometric Muscle Loading", "categories": ["physics.bio-ph", "q-bio.QM"], "comment": null, "summary": "Accurate quantitative assessment of metabolic cost during static posture holding is a strategically important problem in biomechanics and physiology. Traditional metrics such as ``time under tension'' are fundamentally insufficient, because they are scalar quantities that ignore the temporal history of deviations, that is, the microdynamics of posture, which has nontrivial energetic consequences. In this work, we propose a theoretically grounded methodology to address this problem by introducing the concept of the \\textbf{deviation absement} ($\u0394\\mathcal{A}_\\ell$), defined as the time integral of the deviation of the muscle--tendon unit length from a reference value.\n  We rigorously prove that, for a broad class of quasi-static models, absement appears as the leading first-order state variable. For small deviations in a neighbourhood of a reference posture, the total metabolic cost $\\mathcal{E}_{\\mathrm{met}}(\\ell)$ admits a universal asymptotic expansion of the form \\begin{equation*} \\mathcal{E}_{\\mathrm{met}}(\\ell) = P_0 T + C_1 \u0394\\mathcal{A}_\\ell + C_2 \\int_0^T(\\ell(t)-\\ell_0)^2\\,dt + O(\\|\\ell-\\ell_0\\|_{L^\\infty}^3), \\end{equation*} where $T$ is the duration of loading, and $P_0, C_1, C_2$ are constants determined by local properties of the system.\n  Thus, the deviation absement ($\u0394\\mathcal{A}_\\ell$) is the \\textbf{unique first-order sufficient statistic} that allows one to quantify and separate the energetic contribution of systematic drift of the mean posture from the contribution of micro-oscillations (tremor), which is described by the quadratic term. This result has direct consequences for parameter identification: the proposed formalism makes it possible to recover physically meaningful coefficients $(P_0, C_1, C_2)$ by means of linear regression of experimental data obtained from standard kinematic measurements and indirect calorimetry.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u504f\u5dee\u4f4d\u79fb\uff08deviation absement\uff09\u4f5c\u4e3a\u9759\u6001\u59ff\u52bf\u4fdd\u6301\u4e2d\u4ee3\u8c22\u6210\u672c\u8bc4\u4f30\u7684\u65b0\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u5b83\u662f\u91cf\u5316\u59ff\u52bf\u7cfb\u7edf\u6027\u6f02\u79fb\u80fd\u91cf\u8d21\u732e\u7684\u4e00\u9636\u5145\u5206\u7edf\u8ba1\u91cf\u3002", "motivation": "\u4f20\u7edf\u6307\u6807\u5982\"\u5f20\u529b\u65f6\u95f4\"\u662f\u6807\u91cf\uff0c\u5ffd\u7565\u4e86\u59ff\u52bf\u5fae\u52a8\u529b\u5b66\u7684\u65f6\u5e8f\u5386\u53f2\uff0c\u800c\u8fd9\u4e9b\u5fae\u52a8\u6001\u5177\u6709\u91cd\u8981\u7684\u80fd\u91cf\u5b66\u610f\u4e49\u3002\u9700\u8981\u66f4\u51c6\u786e\u7684\u65b9\u6cd5\u6765\u5b9a\u91cf\u8bc4\u4f30\u9759\u6001\u59ff\u52bf\u4fdd\u6301\u4e2d\u7684\u4ee3\u8c22\u6210\u672c\u3002", "method": "\u5f15\u5165\u504f\u5dee\u4f4d\u79fb\u6982\u5ff5\uff08\u0394A_\u2113\uff09\uff0c\u5b9a\u4e49\u4e3a\u808c\u8089-\u808c\u8171\u5355\u5143\u957f\u5ea6\u76f8\u5bf9\u4e8e\u53c2\u8003\u503c\u504f\u5dee\u7684\u65f6\u95f4\u79ef\u5206\u3002\u901a\u8fc7\u4e25\u683c\u6570\u5b66\u8bc1\u660e\uff0c\u5728\u51c6\u9759\u6001\u6a21\u578b\u7c7b\u4e2d\uff0c\u504f\u5dee\u4f4d\u79fb\u4f5c\u4e3a\u4e00\u9636\u72b6\u6001\u53d8\u91cf\u51fa\u73b0\uff0c\u5e76\u63a8\u5bfc\u51fa\u4ee3\u8c22\u6210\u672c\u7684\u901a\u7528\u6e10\u8fd1\u5c55\u5f00\u5f0f\u3002", "result": "\u8bc1\u660e\u504f\u5dee\u4f4d\u79fb\u662f\u552f\u4e00\u7684\u4e00\u9636\u5145\u5206\u7edf\u8ba1\u91cf\uff0c\u80fd\u591f\u5206\u79bb\u59ff\u52bf\u7cfb\u7edf\u6027\u6f02\u79fb\u548c\u5fae\u632f\u8361\uff08\u9707\u98a4\uff09\u7684\u80fd\u91cf\u8d21\u732e\u3002\u8be5\u5f62\u5f0f\u5316\u65b9\u6cd5\u4f7f\u5f97\u901a\u8fc7\u7ebf\u6027\u56de\u5f52\u4ece\u6807\u51c6\u8fd0\u52a8\u5b66\u6d4b\u91cf\u548c\u95f4\u63a5\u70ed\u91cf\u6d4b\u5b9a\u6570\u636e\u4e2d\u6062\u590d\u7269\u7406\u610f\u4e49\u7cfb\u6570\u6210\u4e3a\u53ef\u80fd\u3002", "conclusion": "\u504f\u5dee\u4f4d\u79fb\u4e3a\u9759\u6001\u59ff\u52bf\u4fdd\u6301\u7684\u4ee3\u8c22\u6210\u672c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6807\u91cf\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u53c2\u6570\u8bc6\u522b\u548c\u5b9e\u9a8c\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2512.13927", "pdf": "https://arxiv.org/pdf/2512.13927", "abs": "https://arxiv.org/abs/2512.13927", "authors": ["Sophia Tang"], "title": "A Complete Guide to Spherical Equivariant Graph Transformers", "categories": ["cs.LG", "q-bio.QM"], "comment": "This paper is a technical version of the article originally published in Alchemy Bio (99 pages, 46 figures)", "summary": "Spherical equivariant graph neural networks (EGNNs) provide a principled framework for learning on three-dimensional molecular and biomolecular systems, where predictions must respect the rotational symmetries inherent in physics. These models extend traditional message-passing GNNs and Transformers by representing node and edge features as spherical tensors that transform under irreducible representations of the rotation group SO(3), ensuring that predictions change in physically meaningful ways under rotations of the input. This guide develops a complete, intuitive foundation for spherical equivariant modeling - from group representations and spherical harmonics, to tensor products, Clebsch-Gordan decomposition, and the construction of SO(3)-equivariant kernels. Building on this foundation, we construct the Tensor Field Network and SE(3)-Transformer architectures and explain how they perform equivariant message-passing and attention on geometric graphs. Through clear mathematical derivations and annotated code excerpts, this guide serves as a self-contained introduction for researchers and learners seeking to understand or implement spherical EGNNs for applications in chemistry, molecular property prediction, protein structure modeling, and generative modeling.", "AI": {"tldr": "\u8be5\u6307\u5357\u7cfb\u7edf\u4ecb\u7ecd\u4e86\u7403\u9762\u7b49\u53d8\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u7406\u8bba\u57fa\u7840\u4e0e\u5b9e\u73b0\u65b9\u6cd5\uff0c\u5305\u62ec\u7fa4\u8868\u793a\u3001\u7403\u8c10\u51fd\u6570\u3001\u5f20\u91cf\u79ef\u7b49\u6570\u5b66\u5de5\u5177\uff0c\u5e76\u6784\u5efa\u4e86Tensor Field Network\u548cSE(3)-Transformer\u67b6\u6784\u3002", "motivation": "\u4e09\u7ef4\u5206\u5b50\u548c\u751f\u7269\u5206\u5b50\u7cfb\u7edf\u5177\u6709\u65cb\u8f6c\u5bf9\u79f0\u6027\uff0c\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u65e0\u6cd5\u4fdd\u8bc1\u9884\u6d4b\u7ed3\u679c\u5728\u7269\u7406\u65cb\u8f6c\u4e0b\u7684\u6b63\u786e\u53d8\u6362\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4fdd\u6301SO(3)\u65cb\u8f6c\u5bf9\u79f0\u6027\u7684\u7b49\u53d8\u6a21\u578b\uff0c\u786e\u4fdd\u9884\u6d4b\u7ed3\u679c\u5728\u7269\u7406\u4e0a\u6709\u610f\u4e49\u3002", "method": "\u57fa\u4e8e\u7fa4\u8868\u793a\u7406\u8bba\u548c\u7403\u8c10\u51fd\u6570\uff0c\u5c06\u8282\u70b9\u548c\u8fb9\u7279\u5f81\u8868\u793a\u4e3a\u7403\u9762\u5f20\u91cf\uff08SO(3)\u4e0d\u53ef\u7ea6\u8868\u793a\uff09\uff0c\u901a\u8fc7\u5f20\u91cf\u79ef\u548cClebsch-Gordan\u5206\u89e3\u6784\u5efa\u7b49\u53d8\u6838\u51fd\u6570\uff0c\u5b9e\u73b0\u7b49\u53d8\u6d88\u606f\u4f20\u9012\u548c\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u6784\u5efa\u4e86Tensor Field Network\u548cSE(3)-Transformer\u67b6\u6784\uff0c\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u6570\u5b66\u63a8\u5bfc\u548c\u4ee3\u7801\u5b9e\u73b0\uff0c\u4e3a\u5316\u5b66\u3001\u5206\u5b50\u6027\u8d28\u9884\u6d4b\u3001\u86cb\u767d\u8d28\u7ed3\u6784\u5efa\u6a21\u548c\u751f\u6210\u5efa\u6a21\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u7403\u9762\u7b49\u53d8\u56fe\u795e\u7ecf\u7f51\u7edc\u4e3a\u4e09\u7ef4\u5206\u5b50\u7cfb\u7edf\u5efa\u6a21\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u4fdd\u6301\u65cb\u8f6c\u5bf9\u79f0\u6027\u786e\u4fdd\u7269\u7406\u9884\u6d4b\u7684\u6b63\u786e\u6027\uff0c\u8be5\u6307\u5357\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u57fa\u7840\u3002"}}
{"id": "2512.13935", "pdf": "https://arxiv.org/pdf/2512.13935", "abs": "https://arxiv.org/abs/2512.13935", "authors": ["Qi Chen", "Fabio Ramos", "Al\u00e1n Aspuru-Guzik", "Florian Shkurti"], "title": "Informing Acquisition Functions via Foundation Models for Molecular Discovery", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "Bayesian Optimization (BO) is a key methodology for accelerating molecular discovery by estimating the mapping from molecules to their properties while seeking the optimal candidate. Typically, BO iteratively updates a probabilistic surrogate model of this mapping and optimizes acquisition functions derived from the model to guide molecule selection. However, its performance is limited in low-data regimes with insufficient prior knowledge and vast candidate spaces. Large language models (LLMs) and chemistry foundation models offer rich priors to enhance BO, but high-dimensional features, costly in-context learning, and the computational burden of deep Bayesian surrogates hinder their full utilization. To address these challenges, we propose a likelihood-free BO method that bypasses explicit surrogate modeling and directly leverages priors from general LLMs and chemistry-specific foundation models to inform acquisition functions. Our method also learns a tree-structured partition of the molecular search space with local acquisition functions, enabling efficient candidate selection via Monte Carlo Tree Search. By further incorporating coarse-grained LLM-based clustering, it substantially improves scalability to large candidate sets by restricting acquisition function evaluations to clusters with statistically higher property values. We show through extensive experiments and ablations that the proposed method substantially improves scalability, robustness, and sample efficiency in LLM-guided BO for molecular discovery.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u4f3c\u7136\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff0c\u5229\u7528LLM\u548c\u5316\u5b66\u57fa\u7840\u6a21\u578b\u5148\u9a8c\uff0c\u901a\u8fc7\u6811\u7ed3\u6784\u7a7a\u95f4\u5212\u5206\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u5b9e\u73b0\u9ad8\u6548\u5206\u5b50\u53d1\u73b0", "motivation": "\u4f20\u7edf\u8d1d\u53f6\u65af\u4f18\u5316\u5728\u4f4e\u6570\u636e\u3001\u5927\u641c\u7d22\u7a7a\u95f4\u4e0b\u6027\u80fd\u53d7\u9650\uff0c\u800cLLM\u548c\u5316\u5b66\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u7684\u4e30\u5bcc\u5148\u9a8c\u96be\u4ee5\u5145\u5206\u5229\u7528\uff0c\u9700\u8981\u89e3\u51b3\u9ad8\u7ef4\u7279\u5f81\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\u6210\u672c\u9ad8\u548c\u6df1\u5ea6\u8d1d\u53f6\u65af\u4ee3\u7406\u6a21\u578b\u8ba1\u7b97\u8d1f\u62c5\u7b49\u95ee\u9898", "method": "\u63d0\u51fa\u65e0\u4f3c\u7136\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff0c\u7ed5\u8fc7\u663e\u5f0f\u4ee3\u7406\u5efa\u6a21\uff0c\u76f4\u63a5\u5229\u7528LLM\u548c\u5316\u5b66\u57fa\u7840\u6a21\u578b\u5148\u9a8c\u6307\u5bfc\u91c7\u96c6\u51fd\u6570\uff1b\u5b66\u4e60\u5206\u5b50\u641c\u7d22\u7a7a\u95f4\u7684\u6811\u7ed3\u6784\u5212\u5206\uff0c\u7ed3\u5408\u5c40\u90e8\u91c7\u96c6\u51fd\u6570\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u8fdb\u884c\u5019\u9009\u9009\u62e9\uff1b\u5f15\u5165\u7c97\u7c92\u5ea6LLM\u805a\u7c7b\uff0c\u5c06\u91c7\u96c6\u51fd\u6570\u8bc4\u4f30\u9650\u5236\u5728\u5177\u6709\u66f4\u9ad8\u5c5e\u6027\u503c\u7684\u805a\u7c7b\u4e2d", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728LLM\u5f15\u5bfc\u7684\u5206\u5b50\u53d1\u73b0\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u53ef\u6269\u5c55\u6027\u3001\u9c81\u68d2\u6027\u548c\u6837\u672c\u6548\u7387", "conclusion": "\u63d0\u51fa\u7684\u65e0\u4f3c\u7136\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u901a\u8fc7\u6709\u6548\u5229\u7528LLM\u548c\u5316\u5b66\u57fa\u7840\u6a21\u578b\u5148\u9a8c\uff0c\u7ed3\u5408\u6811\u7ed3\u6784\u7a7a\u95f4\u5212\u5206\u548c\u805a\u7c7b\u6280\u672f\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u5206\u5b50\u53d1\u73b0\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u95ee\u9898"}}
{"id": "2512.14011", "pdf": "https://arxiv.org/pdf/2512.14011", "abs": "https://arxiv.org/abs/2512.14011", "authors": ["Yue Wan", "Jiayi Yuan", "Zhiwei Feng", "Xiaowei Jia"], "title": "Accelerating MHC-II Epitope Discovery via Multi-Scale Prediction in Antigen Presentation", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Antigenic epitope presented by major histocompatibility complex II (MHC-II) proteins plays an essential role in immunotherapy. However, compared to the more widely studied MHC-I in computational immunotherapy, the study of MHC-II antigenic epitope poses significantly more challenges due to its complex binding specificity and ambiguous motif patterns. Consequently, existing datasets for MHC-II interactions are smaller and less standardized than those available for MHC-I. To address these challenges, we present a well-curated dataset derived from the Immune Epitope Database (IEDB) and other public sources. It not only extends and standardizes existing peptide-MHC-II datasets, but also introduces a novel antigen-MHC-II dataset with richer biological context. Leveraging this dataset, we formulate three major machine learning (ML) tasks of peptide binding, peptide presentation, and antigen presentation, which progressively capture the broader biological processes within the MHC-II antigen presentation pathway. We further employ a multi-scale evaluation framework to benchmark existing models, along with a comprehensive analysis over various modeling designs to this problem with a modular framework. Overall, this work serves as a valuable resource for advancing computational immunotherapy, providing a foundation for future research in ML guided epitope discovery and predictive modeling of immune responses.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u7cbe\u5fc3\u6574\u7406\u7684MHC-II\u6297\u539f\u8868\u4f4d\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u4e86\u4e09\u4e2a\u673a\u5668\u5b66\u4e60\u4efb\u52a1\uff0c\u5e76\u5efa\u7acb\u4e86\u591a\u5c3a\u5ea6\u8bc4\u4f30\u6846\u67b6\u6765\u63a8\u8fdb\u8ba1\u7b97\u514d\u75ab\u6cbb\u7597\u7814\u7a76\u3002", "motivation": "MHC-II\u6297\u539f\u8868\u4f4d\u5728\u514d\u75ab\u6cbb\u7597\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4e0eMHC-I\u76f8\u6bd4\uff0cMHC-II\u7684\u7814\u7a76\u9762\u4e34\u66f4\u591a\u6311\u6218\uff1a\u7ed3\u5408\u7279\u5f02\u6027\u590d\u6742\u3001\u57fa\u5e8f\u6a21\u5f0f\u6a21\u7cca\u3001\u6570\u636e\u96c6\u8f83\u5c0f\u4e14\u6807\u51c6\u5316\u7a0b\u5ea6\u4f4e\u3002\u9700\u8981\u66f4\u597d\u7684\u6570\u636e\u96c6\u548c\u8ba1\u7b97\u6846\u67b6\u6765\u63a8\u8fdb\u8be5\u9886\u57df\u53d1\u5c55\u3002", "method": "1. \u4eceIEDB\u548c\u5176\u4ed6\u516c\u5171\u6765\u6e90\u6784\u5efa\u7cbe\u5fc3\u6574\u7406\u7684MHC-II\u6570\u636e\u96c6\uff1b2. \u6269\u5c55\u548c\u6807\u51c6\u5316\u73b0\u6709\u7684\u80bd-MHC-II\u6570\u636e\u96c6\uff1b3. \u5f15\u5165\u5177\u6709\u66f4\u4e30\u5bcc\u751f\u7269\u5b66\u80cc\u666f\u7684\u65b0\u578b\u6297\u539f-MHC-II\u6570\u636e\u96c6\uff1b4. \u5236\u5b9a\u80bd\u7ed3\u5408\u3001\u80bd\u5448\u9012\u548c\u6297\u539f\u5448\u9012\u4e09\u4e2a\u673a\u5668\u5b66\u4e60\u4efb\u52a1\uff1b5. \u5efa\u7acb\u591a\u5c3a\u5ea6\u8bc4\u4f30\u6846\u67b6\u6765\u57fa\u51c6\u6d4b\u8bd5\u73b0\u6709\u6a21\u578b\uff1b6. \u4f7f\u7528\u6a21\u5757\u5316\u6846\u67b6\u8fdb\u884c\u5168\u9762\u7684\u5efa\u6a21\u8bbe\u8ba1\u5206\u6790\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u6709\u4ef7\u503c\u7684MHC-II\u6297\u539f\u8868\u4f4d\u6570\u636e\u96c6\u8d44\u6e90\uff0c\u8be5\u6570\u636e\u96c6\u4e0d\u4ec5\u6269\u5c55\u548c\u6807\u51c6\u5316\u4e86\u73b0\u6709\u6570\u636e\uff0c\u8fd8\u5f15\u5165\u4e86\u5177\u6709\u66f4\u4e30\u5bcc\u751f\u7269\u5b66\u80cc\u666f\u7684\u65b0\u578b\u6297\u539f-MHC-II\u6570\u636e\u96c6\u3002\u5efa\u7acb\u4e86\u4e09\u4e2a\u9010\u6b65\u6355\u83b7MHC-II\u6297\u539f\u5448\u9012\u9014\u5f84\u4e2d\u66f4\u5e7f\u6cdb\u751f\u7269\u5b66\u8fc7\u7a0b\u7684\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4e86\u73b0\u6709\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u63a8\u8fdb\u8ba1\u7b97\u514d\u75ab\u6cbb\u7597\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\uff0c\u4e3a\u672a\u6765\u673a\u5668\u5b66\u4e60\u6307\u5bfc\u7684\u8868\u4f4d\u53d1\u73b0\u548c\u514d\u75ab\u53cd\u5e94\u9884\u6d4b\u5efa\u6a21\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u901a\u8fc7\u63d0\u4f9b\u6807\u51c6\u5316\u7684\u6570\u636e\u96c6\u3001\u660e\u786e\u7684\u4efb\u52a1\u5b9a\u4e49\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u89e3\u51b3MHC-II\u7814\u7a76\u4e2d\u7684\u6311\u6218\u3002"}}
{"id": "2512.14019", "pdf": "https://arxiv.org/pdf/2512.14019", "abs": "https://arxiv.org/abs/2512.14019", "authors": ["Juseung Yun", "Sunwoo Yu", "Sumin Ha", "Jonghyun Kim", "Janghyeon Lee", "Jongseong Jang", "Soonyoung Lee"], "title": "EXAONE Path 2.5: Pathology Foundation Model with Multi-Omics Alignment", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Cancer progression arises from interactions across multiple biological layers, especially beyond morphological and across molecular layers that remain invisible to image-only models. To capture this broader biological landscape, we present EXAONE Path 2.5, a pathology foundation model that jointly models histologic, genomic, epigenetic and transcriptomic modalities, producing an integrated patient representation that reflects tumor biology more comprehensively. Our approach incorporates three key components: (1) multimodal SigLIP loss enabling all-pairwise contrastive learning across heterogeneous modalities, (2) a fragment-aware rotary positional encoding (F-RoPE) module that preserves spatial structure and tissue-fragment topology in WSI, and (3) domain-specialized internal foundation models for both WSI and RNA-seq to provide biologically grounded embeddings for robust multimodal alignment. We evaluate EXAONE Path 2.5 against six leading pathology foundation models across two complementary benchmarks: an internal real-world clinical dataset and the Patho-Bench benchmark covering 80 tasks. Our framework demonstrates high data and parameter efficiency, achieving on-par performance with state-of-the-art foundation models on Patho-Bench while exhibiting the highest adaptability in the internal clinical setting. These results highlight the value of biologically informed multimodal design and underscore the potential of integrated genotype-to-phenotype modeling for next-generation precision oncology.", "AI": {"tldr": "EXAONE Path 2.5\u662f\u4e00\u4e2a\u75c5\u7406\u5b66\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u7ec4\u7ec7\u5b66\u3001\u57fa\u56e0\u7ec4\u5b66\u3001\u8868\u89c2\u9057\u4f20\u5b66\u548c\u8f6c\u5f55\u7ec4\u5b66\u7b49\u591a\u6a21\u6001\u6570\u636e\uff0c\u521b\u5efa\u7efc\u5408\u7684\u60a3\u8005\u8868\u5f81\uff0c\u66f4\u5168\u9762\u5730\u53cd\u6620\u80bf\u7624\u751f\u7269\u5b66\u7279\u5f81\u3002", "motivation": "\u764c\u75c7\u8fdb\u5c55\u6d89\u53ca\u591a\u4e2a\u751f\u7269\u5c42\u9762\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u7279\u522b\u662f\u8d85\u8d8a\u5f62\u6001\u5b66\u5c42\u9762\u7684\u5206\u5b50\u5c42\u9762\uff0c\u8fd9\u4e9b\u5bf9\u4e8e\u4ec5\u57fa\u4e8e\u56fe\u50cf\u7684\u6a21\u578b\u662f\u4e0d\u53ef\u89c1\u7684\u3002\u4e3a\u4e86\u6355\u6349\u66f4\u5e7f\u6cdb\u7684\u751f\u7269\u5b66\u666f\u89c2\uff0c\u9700\u8981\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u6765\u66f4\u5168\u9762\u5730\u7406\u89e3\u80bf\u7624\u751f\u7269\u5b66\u3002", "method": "1. \u591a\u6a21\u6001SigLIP\u635f\u5931\u5b9e\u73b0\u5f02\u8d28\u6a21\u6001\u95f4\u7684\u5168\u914d\u5bf9\u5bf9\u6bd4\u5b66\u4e60\uff1b2. \u7247\u6bb5\u611f\u77e5\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801(F-RoPE)\u6a21\u5757\uff0c\u5728WSI\u4e2d\u4fdd\u6301\u7a7a\u95f4\u7ed3\u6784\u548c\u7ec4\u7ec7\u7247\u6bb5\u62d3\u6251\uff1b3. \u9488\u5bf9WSI\u548cRNA-seq\u7684\u9886\u57df\u4e13\u4e1a\u5316\u5185\u90e8\u57fa\u7840\u6a21\u578b\uff0c\u4e3a\u7a33\u5065\u7684\u591a\u6a21\u6001\u5bf9\u9f50\u63d0\u4f9b\u751f\u7269\u5b66\u57fa\u7840\u5d4c\u5165\u3002", "result": "\u5728\u4e24\u4e2a\u4e92\u8865\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\uff1a\u5185\u90e8\u771f\u5b9e\u4e16\u754c\u4e34\u5e8a\u6570\u636e\u96c6\u548c\u5305\u542b80\u4e2a\u4efb\u52a1\u7684Patho-Bench\u57fa\u51c6\u3002\u6a21\u578b\u8868\u73b0\u51fa\u9ad8\u6570\u636e\u548c\u53c2\u6570\u6548\u7387\uff0c\u5728Patho-Bench\u4e0a\u8fbe\u5230\u4e0e\u6700\u5148\u8fdb\u57fa\u7840\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5728\u5185\u90e8\u4e34\u5e8a\u8bbe\u7f6e\u4e2d\u8868\u73b0\u51fa\u6700\u9ad8\u7684\u9002\u5e94\u6027\u3002", "conclusion": "\u751f\u7269\u5b66\u4fe1\u606f\u7684\u591a\u6a21\u6001\u8bbe\u8ba1\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u6574\u5408\u57fa\u56e0\u578b\u5230\u8868\u578b\u5efa\u6a21\u4e3a\u4e0b\u4e00\u4ee3\u7cbe\u51c6\u80bf\u7624\u5b66\u5c55\u793a\u4e86\u6f5c\u529b\u3002EXAONE Path 2.5\u901a\u8fc7\u591a\u6a21\u6001\u6574\u5408\u4e3a\u66f4\u5168\u9762\u7684\u80bf\u7624\u751f\u7269\u5b66\u7406\u89e3\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2512.14461", "pdf": "https://arxiv.org/pdf/2512.14461", "abs": "https://arxiv.org/abs/2512.14461", "authors": ["Niklas Grieger", "Jannik Raskob", "Siamak Mehrkanoon", "Stephan Bialonski"], "title": "AnySleep: a channel-agnostic deep learning system for high-resolution sleep staging in multi-center cohorts", "categories": ["cs.LG", "eess.SP", "q-bio.QM"], "comment": "18 pages, 6 figures, 2 tables", "summary": "Sleep is essential for good health throughout our lives, yet studying its dynamics requires manual sleep staging, a labor-intensive step in sleep research and clinical care. Across centers, polysomnography (PSG) recordings are traditionally scored in 30-s epochs for pragmatic, not physiological, reasons and can vary considerably in electrode count, montage, and subject characteristics. These constraints present challenges in conducting harmonized multi-center sleep studies and discovering novel, robust biomarkers on shorter timescales. Here, we present AnySleep, a deep neural network model that uses any electroencephalography (EEG) or electrooculography (EOG) data to score sleep at adjustable temporal resolutions. We trained and validated the model on over 19,000 overnight recordings from 21 datasets collected across multiple clinics, spanning nearly 200,000 hours of EEG and EOG data, to promote robust generalization across sites. The model attains state-of-the-art performance and surpasses or equals established baselines at 30-s epochs. Performance improves as more channels are provided, yet remains strong when EOG is absent or when only EOG or single EEG derivations (frontal, central, or occipital) are available. On sub-30-s timescales, the model captures short wake intrusions consistent with arousals and improves prediction of physiological characteristics (age, sex) and pathophysiological conditions (sleep apnea), relative to standard 30-s scoring. We make the model publicly available to facilitate large-scale studies with heterogeneous electrode setups and to accelerate the discovery of novel biomarkers in sleep.", "AI": {"tldr": "AnySleep\u662f\u4e00\u4e2a\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u80fd\u591f\u4f7f\u7528\u4efb\u610fEEG\u6216EOG\u6570\u636e\u5728\u53ef\u8c03\u65f6\u95f4\u5206\u8fa8\u7387\u4e0b\u8fdb\u884c\u7761\u7720\u5206\u671f\uff0c\u572821\u4e2a\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u6027\u80fd\u8fbe\u5230SOTA\uff0c\u652f\u6301\u591a\u4e2d\u5fc3\u7814\u7a76\u548c\u65b0\u578b\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u3002", "motivation": "\u4f20\u7edf\u7761\u7720\u5206\u671f\u9700\u8981\u624b\u52a8\u6807\u6ce8\uff0c\u8017\u65f6\u8017\u529b\uff1b\u4e0d\u540c\u4e2d\u5fc3\u7684PSG\u8bb0\u5f55\u5728\u7535\u6781\u6570\u91cf\u3001\u5bfc\u8054\u65b9\u5f0f\u548c\u53d7\u8bd5\u8005\u7279\u5f81\u4e0a\u5dee\u5f02\u5f88\u5927\uff1b30\u79d2\u5206\u671f\u7684\u6807\u51c6\u662f\u51fa\u4e8e\u5b9e\u7528\u800c\u975e\u751f\u7406\u539f\u56e0\uff1b\u8fd9\u4e9b\u9650\u5236\u963b\u788d\u4e86\u591a\u4e2d\u5fc3\u7761\u7720\u7814\u7a76\u7684\u534f\u8c03\u548c\u77ed\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u65b0\u578b\u751f\u7269\u6807\u5fd7\u7269\u7684\u53d1\u73b0\u3002", "method": "\u5f00\u53d1\u4e86AnySleep\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u4f7f\u7528\u4efb\u610fEEG\u6216EOG\u6570\u636e\u8fdb\u884c\u7761\u7720\u5206\u671f\uff0c\u652f\u6301\u53ef\u8c03\u65f6\u95f4\u5206\u8fa8\u7387\u3002\u572821\u4e2a\u6570\u636e\u96c6\u7684\u8d85\u8fc719,000\u4e2a\u591c\u95f4\u8bb0\u5f55\uff08\u8fd1200,000\u5c0f\u65f6EEG/EOG\u6570\u636e\uff09\u4e0a\u8bad\u7ec3\u548c\u9a8c\u8bc1\uff0c\u4ee5\u4fc3\u8fdb\u8de8\u7ad9\u70b9\u7684\u9c81\u68d2\u6cdb\u5316\u3002", "result": "\u6a21\u578b\u572830\u79d2\u5206\u671f\u4e0a\u8fbe\u5230\u6216\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\u6027\u80fd\uff1b\u63d0\u4f9b\u66f4\u591a\u901a\u9053\u65f6\u6027\u80fd\u63d0\u5347\uff0c\u4f46\u5728EOG\u7f3a\u5931\u6216\u4ec5\u6709EOG\u6216\u5355\u4e2aEEG\u5bfc\u8054\uff08\u989d\u3001\u4e2d\u592e\u3001\u6795\uff09\u65f6\u4ecd\u4fdd\u6301\u826f\u597d\u6027\u80fd\uff1b\u572830\u79d2\u4ee5\u4e0b\u65f6\u95f4\u5c3a\u5ea6\u4e0a\uff0c\u6a21\u578b\u80fd\u6355\u6349\u4e0e\u89c9\u9192\u4e00\u81f4\u7684\u77ed\u6682\u5524\u9192\uff0c\u5e76\u76f8\u5bf9\u4e8e\u6807\u51c630\u79d2\u5206\u671f\u6539\u8fdb\u4e86\u751f\u7406\u7279\u5f81\uff08\u5e74\u9f84\u3001\u6027\u522b\uff09\u548c\u75c5\u7406\u72b6\u51b5\uff08\u7761\u7720\u547c\u5438\u6682\u505c\uff09\u7684\u9884\u6d4b\u3002", "conclusion": "AnySleep\u6a21\u578b\u516c\u5f00\u53ef\u7528\uff0c\u5c06\u4fc3\u8fdb\u5177\u6709\u5f02\u8d28\u7535\u6781\u8bbe\u7f6e\u7684\u5927\u89c4\u6a21\u7814\u7a76\uff0c\u5e76\u52a0\u901f\u7761\u7720\u4e2d\u65b0\u578b\u751f\u7269\u6807\u5fd7\u7269\u7684\u53d1\u73b0\uff0c\u4e3a\u591a\u4e2d\u5fc3\u7761\u7720\u7814\u7a76\u548c\u4e34\u5e8a\u62a4\u7406\u63d0\u4f9b\u5f3a\u5927\u5de5\u5177\u3002"}}
