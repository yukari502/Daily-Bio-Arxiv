{"id": "2601.00036", "pdf": "https://arxiv.org/pdf/2601.00036", "abs": "https://arxiv.org/abs/2601.00036", "authors": ["Eugenio Simao"], "title": "Unifying Weak Independence and Signal Hierarchy Theory: Extended Biological Petri Net Formalism with Application to Vibrio fischeri Quorum Sensing", "categories": ["q-bio.MN", "q-bio.QM"], "comment": "9 pages, 3 figures", "summary": "Biological Petri Nets (Bio-PNs) require extensions beyond classical formalism to capture biochemical reality: multiple reactions simultaneously affect shared metabolites through convergent production or regulatory coupling, while signal places carry hierarchical control information distinct from material flow. We present a unified 13-tuple Extended Bio-PN formalism integrating two complementary theories: Weak Independence Theory (enabling coupled parallelism despite place-sharing) and Signal Hierarchy Theory (separating information flow from mass transfer). The extended definition adds signal partition (Psi subset P), arc type classification (A), regulatory structure (Sigma), environmental exchange (Theta), dependency taxonomy (Delta), heterogeneous transition types (tau), and biochemical formula tracking (rho). We formalize signal token consumption semantics through two-phase execution (enabling vs. consumption) and prove weak independence correctness for continuous dynamics. Application to Vibrio fischeri quorum sensing demonstrates how energy metabolism (ENERGY signals) orchestrates binary ON/OFF decisions through hierarchical constraint propagation to regulatory signals (LuxR-AHL complex), with 133-fold difference separating states. Analysis reveals signal saturation timing as the orchestrator forcing threshold-crossing, analogous to bacteriophage lambda lysogeny-lysis decisions. This work establishes formal foundations for modeling biological information flow in Petri nets, with implications for systems biology, synthetic circuit design, and parallel biochemical simulation."}
{"id": "2601.00030", "pdf": "https://arxiv.org/pdf/2601.00030", "abs": "https://arxiv.org/abs/2601.00030", "authors": ["A. Murat Maga", "Steve Pieper", "Cassandra Donatelli", "Paul M Gignac", "Matthew Kolmann", "Christopher Noto", "Adam Summers", "Natalie Taft"], "title": "Forking Anatomy: How MorphoDepot Applies the Open-Source Development Model to 3D Digital Morphology", "categories": ["q-bio.QM"], "comment": "20 pages, 1 table and 2 figures", "summary": "The increasing use of 3D imaging technologies in biological sciences is generating vast repositories of anatomical data, yet significant barriers prevent this data from reaching its full potential in educational and collaborative contexts. While sharing raw CT and MRI scans has become routine, distributing value-added segmented datasets, where anatomical structures are precisely labeled and delineated, remains difficult and rare. Current repositories function primarily as static archives, lacking mechanisms for iterative refinement, community-driven curation, standardized orientation protocols, and the controlled terminology essential for downstream computational applications, including artificial intelligence, to help us analyze and interpret these unprecedented data resources.\n  We introduce MorphoDepot, a framework that adapts the \"fork-and-contribute\" model, a cornerstone of modern open-source software development, for collaborative management of 3D morphological data. By integrating git version control and GitHub's \"social\" collaborative infrastructure with 3D Slicer and its SlicerMorph extension, MorphoDepot transforms segmented anatomical datasets from static resources into dynamic, community-curated projects. This approach directly addresses the challenges of distributed collaboration, enforces transparent provenance tracking, and creates high-quality, standardized training data for AI model development. The result is a system that embodies FAIR (Findable, Accessible, Interoperable, and Reusable) data principles while creating powerful new opportunities for remote learning and collaborative science for biological sciences in general and evolutionary morphology in particular."}
{"id": "2601.00050", "pdf": "https://arxiv.org/pdf/2601.00050", "abs": "https://arxiv.org/abs/2601.00050", "authors": ["Sam Victor"], "title": "Domain-aware priors enable vertical federated learning in data-scarce coral multi-omics", "categories": ["q-bio.QM"], "comment": "19 pages, 06 figures, 01 tables, 21 references. Journal submission currently in progress", "summary": "Vertical federated learning enables multi-laboratory collaboration on distributed multi-omics datasets without sharing raw data, but exhibits severe instability under extreme data scarcity (P much greater than N) when applied generically. Here, we investigate how domain-aware design choices, specifically gradient saliency guided feature selection with biologically motivated priors, affect the stability and interpretability of VFL architectures in small-sample coral stress classification (N = 13 samples, P = 90579 features across transcriptomics, proteomics, metabolomics, and microbiome data).\n  We benchmark a domain-aware VFL framework against two baselines on the Montipora capitata thermal stress dataset: (i) a standard NVFlare-based VFL and (ii) LASER, a label-aware VFL method. Domain-aware VFL achieves an AUROC of 0.833 plus or minus 0.030 after reducing dimensionality by 98.6 percent, significantly outperforming NVFlare VFL, which performs at chance level (AUROC 0.500 plus or minus 0.125, p = 0.0058). LASER shows modest improvement (AUROC 0.600 plus or minus 0.215) but exhibits higher variance and does not reach statistical significance.\n  Domain-aware feature selection yields stable top-feature sets across analysis parameters. Negative control experiments using permuted labels produce AUROC values below chance (0.262), confirming the absence of data leakage and indicating that observed performance arises from genuine biological signal. These results motivate design principles for VFL in extreme P much greater than N regimes, emphasizing domain-informed dimensionality reduction and stability-focused evaluation."}
{"id": "2601.00073", "pdf": "https://arxiv.org/pdf/2601.00073", "abs": "https://arxiv.org/abs/2601.00073", "authors": ["Md Anisur Rahman", "Md Asif Hasan Khan", "Tuan Mai", "Jinki Kim"], "title": "Non-Contact and Non-Destructive Detection of Structural Defects in Bioprinted Constructs Using Video-Based Vibration Analysis", "categories": ["q-bio.QM"], "comment": null, "summary": "Bioprinting technology has advanced significantly in the fabrication of tissue-like constructs with complex geometries for regenerative medicine. However, maintaining the structural integrity of bioprinted materials remains a major challenge, primarily due to the frequent and unexpected formation of hidden defects. Traditional defect detection methods often require physical contact that may not be suitable for hydrogel-based biomaterials due to their inherently soft nature, making non-invasive and straightforward structural evaluation necessary in this field. To advance the state of the art, this study presents a novel non-contact method for non-destructively detecting structural defects in bioprinted constructs using video-based vibration analysis. Ear-shaped constructs were fabricated using a bioink composed of sodium alginate and \\k{appa}-carrageenan using extrusion-based bioprinting. To simulate printing defects, controlled geometric, interlayer, and pressure-induced defects were systematically introduced into the samples. The dynamic response of each structure was recorded using a high-speed camera and analyzed via phase-based motion estimation techniques. Experimental results demonstrate that all defective samples exhibit consistent changes in the dynamic characteristics compared to baseline samples, with increasingly pronounced deviation observed as defect severity increases, which reflect changes in effective stiffness and mass distribution induced by internal anomalies, even when such defects are not detectable through surface inspection. The experimental trends were also validated through finite element simulations. Overall, this work demonstrates that video-based vibrometry is a powerful approach for assessing the quality of bioprinted constructs, offering a practical pathway toward robust structural health monitoring in next-generation bio-additive manufacturing workflows."}
{"id": "2601.00277", "pdf": "https://arxiv.org/pdf/2601.00277", "abs": "https://arxiv.org/abs/2601.00277", "authors": ["Ali Anaissi", "Seid Miad Zandavi", "Weidong Huang", "Junaid Akram", "Basem Suleiman", "Ali Braytee", "Jie Hua"], "title": "Benchmarking Preprocessing and Integration Methods in Single-Cell Genomics", "categories": ["q-bio.QM", "cs.AI"], "comment": "The 23rd Australasian Data Science and Machine Learning Conference (AusDM'25)", "summary": "Single-cell data analysis has the potential to revolutionize personalized medicine by characterizing disease-associated molecular changes at the single-cell level. Advanced single-cell multimodal assays can now simultaneously measure various molecules (e.g., DNA, RNA, Protein) across hundreds of thousands of individual cells, providing a comprehensive molecular readout. A significant analytical challenge is integrating single-cell measurements across different modalities. Various methods have been developed to address this challenge, but there has been no systematic evaluation of these techniques with different preprocessing strategies. This study examines a general pipeline for single-cell data analysis, which includes normalization, data integration, and dimensionality reduction. The performance of different algorithm combinations often depends on the dataset sizes and characteristics. We evaluate six datasets across diverse modalities, tissues, and organisms using three metrics: Silhouette Coefficient Score, Adjusted Rand Index, and Calinski-Harabasz Index. Our experiments involve combinations of seven normalization methods, four dimensional reduction methods, and five integration methods. The results show that Seurat and Harmony excel in data integration, with Harmony being more time-efficient, especially for large datasets. UMAP is the most compatible dimensionality reduction method with the integration techniques, and the choice of normalization method varies depending on the integration method used."}
{"id": "2601.00608", "pdf": "https://arxiv.org/pdf/2601.00608", "abs": "https://arxiv.org/abs/2601.00608", "authors": ["Clara Bender", "Line Davidsen", "Søren Schou Olesen", "Simon Lebech Cichosz"], "title": "Peak-Nadir Encoding for Efficient CGM Data Compression and High-Fidelity Reconstruction", "categories": ["q-bio.QM"], "comment": null, "summary": "Aim/background: Continuous glucose monitoring (CGM) generates dense time-series data, posing challenges for efficient storage, transmission, and analysis. This study evaluates novel encoding strategies that reduce CGM profiles to a compact set of landmark points while maintaining fidelity in reconstructed signals and derived glycemic metrics.\n  Methods: We utilized two complementary CGM datasets, synthetic data generated via a Conditional Generative Adversarial Network (CGAN) and real-world measurements from a randomized crossover trial, to develop and validate three encoding approaches: (1) Peaks & Nadirs (PN), (2) Peaks, Nadirs, and Support Points (PN+), and (3) Uniform Downsampling. Each method compresses CGM profiles by selecting key timestamps and glucose values, followed by signal reconstruction via interpolation. Performance was assessed using compression ratio, mean absolute error (MAE), and R^2 between original and reconstructed clinically relevant CGM-derived metrics. Statistical analyses evaluated the preservation of clinically relevant glucose features.\n  Results: Across varying compression settings, PN+ consistently outperformed PN and downsampling, achieving the highest R^2 and lowest MAE. At a compression ratio of 13 (22 landmark points per 24-hour profile), PN+ reduced MAE by a factor of 3.6 compared to downsampling (0.77 vs. 2.75), with notable improvements in metrics sensitive to glucose excursions. Encoding and decoding required an average of 0.13 seconds per profile. Validation on real-world data confirmed these trends.\n  Conclusions: The proposed PN+ method produces a compact CGM representation that retains critical glycemic dynamics while discarding redundant portions of the profiles. The CGM signal can be reconstructed with high precision from the encoding representation."}
{"id": "2601.00618", "pdf": "https://arxiv.org/pdf/2601.00618", "abs": "https://arxiv.org/abs/2601.00618", "authors": ["Vasiliki Tsampazi", "Nicholas M. Glykos"], "title": "Quantifying the uncertainty of molecular dynamics simulations : Good-Turing statistics revisited", "categories": ["q-bio.QM", "q-bio.BM"], "comment": null, "summary": "We have previously shown that Good-Turing statistics can be applied to molecular dynamics trajectories to estimate the probability of observing completely new (thus far unobserved) biomolecular structures, and showed that the method is stable, dependable and its predictions verifiable. The major problem with that initial algorithm was the requirement for calculating and storing in memory the two-dimensional RMSD matrix of the currently available trajectory. This requirement precluded the application of the method to very long simulations. Here we describe a new variant of the Good-Turing algorithm whose memory requirements scale linearly with the number of structures in the trajectory, making it suitable even for extremely long simulations. We show that the new method gives essentially identical results with the older implementation, and present results obtained from trajectories containing up to 22 million structures. A computer program implementing the new algorithm is available from standard repositories."}
{"id": "2601.00656", "pdf": "https://arxiv.org/pdf/2601.00656", "abs": "https://arxiv.org/abs/2601.00656", "authors": ["Biraja Ghoshal"], "title": "Quantum Simulation of Protein Fragment Electronic Structure Using Moment-based Adaptive Variational Quantum Algorithms", "categories": ["q-bio.QM", "cs.ET"], "comment": "Keywords: quantum computing, variational quantum eigensolver, protein fragments, electronic structure, drug discovery, enzyme engineering", "summary": "Background: Understanding electronic interactions in protein active sites is fundamental to drug discovery and enzyme engineering, but remains computationally challenging due to exponential scaling of quantum mechanical calculations.\n  Results: We present a quantum-classical hybrid framework for simulating protein fragment electronic structure using variational quantum algorithms. We construct fermionic Hamiltonians from experimentally determined protein structures, map them to qubits via Jordan-Wigner transformation, and optimize ground state energies using the Variational Quantum Eigensolver implemented in pure Python. For a 4-orbital serine protease fragment, we achieve chemical accuracy (< 1.6 mHartree) with 95.3% correlation energy recovery. Systematic analysis reveals three-phase convergence behaviour with exponential decay (α = 0.95), power law optimization (γ = 1.21), and asymptotic approach. Application to SARS-CoV-2 protease inhibition demonstrates predictive accuracy (MAE=0.25 kcal/mol), while cytochrome P450 metabolism predictions achieve 85% site accuracy.\n  Conclusions: This work establishes a pathway for quantum-enhanced biomolecular simulations on near-term quantum hardware, bridging quantum algorithm development with practical biological applications."}
{"id": "2512.22415", "pdf": "https://arxiv.org/pdf/2512.22415", "abs": "https://arxiv.org/abs/2512.22415", "authors": ["Eugenio Simao"], "title": "Hierarchical Preemption: A Novel Information-Theoretic Control Mechanism in Lambda Phage Decision-Making", "categories": ["q-bio.MN", "q-bio.QM"], "comment": "6 pages, 2 figures. Related to arXiv:2512.17106", "summary": "Biological systems organize into hierarchies to manage complexity, yet the mechanisms governing hierarchical control remain incompletely understood. Using information theory and the Lambda phage lysis-lysogeny decision as a model system, we discover that hierarchical control operates through hierarchical preemption - higher layers collapse decision space rather than blocking lower-layer signals. Through mutual information (MI) analysis of 200 stochastic simulations, we demonstrate that the UV damage sensor (RecA) achieves 2.01x information advantage over environmental signals by preempting bistable outcomes into monostable attractors (98% lysogenic or 85% lytic). Conditional MI analysis reveals that the integrator signal (CII) carries lower information when RecA is absent (saturated, 0.06 bits) than when RecA is active (subsaturated, 0.38 bits). This saturation effect demonstrates that signals orchestrate compartment behaviors by removing decision space - achieving 85-98% outcome certainty while preserving 2-15% escape routes. These findings establish a quantitative framework for hierarchical information processing in cellular decision-making."}
{"id": "2601.00036", "pdf": "https://arxiv.org/pdf/2601.00036", "abs": "https://arxiv.org/abs/2601.00036", "authors": ["Eugenio Simao"], "title": "Unifying Weak Independence and Signal Hierarchy Theory: Extended Biological Petri Net Formalism with Application to Vibrio fischeri Quorum Sensing", "categories": ["q-bio.MN", "q-bio.QM"], "comment": "9 pages, 3 figures", "summary": "Biological Petri Nets (Bio-PNs) require extensions beyond classical formalism to capture biochemical reality: multiple reactions simultaneously affect shared metabolites through convergent production or regulatory coupling, while signal places carry hierarchical control information distinct from material flow. We present a unified 13-tuple Extended Bio-PN formalism integrating two complementary theories: Weak Independence Theory (enabling coupled parallelism despite place-sharing) and Signal Hierarchy Theory (separating information flow from mass transfer). The extended definition adds signal partition (Psi subset P), arc type classification (A), regulatory structure (Sigma), environmental exchange (Theta), dependency taxonomy (Delta), heterogeneous transition types (tau), and biochemical formula tracking (rho). We formalize signal token consumption semantics through two-phase execution (enabling vs. consumption) and prove weak independence correctness for continuous dynamics. Application to Vibrio fischeri quorum sensing demonstrates how energy metabolism (ENERGY signals) orchestrates binary ON/OFF decisions through hierarchical constraint propagation to regulatory signals (LuxR-AHL complex), with 133-fold difference separating states. Analysis reveals signal saturation timing as the orchestrator forcing threshold-crossing, analogous to bacteriophage lambda lysogeny-lysis decisions. This work establishes formal foundations for modeling biological information flow in Petri nets, with implications for systems biology, synthetic circuit design, and parallel biochemical simulation."}
{"id": "2601.00647", "pdf": "https://arxiv.org/pdf/2601.00647", "abs": "https://arxiv.org/abs/2601.00647", "authors": ["QiWei Meng"], "title": "Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations", "categories": ["cs.CL", "cs.CE", "q-bio.QM"], "comment": null, "summary": "Large Protein Language Models have shown strong potential for generative protein design, yet they frequently produce structural hallucinations, generating sequences with high linguistic likelihood that fold into thermodynamically unstable conformations. Existing alignment approaches such as Direct Preference Optimization are limited in this setting, as they model preferences as binary labels and ignore the continuous structure of the physical energy landscape. We propose Physio-DPO, a physics informed alignment framework that grounds protein language models in thermodynamic stability. Physio-DPO introduces a magnitude aware objective that scales optimization updates according to the energy gap between native structures and physics perturbed hard negatives. Experiments show that Physio-DPO consistently outperforms strong baselines including SFT, PPO, and standard DPO, reducing self consistency RMSD to 1.28 Å and increasing foldability to 92.8%. Qualitative analysis further demonstrates that Physio-DPO effectively mitigates structural hallucinations by recovering biophysical interactions such as hydrophobic core packing and hydrogen bond networks."}
