{"id": "2601.01358", "pdf": "https://arxiv.org/pdf/2601.01358", "abs": "https://arxiv.org/abs/2601.01358", "authors": ["Di Su", "Kai Ming Ting", "Jie Zhang", "Xiaorui Zhang", "Xinpeng Li"], "title": "A New Framework for Explainable Rare Cell Identification in Single-Cell Transcriptomics Data", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "The detection of rare cell types in single-cell transcriptomics data is crucial for elucidating disease pathogenesis and tissue development dynamics. However, a critical gap that persists in current methods is their inability to provide an explanation based on genes for each cell they have detected as rare. We identify three primary sources of this deficiency. First, the anomaly detectors often function as \"black boxes\", designed to detect anomalies but unable to explain why a cell is anomalous. Second, the standard analytical framework hinders interpretability by relying on dimensionality reduction techniques, such as Principal Component Analysis (PCA), which transform meaningful gene expression data into abstract, uninterpretable features. Finally, existing explanation algorithms cannot be readily applied to this domain, as single-cell data is characterized by high dimensionality, noise, and substantial sparsity. To overcome these limitations, we introduce a framework for explainable anomaly detection in single-cell transcriptomics data which not only identifies individual anomalies, but also provides a visual explanation based on genes that makes an instance anomalous. This framework has two key ingredients that are not existed in current methods applied in this domain. First, it eliminates the PCA step which is deemed to be an essential component in previous studies. Second, it employs the state-of-art anomaly detector and explainer as the efficient and effective means to find each rare cell and the relevant gene subspace in order to provide explanations for each rare cell as well as the typical normal cell associated with the rare cell's closest normal cells."}
{"id": "2601.01089", "pdf": "https://arxiv.org/pdf/2601.01089", "abs": "https://arxiv.org/abs/2601.01089", "authors": ["Nobuyuki Ota"], "title": "Central Dogma Transformer: Towards Mechanism-Oriented AI for Cellular Understanding", "categories": ["cs.LG", "q-bio.GN"], "comment": null, "summary": "Understanding cellular mechanisms requires integrating information across DNA, RNA, and protein - the three molecular systems linked by the Central Dogma of molecular biology. While domain-specific foundation models have achieved success for each modality individually, they remain isolated, limiting our ability to model integrated cellular processes. Here we present the Central Dogma Transformer (CDT), an architecture that integrates pre-trained language models for DNA, RNA, and protein following the directional logic of the Central Dogma. CDT employs directional cross-attention mechanisms - DNA-to-RNA attention models transcriptional regulation, while RNA-to-Protein attention models translational relationships - producing a unified Virtual Cell Embedding that integrates all three modalities. We validate CDT v1 - a proof-of-concept implementation using fixed (non-cell-specific) RNA and protein embeddings - on CRISPRi enhancer perturbation data from K562 cells, achieving a Pearson correlation of 0.503, representing 63% of the theoretical ceiling set by cross-experiment variability (r = 0.797). Attention and gradient analyses provide complementary interpretive windows: in detailed case studies, these approaches highlight largely distinct genomic regions, with gradient analysis identifying a CTCF binding site that Hi-C data showed as physically contacting both enhancer and target gene. These results suggest that AI architectures aligned with biological information flow can achieve both predictive accuracy and mechanistic interpretability."}
{"id": "2601.00895", "pdf": "https://arxiv.org/pdf/2601.00895", "abs": "https://arxiv.org/abs/2601.00895", "authors": ["Annabelle Yao"], "title": "Deep Learning Framework for RNA Inverse Folding with Geometric Structure Potentials", "categories": ["q-bio.QM", "cs.LG"], "comment": null, "summary": "RNA's diverse biological functions stem from its structural versatility, yet accurately predicting and designing RNA sequences given a 3D conformation (inverse folding) remains a challenge. Here, I introduce a deep learning framework that integrates Geometric Vector Perceptron (GVP) layers with a Transformer architecture to enable end-to-end RNA design. I construct a dataset consisting of experimentally solved RNA 3D structures, filtered and deduplicated from the BGSU RNA list, and evaluate performance using both sequence recovery rate and TM-score to assess sequence and structural fidelity, respectively. On standard benchmarks and RNA-Puzzles, my model achieves state-of-the-art performance, with recovery and TM-scores of 0.481 and 0.332, surpassing existing methods across diverse RNA families and length scales. Masked family-level validation using Rfam annotations confirms strong generalization beyond seen families. Furthermore, inverse-folded sequences, when refolded using AlphaFold3, closely resemble native structures, highlighting the critical role of geometric features captured by GVP layers in enhancing Transformer-based RNA design."}
{"id": "2601.01850", "pdf": "https://arxiv.org/pdf/2601.01850", "abs": "https://arxiv.org/abs/2601.01850", "authors": ["Pedro Pessoa", "Steve Press√©", "S. Banu Ozkan"], "title": "Allostery Beyond Amplification: Temporal Regulation of Signaling Information", "categories": ["q-bio.MN", "math.DS", "physics.bio-ph", "physics.chem-ph"], "comment": null, "summary": "Allostery is a fundamental mechanism of protein regulation and is commonly interpreted as modulating enzymatic activity or product abundance. Here we show that this view is incomplete. Using a stochastic model of allosteric regulation combined with an information-theoretic analysis, we quantify the mutual information between an enzyme's regulatory state and the states of downstream signaling components. Beyond controlling steady-state production levels, allostery also regulates the timing and duration over which information is transmitted. By tuning the temporal operating regime of signaling pathways, allosteric regulation enables distinct dynamical outcomes from identical molecular components, providing a physical mechanism for temporal information flow, signaling specificity, and coordination without changes in metabolic pathways."}
{"id": "2601.00941", "pdf": "https://arxiv.org/pdf/2601.00941", "abs": "https://arxiv.org/abs/2601.00941", "authors": ["Xujun Che", "Xiuxia Du", "Depeng Xu"], "title": "Comparative Analysis of Formula and Structure Prediction from Tandem Mass Spectra", "categories": ["q-bio.QM", "cs.AI", "cs.CE"], "comment": null, "summary": "Liquid chromatography mass spectrometry (LC-MS)-based metabolomics and exposomics aim to measure detectable small molecules in biological samples. The results facilitate hypothesis-generating discovery of metabolic changes and disease mechanisms and provide information about environmental exposures and their effects on human health. Metabolomics and exposomics are made possible by the high resolving power of LC and high mass measurement accuracy of MS. However, a majority of the signals from such studies still cannot be identified or annotated using conventional library searching because existing spectral libraries are far from covering the vast chemical space captured by LC-MS/MS. To address this challenge and unleash the full potential of metabolomics and exposomics, a number of computational approaches have been developed to predict compounds based on tandem mass spectra. Published assessment of these approaches used different datasets and evaluation. To select prediction workflows for practical applications and identify areas for further improvements, we have carried out a systematic evaluation of the state-of-the-art prediction algorithms. Specifically, the accuracy of formula prediction and structure prediction was evaluated for different types of adducts. The resulting findings have established realistic performance baselines, identified critical bottlenecks, and provided guidance to further improve compound predictions based on MS."}
{"id": "2601.01337", "pdf": "https://arxiv.org/pdf/2601.01337", "abs": "https://arxiv.org/abs/2601.01337", "authors": ["Xueqing Xu", "Yonghang Gao", "Duanchen Sun", "Ling-Yun Wu"], "title": "HyperNetWalk: A Unified Framework for Personalized and Population-Level Cancer Driver Gene Identification via Multi-Network Hypergraph Diffusion", "categories": ["q-bio.QM", "q-bio.MN"], "comment": "31 pages, 4 main figures, 7 supplementary figures. Code is available at https://github.com/xqxu921/HyperNetWalk", "summary": "Identifying cancer driver genes is crucial for understanding tumor biology and developing precision therapies. However, existing computational methods often rely on single biological networks or population-level mutation patterns, limiting their ability to identify patient-specific drivers and leverage the complementary information from multiple network types. Here, we present HyperNetWalk, a novel computational framework that integrates multiple biological networks and hypergraph diffusion to identify driver genes at both personalized and cohort levels. In the first stage, HyperNetWalk integrates protein-protein interaction networks, gene regulatory networks, and dynamic co-expression networks through sample-independent random walks on patient-specific subnetworks to capture topological importance and expression perturbation effects. In the second stage, it refines predictions through hypergraph-based random walks that leverage cross-sample information while preserving individual mutational contexts. Comprehensive evaluation on 12 TCGA cancer types demonstrates that HyperNetWalk achieves superior or competitive performance compared to state-of-the-art methods in both personalized and cohort-level predictions. Notably, HyperNetWalk successfully identifies known driver genes with high precision while revealing cancer type-specific drivers that reflect distinct biological mechanisms. Our framework provides a unified solution for personalized and population-based driver gene identification, offering valuable insights for precision oncology and therapeutic target discovery."}
{"id": "2601.01116", "pdf": "https://arxiv.org/pdf/2601.01116", "abs": "https://arxiv.org/abs/2601.01116", "authors": ["Richik Chakraborty"], "title": "Beyond P-Values: Importing Quantitative Finance's Risk and Regret Metrics for AI in Learning Health Systems", "categories": ["stat.ME", "q-bio.QM"], "comment": "Manuscript: 12 pages, 3 mathematical boxes, 1 figure, 1 table, 26 references", "summary": "The increasing deployment of artificial intelligence (AI) in clinical settings challenges foundational assumptions underlying traditional frameworks of medical evidence. Classical statistical approaches, centered on randomized controlled trials, frequentist hypothesis testing, and static confidence intervals, were designed for fixed interventions evaluated under stable conditions. In contrast, AI-driven clinical systems learn continuously, adapt their behavior over time, and operate in non-stationary environments shaped by evolving populations, practices, and feedback effects. In such systems, clinical harm arises less from average error rates than from calibration drift, rare but severe failures, and the accumulation of suboptimal decisions over time.\n  In this perspective, we argue that prevailing notions of statistical significance are insufficient for characterizing evidence and safety in learning health systems. Drawing on risk-theoretic concepts from quantitative finance and online decision theory, we propose reframing medical evidence for adaptive AI systems in terms of time-indexed calibration stability, bounded downside risk, and controlled cumulative regret. We emphasize that this approach does not replace randomized trials or causal inference, but complements them by addressing dimensions of risk and uncertainty that emerge only after deployment. This framework provides a principled mathematical language for evaluating AI-driven clinical systems under continual learning and offers implications for clinical practice, research design, and regulatory oversight."}
{"id": "2601.01245", "pdf": "https://arxiv.org/pdf/2601.01245", "abs": "https://arxiv.org/abs/2601.01245", "authors": ["Yiyuan Huang", "Ling Zhou", "Min Zhang", "Peter X. K. Song"], "title": "Model-Assisted Causal Inference for the Treatment Effect on Recurrent Events in the Presence of Terminal Events", "categories": ["stat.AP", "q-bio.QM", "q-bio.TO", "stat.ME"], "comment": null, "summary": "This paper is motivated by evaluating the benefits of patients receiving mechanical circulatory support (MCS) devices in end-stage heart failure management inference, in which hypothesis testing for a treatment effect on the risk of recurrent events is challenged in the presence of terminal events. Existing methods based on cumulative frequency unreasonably disadvantage longer survivors as they tend to experience more recurrent events. The While-Alive-based (WA) test has provided a solution to address this survival-length-bias problem, and it performs well when the recurrent event rate holds constant over time. However, if such a constant-rate assumption is violated, the WA test can exhibit an inflated type I error and inaccurate estimation of treatment effects. To fill this methodological gap, we propose a Proportional Rate Marginal Structural Model-assisted Test (PR-MSMaT) in the causal inference framework of separable treatment effects for recurrent and terminal events. Using the simulation study, we demonstrate that our PR-MSMaT can properly control type I error while gaining power comparable to the WA test under time-varying recurrent event rates. We employ PR-MSMaT to compare different MCS devices with the postoperative risk of gastrointestinal bleeding among patients enrolled in the Interagency Registry of Mechanically Assisted Circulatory Support program."}
{"id": "2601.01875", "pdf": "https://arxiv.org/pdf/2601.01875", "abs": "https://arxiv.org/abs/2601.01875", "authors": ["Kewen Cao", "Jianxu Chen", "Yongbing Zhang", "Ye Zhang", "Hongxiao Wang"], "title": "Toward Auditable Neuro-Symbolic Reasoning in Pathology: SQL as an Explicit Trace of Evidence", "categories": ["cs.AI", "q-bio.QM"], "comment": null, "summary": "Automated pathology image analysis is central to clinical diagnosis, but clinicians still ask which slide features drive a model's decision and why. Vision-language models can produce natural language explanations, but these are often correlational and lack verifiable evidence. In this paper, we introduce an SQL-centered agentic framework that enables both feature measurement and reasoning to be auditable. Specifically, after extracting human-interpretable cellular features, Feature Reasoning Agents compose and execute SQL queries over feature tables to aggregate visual evidence into quantitative findings. A Knowledge Comparison Agent then evaluates these findings against established pathological knowledge, mirroring how pathologists justify diagnoses from measurable observations. Extensive experiments evaluated on two pathology visual question answering datasets demonstrate our method improves interpretability and decision traceability while producing executable SQL traces that link cellular measurements to diagnostic conclusions."}
{"id": "2601.02138", "pdf": "https://arxiv.org/pdf/2601.02138", "abs": "https://arxiv.org/abs/2601.02138", "authors": ["Weisen Yang", "Hanqing Zhang", "Wangren Qiu", "Xuan Xiao", "Weizhong Lin"], "title": "Edge-aware GAT-based protein binding site prediction", "categories": ["cs.LG", "q-bio.QM"], "comment": "24 pages, 10 figures, 6 tables", "summary": "Accurate identification of protein binding sites is crucial for understanding biomolecular interaction mechanisms and for the rational design of drug targets. Traditional predictive methods often struggle to balance prediction accuracy with computational efficiency when capturing complex spatial conformations. To address this challenge, we propose an Edge-aware Graph Attention Network (Edge-aware GAT) model for the fine-grained prediction of binding sites across various biomolecules, including proteins, DNA/RNA, ions, ligands, and lipids. Our method constructs atom-level graphs and integrates multidimensional structural features, including geometric descriptors, DSSP-derived secondary structure, and relative solvent accessibility (RSA), to generate spatially aware embedding vectors. By incorporating interatomic distances and directional vectors as edge features within the attention mechanism, the model significantly enhances its representation capacity. On benchmark datasets, our model achieves an ROC-AUC of 0.93 for protein-protein binding site prediction, outperforming several state-of-the-art methods. The use of directional tensor propagation and residue-level attention pooling further improves both binding site localization and the capture of local structural details. Visualizations using PyMOL confirm the model's practical utility and interpretability. To facilitate community access and application, we have deployed a publicly accessible web server at http://119.45.201.89:5000/. In summary, our approach offers a novel and efficient solution that balances prediction accuracy, generalization, and interpretability for identifying functional sites in proteins."}
