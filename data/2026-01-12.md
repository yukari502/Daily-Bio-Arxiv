<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 2]
- [q-bio.QM](#q-bio.QM) [Total: 2]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [stat.AP](#stat.AP) [Total: 1]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [DNATokenizer: A GPU-First Byte-to-Identifier Tokenizer for High-Throughput DNA Language Models](https://arxiv.org/abs/2601.05531)
*Eliatan Niktab,Hardip Patel*

Main category: q-bio.GN

TL;DR: DNATok是一个高性能GPU优先的基因组数据tokenization系统，通过字节查找表和流水线优化，显著提升基因组模型训练和推理的tokenization吞吐量。


<details>
  <summary>Details</summary>
Motivation: 基因组数据tokenization面临算法设计（信息泄露、边界敏感）和系统性能（字符串处理、主机绑定词汇查找成为瓶颈）的双重挑战，特别是在处理数十亿碱基规模时。

Method: DNATok采用GPU优先设计：1) 用字节查找表替代通用字符串处理；2) 使用固定内存和架构并行实现主机到设备的流水线重叠；3) 支持单核苷酸、非重叠k-mer和BPE等多种tokenization方法。

Result: DNATok比优化的Hugging Face基线实现84-95倍编码吞吐量提升，主机到设备吞吐量提升1.9倍，端到端流处理达到1.27-1.84e8 tokens/s，消除了tokenization瓶颈。

Conclusion: DNATok作为一个词汇无关的高性能tokenization系统层，有效解决了基因组基础模型在大规模训练和推理中的tokenization性能瓶颈问题。

Abstract: Tokenization sits at the boundary between high-throughput genomic input and GPU compute, posing challenges in both algorithm design and system throughput. Overlapping k-mer tokenization can introduce information leakage under masked language modeling (MLM) and may degrade downstream accuracy. Single-nucleotide tokenization avoids leakage and preserves per-base fidelity, but it greatly increases sequence length for attention-based architectures. Non-overlapping k-mers and byte-pair encoding (BPE) provide compression and avoid leakage, at the cost of boundary sensitivity or reduced interpretability. Empirically, the choice of tokenization interacts strongly with model architecture and task requirements. At the system level, however, standard string tokenizers and host-bound vocabulary lookups dominate wall-clock time once inputs reach billions of bases, regardless of the tokenization algorithm. We present DNATok, a high-performance, GPU-first tokenization system that replaces general-purpose string processing with byte lookup table (LUT)-based identifier streaming and an overlapped host-to-device (H2D)/compute pipeline using pinned memory and architectural parallelism. DNATok is vocabulary-agnostic: it accelerates single-nucleotide, non-overlapping k-mer, and BPE tokenization, and integrates as a drop-in systems layer beneath genomic foundation models. DNATok achieves 84-95x higher encoding throughput than optimized Hugging Face baselines and up to 1.9x higher H2D throughput. End-to-end streaming reaches 1.27-1.84e8 tokens/s depending on configuration, effectively removing tokenization as a bottleneck for production-scale training and inference.

</details>


### [2] [Open World Knowledge Aided Single-Cell Foundation Model with Robust Cross-Modal Cell-Language Pre-training](https://arxiv.org/abs/2601.05648)
*Haoran Wang,Xuanyi Zhang,Shuangsang Fang,Longke Ran,Ziqing Deng,Yong Zhang,Yuxiang Li,Shaoshuai Li*

Main category: q-bio.GN

TL;DR: OKR-CELL是一个开放世界语言知识增强的鲁棒单细胞基础模型，通过跨模态细胞-语言预训练框架，利用LLM和RAG丰富细胞文本描述，并设计跨模态鲁棒对齐目标来增强对噪声数据的抵抗能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练语言模型的单细胞基础模型存在两个主要限制：1) 对个体深度特征的整合不足；2) 忽视多模态数据中的噪声影响。需要开发能够更好整合开放世界知识并抵抗数据噪声的模型。

Method: 提出OKR-CELL模型，基于跨模态细胞-语言预训练框架，包含两个关键创新：1) 利用基于大型语言模型的工作流程，通过检索增强生成技术使用开放世界知识丰富细胞文本描述；2) 设计跨模态鲁棒对齐目标，结合样本可靠性评估、课程学习和耦合动量对比学习来增强模型对噪声数据的抵抗能力。

Result: 在3200万细胞-文本对上进行预训练后，OKR-CELL在6个评估任务中取得了最先进的结果。除了细胞聚类、细胞类型注释、批次效应校正和少样本注释等标准基准外，模型在更广泛的多模态应用中也表现出优越性能，包括零样本细胞类型注释和双向细胞-文本检索。

Conclusion: OKR-CELL通过整合开放世界知识和增强对噪声的鲁棒性，显著提升了单细胞基础模型的性能，为单细胞多组学分析提供了更强大的工具，特别是在多模态应用场景中表现出色。

Abstract: Recent advancements in single-cell multi-omics, particularly RNA-seq, have provided profound insights into cellular heterogeneity and gene regulation. While pre-trained language model (PLM) paradigm based single-cell foundation models have shown promise, they remain constrained by insufficient integration of in-depth individual profiles and neglecting the influence of noise within multi-modal data. To address both issues, we propose an Open-world Language Knowledge-Aided Robust Single-Cell Foundation Model (OKR-CELL). It is built based on a cross-modal Cell-Language pre-training framework, which comprises two key innovations: (1) leveraging Large Language Models (LLMs) based workflow with retrieval-augmented generation (RAG) enriches cell textual descriptions using open-world knowledge; (2) devising a Cross-modal Robust Alignment (CRA) objective that incorporates sample reliability assessment, curriculum learning, and coupled momentum contrastive learning to strengthen the model's resistance to noisy data. After pretraining on 32M cell-text pairs, OKR-CELL obtains cutting-edge results across 6 evaluation tasks. Beyond standard benchmarks such as cell clustering, cell-type annotation, batch-effect correction, and few-shot annotation, the model also demonstrates superior performance in broader multi-modal applications, including zero-shot cell-type annotation and bidirectional cell-text retrieval.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [3] [AntibodyDesignBFN: High-Fidelity Fixed-Backbone Antibody Design via Discrete Bayesian Flow Networks](https://arxiv.org/abs/2601.05605)
*Yue Hu,YingChao Liu*

Main category: q-bio.QM

TL;DR: 提出了AntibodyDesignBFN框架，基于离散贝叶斯流网络进行固定骨架抗体设计，在H-CDR3上达到48.1%的氨基酸恢复率。


<details>
  <summary>Details</summary>
Motivation: 现有基于DDPM的抗体生成方法计算成本高，难以处理氨基酸序列等离散变量，需要更高效的抗体设计框架。

Method: 使用离散贝叶斯流网络直接在概率单纯形上进行连续时间可微生成过程，结合轻量级几何Transformer和不变点注意力，采用梯度累积的资源高效训练策略。

Result: 在2025年时间测试集上，H-CDR3的氨基酸恢复率达到48.1%，优于现有方法，展示了BFN在3D几何约束下的高效抗体设计能力。

Conclusion: BFN结合3D几何约束为高保真抗体设计提供了稳健的数学框架，AntibodyDesignBFN在固定骨架抗体设计任务上表现出色。

Abstract: The computational design of antibodies with high specificity and affinity is a cornerstone of modern therapeutic development. While deep generative models, particularly Denoising Diffusion Probabilistic Models (DDPMs), have demonstrated the ability to generate realistic antibody structures, they often suffer from high computational costs and the difficulty of modeling discrete variables like amino acid sequences. In this work, we present AntibodyDesignBFN, a novel framework for fixed-backbone antibody design based on Discrete Bayesian Flow Networks(BFN). Unlike standard diffusion models that rely on Gaussian noise removal or complex discrete corruption processes, BFNs operate directly on the parameters of the data distribution, enabling a continuous-time, fully differentiable generative process on the probability simplex. While recent pioneering works like IgCraft and AbBFN have introduced BFNs to the domain of antibody sequence generation and inpainting, our work focuses specifically on the inverse folding task-designing sequences that fold into a fixed 3D backbone. By integrating a lightweight Geometric Transformer utilizing Invariant Point Attention (IPA) and a resource-efficient training strategy with gradient accumulation, our model achieves superior performance. Evaluations on a rigorous 2025 temporal test set reveal that AntibodyDesignBFN achieves a remarkable 48.1% Amino Acid Recovery (AAR) on H-CDR3, demonstrating that BFNs, when conditioned on 3D geometric constraints, offer a robust mathematical framework for high-fidelity antibody design$.$Code and model checkpoints are available at https://github.com/YueHuLab/AntibodyDesignBFN and https://huggingface.co/YueHuLab/AntibodyDesignBFN, respectively.

</details>


### [4] [Evaluating infectious disease forecasts in a cost-loss situation](https://arxiv.org/abs/2601.05921)
*Philip Gerlee,Torbjörn Lundh,Anna Saxne Jöud,Henrik Thorén*

Main category: q-bio.QM

TL;DR: 提出基于决策理论的流行病学预测评估框架，使用价值分数衡量模型对决策者的实际价值，应用于流感预测挑战赛数据


<details>
  <summary>Details</summary>
Motivation: 现有流行病学预测评估指标未考虑决策者面临的实际成本和损失，需要开发能反映决策价值的评估方法

Method: 将决策理论框架应用于流行病学背景，通过比较基于模型预测和历史事件概率的预期费用，计算价值分数

Result: 大多数流感预测模型在某些成本损失比范围内表现出正价值分数，但与传统评估指标（修正对数评分）的排名无明确关系

Conclusion: 基于决策理论的评估框架能更好地反映预测对决策者的实际价值，有助于改进流行病学预测的利用

Abstract: In order for epidemiological forecasts to be useful for decision-makers the forecasts need to be properly validated and evaluated. Although several metrics fore evaluation have been proposed and used none of them account for the potential costs and losses that the decision-maker faces. We have adapted a decision-theoretic framework to an epidemiological context which assigns a Value Score (VS) to each model by comparing the expected expense of the decision-maker when acting on the model forecast to the expected expense obtained from acting on historical event probabilities. The VS depends on the cost-loss ratio and a positive VS implies added value for the decision-maker whereas a negative VS means that historical event probabilities outperform the model forecasts. We apply this framework to a subset of model forecasts of influenza peak intensity from the FluSight Challenge and show that most models exhibit a positive VS for some range of cost-loss ratios. However, there is no clear relationship between the VS and the original ranking of the model forecasts obtained using a modified log score. This is in part explained by the fact that the VS is sensitive to over- vs. under-prediction, which is not the case for standard evaluation metrics. We believe that this type of context-sensitive evaluation will lead to improved utilisation of epidemiological forecasts by decision-makers.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [5] [Cedalion Tutorial: A Python-based framework for comprehensive analysis of multimodal fNIRS & DOT from the lab to the everyday world](https://arxiv.org/abs/2601.05923)
*E. Middell,L. Carlton,S. Moradi,T. Codina,T. Fischer,J. Cutler,S. Kelley,J. Behrendt,T. Dissanayake,N. Harmening,M. A. Yücel,D. A. Boas,A. von Lühmann*

Main category: eess.SP

TL;DR: Cedalion是一个基于Python的开源框架，用于统一fNIRS和DOT数据的模型驱动与数据驱动分析，支持可重复、可扩展的神经影像工作流。


<details>
  <summary>Details</summary>
Motivation: 当前fNIRS和DOT分析工具分散在不同平台，限制了可重复性、互操作性和与现代机器学习工作流的集成，需要统一的分析框架。

Method: 开发基于Python的开源框架，整合前向建模、光极配准、信号处理、GLM分析、DOT图像重建和机器学习方法，遵循SNIRF和BIDS标准，支持容器化工作流。

Result: 创建了Cedalion框架，提供七个可执行笔记本演示核心功能，实现可重复、可扩展、云就绪的fNIRS/DOT分析工作流，支持与EEG、MEG等多模态数据融合。

Conclusion: Cedalion为实验室和真实世界神经影像提供了开放、透明、社区可扩展的基础，支持可重复、可扩展、云和机器学习就绪的fNIRS/DOT工作流。

Abstract: Functional near-infrared spectroscopy (fNIRS) and diffuse optical tomography (DOT) are rapidly evolving toward wearable, multimodal, and data-driven, AI-supported neuroimaging in the everyday world. However, current analytical tools are fragmented across platforms, limiting reproducibility, interoperability, and integration with modern machine learning (ML) workflows. Cedalion is a Python-based open-source framework designed to unify advanced model-based and data-driven analysis of multimodal fNIRS and DOT data within a reproducible, extensible, and community-driven environment. Cedalion integrates forward modelling, photogrammetric optode co-registration, signal processing, GLM Analysis, DOT image reconstruction, and ML-based data-driven methods within a single standardized architecture based on the Python ecosystem. It adheres to SNIRF and BIDS standards, supports cloud-executable Jupyter notebooks, and provides containerized workflows for scalable, fully reproducible analysis pipelines that can be provided alongside original research publications. Cedalion connects established optical-neuroimaging pipelines with ML frameworks such as scikit-learn and PyTorch, enabling seamless multimodal fusion with EEG, MEG, and physiological data. It implements validated algorithms for signal-quality assessment, motion correction, GLM modelling, and DOT reconstruction, complemented by modules for simulation, data augmentation, and multimodal physiology analysis. Automated documentation links each method to its source publication, and continuous-integration testing ensures robustness. This tutorial paper provides seven fully executable notebooks that demonstrate core features. Cedalion offers an open, transparent, and community extensible foundation that supports reproducible, scalable, cloud- and ML-ready fNIRS/DOT workflows for laboratory-based and real-world neuroimaging.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [6] [PRISM: Protocol Refinement through Intelligent Simulation Modeling](https://arxiv.org/abs/2601.05356)
*Brian Hsu,Priyanka V Setty,Rory M Butler,Ryan Lewis,Casey Stone,Rebecca Weinberg,Thomas Brettin,Rick Stevens,Ian Foster,Arvind Ramanathan*

Main category: cs.RO

TL;DR: PRISM框架通过语言模型代理自动设计、验证和执行实验协议，实现端到端的自动化实验室工作流


<details>
  <summary>Details</summary>
Motivation: 实验协议设计和执行自动化是实现自主实验室的关键瓶颈，需要解决协议生成、验证和执行的自动化问题

Method: 使用基于语言模型的多代理系统，通过规划-批判-验证循环从网络资源生成结构化实验步骤，转换为统一协议格式，并在数字孪生环境中验证

Result: 成功开发了PRISM框架，能够自动生成实验协议，通过数字孪生验证，并在实际机器人平台上执行（Opentrons OT-2、PF400机械臂等）

Conclusion: PRISM为自主实验室提供了实用的端到端工作流，连接了语言协议生成、模拟验证和机器人执行，展示了在Luna qPCR和Cell Painting案例中的有效性

Abstract: Automating experimental protocol design and execution remains as a fundamental bottleneck in realizing self-driving laboratories. We introduce PRISM (Protocol Refinement through Intelligent Simulation Modeling), a framework that automates the design, validation, and execution of experimental protocols on a laboratory platform composed of off-the-shelf robotic instruments. PRISM uses a set of language-model-based agents that work together to generate and refine experimental steps. The process begins with automatically gathering relevant procedures from web-based sources describing experimental workflows. These are converted into structured experimental steps (e.g., liquid handling steps, deck layout and other related operations) through a planning, critique, and validation loop. The finalized steps are translated into the Argonne MADSci protocol format, which provides a unified interface for coordinating multiple robotic instruments (Opentrons OT-2 liquid handler, PF400 arm, Azenta plate sealer and peeler) without requiring human intervention between steps. To evaluate protocol-generation performance, we benchmarked both single reasoning models and multi-agent workflow across constrained and open-ended prompting paradigms. The resulting protocols were validated in a digital-twin environment built in NVIDIA Omniverse to detect physical or sequencing errors before execution. Using Luna qPCR amplification and Cell Painting as case studies, we demonstrate PRISM as a practical end-to-end workflow that bridges language-based protocol generation, simulation-based validation, and automated robotic execution.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [7] [A latent factor approach to hyperspectral time series data for multivariate genomic prediction of grain yield in wheat](https://arxiv.org/abs/2601.05842)
*Jonathan F. Kunst,Killian A. C. Melsen,Willem Kruijer,José Crossa,Chris Maliepaard,Fred A. van Eeuwijk,Carel F. W. Peeters*

Main category: stat.AP

TL;DR: 利用因子分析和Procrustes旋转从高光谱数据中提取潜在变量，通过多变量基因组预测提高小麦产量预测精度


<details>
  <summary>Details</summary>
Motivation: 植物育种中高维时间序列表型数据日益普遍，但分析和整合这些数据进行遗传分析和基因组预测仍然困难。需要开发方法从高光谱数据中提取相关特征，提高基因组预测能力。

Method: 使用因子分析结合Procrustes旋转对高光谱数据的遗传相关矩阵进行处理，提取潜在变量。利用CIMMYT 2014-2015年1,033个小麦基因型的数据，在三种灌溉处理下通过载人飞机搭载高光谱传感器（385-850nm，62个波段）获取多时间点数据。采用多变量基因组预测模型整合高光谱数据的潜在变量。

Result: 通过整合高光谱数据的潜在变量，在相关尺度上比单变量基因组预测提高了0.1-0.3的预测能力。确定了试验中重要的时间点及其与植物生长阶段的关系。

Conclusion: 展示了如何结合领域知识和数据驱动方法，提高基因组预测能力并从高通量表型平台的传感器数据中获得新见解。该方法为处理高维时间序列表型数据提供了有效途径。

Abstract: High-dimensional time series phenotypic data is becoming increasingly common within plant breeding programmes. However, analysing and integrating such data for genetic analysis and genomic prediction remains difficult. Here we show how factor analysis with Procrustes rotation on the genetic correlation matrix of hyperspectral secondary phenotype data can help in extracting relevant features for within-trial prediction. We use a subset of Centro Internacional de Mejoramiento de Maíz y Trigo (CIMMYT) elite yield wheat trial of 2014-2015, consisting of 1,033 genotypes. These were measured across three irrigation treatments at several timepoints during the season, using manned airplane flights with hyperspectral sensors capturing 62 bands in the spectrum of 385-850 nm. We perform multivariate genomic prediction using latent variables to improve within-trial genomic predictive ability (PA) of wheat grain yield within three distinct watering treatments. By integrating latent variables of the hyperspectral data in a multivariate genomic prediction model, we are able to achieve an absolute gain of .1 to .3 (on the correlation scale) in PA compared to univariate genomic prediction. Furthermore, we show which timepoints within a trial are important and how these relate to plant growth stages. This paper showcases how domain knowledge and data-driven approaches can be combined to increase PA and gain new insights from sensor data of high-throughput phenotyping platforms.

</details>
