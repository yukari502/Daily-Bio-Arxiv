{"id": "2601.05605", "pdf": "https://arxiv.org/pdf/2601.05605", "abs": "https://arxiv.org/abs/2601.05605", "authors": ["Yue Hu", "YingChao Liu"], "title": "AntibodyDesignBFN: High-Fidelity Fixed-Backbone Antibody Design via Discrete Bayesian Flow Networks", "categories": ["q-bio.QM"], "comment": "4 pages, 1 table, 4 equations", "summary": "The computational design of antibodies with high specificity and affinity is a cornerstone of modern therapeutic development. While deep generative models, particularly Denoising Diffusion Probabilistic Models (DDPMs), have demonstrated the ability to generate realistic antibody structures, they often suffer from high computational costs and the difficulty of modeling discrete variables like amino acid sequences. In this work, we present AntibodyDesignBFN, a novel framework for fixed-backbone antibody design based on Discrete Bayesian Flow Networks(BFN). Unlike standard diffusion models that rely on Gaussian noise removal or complex discrete corruption processes, BFNs operate directly on the parameters of the data distribution, enabling a continuous-time, fully differentiable generative process on the probability simplex. While recent pioneering works like IgCraft and AbBFN have introduced BFNs to the domain of antibody sequence generation and inpainting, our work focuses specifically on the inverse folding task-designing sequences that fold into a fixed 3D backbone. By integrating a lightweight Geometric Transformer utilizing Invariant Point Attention (IPA) and a resource-efficient training strategy with gradient accumulation, our model achieves superior performance. Evaluations on a rigorous 2025 temporal test set reveal that AntibodyDesignBFN achieves a remarkable 48.1% Amino Acid Recovery (AAR) on H-CDR3, demonstrating that BFNs, when conditioned on 3D geometric constraints, offer a robust mathematical framework for high-fidelity antibody design$.$Code and model checkpoints are available at https://github.com/YueHuLab/AntibodyDesignBFN and https://huggingface.co/YueHuLab/AntibodyDesignBFN, respectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86AntibodyDesignBFN\u6846\u67b6\uff0c\u57fa\u4e8e\u79bb\u6563\u8d1d\u53f6\u65af\u6d41\u7f51\u7edc\u8fdb\u884c\u56fa\u5b9a\u9aa8\u67b6\u6297\u4f53\u8bbe\u8ba1\uff0c\u5728H-CDR3\u4e0a\u8fbe\u523048.1%\u7684\u6c28\u57fa\u9178\u6062\u590d\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eDDPM\u7684\u6297\u4f53\u751f\u6210\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u5904\u7406\u6c28\u57fa\u9178\u5e8f\u5217\u7b49\u79bb\u6563\u53d8\u91cf\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6297\u4f53\u8bbe\u8ba1\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u79bb\u6563\u8d1d\u53f6\u65af\u6d41\u7f51\u7edc\u76f4\u63a5\u5728\u6982\u7387\u5355\u7eaf\u5f62\u4e0a\u8fdb\u884c\u8fde\u7eed\u65f6\u95f4\u53ef\u5fae\u751f\u6210\u8fc7\u7a0b\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u51e0\u4f55Transformer\u548c\u4e0d\u53d8\u70b9\u6ce8\u610f\u529b\uff0c\u91c7\u7528\u68af\u5ea6\u7d2f\u79ef\u7684\u8d44\u6e90\u9ad8\u6548\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u57282025\u5e74\u65f6\u95f4\u6d4b\u8bd5\u96c6\u4e0a\uff0cH-CDR3\u7684\u6c28\u57fa\u9178\u6062\u590d\u7387\u8fbe\u523048.1%\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86BFN\u57283D\u51e0\u4f55\u7ea6\u675f\u4e0b\u7684\u9ad8\u6548\u6297\u4f53\u8bbe\u8ba1\u80fd\u529b\u3002", "conclusion": "BFN\u7ed3\u54083D\u51e0\u4f55\u7ea6\u675f\u4e3a\u9ad8\u4fdd\u771f\u6297\u4f53\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u6570\u5b66\u6846\u67b6\uff0cAntibodyDesignBFN\u5728\u56fa\u5b9a\u9aa8\u67b6\u6297\u4f53\u8bbe\u8ba1\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2601.05921", "pdf": "https://arxiv.org/pdf/2601.05921", "abs": "https://arxiv.org/abs/2601.05921", "authors": ["Philip Gerlee", "Torbj\u00f6rn Lundh", "Anna Saxne J\u00f6ud", "Henrik Thor\u00e9n"], "title": "Evaluating infectious disease forecasts in a cost-loss situation", "categories": ["q-bio.QM"], "comment": null, "summary": "In order for epidemiological forecasts to be useful for decision-makers the forecasts need to be properly validated and evaluated. Although several metrics fore evaluation have been proposed and used none of them account for the potential costs and losses that the decision-maker faces. We have adapted a decision-theoretic framework to an epidemiological context which assigns a Value Score (VS) to each model by comparing the expected expense of the decision-maker when acting on the model forecast to the expected expense obtained from acting on historical event probabilities. The VS depends on the cost-loss ratio and a positive VS implies added value for the decision-maker whereas a negative VS means that historical event probabilities outperform the model forecasts. We apply this framework to a subset of model forecasts of influenza peak intensity from the FluSight Challenge and show that most models exhibit a positive VS for some range of cost-loss ratios. However, there is no clear relationship between the VS and the original ranking of the model forecasts obtained using a modified log score. This is in part explained by the fact that the VS is sensitive to over- vs. under-prediction, which is not the case for standard evaluation metrics. We believe that this type of context-sensitive evaluation will lead to improved utilisation of epidemiological forecasts by decision-makers.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u51b3\u7b56\u7406\u8bba\u7684\u6d41\u884c\u75c5\u5b66\u9884\u6d4b\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528\u4ef7\u503c\u5206\u6570\u8861\u91cf\u6a21\u578b\u5bf9\u51b3\u7b56\u8005\u7684\u5b9e\u9645\u4ef7\u503c\uff0c\u5e94\u7528\u4e8e\u6d41\u611f\u9884\u6d4b\u6311\u6218\u8d5b\u6570\u636e", "motivation": "\u73b0\u6709\u6d41\u884c\u75c5\u5b66\u9884\u6d4b\u8bc4\u4f30\u6307\u6807\u672a\u8003\u8651\u51b3\u7b56\u8005\u9762\u4e34\u7684\u5b9e\u9645\u6210\u672c\u548c\u635f\u5931\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u53cd\u6620\u51b3\u7b56\u4ef7\u503c\u7684\u8bc4\u4f30\u65b9\u6cd5", "method": "\u5c06\u51b3\u7b56\u7406\u8bba\u6846\u67b6\u5e94\u7528\u4e8e\u6d41\u884c\u75c5\u5b66\u80cc\u666f\uff0c\u901a\u8fc7\u6bd4\u8f83\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u548c\u5386\u53f2\u4e8b\u4ef6\u6982\u7387\u7684\u9884\u671f\u8d39\u7528\uff0c\u8ba1\u7b97\u4ef7\u503c\u5206\u6570", "result": "\u5927\u591a\u6570\u6d41\u611f\u9884\u6d4b\u6a21\u578b\u5728\u67d0\u4e9b\u6210\u672c\u635f\u5931\u6bd4\u8303\u56f4\u5185\u8868\u73b0\u51fa\u6b63\u4ef7\u503c\u5206\u6570\uff0c\u4f46\u4e0e\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\uff08\u4fee\u6b63\u5bf9\u6570\u8bc4\u5206\uff09\u7684\u6392\u540d\u65e0\u660e\u786e\u5173\u7cfb", "conclusion": "\u57fa\u4e8e\u51b3\u7b56\u7406\u8bba\u7684\u8bc4\u4f30\u6846\u67b6\u80fd\u66f4\u597d\u5730\u53cd\u6620\u9884\u6d4b\u5bf9\u51b3\u7b56\u8005\u7684\u5b9e\u9645\u4ef7\u503c\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u6d41\u884c\u75c5\u5b66\u9884\u6d4b\u7684\u5229\u7528"}}
{"id": "2601.05356", "pdf": "https://arxiv.org/pdf/2601.05356", "abs": "https://arxiv.org/abs/2601.05356", "authors": ["Brian Hsu", "Priyanka V Setty", "Rory M Butler", "Ryan Lewis", "Casey Stone", "Rebecca Weinberg", "Thomas Brettin", "Rick Stevens", "Ian Foster", "Arvind Ramanathan"], "title": "PRISM: Protocol Refinement through Intelligent Simulation Modeling", "categories": ["cs.RO", "cs.AI", "cs.MA", "q-bio.QM"], "comment": "43 pages, 8 figures, submitted to RSC Digital Discovery. Equal contribution: B. Hsu, P.V. Setty, R.M. Butler. Corresponding author: A. Ramanathan", "summary": "Automating experimental protocol design and execution remains as a fundamental bottleneck in realizing self-driving laboratories. We introduce PRISM (Protocol Refinement through Intelligent Simulation Modeling), a framework that automates the design, validation, and execution of experimental protocols on a laboratory platform composed of off-the-shelf robotic instruments. PRISM uses a set of language-model-based agents that work together to generate and refine experimental steps. The process begins with automatically gathering relevant procedures from web-based sources describing experimental workflows. These are converted into structured experimental steps (e.g., liquid handling steps, deck layout and other related operations) through a planning, critique, and validation loop. The finalized steps are translated into the Argonne MADSci protocol format, which provides a unified interface for coordinating multiple robotic instruments (Opentrons OT-2 liquid handler, PF400 arm, Azenta plate sealer and peeler) without requiring human intervention between steps. To evaluate protocol-generation performance, we benchmarked both single reasoning models and multi-agent workflow across constrained and open-ended prompting paradigms. The resulting protocols were validated in a digital-twin environment built in NVIDIA Omniverse to detect physical or sequencing errors before execution. Using Luna qPCR amplification and Cell Painting as case studies, we demonstrate PRISM as a practical end-to-end workflow that bridges language-based protocol generation, simulation-based validation, and automated robotic execution.", "AI": {"tldr": "PRISM\u6846\u67b6\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u81ea\u52a8\u8bbe\u8ba1\u3001\u9a8c\u8bc1\u548c\u6267\u884c\u5b9e\u9a8c\u534f\u8bae\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u5316\u5b9e\u9a8c\u5ba4\u5de5\u4f5c\u6d41", "motivation": "\u5b9e\u9a8c\u534f\u8bae\u8bbe\u8ba1\u548c\u6267\u884c\u81ea\u52a8\u5316\u662f\u5b9e\u73b0\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u7684\u5173\u952e\u74f6\u9888\uff0c\u9700\u8981\u89e3\u51b3\u534f\u8bae\u751f\u6210\u3001\u9a8c\u8bc1\u548c\u6267\u884c\u7684\u81ea\u52a8\u5316\u95ee\u9898", "method": "\u4f7f\u7528\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u89c4\u5212-\u6279\u5224-\u9a8c\u8bc1\u5faa\u73af\u4ece\u7f51\u7edc\u8d44\u6e90\u751f\u6210\u7ed3\u6784\u5316\u5b9e\u9a8c\u6b65\u9aa4\uff0c\u8f6c\u6362\u4e3a\u7edf\u4e00\u534f\u8bae\u683c\u5f0f\uff0c\u5e76\u5728\u6570\u5b57\u5b6a\u751f\u73af\u5883\u4e2d\u9a8c\u8bc1", "result": "\u6210\u529f\u5f00\u53d1\u4e86PRISM\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u52a8\u751f\u6210\u5b9e\u9a8c\u534f\u8bae\uff0c\u901a\u8fc7\u6570\u5b57\u5b6a\u751f\u9a8c\u8bc1\uff0c\u5e76\u5728\u5b9e\u9645\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u6267\u884c\uff08Opentrons OT-2\u3001PF400\u673a\u68b0\u81c2\u7b49\uff09", "conclusion": "PRISM\u4e3a\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u7aef\u5230\u7aef\u5de5\u4f5c\u6d41\uff0c\u8fde\u63a5\u4e86\u8bed\u8a00\u534f\u8bae\u751f\u6210\u3001\u6a21\u62df\u9a8c\u8bc1\u548c\u673a\u5668\u4eba\u6267\u884c\uff0c\u5c55\u793a\u4e86\u5728Luna qPCR\u548cCell Painting\u6848\u4f8b\u4e2d\u7684\u6709\u6548\u6027"}}
{"id": "2601.05842", "pdf": "https://arxiv.org/pdf/2601.05842", "abs": "https://arxiv.org/abs/2601.05842", "authors": ["Jonathan F. Kunst", "Killian A. C. Melsen", "Willem Kruijer", "Jos\u00e9 Crossa", "Chris Maliepaard", "Fred A. van Eeuwijk", "Carel F. W. Peeters"], "title": "A latent factor approach to hyperspectral time series data for multivariate genomic prediction of grain yield in wheat", "categories": ["stat.AP", "q-bio.QM", "stat.ME"], "comment": "20 pages, 8 figures", "summary": "High-dimensional time series phenotypic data is becoming increasingly common within plant breeding programmes. However, analysing and integrating such data for genetic analysis and genomic prediction remains difficult. Here we show how factor analysis with Procrustes rotation on the genetic correlation matrix of hyperspectral secondary phenotype data can help in extracting relevant features for within-trial prediction. We use a subset of Centro Internacional de Mejoramiento de Ma\u00edz y Trigo (CIMMYT) elite yield wheat trial of 2014-2015, consisting of 1,033 genotypes. These were measured across three irrigation treatments at several timepoints during the season, using manned airplane flights with hyperspectral sensors capturing 62 bands in the spectrum of 385-850 nm. We perform multivariate genomic prediction using latent variables to improve within-trial genomic predictive ability (PA) of wheat grain yield within three distinct watering treatments. By integrating latent variables of the hyperspectral data in a multivariate genomic prediction model, we are able to achieve an absolute gain of .1 to .3 (on the correlation scale) in PA compared to univariate genomic prediction. Furthermore, we show which timepoints within a trial are important and how these relate to plant growth stages. This paper showcases how domain knowledge and data-driven approaches can be combined to increase PA and gain new insights from sensor data of high-throughput phenotyping platforms.", "AI": {"tldr": "\u5229\u7528\u56e0\u5b50\u5206\u6790\u548cProcrustes\u65cb\u8f6c\u4ece\u9ad8\u5149\u8c31\u6570\u636e\u4e2d\u63d0\u53d6\u6f5c\u5728\u53d8\u91cf\uff0c\u901a\u8fc7\u591a\u53d8\u91cf\u57fa\u56e0\u7ec4\u9884\u6d4b\u63d0\u9ad8\u5c0f\u9ea6\u4ea7\u91cf\u9884\u6d4b\u7cbe\u5ea6", "motivation": "\u690d\u7269\u80b2\u79cd\u4e2d\u9ad8\u7ef4\u65f6\u95f4\u5e8f\u5217\u8868\u578b\u6570\u636e\u65e5\u76ca\u666e\u904d\uff0c\u4f46\u5206\u6790\u548c\u6574\u5408\u8fd9\u4e9b\u6570\u636e\u8fdb\u884c\u9057\u4f20\u5206\u6790\u548c\u57fa\u56e0\u7ec4\u9884\u6d4b\u4ecd\u7136\u56f0\u96be\u3002\u9700\u8981\u5f00\u53d1\u65b9\u6cd5\u4ece\u9ad8\u5149\u8c31\u6570\u636e\u4e2d\u63d0\u53d6\u76f8\u5173\u7279\u5f81\uff0c\u63d0\u9ad8\u57fa\u56e0\u7ec4\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u56e0\u5b50\u5206\u6790\u7ed3\u5408Procrustes\u65cb\u8f6c\u5bf9\u9ad8\u5149\u8c31\u6570\u636e\u7684\u9057\u4f20\u76f8\u5173\u77e9\u9635\u8fdb\u884c\u5904\u7406\uff0c\u63d0\u53d6\u6f5c\u5728\u53d8\u91cf\u3002\u5229\u7528CIMMYT 2014-2015\u5e741,033\u4e2a\u5c0f\u9ea6\u57fa\u56e0\u578b\u7684\u6570\u636e\uff0c\u5728\u4e09\u79cd\u704c\u6e89\u5904\u7406\u4e0b\u901a\u8fc7\u8f7d\u4eba\u98de\u673a\u642d\u8f7d\u9ad8\u5149\u8c31\u4f20\u611f\u5668\uff08385-850nm\uff0c62\u4e2a\u6ce2\u6bb5\uff09\u83b7\u53d6\u591a\u65f6\u95f4\u70b9\u6570\u636e\u3002\u91c7\u7528\u591a\u53d8\u91cf\u57fa\u56e0\u7ec4\u9884\u6d4b\u6a21\u578b\u6574\u5408\u9ad8\u5149\u8c31\u6570\u636e\u7684\u6f5c\u5728\u53d8\u91cf\u3002", "result": "\u901a\u8fc7\u6574\u5408\u9ad8\u5149\u8c31\u6570\u636e\u7684\u6f5c\u5728\u53d8\u91cf\uff0c\u5728\u76f8\u5173\u5c3a\u5ea6\u4e0a\u6bd4\u5355\u53d8\u91cf\u57fa\u56e0\u7ec4\u9884\u6d4b\u63d0\u9ad8\u4e860.1-0.3\u7684\u9884\u6d4b\u80fd\u529b\u3002\u786e\u5b9a\u4e86\u8bd5\u9a8c\u4e2d\u91cd\u8981\u7684\u65f6\u95f4\u70b9\u53ca\u5176\u4e0e\u690d\u7269\u751f\u957f\u9636\u6bb5\u7684\u5173\u7cfb\u3002", "conclusion": "\u5c55\u793a\u4e86\u5982\u4f55\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u548c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u63d0\u9ad8\u57fa\u56e0\u7ec4\u9884\u6d4b\u80fd\u529b\u5e76\u4ece\u9ad8\u901a\u91cf\u8868\u578b\u5e73\u53f0\u7684\u4f20\u611f\u5668\u6570\u636e\u4e2d\u83b7\u5f97\u65b0\u89c1\u89e3\u3002\u8be5\u65b9\u6cd5\u4e3a\u5904\u7406\u9ad8\u7ef4\u65f6\u95f4\u5e8f\u5217\u8868\u578b\u6570\u636e\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2601.05531", "pdf": "https://arxiv.org/pdf/2601.05531", "abs": "https://arxiv.org/abs/2601.05531", "authors": ["Eliatan Niktab", "Hardip Patel"], "title": "DNATokenizer: A GPU-First Byte-to-Identifier Tokenizer for High-Throughput DNA Language Models", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "Tokenization sits at the boundary between high-throughput genomic input and GPU compute, posing challenges in both algorithm design and system throughput. Overlapping k-mer tokenization can introduce information leakage under masked language modeling (MLM) and may degrade downstream accuracy. Single-nucleotide tokenization avoids leakage and preserves per-base fidelity, but it greatly increases sequence length for attention-based architectures. Non-overlapping k-mers and byte-pair encoding (BPE) provide compression and avoid leakage, at the cost of boundary sensitivity or reduced interpretability. Empirically, the choice of tokenization interacts strongly with model architecture and task requirements. At the system level, however, standard string tokenizers and host-bound vocabulary lookups dominate wall-clock time once inputs reach billions of bases, regardless of the tokenization algorithm. We present DNATok, a high-performance, GPU-first tokenization system that replaces general-purpose string processing with byte lookup table (LUT)-based identifier streaming and an overlapped host-to-device (H2D)/compute pipeline using pinned memory and architectural parallelism. DNATok is vocabulary-agnostic: it accelerates single-nucleotide, non-overlapping k-mer, and BPE tokenization, and integrates as a drop-in systems layer beneath genomic foundation models. DNATok achieves 84-95x higher encoding throughput than optimized Hugging Face baselines and up to 1.9x higher H2D throughput. End-to-end streaming reaches 1.27-1.84e8 tokens/s depending on configuration, effectively removing tokenization as a bottleneck for production-scale training and inference.", "AI": {"tldr": "DNATok\u662f\u4e00\u4e2a\u9ad8\u6027\u80fdGPU\u4f18\u5148\u7684\u57fa\u56e0\u7ec4\u6570\u636etokenization\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b57\u8282\u67e5\u627e\u8868\u548c\u6d41\u6c34\u7ebf\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u57fa\u56e0\u7ec4\u6a21\u578b\u8bad\u7ec3\u548c\u63a8\u7406\u7684tokenization\u541e\u5410\u91cf\u3002", "motivation": "\u57fa\u56e0\u7ec4\u6570\u636etokenization\u9762\u4e34\u7b97\u6cd5\u8bbe\u8ba1\uff08\u4fe1\u606f\u6cc4\u9732\u3001\u8fb9\u754c\u654f\u611f\uff09\u548c\u7cfb\u7edf\u6027\u80fd\uff08\u5b57\u7b26\u4e32\u5904\u7406\u3001\u4e3b\u673a\u7ed1\u5b9a\u8bcd\u6c47\u67e5\u627e\u6210\u4e3a\u74f6\u9888\uff09\u7684\u53cc\u91cd\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u6570\u5341\u4ebf\u78b1\u57fa\u89c4\u6a21\u65f6\u3002", "method": "DNATok\u91c7\u7528GPU\u4f18\u5148\u8bbe\u8ba1\uff1a1) \u7528\u5b57\u8282\u67e5\u627e\u8868\u66ff\u4ee3\u901a\u7528\u5b57\u7b26\u4e32\u5904\u7406\uff1b2) \u4f7f\u7528\u56fa\u5b9a\u5185\u5b58\u548c\u67b6\u6784\u5e76\u884c\u5b9e\u73b0\u4e3b\u673a\u5230\u8bbe\u5907\u7684\u6d41\u6c34\u7ebf\u91cd\u53e0\uff1b3) \u652f\u6301\u5355\u6838\u82f7\u9178\u3001\u975e\u91cd\u53e0k-mer\u548cBPE\u7b49\u591a\u79cdtokenization\u65b9\u6cd5\u3002", "result": "DNATok\u6bd4\u4f18\u5316\u7684Hugging Face\u57fa\u7ebf\u5b9e\u73b084-95\u500d\u7f16\u7801\u541e\u5410\u91cf\u63d0\u5347\uff0c\u4e3b\u673a\u5230\u8bbe\u5907\u541e\u5410\u91cf\u63d0\u53471.9\u500d\uff0c\u7aef\u5230\u7aef\u6d41\u5904\u7406\u8fbe\u52301.27-1.84e8 tokens/s\uff0c\u6d88\u9664\u4e86tokenization\u74f6\u9888\u3002", "conclusion": "DNATok\u4f5c\u4e3a\u4e00\u4e2a\u8bcd\u6c47\u65e0\u5173\u7684\u9ad8\u6027\u80fdtokenization\u7cfb\u7edf\u5c42\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u57fa\u56e0\u7ec4\u57fa\u7840\u6a21\u578b\u5728\u5927\u89c4\u6a21\u8bad\u7ec3\u548c\u63a8\u7406\u4e2d\u7684tokenization\u6027\u80fd\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2601.05923", "pdf": "https://arxiv.org/pdf/2601.05923", "abs": "https://arxiv.org/abs/2601.05923", "authors": ["E. Middell", "L. Carlton", "S. Moradi", "T. Codina", "T. Fischer", "J. Cutler", "S. Kelley", "J. Behrendt", "T. Dissanayake", "N. Harmening", "M. A. Y\u00fccel", "D. A. Boas", "A. von L\u00fchmann"], "title": "Cedalion Tutorial: A Python-based framework for comprehensive analysis of multimodal fNIRS & DOT from the lab to the everyday world", "categories": ["eess.SP", "cs.AI", "cs.LG", "eess.IV", "q-bio.QM"], "comment": "33 pages main manuscript, 180 pages Supplementary Tutorial Notebooks, 12 figures, 6 tables, under review in SPIE Neurophotonics", "summary": "Functional near-infrared spectroscopy (fNIRS) and diffuse optical tomography (DOT) are rapidly evolving toward wearable, multimodal, and data-driven, AI-supported neuroimaging in the everyday world. However, current analytical tools are fragmented across platforms, limiting reproducibility, interoperability, and integration with modern machine learning (ML) workflows. Cedalion is a Python-based open-source framework designed to unify advanced model-based and data-driven analysis of multimodal fNIRS and DOT data within a reproducible, extensible, and community-driven environment. Cedalion integrates forward modelling, photogrammetric optode co-registration, signal processing, GLM Analysis, DOT image reconstruction, and ML-based data-driven methods within a single standardized architecture based on the Python ecosystem. It adheres to SNIRF and BIDS standards, supports cloud-executable Jupyter notebooks, and provides containerized workflows for scalable, fully reproducible analysis pipelines that can be provided alongside original research publications. Cedalion connects established optical-neuroimaging pipelines with ML frameworks such as scikit-learn and PyTorch, enabling seamless multimodal fusion with EEG, MEG, and physiological data. It implements validated algorithms for signal-quality assessment, motion correction, GLM modelling, and DOT reconstruction, complemented by modules for simulation, data augmentation, and multimodal physiology analysis. Automated documentation links each method to its source publication, and continuous-integration testing ensures robustness. This tutorial paper provides seven fully executable notebooks that demonstrate core features. Cedalion offers an open, transparent, and community extensible foundation that supports reproducible, scalable, cloud- and ML-ready fNIRS/DOT workflows for laboratory-based and real-world neuroimaging.", "AI": {"tldr": "Cedalion\u662f\u4e00\u4e2a\u57fa\u4e8ePython\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u7528\u4e8e\u7edf\u4e00fNIRS\u548cDOT\u6570\u636e\u7684\u6a21\u578b\u9a71\u52a8\u4e0e\u6570\u636e\u9a71\u52a8\u5206\u6790\uff0c\u652f\u6301\u53ef\u91cd\u590d\u3001\u53ef\u6269\u5c55\u7684\u795e\u7ecf\u5f71\u50cf\u5de5\u4f5c\u6d41\u3002", "motivation": "\u5f53\u524dfNIRS\u548cDOT\u5206\u6790\u5de5\u5177\u5206\u6563\u5728\u4e0d\u540c\u5e73\u53f0\uff0c\u9650\u5236\u4e86\u53ef\u91cd\u590d\u6027\u3001\u4e92\u64cd\u4f5c\u6027\u548c\u4e0e\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u7684\u96c6\u6210\uff0c\u9700\u8981\u7edf\u4e00\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u57fa\u4e8ePython\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u6574\u5408\u524d\u5411\u5efa\u6a21\u3001\u5149\u6781\u914d\u51c6\u3001\u4fe1\u53f7\u5904\u7406\u3001GLM\u5206\u6790\u3001DOT\u56fe\u50cf\u91cd\u5efa\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u9075\u5faaSNIRF\u548cBIDS\u6807\u51c6\uff0c\u652f\u6301\u5bb9\u5668\u5316\u5de5\u4f5c\u6d41\u3002", "result": "\u521b\u5efa\u4e86Cedalion\u6846\u67b6\uff0c\u63d0\u4f9b\u4e03\u4e2a\u53ef\u6267\u884c\u7b14\u8bb0\u672c\u6f14\u793a\u6838\u5fc3\u529f\u80fd\uff0c\u5b9e\u73b0\u53ef\u91cd\u590d\u3001\u53ef\u6269\u5c55\u3001\u4e91\u5c31\u7eea\u7684fNIRS/DOT\u5206\u6790\u5de5\u4f5c\u6d41\uff0c\u652f\u6301\u4e0eEEG\u3001MEG\u7b49\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u3002", "conclusion": "Cedalion\u4e3a\u5b9e\u9a8c\u5ba4\u548c\u771f\u5b9e\u4e16\u754c\u795e\u7ecf\u5f71\u50cf\u63d0\u4f9b\u4e86\u5f00\u653e\u3001\u900f\u660e\u3001\u793e\u533a\u53ef\u6269\u5c55\u7684\u57fa\u7840\uff0c\u652f\u6301\u53ef\u91cd\u590d\u3001\u53ef\u6269\u5c55\u3001\u4e91\u548c\u673a\u5668\u5b66\u4e60\u5c31\u7eea\u7684fNIRS/DOT\u5de5\u4f5c\u6d41\u3002"}}
{"id": "2601.05648", "pdf": "https://arxiv.org/pdf/2601.05648", "abs": "https://arxiv.org/abs/2601.05648", "authors": ["Haoran Wang", "Xuanyi Zhang", "Shuangsang Fang", "Longke Ran", "Ziqing Deng", "Yong Zhang", "Yuxiang Li", "Shaoshuai Li"], "title": "Open World Knowledge Aided Single-Cell Foundation Model with Robust Cross-Modal Cell-Language Pre-training", "categories": ["q-bio.GN", "cs.AI", "cs.CL", "cs.LG"], "comment": "41 pages", "summary": "Recent advancements in single-cell multi-omics, particularly RNA-seq, have provided profound insights into cellular heterogeneity and gene regulation. While pre-trained language model (PLM) paradigm based single-cell foundation models have shown promise, they remain constrained by insufficient integration of in-depth individual profiles and neglecting the influence of noise within multi-modal data. To address both issues, we propose an Open-world Language Knowledge-Aided Robust Single-Cell Foundation Model (OKR-CELL). It is built based on a cross-modal Cell-Language pre-training framework, which comprises two key innovations: (1) leveraging Large Language Models (LLMs) based workflow with retrieval-augmented generation (RAG) enriches cell textual descriptions using open-world knowledge; (2) devising a Cross-modal Robust Alignment (CRA) objective that incorporates sample reliability assessment, curriculum learning, and coupled momentum contrastive learning to strengthen the model's resistance to noisy data. After pretraining on 32M cell-text pairs, OKR-CELL obtains cutting-edge results across 6 evaluation tasks. Beyond standard benchmarks such as cell clustering, cell-type annotation, batch-effect correction, and few-shot annotation, the model also demonstrates superior performance in broader multi-modal applications, including zero-shot cell-type annotation and bidirectional cell-text retrieval.", "AI": {"tldr": "OKR-CELL\u662f\u4e00\u4e2a\u5f00\u653e\u4e16\u754c\u8bed\u8a00\u77e5\u8bc6\u589e\u5f3a\u7684\u9c81\u68d2\u5355\u7ec6\u80de\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u7ec6\u80de-\u8bed\u8a00\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u5229\u7528LLM\u548cRAG\u4e30\u5bcc\u7ec6\u80de\u6587\u672c\u63cf\u8ff0\uff0c\u5e76\u8bbe\u8ba1\u8de8\u6a21\u6001\u9c81\u68d2\u5bf9\u9f50\u76ee\u6807\u6765\u589e\u5f3a\u5bf9\u566a\u58f0\u6570\u636e\u7684\u62b5\u6297\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5355\u7ec6\u80de\u57fa\u7840\u6a21\u578b\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u9650\u5236\uff1a1) \u5bf9\u4e2a\u4f53\u6df1\u5ea6\u7279\u5f81\u7684\u6574\u5408\u4e0d\u8db3\uff1b2) \u5ffd\u89c6\u591a\u6a21\u6001\u6570\u636e\u4e2d\u7684\u566a\u58f0\u5f71\u54cd\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u66f4\u597d\u6574\u5408\u5f00\u653e\u4e16\u754c\u77e5\u8bc6\u5e76\u62b5\u6297\u6570\u636e\u566a\u58f0\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51faOKR-CELL\u6a21\u578b\uff0c\u57fa\u4e8e\u8de8\u6a21\u6001\u7ec6\u80de-\u8bed\u8a00\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u521b\u65b0\uff1a1) \u5229\u7528\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u4f7f\u7528\u5f00\u653e\u4e16\u754c\u77e5\u8bc6\u4e30\u5bcc\u7ec6\u80de\u6587\u672c\u63cf\u8ff0\uff1b2) \u8bbe\u8ba1\u8de8\u6a21\u6001\u9c81\u68d2\u5bf9\u9f50\u76ee\u6807\uff0c\u7ed3\u5408\u6837\u672c\u53ef\u9760\u6027\u8bc4\u4f30\u3001\u8bfe\u7a0b\u5b66\u4e60\u548c\u8026\u5408\u52a8\u91cf\u5bf9\u6bd4\u5b66\u4e60\u6765\u589e\u5f3a\u6a21\u578b\u5bf9\u566a\u58f0\u6570\u636e\u7684\u62b5\u6297\u80fd\u529b\u3002", "result": "\u57283200\u4e07\u7ec6\u80de-\u6587\u672c\u5bf9\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\u540e\uff0cOKR-CELL\u57286\u4e2a\u8bc4\u4f30\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002\u9664\u4e86\u7ec6\u80de\u805a\u7c7b\u3001\u7ec6\u80de\u7c7b\u578b\u6ce8\u91ca\u3001\u6279\u6b21\u6548\u5e94\u6821\u6b63\u548c\u5c11\u6837\u672c\u6ce8\u91ca\u7b49\u6807\u51c6\u57fa\u51c6\u5916\uff0c\u6a21\u578b\u5728\u66f4\u5e7f\u6cdb\u7684\u591a\u6a21\u6001\u5e94\u7528\u4e2d\u4e5f\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u5305\u62ec\u96f6\u6837\u672c\u7ec6\u80de\u7c7b\u578b\u6ce8\u91ca\u548c\u53cc\u5411\u7ec6\u80de-\u6587\u672c\u68c0\u7d22\u3002", "conclusion": "OKR-CELL\u901a\u8fc7\u6574\u5408\u5f00\u653e\u4e16\u754c\u77e5\u8bc6\u548c\u589e\u5f3a\u5bf9\u566a\u58f0\u7684\u9c81\u68d2\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5355\u7ec6\u80de\u57fa\u7840\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4e3a\u5355\u7ec6\u80de\u591a\u7ec4\u5b66\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u591a\u6a21\u6001\u5e94\u7528\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
