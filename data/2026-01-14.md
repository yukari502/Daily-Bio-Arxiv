<div id=toc></div>

# Table of Contents

- [q-bio.QM](#q-bio.QM) [Total: 6]
- [cs.CV](#cs.CV) [Total: 1]


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [1] [From local defects to shear-organized biofilms in tonsillar crypts via computational simulations](https://arxiv.org/abs/2601.07863)
*Arturo Tozzi*

Main category: q-bio.QM

TL;DR: 提出一个生物物理框架，将扁桃体隐窝生物膜动力学解释为两种机械现象相互作用的结果：Kosterlitz-Thouless型缺陷成核过程和Kelvin-Helmholtz型剪切驱动界面不稳定性。


<details>
  <summary>Details</summary>
Motivation: 人类扁桃体隐窝中的生物膜表现出长期持续性和间歇性分散，现有的生化和微生物学描述无法完全解释这种现象，特别是在空间定位方面。

Method: 将隐窝几何结构建模为受限、异质环境，促进由生长诱导压缩产生的机械持久表面缺陷。引入包含缺陷成核和剪切驱动界面不稳定性的生物物理框架，并进行数值模拟。

Result: 数值模拟显示，只有当两种机制共存时才能产生局部化、传播和持久的界面结构，而缺乏这些机制则导致扩散、非结构化的动力学。

Conclusion: 扁桃体生物膜动力学可以通过机械缺陷成核和剪切驱动界面不稳定性的相互作用来解释，这为理解生物膜的空间定位和持久性提供了新的生物物理视角。

Abstract: Biofilms in human tonsillar crypts show long term persistence with episodic dispersal that current biochemical and microbiological descriptions do not fully explain, particularly with respect to spatial localization. We introduce a biophysical framework in which tonsillar biofilm dynamics arise from the interaction between two mechanical phenomena: a Kosterlitz Thouless type defect nucleation process and a Kelvin Helmholtz type shear driven interfacial instability. Crypt geometry is modeled as a confined, heterogeneous environment that promotes mechanically persistent surface defects generated by growth induced compression. Tangential shear associated with breathing and swallowing selectively amplifies these defects, producing organized surface deformations. Numerical simulations show that only the coexistence of both mechanisms yields localized, propagating, and persistent interface structures, whereas their absence leads to diffuse, unstructured dynamics.

</details>


### [2] [Imaging-anchored Multiomics in Cardiovascular Disease: Integrating Cardiac Imaging, Bulk, Single-cell, and Spatial Transcriptomics](https://arxiv.org/abs/2601.07871)
*Minh H. N. Le,Tuan Vinh,Thanh-Huy Nguyen,Tao Li,Bao Quang Gia Le,Han H. Huynh,Monika Raj,Carl Yang,Min Xu,Nguyen Quoc Khanh Le*

Main category: q-bio.QM

TL;DR: 这篇综述探讨了将心脏成像表型与转录组学和空间分子状态联系起来的联合表征方法，旨在整合心脏MRI、CT、超声心动图与转录组学数据，推动心血管疾病的多组学研究。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病源于遗传风险、分子程序和临床影像观察到的组织重塑之间的相互作用。目前医疗系统虽然生成了大量心脏影像和转录组学数据，但这些数据仍在分离的流程中分析，缺乏整合。

Method: 采用影像锚定的视角：心脏影像定义空间表型，转录组学提供细胞类型和位置特异的分子背景。综述了各模态的生物学和技术特征、表征学习策略，以及处理缺失数据、样本量有限和批次效应的多模态融合方法。

Result: 讨论了放射基因组学、空间分子对齐和基于影像的基因表达预测的整合流程，分析了常见失败模式、实际考虑因素和开放挑战。指出空间多组学、单细胞/空间基础模型和多模态医学基础模型正在推动影像锚定多组学向大规模心血管转化迈进。

Conclusion: 整合心脏成像与分子数据的联合表征方法正在快速发展，为理解心血管疾病机制和开发精准医疗方法提供了新途径，但仍面临技术挑战和实际应用障碍。

Abstract: Cardiovascular disease arises from interactions between inherited risk, molecular programmes, and tissue-scale remodelling that are observed clinically through imaging. Health systems now routinely generate large volumes of cardiac MRI, CT and echocardiography together with bulk, single-cell and spatial transcriptomics, yet these data are still analysed in separate pipelines. This review examines joint representations that link cardiac imaging phenotypes to transcriptomic and spatially resolved molecular states. An imaging-anchored perspective is adopted in which echocardiography, cardiac MRI and CT define a spatial phenotype of the heart, and bulk, single-cell and spatial transcriptomics provide cell-type- and location-specific molecular context. The biological and technical characteristics of these modalities are first summarised, and representation-learning strategies for each are outlined. Multimodal fusion approaches are reviewed, with emphasis on handling missing data, limited sample size, and batch effects. Finally, integrative pipelines for radiogenomics, spatial molecular alignment, and image-based prediction of gene expression are discussed, together with common failure modes, practical considerations, and open challenges. Spatial multiomics of human myocardium and atherosclerotic plaque, single-cell and spatial foundation models, and multimodal medical foundation models are collectively bringing imaging-anchored multiomics closer to large-scale cardiovascular translation.

</details>


### [3] [Network Pharmacology Framework Characterizes Polypharmacological Properties of Dietary Flavonoids: Integration of Computational, Experimental, and Epidemiological Evidence](https://arxiv.org/abs/2601.08147)
*Koyo Fujisaki,Osei Horikoshi,Yukitoshi Nagahara,Kengo Morohashi*

Main category: q-bio.QM

TL;DR: 该研究运用网络药理学系统分析14种膳食黄酮类化合物的多靶点作用机制，发现黄酮类化合物平均靶点数量是FDA批准药物的2.7倍，预测并实验验证了黄酮类化合物的抗癌活性，将网络关联转化为506种食物的685种食物-药物治疗组合预测。


<details>
  <summary>Details</summary>
Motivation: 流行病学研究显示膳食黄酮类化合物与疾病预防相关，但其多药理学机制尚不清楚。需要建立系统框架来表征黄酮类化合物的治疗特性，弥合营养科学与系统药理学之间的鸿沟。

Method: 采用网络药理学方法，构建包含17,869个人类蛋白质、14种膳食黄酮类化合物和1,496种FDA批准药物的主网络（278,768个相互作用）。通过统计分析、MTT法Jurkat细胞实验验证网络预测，并将网络关联转化为食物水平的预测。

Result: 黄酮类化合物平均每个化合物靶向45.3个蛋白质，是FDA批准药物（16.8个）的2.7倍。71.4%的黄酮类化合物靶向心血管药物相关蛋白质，78.6%与抗肿瘤药物靶点一致。实验验证显示高关联黄酮类化合物（木犀草素LC50=31.4μM，杨梅素=29.5μM）具有强细胞毒性。网络预测关联强度与实验生物活性高度相关（Pearson r=0.918）。识别出506种食物的685种食物-药物治疗组合，文献验证支持96个关联。

Conclusion: 网络药理学能够系统表征膳食多药理学特性，生成基于证据的食物-治疗预测，为营养科学与系统药理学搭建桥梁，为膳食干预提供科学依据。

Abstract: Dietary flavonoids associate with disease prevention in epidemiological studies, yet their polypharmacological mechanisms remain unclear. We establish network pharmacology as a systematic framework to characterize flavonoid therapeutic properties through integrated computational, experimental, and epidemiological validation. We constructed a master network of 17,869 human proteins, 14 dietary flavonoids, and 1,496 FDA-approved drugs with 278,768 interactions. Flavonoids averaged 45.3 target proteins per compound compared to 16.8 for FDA-approved drugs (2.7-fold higher; p=7.5x10^-4), reflecting multi-target architecture. Statistical analysis revealed that 71.4% of flavonoids targeted proteins associated with cardiovascular drugs and 78.6% aligned with antineoplastic drug targets. MTT-based Jurkat cell assays confirmed network predictions: high-association flavonoids (luteolin LC50=31.4 microM, myricetin=29.5 microM) produced strong cytotoxicity, while low-association flavonoids showed minimal activity (LC50>200 microM). Network-predicted association strengths correlated with experimental bioactivity (Pearson r=0.918; R^2=0.843). We translated network associations into food-level predictions across 506 foods, identifying 685 food-drug therapeutic combinations. Systematic literature searches confirmed 96 associations supported by 132 unique references. Cardiovascular domains achieved 47.1% validation. Top-validated foods included tea (31 evidence items), blueberries (18 items), tomato (13 items), grape juice (10 items), and plum (9 items). Network pharmacology characterizes dietary polypharmacological properties and generates evidence-based food-therapeutic predictions, bridging nutritional science and systems pharmacology.

</details>


### [4] [An open-source computational framework for immersed fluid-structure interaction modeling using FEBio and MFEM](https://arxiv.org/abs/2601.08266)
*Ryan T. Black,Steve A. Maas,Wensi Wu,Jalaj Maheshwari,Tzanio Kolev,Jeffrey A. Weiss,Matthew A. Jolley*

Main category: q-bio.QM

TL;DR: 提出开源浸入式流固耦合框架，结合MFEM和FEBio库，用于生物系统仿真，特别针对心脏瓣膜等大变形接触问题


<details>
  <summary>Details</summary>
Motivation: 生物系统的流固耦合仿真面临计算挑战，特别是心脏瓣膜等大变形接触问题。传统ALE方法因网格畸变而困难，需要浸入式技术

Method: 耦合两个成熟的有限元库：MFEM（GPU就绪、可扩展）和FEBio（非线性有限元、生物力学专用）。采用虚构域方法，变分多尺度稳定化，全隐式单块方案

Result: 开发了开源浸入式流固耦合框架，通过多个测试问题验证，包括3D半月瓣心脏瓣膜仿真，展示了框架能力

Conclusion: 该平台满足了将先进生物力学建模与高性能计算基础设施结合的开源浸入式流固耦合软件的关键需求

Abstract: Fluid-structure interaction (FSI) simulation of biological systems presents significant computational challenges, particularly for applications involving large structural deformations and contact mechanics, such as heart valve dynamics. Traditional ALE methods encounter fundamental difficulties with such problems due to mesh distortion, motivating immersed techniques. This work presents a novel open-source immersed FSI framework that strategically couples two mature finite element libraries: MFEM, a GPU-ready and scalable library with state-of-the-art parallel performance developed at Lawrence Livermore National Laboratory, and FEBio, a nonlinear finite element solver with sophisticated solid mechanics capabilities designed for biomechanics applications developed at the University of Utah. This coupling creates a unique synergy wherein the fluid solver leverages MFEM's distributed-memory parallelization and pathway to GPU acceleration, while the immersed solid exploits FEBio's comprehensive suite of hyperelastic and viscoelastic constitutive models and advanced solid mechanics modeling targeted for biomechanics applications. FSI coupling is achieved using a fictitious domain methodology with variational multiscale stabilization for enhanced accuracy on under-resolved grids expected with unfitted meshes used in immersed FSI. A fully implicit, monolithic scheme provides robust coupling for strongly coupled FSI characteristic of cardiovascular applications. The framework's modular architecture facilitates straightforward extension to additional physics and element technologies. Several test problems are considered to demonstrate the capabilities of the proposed framework, including a 3D semilunar heart valve simulation. This platform addresses a critical need for open-source immersed FSI software combining advanced biomechanics modeling with high-performance computing infrastructure.

</details>


### [5] [Disentangling History and Propagation Dependencies in Cross-Subject Knee Contact Stress Prediction Using a Shared MeshGraphNet Backbone](https://arxiv.org/abs/2601.08318)
*Zhengye Pan,Jianwei Zuo,Jiajia Luo*

Main category: q-bio.QM

TL;DR: 该研究通过对比四种图神经网络变体，发现时间历史依赖是跨受试者膝关节接触力学预测不确定性的主要来源，而空间传播调制单独使用无显著改善。


<details>
  <summary>Details</summary>
Motivation: 针对膝关节有限元分析计算成本高的问题，深度学习代理模型提供了快速替代方案，但现有模型在有限姿态和载荷输入下跨受试者的泛化能力不明确，且不确定预测误差主要来自时间历史依赖还是空间传播依赖。

Method: 使用共享MGN骨干网络和固定网格拓扑，构建了9名受试者跑步试验数据集。开发了四种模型变体：基线MGN、加入Control Transformer编码短期历史的CT-MGN、应用状态条件调制进行自适应传播的MsgModMGN、以及结合两者的CT-MsgModMGN。采用严格的分组3折交叉验证评估模型。

Result: 包含历史编码的模型在全局精度和空间一致性上显著优于基线MGN和MsgModMGN。CT模块有效缓解了深度代理模型中常见的峰值削平缺陷，显著降低了峰值应力预测误差。而空间传播调制单独使用无显著改善，与CT结合也无额外收益。

Conclusion: 时间历史依赖而非空间传播调制是跨受试者膝关节接触力学预测不确定性的主要驱动因素。显式编码短期驱动序列使代理模型能够恢复隐含的相位信息，从而在峰值应力捕获和高风险定位方面优于纯状态基方法。

Abstract: Background:Subject-specific finite element analysis accurately characterizes knee joint mechanics but is computationally expensive. Deep surrogate models provide a rapid alternative, yet their generalization across subjects under limited pose and load inputs remains unclear. It remains unclear whether the dominant source of prediction uncertainty arises from temporal history dependence or spatial propagation dependence. Methods:To disentangle these factors, we employed a shared MGN backbone with a fixed mesh topology. A dataset of running trials from nine subjects was constructed using an OpenSim-FEBio workflow. We developed four model variants to isolate specific dependencies: (1) a baseline MGN; (2) CT-MGN, incorporating a Control Transformer to encode short-horizon history; (3) MsgModMGN, applying state-conditioned modulation to message passing for adaptive propagation; (4) CT-MsgModMGN, combining both mechanisms. Models were evaluated using a rigorous grouped 3-fold cross-validation on unseen subjects.Results:The models incorporating history encoding significantly outperformed the baseline MGN and MsgModMGN in global accuracy and spatial consistency. Crucially, the CT module effectively mitigated the peak-shaving defect common in deep surrogates, significantly reducing peak stress prediction errors. In contrast, the spatial propagation modulation alone yielded no significant improvement over the baseline, and combining it with CT provided no additional benefit.Conclusion:Temporal history dependence, rather than spatial propagation modulation, is the primary driver of prediction uncertainty in cross-subject knee contact mechanics. Explicitly encoding short-horizon driver sequences enables the surrogate model to recover implicit phase information, thereby achieving superior fidelity in peak-stress capture and high-risk localization compared to purely state-based approaches.

</details>


### [6] [Automated Lesion Segmentation of Stroke MRI Using nnU-Net: A Comprehensive External Validation Across Acute and Chronic Lesions](https://arxiv.org/abs/2601.08701)
*Tammar Truzman,Matthew A. Lambon Ralph,Ajay D. Halai*

Main category: q-bio.QM

TL;DR: nnU-Net框架在多个公开MRI数据集上评估卒中病灶分割，发现模型在不同卒中阶段、模态和数据集间具有鲁棒泛化能力，性能接近人工标注者间一致性


<details>
  <summary>Details</summary>
Motivation: 现有深度学习卒中病灶分割模型通常在特定成像条件下优化，对独立数据集、模态和卒中阶段的泛化能力较差，需要系统评估自动分割的泛化性能

Method: 使用nnU-Net框架在多个公开MRI数据集上训练和测试卒中病灶分割模型，涵盖急性期和慢性期卒中，评估DWI、FLAIR和T1加权MRI模态，并在独立数据集上验证泛化能力

Result: 模型在不同卒中阶段表现出鲁棒泛化，分割准确度接近人工标注者间一致性；急性期DWI模型优于FLAIR模型，多模态组合增益有限；慢性期增加训练集规模可提升性能，但超过数百例后收益递减；病灶体积是准确度的关键因素，小病灶更难分割；MRI图像质量影响泛化能力

Conclusion: 自动病灶分割可接近人工水平性能，同时识别了影响泛化能力的关键因素，为开发卒中病灶分割工具提供了重要指导

Abstract: Accurate and generalisable segmentation of stroke lesions from magnetic resonance imaging (MRI) is essential for advancing clinical research, prognostic modelling, and personalised interventions. Although deep learning has improved automated lesion delineation, many existing models are optimised for narrow imaging contexts and generalise poorly to independent datasets, modalities, and stroke stages. Here, we systematically evaluated stroke lesion segmentation using the nnU-Net framework across multiple heterogeneous, publicly available MRI datasets spanning acute and chronic stroke. Models were trained and tested on diffusion-weighted imaging (DWI), fluid-attenuated inversion recovery (FLAIR), and T1-weighted MRI, and evaluated on independent datasets. Across stroke stages, models showed robust generalisation, with segmentation accuracy approaching reported inter-rater reliability. Performance varied with imaging modality and training data characteristics. In acute stroke, DWI-trained models consistently outperformed FLAIR-based models, with only modest gains from multimodal combinations. In chronic stroke, increasing training set size improved performance, with diminishing returns beyond several hundred cases. Lesion volume was a key determinant of accuracy: smaller lesions were harder to segment, and models trained on restricted volume ranges generalised poorly. MRI image quality further constrained generalisability: models trained on lower-quality scans transferred poorly, whereas those trained on higher-quality data generalised well to noisier images. Discrepancies between predictions and reference masks were often attributable to limitations in manual annotations. Together, these findings show that automated lesion segmentation can approach human-level performance while identifying key factors governing generalisability and informing the development of lesion segmentation tools.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [7] [Near-perfect photo-ID of the Hula painted frog with zero-shot deep local-feature matching](https://arxiv.org/abs/2601.08798)
*Maayan Yesharim,R. G. Bina Perl,Uri Roll,Sarig Gafny,Eli Geffen,Yoav Ram*

Main category: cs.CV

TL;DR: 本文评估了计算机视觉方法在濒危两栖动物Hula painted frog照片重识别中的应用，发现零样本深度局部特征匹配优于全局特征嵌入，并提出两阶段工作流程实现高效准确的个体识别。


<details>
  <summary>Details</summary>
Motivation: 对于濒危两栖动物的监测，准确的个体识别至关重要，但侵入性标记方法通常不适用于极度濒危物种。需要开发非侵入性的照片重识别方法来支持保护监测和捕获-重捕获分析。

Method: 使用191只个体的1,233张腹面图像，比较零样本深度局部特征匹配与深度全局特征嵌入模型。开发两阶段工作流程：先用微调的全局特征模型检索候选列表，再用局部特征匹配重新排序，实现高效准确的识别。

Result: 局部特征管道达到98%的top-1闭集识别准确率，优于所有全局特征模型。两阶段工作流程将端到端运行时间从6.5-7.8小时减少到约38分钟，同时保持约96%的top-1闭集准确率。开发了用于常规野外使用的网络应用程序。

Conclusion: 对于该物种，零样本深度局部特征匹配优于全局特征嵌入，为照片重识别提供了强大的默认方法。两阶段工作流程结合了可扩展性和准确性，支持开放集识别，为非侵入性保护监测提供了实用解决方案。

Abstract: Accurate individual identification is essential for monitoring rare amphibians, yet invasive marking is often unsuitable for critically endangered species. We evaluate state-of-the-art computer-vision methods for photographic re-identification of the Hula painted frog (Latonia nigriventer) using 1,233 ventral images from 191 individuals collected during 2013-2020 capture-recapture surveys. We compare deep local-feature matching in a zero-shot setting with deep global-feature embedding models. The local-feature pipeline achieves 98% top-1 closed-set identification accuracy, outperforming all global-feature models; fine-tuning improves the best global-feature model to 60% top-1 (91% top-10) but remains below local matching. To combine scalability with accuracy, we implement a two-stage workflow in which a fine-tuned global-feature model retrieves a short candidate list that is re-ranked by local-feature matching, reducing end-to-end runtime from 6.5-7.8 hours to ~38 minutes while maintaining ~96% top-1 closed-set accuracy on the labeled dataset. Separation of match scores between same- and different-individual pairs supports thresholding for open-set identification, enabling practical handling of novel individuals. We deploy this pipeline as a web application for routine field use, providing rapid, standardized, non-invasive identification to support conservation monitoring and capture-recapture analyses. Overall, in this species, zero-shot deep local-feature matching outperformed global-feature embedding and provides a strong default for photo-identification.

</details>
