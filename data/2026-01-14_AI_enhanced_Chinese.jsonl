{"id": "2601.07863", "pdf": "https://arxiv.org/pdf/2601.07863", "abs": "https://arxiv.org/abs/2601.07863", "authors": ["Arturo Tozzi"], "title": "From local defects to shear-organized biofilms in tonsillar crypts via computational simulations", "categories": ["q-bio.QM"], "comment": "11 pates, 5 figures, 1 table", "summary": "Biofilms in human tonsillar crypts show long term persistence with episodic dispersal that current biochemical and microbiological descriptions do not fully explain, particularly with respect to spatial localization. We introduce a biophysical framework in which tonsillar biofilm dynamics arise from the interaction between two mechanical phenomena: a Kosterlitz Thouless type defect nucleation process and a Kelvin Helmholtz type shear driven interfacial instability. Crypt geometry is modeled as a confined, heterogeneous environment that promotes mechanically persistent surface defects generated by growth induced compression. Tangential shear associated with breathing and swallowing selectively amplifies these defects, producing organized surface deformations. Numerical simulations show that only the coexistence of both mechanisms yields localized, propagating, and persistent interface structures, whereas their absence leads to diffuse, unstructured dynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u751f\u7269\u7269\u7406\u6846\u67b6\uff0c\u5c06\u6241\u6843\u4f53\u9690\u7a9d\u751f\u7269\u819c\u52a8\u529b\u5b66\u89e3\u91ca\u4e3a\u4e24\u79cd\u673a\u68b0\u73b0\u8c61\u76f8\u4e92\u4f5c\u7528\u7684\u7ed3\u679c\uff1aKosterlitz-Thouless\u578b\u7f3a\u9677\u6210\u6838\u8fc7\u7a0b\u548cKelvin-Helmholtz\u578b\u526a\u5207\u9a71\u52a8\u754c\u9762\u4e0d\u7a33\u5b9a\u6027\u3002", "motivation": "\u4eba\u7c7b\u6241\u6843\u4f53\u9690\u7a9d\u4e2d\u7684\u751f\u7269\u819c\u8868\u73b0\u51fa\u957f\u671f\u6301\u7eed\u6027\u548c\u95f4\u6b47\u6027\u5206\u6563\uff0c\u73b0\u6709\u7684\u751f\u5316\u548c\u5fae\u751f\u7269\u5b66\u63cf\u8ff0\u65e0\u6cd5\u5b8c\u5168\u89e3\u91ca\u8fd9\u79cd\u73b0\u8c61\uff0c\u7279\u522b\u662f\u5728\u7a7a\u95f4\u5b9a\u4f4d\u65b9\u9762\u3002", "method": "\u5c06\u9690\u7a9d\u51e0\u4f55\u7ed3\u6784\u5efa\u6a21\u4e3a\u53d7\u9650\u3001\u5f02\u8d28\u73af\u5883\uff0c\u4fc3\u8fdb\u7531\u751f\u957f\u8bf1\u5bfc\u538b\u7f29\u4ea7\u751f\u7684\u673a\u68b0\u6301\u4e45\u8868\u9762\u7f3a\u9677\u3002\u5f15\u5165\u5305\u542b\u7f3a\u9677\u6210\u6838\u548c\u526a\u5207\u9a71\u52a8\u754c\u9762\u4e0d\u7a33\u5b9a\u6027\u7684\u751f\u7269\u7269\u7406\u6846\u67b6\uff0c\u5e76\u8fdb\u884c\u6570\u503c\u6a21\u62df\u3002", "result": "\u6570\u503c\u6a21\u62df\u663e\u793a\uff0c\u53ea\u6709\u5f53\u4e24\u79cd\u673a\u5236\u5171\u5b58\u65f6\u624d\u80fd\u4ea7\u751f\u5c40\u90e8\u5316\u3001\u4f20\u64ad\u548c\u6301\u4e45\u7684\u754c\u9762\u7ed3\u6784\uff0c\u800c\u7f3a\u4e4f\u8fd9\u4e9b\u673a\u5236\u5219\u5bfc\u81f4\u6269\u6563\u3001\u975e\u7ed3\u6784\u5316\u7684\u52a8\u529b\u5b66\u3002", "conclusion": "\u6241\u6843\u4f53\u751f\u7269\u819c\u52a8\u529b\u5b66\u53ef\u4ee5\u901a\u8fc7\u673a\u68b0\u7f3a\u9677\u6210\u6838\u548c\u526a\u5207\u9a71\u52a8\u754c\u9762\u4e0d\u7a33\u5b9a\u6027\u7684\u76f8\u4e92\u4f5c\u7528\u6765\u89e3\u91ca\uff0c\u8fd9\u4e3a\u7406\u89e3\u751f\u7269\u819c\u7684\u7a7a\u95f4\u5b9a\u4f4d\u548c\u6301\u4e45\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u751f\u7269\u7269\u7406\u89c6\u89d2\u3002"}}
{"id": "2601.07871", "pdf": "https://arxiv.org/pdf/2601.07871", "abs": "https://arxiv.org/abs/2601.07871", "authors": ["Minh H. N. Le", "Tuan Vinh", "Thanh-Huy Nguyen", "Tao Li", "Bao Quang Gia Le", "Han H. Huynh", "Monika Raj", "Carl Yang", "Min Xu", "Nguyen Quoc Khanh Le"], "title": "Imaging-anchored Multiomics in Cardiovascular Disease: Integrating Cardiac Imaging, Bulk, Single-cell, and Spatial Transcriptomics", "categories": ["q-bio.QM", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Cardiovascular disease arises from interactions between inherited risk, molecular programmes, and tissue-scale remodelling that are observed clinically through imaging. Health systems now routinely generate large volumes of cardiac MRI, CT and echocardiography together with bulk, single-cell and spatial transcriptomics, yet these data are still analysed in separate pipelines. This review examines joint representations that link cardiac imaging phenotypes to transcriptomic and spatially resolved molecular states. An imaging-anchored perspective is adopted in which echocardiography, cardiac MRI and CT define a spatial phenotype of the heart, and bulk, single-cell and spatial transcriptomics provide cell-type- and location-specific molecular context. The biological and technical characteristics of these modalities are first summarised, and representation-learning strategies for each are outlined. Multimodal fusion approaches are reviewed, with emphasis on handling missing data, limited sample size, and batch effects. Finally, integrative pipelines for radiogenomics, spatial molecular alignment, and image-based prediction of gene expression are discussed, together with common failure modes, practical considerations, and open challenges. Spatial multiomics of human myocardium and atherosclerotic plaque, single-cell and spatial foundation models, and multimodal medical foundation models are collectively bringing imaging-anchored multiomics closer to large-scale cardiovascular translation.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u63a2\u8ba8\u4e86\u5c06\u5fc3\u810f\u6210\u50cf\u8868\u578b\u4e0e\u8f6c\u5f55\u7ec4\u5b66\u548c\u7a7a\u95f4\u5206\u5b50\u72b6\u6001\u8054\u7cfb\u8d77\u6765\u7684\u8054\u5408\u8868\u5f81\u65b9\u6cd5\uff0c\u65e8\u5728\u6574\u5408\u5fc3\u810fMRI\u3001CT\u3001\u8d85\u58f0\u5fc3\u52a8\u56fe\u4e0e\u8f6c\u5f55\u7ec4\u5b66\u6570\u636e\uff0c\u63a8\u52a8\u5fc3\u8840\u7ba1\u75be\u75c5\u7684\u591a\u7ec4\u5b66\u7814\u7a76\u3002", "motivation": "\u5fc3\u8840\u7ba1\u75be\u75c5\u6e90\u4e8e\u9057\u4f20\u98ce\u9669\u3001\u5206\u5b50\u7a0b\u5e8f\u548c\u4e34\u5e8a\u5f71\u50cf\u89c2\u5bdf\u5230\u7684\u7ec4\u7ec7\u91cd\u5851\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u76ee\u524d\u533b\u7597\u7cfb\u7edf\u867d\u7136\u751f\u6210\u4e86\u5927\u91cf\u5fc3\u810f\u5f71\u50cf\u548c\u8f6c\u5f55\u7ec4\u5b66\u6570\u636e\uff0c\u4f46\u8fd9\u4e9b\u6570\u636e\u4ecd\u5728\u5206\u79bb\u7684\u6d41\u7a0b\u4e2d\u5206\u6790\uff0c\u7f3a\u4e4f\u6574\u5408\u3002", "method": "\u91c7\u7528\u5f71\u50cf\u951a\u5b9a\u7684\u89c6\u89d2\uff1a\u5fc3\u810f\u5f71\u50cf\u5b9a\u4e49\u7a7a\u95f4\u8868\u578b\uff0c\u8f6c\u5f55\u7ec4\u5b66\u63d0\u4f9b\u7ec6\u80de\u7c7b\u578b\u548c\u4f4d\u7f6e\u7279\u5f02\u7684\u5206\u5b50\u80cc\u666f\u3002\u7efc\u8ff0\u4e86\u5404\u6a21\u6001\u7684\u751f\u7269\u5b66\u548c\u6280\u672f\u7279\u5f81\u3001\u8868\u5f81\u5b66\u4e60\u7b56\u7565\uff0c\u4ee5\u53ca\u5904\u7406\u7f3a\u5931\u6570\u636e\u3001\u6837\u672c\u91cf\u6709\u9650\u548c\u6279\u6b21\u6548\u5e94\u7684\u591a\u6a21\u6001\u878d\u5408\u65b9\u6cd5\u3002", "result": "\u8ba8\u8bba\u4e86\u653e\u5c04\u57fa\u56e0\u7ec4\u5b66\u3001\u7a7a\u95f4\u5206\u5b50\u5bf9\u9f50\u548c\u57fa\u4e8e\u5f71\u50cf\u7684\u57fa\u56e0\u8868\u8fbe\u9884\u6d4b\u7684\u6574\u5408\u6d41\u7a0b\uff0c\u5206\u6790\u4e86\u5e38\u89c1\u5931\u8d25\u6a21\u5f0f\u3001\u5b9e\u9645\u8003\u8651\u56e0\u7d20\u548c\u5f00\u653e\u6311\u6218\u3002\u6307\u51fa\u7a7a\u95f4\u591a\u7ec4\u5b66\u3001\u5355\u7ec6\u80de/\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u548c\u591a\u6a21\u6001\u533b\u5b66\u57fa\u7840\u6a21\u578b\u6b63\u5728\u63a8\u52a8\u5f71\u50cf\u951a\u5b9a\u591a\u7ec4\u5b66\u5411\u5927\u89c4\u6a21\u5fc3\u8840\u7ba1\u8f6c\u5316\u8fc8\u8fdb\u3002", "conclusion": "\u6574\u5408\u5fc3\u810f\u6210\u50cf\u4e0e\u5206\u5b50\u6570\u636e\u7684\u8054\u5408\u8868\u5f81\u65b9\u6cd5\u6b63\u5728\u5feb\u901f\u53d1\u5c55\uff0c\u4e3a\u7406\u89e3\u5fc3\u8840\u7ba1\u75be\u75c5\u673a\u5236\u548c\u5f00\u53d1\u7cbe\u51c6\u533b\u7597\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u4f46\u4ecd\u9762\u4e34\u6280\u672f\u6311\u6218\u548c\u5b9e\u9645\u5e94\u7528\u969c\u788d\u3002"}}
{"id": "2601.08147", "pdf": "https://arxiv.org/pdf/2601.08147", "abs": "https://arxiv.org/abs/2601.08147", "authors": ["Koyo Fujisaki", "Osei Horikoshi", "Yukitoshi Nagahara", "Kengo Morohashi"], "title": "Network Pharmacology Framework Characterizes Polypharmacological Properties of Dietary Flavonoids: Integration of Computational, Experimental, and Epidemiological Evidence", "categories": ["q-bio.QM", "q-bio.BM"], "comment": "117 pages, 8 figures, 3 supplementary tables (pages 34-117)", "summary": "Dietary flavonoids associate with disease prevention in epidemiological studies, yet their polypharmacological mechanisms remain unclear. We establish network pharmacology as a systematic framework to characterize flavonoid therapeutic properties through integrated computational, experimental, and epidemiological validation. We constructed a master network of 17,869 human proteins, 14 dietary flavonoids, and 1,496 FDA-approved drugs with 278,768 interactions. Flavonoids averaged 45.3 target proteins per compound compared to 16.8 for FDA-approved drugs (2.7-fold higher; p=7.5x10^-4), reflecting multi-target architecture. Statistical analysis revealed that 71.4% of flavonoids targeted proteins associated with cardiovascular drugs and 78.6% aligned with antineoplastic drug targets. MTT-based Jurkat cell assays confirmed network predictions: high-association flavonoids (luteolin LC50=31.4 microM, myricetin=29.5 microM) produced strong cytotoxicity, while low-association flavonoids showed minimal activity (LC50>200 microM). Network-predicted association strengths correlated with experimental bioactivity (Pearson r=0.918; R^2=0.843). We translated network associations into food-level predictions across 506 foods, identifying 685 food-drug therapeutic combinations. Systematic literature searches confirmed 96 associations supported by 132 unique references. Cardiovascular domains achieved 47.1% validation. Top-validated foods included tea (31 evidence items), blueberries (18 items), tomato (13 items), grape juice (10 items), and plum (9 items). Network pharmacology characterizes dietary polypharmacological properties and generates evidence-based food-therapeutic predictions, bridging nutritional science and systems pharmacology.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8fd0\u7528\u7f51\u7edc\u836f\u7406\u5b66\u7cfb\u7edf\u5206\u679014\u79cd\u81b3\u98df\u9ec4\u916e\u7c7b\u5316\u5408\u7269\u7684\u591a\u9776\u70b9\u4f5c\u7528\u673a\u5236\uff0c\u53d1\u73b0\u9ec4\u916e\u7c7b\u5316\u5408\u7269\u5e73\u5747\u9776\u70b9\u6570\u91cf\u662fFDA\u6279\u51c6\u836f\u7269\u76842.7\u500d\uff0c\u9884\u6d4b\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u9ec4\u916e\u7c7b\u5316\u5408\u7269\u7684\u6297\u764c\u6d3b\u6027\uff0c\u5c06\u7f51\u7edc\u5173\u8054\u8f6c\u5316\u4e3a506\u79cd\u98df\u7269\u7684685\u79cd\u98df\u7269-\u836f\u7269\u6cbb\u7597\u7ec4\u5408\u9884\u6d4b\u3002", "motivation": "\u6d41\u884c\u75c5\u5b66\u7814\u7a76\u663e\u793a\u81b3\u98df\u9ec4\u916e\u7c7b\u5316\u5408\u7269\u4e0e\u75be\u75c5\u9884\u9632\u76f8\u5173\uff0c\u4f46\u5176\u591a\u836f\u7406\u5b66\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\u3002\u9700\u8981\u5efa\u7acb\u7cfb\u7edf\u6846\u67b6\u6765\u8868\u5f81\u9ec4\u916e\u7c7b\u5316\u5408\u7269\u7684\u6cbb\u7597\u7279\u6027\uff0c\u5f25\u5408\u8425\u517b\u79d1\u5b66\u4e0e\u7cfb\u7edf\u836f\u7406\u5b66\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002", "method": "\u91c7\u7528\u7f51\u7edc\u836f\u7406\u5b66\u65b9\u6cd5\uff0c\u6784\u5efa\u5305\u542b17,869\u4e2a\u4eba\u7c7b\u86cb\u767d\u8d28\u300114\u79cd\u81b3\u98df\u9ec4\u916e\u7c7b\u5316\u5408\u7269\u548c1,496\u79cdFDA\u6279\u51c6\u836f\u7269\u7684\u4e3b\u7f51\u7edc\uff08278,768\u4e2a\u76f8\u4e92\u4f5c\u7528\uff09\u3002\u901a\u8fc7\u7edf\u8ba1\u5206\u6790\u3001MTT\u6cd5Jurkat\u7ec6\u80de\u5b9e\u9a8c\u9a8c\u8bc1\u7f51\u7edc\u9884\u6d4b\uff0c\u5e76\u5c06\u7f51\u7edc\u5173\u8054\u8f6c\u5316\u4e3a\u98df\u7269\u6c34\u5e73\u7684\u9884\u6d4b\u3002", "result": "\u9ec4\u916e\u7c7b\u5316\u5408\u7269\u5e73\u5747\u6bcf\u4e2a\u5316\u5408\u7269\u9776\u541145.3\u4e2a\u86cb\u767d\u8d28\uff0c\u662fFDA\u6279\u51c6\u836f\u7269\uff0816.8\u4e2a\uff09\u76842.7\u500d\u300271.4%\u7684\u9ec4\u916e\u7c7b\u5316\u5408\u7269\u9776\u5411\u5fc3\u8840\u7ba1\u836f\u7269\u76f8\u5173\u86cb\u767d\u8d28\uff0c78.6%\u4e0e\u6297\u80bf\u7624\u836f\u7269\u9776\u70b9\u4e00\u81f4\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\u9ad8\u5173\u8054\u9ec4\u916e\u7c7b\u5316\u5408\u7269\uff08\u6728\u7280\u8349\u7d20LC50=31.4\u03bcM\uff0c\u6768\u6885\u7d20=29.5\u03bcM\uff09\u5177\u6709\u5f3a\u7ec6\u80de\u6bd2\u6027\u3002\u7f51\u7edc\u9884\u6d4b\u5173\u8054\u5f3a\u5ea6\u4e0e\u5b9e\u9a8c\u751f\u7269\u6d3b\u6027\u9ad8\u5ea6\u76f8\u5173\uff08Pearson r=0.918\uff09\u3002\u8bc6\u522b\u51fa506\u79cd\u98df\u7269\u7684685\u79cd\u98df\u7269-\u836f\u7269\u6cbb\u7597\u7ec4\u5408\uff0c\u6587\u732e\u9a8c\u8bc1\u652f\u630196\u4e2a\u5173\u8054\u3002", "conclusion": "\u7f51\u7edc\u836f\u7406\u5b66\u80fd\u591f\u7cfb\u7edf\u8868\u5f81\u81b3\u98df\u591a\u836f\u7406\u5b66\u7279\u6027\uff0c\u751f\u6210\u57fa\u4e8e\u8bc1\u636e\u7684\u98df\u7269-\u6cbb\u7597\u9884\u6d4b\uff0c\u4e3a\u8425\u517b\u79d1\u5b66\u4e0e\u7cfb\u7edf\u836f\u7406\u5b66\u642d\u5efa\u6865\u6881\uff0c\u4e3a\u81b3\u98df\u5e72\u9884\u63d0\u4f9b\u79d1\u5b66\u4f9d\u636e\u3002"}}
{"id": "2601.08266", "pdf": "https://arxiv.org/pdf/2601.08266", "abs": "https://arxiv.org/abs/2601.08266", "authors": ["Ryan T. Black", "Steve A. Maas", "Wensi Wu", "Jalaj Maheshwari", "Tzanio Kolev", "Jeffrey A. Weiss", "Matthew A. Jolley"], "title": "An open-source computational framework for immersed fluid-structure interaction modeling using FEBio and MFEM", "categories": ["q-bio.QM", "physics.comp-ph"], "comment": null, "summary": "Fluid-structure interaction (FSI) simulation of biological systems presents significant computational challenges, particularly for applications involving large structural deformations and contact mechanics, such as heart valve dynamics. Traditional ALE methods encounter fundamental difficulties with such problems due to mesh distortion, motivating immersed techniques. This work presents a novel open-source immersed FSI framework that strategically couples two mature finite element libraries: MFEM, a GPU-ready and scalable library with state-of-the-art parallel performance developed at Lawrence Livermore National Laboratory, and FEBio, a nonlinear finite element solver with sophisticated solid mechanics capabilities designed for biomechanics applications developed at the University of Utah. This coupling creates a unique synergy wherein the fluid solver leverages MFEM's distributed-memory parallelization and pathway to GPU acceleration, while the immersed solid exploits FEBio's comprehensive suite of hyperelastic and viscoelastic constitutive models and advanced solid mechanics modeling targeted for biomechanics applications. FSI coupling is achieved using a fictitious domain methodology with variational multiscale stabilization for enhanced accuracy on under-resolved grids expected with unfitted meshes used in immersed FSI. A fully implicit, monolithic scheme provides robust coupling for strongly coupled FSI characteristic of cardiovascular applications. The framework's modular architecture facilitates straightforward extension to additional physics and element technologies. Several test problems are considered to demonstrate the capabilities of the proposed framework, including a 3D semilunar heart valve simulation. This platform addresses a critical need for open-source immersed FSI software combining advanced biomechanics modeling with high-performance computing infrastructure.", "AI": {"tldr": "\u63d0\u51fa\u5f00\u6e90\u6d78\u5165\u5f0f\u6d41\u56fa\u8026\u5408\u6846\u67b6\uff0c\u7ed3\u5408MFEM\u548cFEBio\u5e93\uff0c\u7528\u4e8e\u751f\u7269\u7cfb\u7edf\u4eff\u771f\uff0c\u7279\u522b\u9488\u5bf9\u5fc3\u810f\u74e3\u819c\u7b49\u5927\u53d8\u5f62\u63a5\u89e6\u95ee\u9898", "motivation": "\u751f\u7269\u7cfb\u7edf\u7684\u6d41\u56fa\u8026\u5408\u4eff\u771f\u9762\u4e34\u8ba1\u7b97\u6311\u6218\uff0c\u7279\u522b\u662f\u5fc3\u810f\u74e3\u819c\u7b49\u5927\u53d8\u5f62\u63a5\u89e6\u95ee\u9898\u3002\u4f20\u7edfALE\u65b9\u6cd5\u56e0\u7f51\u683c\u7578\u53d8\u800c\u56f0\u96be\uff0c\u9700\u8981\u6d78\u5165\u5f0f\u6280\u672f", "method": "\u8026\u5408\u4e24\u4e2a\u6210\u719f\u7684\u6709\u9650\u5143\u5e93\uff1aMFEM\uff08GPU\u5c31\u7eea\u3001\u53ef\u6269\u5c55\uff09\u548cFEBio\uff08\u975e\u7ebf\u6027\u6709\u9650\u5143\u3001\u751f\u7269\u529b\u5b66\u4e13\u7528\uff09\u3002\u91c7\u7528\u865a\u6784\u57df\u65b9\u6cd5\uff0c\u53d8\u5206\u591a\u5c3a\u5ea6\u7a33\u5b9a\u5316\uff0c\u5168\u9690\u5f0f\u5355\u5757\u65b9\u6848", "result": "\u5f00\u53d1\u4e86\u5f00\u6e90\u6d78\u5165\u5f0f\u6d41\u56fa\u8026\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u4e2a\u6d4b\u8bd5\u95ee\u9898\u9a8c\u8bc1\uff0c\u5305\u62ec3D\u534a\u6708\u74e3\u5fc3\u810f\u74e3\u819c\u4eff\u771f\uff0c\u5c55\u793a\u4e86\u6846\u67b6\u80fd\u529b", "conclusion": "\u8be5\u5e73\u53f0\u6ee1\u8db3\u4e86\u5c06\u5148\u8fdb\u751f\u7269\u529b\u5b66\u5efa\u6a21\u4e0e\u9ad8\u6027\u80fd\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u7ed3\u5408\u7684\u5f00\u6e90\u6d78\u5165\u5f0f\u6d41\u56fa\u8026\u5408\u8f6f\u4ef6\u7684\u5173\u952e\u9700\u6c42"}}
{"id": "2601.08318", "pdf": "https://arxiv.org/pdf/2601.08318", "abs": "https://arxiv.org/abs/2601.08318", "authors": ["Zhengye Pan", "Jianwei Zuo", "Jiajia Luo"], "title": "Disentangling History and Propagation Dependencies in Cross-Subject Knee Contact Stress Prediction Using a Shared MeshGraphNet Backbone", "categories": ["q-bio.QM", "cs.LG"], "comment": null, "summary": "Background:Subject-specific finite element analysis accurately characterizes knee joint mechanics but is computationally expensive. Deep surrogate models provide a rapid alternative, yet their generalization across subjects under limited pose and load inputs remains unclear. It remains unclear whether the dominant source of prediction uncertainty arises from temporal history dependence or spatial propagation dependence. Methods:To disentangle these factors, we employed a shared MGN backbone with a fixed mesh topology. A dataset of running trials from nine subjects was constructed using an OpenSim-FEBio workflow. We developed four model variants to isolate specific dependencies: (1) a baseline MGN; (2) CT-MGN, incorporating a Control Transformer to encode short-horizon history; (3) MsgModMGN, applying state-conditioned modulation to message passing for adaptive propagation; (4) CT-MsgModMGN, combining both mechanisms. Models were evaluated using a rigorous grouped 3-fold cross-validation on unseen subjects.Results:The models incorporating history encoding significantly outperformed the baseline MGN and MsgModMGN in global accuracy and spatial consistency. Crucially, the CT module effectively mitigated the peak-shaving defect common in deep surrogates, significantly reducing peak stress prediction errors. In contrast, the spatial propagation modulation alone yielded no significant improvement over the baseline, and combining it with CT provided no additional benefit.Conclusion:Temporal history dependence, rather than spatial propagation modulation, is the primary driver of prediction uncertainty in cross-subject knee contact mechanics. Explicitly encoding short-horizon driver sequences enables the surrogate model to recover implicit phase information, thereby achieving superior fidelity in peak-stress capture and high-risk localization compared to purely state-based approaches.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5bf9\u6bd4\u56db\u79cd\u56fe\u795e\u7ecf\u7f51\u7edc\u53d8\u4f53\uff0c\u53d1\u73b0\u65f6\u95f4\u5386\u53f2\u4f9d\u8d56\u662f\u8de8\u53d7\u8bd5\u8005\u819d\u5173\u8282\u63a5\u89e6\u529b\u5b66\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u4e3b\u8981\u6765\u6e90\uff0c\u800c\u7a7a\u95f4\u4f20\u64ad\u8c03\u5236\u5355\u72ec\u4f7f\u7528\u65e0\u663e\u8457\u6539\u5584\u3002", "motivation": "\u9488\u5bf9\u819d\u5173\u8282\u6709\u9650\u5143\u5206\u6790\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u6df1\u5ea6\u5b66\u4e60\u4ee3\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u5feb\u901f\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u5728\u6709\u9650\u59ff\u6001\u548c\u8f7d\u8377\u8f93\u5165\u4e0b\u8de8\u53d7\u8bd5\u8005\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u660e\u786e\uff0c\u4e14\u4e0d\u786e\u5b9a\u9884\u6d4b\u8bef\u5dee\u4e3b\u8981\u6765\u81ea\u65f6\u95f4\u5386\u53f2\u4f9d\u8d56\u8fd8\u662f\u7a7a\u95f4\u4f20\u64ad\u4f9d\u8d56\u3002", "method": "\u4f7f\u7528\u5171\u4eabMGN\u9aa8\u5e72\u7f51\u7edc\u548c\u56fa\u5b9a\u7f51\u683c\u62d3\u6251\uff0c\u6784\u5efa\u4e869\u540d\u53d7\u8bd5\u8005\u8dd1\u6b65\u8bd5\u9a8c\u6570\u636e\u96c6\u3002\u5f00\u53d1\u4e86\u56db\u79cd\u6a21\u578b\u53d8\u4f53\uff1a\u57fa\u7ebfMGN\u3001\u52a0\u5165Control Transformer\u7f16\u7801\u77ed\u671f\u5386\u53f2\u7684CT-MGN\u3001\u5e94\u7528\u72b6\u6001\u6761\u4ef6\u8c03\u5236\u8fdb\u884c\u81ea\u9002\u5e94\u4f20\u64ad\u7684MsgModMGN\u3001\u4ee5\u53ca\u7ed3\u5408\u4e24\u8005\u7684CT-MsgModMGN\u3002\u91c7\u7528\u4e25\u683c\u7684\u5206\u7ec43\u6298\u4ea4\u53c9\u9a8c\u8bc1\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u5305\u542b\u5386\u53f2\u7f16\u7801\u7684\u6a21\u578b\u5728\u5168\u5c40\u7cbe\u5ea6\u548c\u7a7a\u95f4\u4e00\u81f4\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebfMGN\u548cMsgModMGN\u3002CT\u6a21\u5757\u6709\u6548\u7f13\u89e3\u4e86\u6df1\u5ea6\u4ee3\u7406\u6a21\u578b\u4e2d\u5e38\u89c1\u7684\u5cf0\u503c\u524a\u5e73\u7f3a\u9677\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5cf0\u503c\u5e94\u529b\u9884\u6d4b\u8bef\u5dee\u3002\u800c\u7a7a\u95f4\u4f20\u64ad\u8c03\u5236\u5355\u72ec\u4f7f\u7528\u65e0\u663e\u8457\u6539\u5584\uff0c\u4e0eCT\u7ed3\u5408\u4e5f\u65e0\u989d\u5916\u6536\u76ca\u3002", "conclusion": "\u65f6\u95f4\u5386\u53f2\u4f9d\u8d56\u800c\u975e\u7a7a\u95f4\u4f20\u64ad\u8c03\u5236\u662f\u8de8\u53d7\u8bd5\u8005\u819d\u5173\u8282\u63a5\u89e6\u529b\u5b66\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\u3002\u663e\u5f0f\u7f16\u7801\u77ed\u671f\u9a71\u52a8\u5e8f\u5217\u4f7f\u4ee3\u7406\u6a21\u578b\u80fd\u591f\u6062\u590d\u9690\u542b\u7684\u76f8\u4f4d\u4fe1\u606f\uff0c\u4ece\u800c\u5728\u5cf0\u503c\u5e94\u529b\u6355\u83b7\u548c\u9ad8\u98ce\u9669\u5b9a\u4f4d\u65b9\u9762\u4f18\u4e8e\u7eaf\u72b6\u6001\u57fa\u65b9\u6cd5\u3002"}}
{"id": "2601.08701", "pdf": "https://arxiv.org/pdf/2601.08701", "abs": "https://arxiv.org/abs/2601.08701", "authors": ["Tammar Truzman", "Matthew A. Lambon Ralph", "Ajay D. Halai"], "title": "Automated Lesion Segmentation of Stroke MRI Using nnU-Net: A Comprehensive External Validation Across Acute and Chronic Lesions", "categories": ["q-bio.QM", "cs.CV"], "comment": "32 pages, 7 figures. Submitted to Brain. Code and trained models available", "summary": "Accurate and generalisable segmentation of stroke lesions from magnetic resonance imaging (MRI) is essential for advancing clinical research, prognostic modelling, and personalised interventions. Although deep learning has improved automated lesion delineation, many existing models are optimised for narrow imaging contexts and generalise poorly to independent datasets, modalities, and stroke stages. Here, we systematically evaluated stroke lesion segmentation using the nnU-Net framework across multiple heterogeneous, publicly available MRI datasets spanning acute and chronic stroke. Models were trained and tested on diffusion-weighted imaging (DWI), fluid-attenuated inversion recovery (FLAIR), and T1-weighted MRI, and evaluated on independent datasets. Across stroke stages, models showed robust generalisation, with segmentation accuracy approaching reported inter-rater reliability. Performance varied with imaging modality and training data characteristics. In acute stroke, DWI-trained models consistently outperformed FLAIR-based models, with only modest gains from multimodal combinations. In chronic stroke, increasing training set size improved performance, with diminishing returns beyond several hundred cases. Lesion volume was a key determinant of accuracy: smaller lesions were harder to segment, and models trained on restricted volume ranges generalised poorly. MRI image quality further constrained generalisability: models trained on lower-quality scans transferred poorly, whereas those trained on higher-quality data generalised well to noisier images. Discrepancies between predictions and reference masks were often attributable to limitations in manual annotations. Together, these findings show that automated lesion segmentation can approach human-level performance while identifying key factors governing generalisability and informing the development of lesion segmentation tools.", "AI": {"tldr": "nnU-Net\u6846\u67b6\u5728\u591a\u4e2a\u516c\u5f00MRI\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u5352\u4e2d\u75c5\u7076\u5206\u5272\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u4e0d\u540c\u5352\u4e2d\u9636\u6bb5\u3001\u6a21\u6001\u548c\u6570\u636e\u96c6\u95f4\u5177\u6709\u9c81\u68d2\u6cdb\u5316\u80fd\u529b\uff0c\u6027\u80fd\u63a5\u8fd1\u4eba\u5de5\u6807\u6ce8\u8005\u95f4\u4e00\u81f4\u6027", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u5352\u4e2d\u75c5\u7076\u5206\u5272\u6a21\u578b\u901a\u5e38\u5728\u7279\u5b9a\u6210\u50cf\u6761\u4ef6\u4e0b\u4f18\u5316\uff0c\u5bf9\u72ec\u7acb\u6570\u636e\u96c6\u3001\u6a21\u6001\u548c\u5352\u4e2d\u9636\u6bb5\u7684\u6cdb\u5316\u80fd\u529b\u8f83\u5dee\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u81ea\u52a8\u5206\u5272\u7684\u6cdb\u5316\u6027\u80fd", "method": "\u4f7f\u7528nnU-Net\u6846\u67b6\u5728\u591a\u4e2a\u516c\u5f00MRI\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u548c\u6d4b\u8bd5\u5352\u4e2d\u75c5\u7076\u5206\u5272\u6a21\u578b\uff0c\u6db5\u76d6\u6025\u6027\u671f\u548c\u6162\u6027\u671f\u5352\u4e2d\uff0c\u8bc4\u4f30DWI\u3001FLAIR\u548cT1\u52a0\u6743MRI\u6a21\u6001\uff0c\u5e76\u5728\u72ec\u7acb\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6cdb\u5316\u80fd\u529b", "result": "\u6a21\u578b\u5728\u4e0d\u540c\u5352\u4e2d\u9636\u6bb5\u8868\u73b0\u51fa\u9c81\u68d2\u6cdb\u5316\uff0c\u5206\u5272\u51c6\u786e\u5ea6\u63a5\u8fd1\u4eba\u5de5\u6807\u6ce8\u8005\u95f4\u4e00\u81f4\u6027\uff1b\u6025\u6027\u671fDWI\u6a21\u578b\u4f18\u4e8eFLAIR\u6a21\u578b\uff0c\u591a\u6a21\u6001\u7ec4\u5408\u589e\u76ca\u6709\u9650\uff1b\u6162\u6027\u671f\u589e\u52a0\u8bad\u7ec3\u96c6\u89c4\u6a21\u53ef\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u8d85\u8fc7\u6570\u767e\u4f8b\u540e\u6536\u76ca\u9012\u51cf\uff1b\u75c5\u7076\u4f53\u79ef\u662f\u51c6\u786e\u5ea6\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5c0f\u75c5\u7076\u66f4\u96be\u5206\u5272\uff1bMRI\u56fe\u50cf\u8d28\u91cf\u5f71\u54cd\u6cdb\u5316\u80fd\u529b", "conclusion": "\u81ea\u52a8\u75c5\u7076\u5206\u5272\u53ef\u63a5\u8fd1\u4eba\u5de5\u6c34\u5e73\u6027\u80fd\uff0c\u540c\u65f6\u8bc6\u522b\u4e86\u5f71\u54cd\u6cdb\u5316\u80fd\u529b\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4e3a\u5f00\u53d1\u5352\u4e2d\u75c5\u7076\u5206\u5272\u5de5\u5177\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc"}}
{"id": "2601.08798", "pdf": "https://arxiv.org/pdf/2601.08798", "abs": "https://arxiv.org/abs/2601.08798", "authors": ["Maayan Yesharim", "R. G. Bina Perl", "Uri Roll", "Sarig Gafny", "Eli Geffen", "Yoav Ram"], "title": "Near-perfect photo-ID of the Hula painted frog with zero-shot deep local-feature matching", "categories": ["cs.CV", "q-bio.QM"], "comment": "18 pages, 4 figures,", "summary": "Accurate individual identification is essential for monitoring rare amphibians, yet invasive marking is often unsuitable for critically endangered species. We evaluate state-of-the-art computer-vision methods for photographic re-identification of the Hula painted frog (Latonia nigriventer) using 1,233 ventral images from 191 individuals collected during 2013-2020 capture-recapture surveys. We compare deep local-feature matching in a zero-shot setting with deep global-feature embedding models. The local-feature pipeline achieves 98% top-1 closed-set identification accuracy, outperforming all global-feature models; fine-tuning improves the best global-feature model to 60% top-1 (91% top-10) but remains below local matching. To combine scalability with accuracy, we implement a two-stage workflow in which a fine-tuned global-feature model retrieves a short candidate list that is re-ranked by local-feature matching, reducing end-to-end runtime from 6.5-7.8 hours to ~38 minutes while maintaining ~96% top-1 closed-set accuracy on the labeled dataset. Separation of match scores between same- and different-individual pairs supports thresholding for open-set identification, enabling practical handling of novel individuals. We deploy this pipeline as a web application for routine field use, providing rapid, standardized, non-invasive identification to support conservation monitoring and capture-recapture analyses. Overall, in this species, zero-shot deep local-feature matching outperformed global-feature embedding and provides a strong default for photo-identification.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u8ba1\u7b97\u673a\u89c6\u89c9\u65b9\u6cd5\u5728\u6fd2\u5371\u4e24\u6816\u52a8\u7269Hula painted frog\u7167\u7247\u91cd\u8bc6\u522b\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u96f6\u6837\u672c\u6df1\u5ea6\u5c40\u90e8\u7279\u5f81\u5339\u914d\u4f18\u4e8e\u5168\u5c40\u7279\u5f81\u5d4c\u5165\uff0c\u5e76\u63d0\u51fa\u4e24\u9636\u6bb5\u5de5\u4f5c\u6d41\u7a0b\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u7684\u4e2a\u4f53\u8bc6\u522b\u3002", "motivation": "\u5bf9\u4e8e\u6fd2\u5371\u4e24\u6816\u52a8\u7269\u7684\u76d1\u6d4b\uff0c\u51c6\u786e\u7684\u4e2a\u4f53\u8bc6\u522b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4fb5\u5165\u6027\u6807\u8bb0\u65b9\u6cd5\u901a\u5e38\u4e0d\u9002\u7528\u4e8e\u6781\u5ea6\u6fd2\u5371\u7269\u79cd\u3002\u9700\u8981\u5f00\u53d1\u975e\u4fb5\u5165\u6027\u7684\u7167\u7247\u91cd\u8bc6\u522b\u65b9\u6cd5\u6765\u652f\u6301\u4fdd\u62a4\u76d1\u6d4b\u548c\u6355\u83b7-\u91cd\u6355\u83b7\u5206\u6790\u3002", "method": "\u4f7f\u7528191\u53ea\u4e2a\u4f53\u76841,233\u5f20\u8179\u9762\u56fe\u50cf\uff0c\u6bd4\u8f83\u96f6\u6837\u672c\u6df1\u5ea6\u5c40\u90e8\u7279\u5f81\u5339\u914d\u4e0e\u6df1\u5ea6\u5168\u5c40\u7279\u5f81\u5d4c\u5165\u6a21\u578b\u3002\u5f00\u53d1\u4e24\u9636\u6bb5\u5de5\u4f5c\u6d41\u7a0b\uff1a\u5148\u7528\u5fae\u8c03\u7684\u5168\u5c40\u7279\u5f81\u6a21\u578b\u68c0\u7d22\u5019\u9009\u5217\u8868\uff0c\u518d\u7528\u5c40\u90e8\u7279\u5f81\u5339\u914d\u91cd\u65b0\u6392\u5e8f\uff0c\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u7684\u8bc6\u522b\u3002", "result": "\u5c40\u90e8\u7279\u5f81\u7ba1\u9053\u8fbe\u523098%\u7684top-1\u95ed\u96c6\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u6240\u6709\u5168\u5c40\u7279\u5f81\u6a21\u578b\u3002\u4e24\u9636\u6bb5\u5de5\u4f5c\u6d41\u7a0b\u5c06\u7aef\u5230\u7aef\u8fd0\u884c\u65f6\u95f4\u4ece6.5-7.8\u5c0f\u65f6\u51cf\u5c11\u5230\u7ea638\u5206\u949f\uff0c\u540c\u65f6\u4fdd\u6301\u7ea696%\u7684top-1\u95ed\u96c6\u51c6\u786e\u7387\u3002\u5f00\u53d1\u4e86\u7528\u4e8e\u5e38\u89c4\u91ce\u5916\u4f7f\u7528\u7684\u7f51\u7edc\u5e94\u7528\u7a0b\u5e8f\u3002", "conclusion": "\u5bf9\u4e8e\u8be5\u7269\u79cd\uff0c\u96f6\u6837\u672c\u6df1\u5ea6\u5c40\u90e8\u7279\u5f81\u5339\u914d\u4f18\u4e8e\u5168\u5c40\u7279\u5f81\u5d4c\u5165\uff0c\u4e3a\u7167\u7247\u91cd\u8bc6\u522b\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u9ed8\u8ba4\u65b9\u6cd5\u3002\u4e24\u9636\u6bb5\u5de5\u4f5c\u6d41\u7a0b\u7ed3\u5408\u4e86\u53ef\u6269\u5c55\u6027\u548c\u51c6\u786e\u6027\uff0c\u652f\u6301\u5f00\u653e\u96c6\u8bc6\u522b\uff0c\u4e3a\u975e\u4fb5\u5165\u6027\u4fdd\u62a4\u76d1\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
