{"id": "2601.17102", "pdf": "https://arxiv.org/pdf/2601.17102", "abs": "https://arxiv.org/abs/2601.17102", "authors": ["Shuo Zhang", "Jian K. Liu"], "title": "Domain-Aware Geometric Multimodal Learning for Multi-Domain Protein-Ligand Affinity Prediction", "categories": ["q-bio.QM"], "comment": null, "summary": "The accurate prediction of protein-ligand binding affinity is important for drug discovery yet remains challenging for multi-domain proteins, where inter-domain dynamics and flexible linkers govern molecular recognition. Current geometric deep learning methods typically treat proteins as monolithic graphs, failing to capture the distinct geometric and energetic signals at domain interfaces. To address this, we introduce DAGML (Domain-Aware Geometric Multimodal Learning), a hierarchical framework that explicitly models domain modularity. DAGML integrates a pre-trained protein language model with a novel domain-aware geometric encoder to distinguish intra- and inter-domain features, while a motif-centric ligand encoder captures pharmacophoric compatibility. We further curate a specialized multi-domain affinity benchmark, classifying complexes by binding topology (e.g., interface vs linker binders). Extensive experiments demonstrate that DAGML achieves a 21% reduction in MSE and a Pearson correlation of 0.726 compared to strong baselines. Ablation studies reveal that explicit modeling of domain interfaces is the primary driver of this improvement, particularly for ligands binding in the clefts between structural units. The code is available at https://github.com/jiankliu/DAGML.", "AI": {"tldr": "DAGML\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u57df\u86cb\u767d\u8d28-\u914d\u4f53\u7ed3\u5408\u4eb2\u548c\u529b\u9884\u6d4b\u7684\u5c42\u6b21\u5316\u51e0\u4f55\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u57df\u6a21\u5757\u5316\u6765\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u5f53\u524d\u51e0\u4f55\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u5c06\u86cb\u767d\u8d28\u89c6\u4e3a\u5355\u4e00\u56fe\u7ed3\u6784\uff0c\u65e0\u6cd5\u6355\u6349\u591a\u57df\u86cb\u767d\u8d28\u4e2d\u57df\u95f4\u52a8\u6001\u548c\u67d4\u6027\u8fde\u63a5\u5b50\u5bf9\u5206\u5b50\u8bc6\u522b\u7684\u5173\u952e\u5f71\u54cd\uff0c\u8fd9\u9650\u5236\u4e86\u591a\u57df\u86cb\u767d\u8d28-\u914d\u4f53\u7ed3\u5408\u4eb2\u548c\u529b\u7684\u51c6\u786e\u9884\u6d4b\u3002", "method": "DAGML\u7ed3\u5408\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u548c\u65b0\u578b\u57df\u611f\u77e5\u51e0\u4f55\u7f16\u7801\u5668\uff0c\u533a\u5206\u57df\u5185\u548c\u57df\u95f4\u7279\u5f81\uff1b\u540c\u65f6\u4f7f\u7528\u4ee5\u57fa\u5e8f\u4e3a\u4e2d\u5fc3\u7684\u914d\u4f53\u7f16\u7801\u5668\u6355\u6349\u836f\u6548\u517c\u5bb9\u6027\uff1b\u5e76\u6784\u5efa\u4e86\u4e13\u95e8\u7684\u591a\u57df\u4eb2\u548c\u529b\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6309\u7ed3\u5408\u62d3\u6251\u5206\u7c7b\u590d\u5408\u7269\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDAGML\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0cMSE\u964d\u4f4e21%\uff0cPearson\u76f8\u5173\u7cfb\u6570\u8fbe\u52300.726\uff1b\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u663e\u5f0f\u5efa\u6a21\u57df\u754c\u9762\u662f\u6027\u80fd\u63d0\u5347\u7684\u4e3b\u8981\u9a71\u52a8\u529b\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5728\u7ed3\u6784\u5355\u5143\u95f4\u88c2\u9699\u7ed3\u5408\u7684\u914d\u4f53\u3002", "conclusion": "DAGML\u901a\u8fc7\u5c42\u6b21\u5316\u5efa\u6a21\u57df\u6a21\u5757\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u57df\u86cb\u767d\u8d28-\u914d\u4f53\u7ed3\u5408\u4eb2\u548c\u529b\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u4e3a\u836f\u7269\u53d1\u73b0\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u8ba1\u7b97\u5de5\u5177\u3002"}}
{"id": "2601.17582", "pdf": "https://arxiv.org/pdf/2601.17582", "abs": "https://arxiv.org/abs/2601.17582", "authors": ["Maurice Filo", "Nicol\u00f2 Rossi", "Zhou Fang", "Mustafa Khammash"], "title": "GenAI-Net: A Generative AI Framework for Automated Biomolecular Network Design", "categories": ["q-bio.QM", "cs.AI", "cs.LG", "eess.SY", "q-bio.MN"], "comment": null, "summary": "Biomolecular networks underpin emerging technologies in synthetic biology-from robust biomanufacturing and metabolic engineering to smart therapeutics and cell-based diagnostics-and also provide a mechanistic language for understanding complex dynamics in natural and ecological systems. Yet designing chemical reaction networks (CRNs) that implement a desired dynamical function remains largely manual: while a proposed network can be checked by simulation, the reverse problem of discovering a network from a behavioral specification is difficult, requiring substantial human insight to navigate a vast space of topologies and kinetic parameters with nonlinear and possibly stochastic dynamics. Here we introduce GenAI-Net, a generative AI framework that automates CRN design by coupling an agent that proposes reactions to simulation-based evaluation defined by a user-specified objective. GenAI-Net efficiently produces novel, topologically diverse solutions across multiple design tasks, including dose responses, complex logic gates, classifiers, oscillators, and robust perfect adaptation in deterministic and stochastic settings (including noise reduction). By turning specifications into families of circuit candidates and reusable motifs, GenAI-Net provides a general route to programmable biomolecular circuit design and accelerates the translation from desired function to implementable mechanisms.", "AI": {"tldr": "GenAI-Net\u662f\u4e00\u4e2a\u751f\u6210\u5f0fAI\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u8bbe\u8ba1\u5b9e\u73b0\u7279\u5b9a\u52a8\u6001\u529f\u80fd\u7684\u5316\u5b66\u53cd\u5e94\u7f51\u7edc\uff0c\u901a\u8fc7\u4ee3\u7406\u63d0\u51fa\u53cd\u5e94\u5e76\u8fdb\u884c\u6a21\u62df\u8bc4\u4f30\u3002", "motivation": "\u8bbe\u8ba1\u5b9e\u73b0\u7279\u5b9a\u52a8\u6001\u529f\u80fd\u7684\u5316\u5b66\u53cd\u5e94\u7f51\u7edc\u76ee\u524d\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\uff0c\u9700\u8981\u4ece\u5e9e\u5927\u7684\u62d3\u6251\u548c\u53c2\u6570\u7a7a\u95f4\u4e2d\u5bfb\u627e\u89e3\u51b3\u65b9\u6848\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u56f0\u96be\u4e14\u8017\u65f6\u3002\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u52a0\u901f\u4ece\u529f\u80fd\u9700\u6c42\u5230\u53ef\u5b9e\u65bd\u673a\u5236\u7684\u8f6c\u5316\u3002", "method": "GenAI-Net\u91c7\u7528\u751f\u6210\u5f0fAI\u6846\u67b6\uff0c\u7ed3\u5408\u4e00\u4e2a\u63d0\u51fa\u53cd\u5e94\u7684\u4ee3\u7406\u548c\u57fa\u4e8e\u7528\u6237\u6307\u5b9a\u76ee\u6807\u7684\u6a21\u62df\u8bc4\u4f30\u7cfb\u7edf\u3002\u901a\u8fc7\u8fd9\u79cd\u8026\u5408\u65b9\u5f0f\u81ea\u52a8\u63a2\u7d22\u5316\u5b66\u53cd\u5e94\u7f51\u7edc\u7684\u8bbe\u8ba1\u7a7a\u95f4\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u9ad8\u6548\u751f\u6210\u65b0\u9896\u4e14\u62d3\u6251\u591a\u6837\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u8bbe\u8ba1\u4efb\u52a1\uff0c\u5305\u62ec\u5242\u91cf\u54cd\u5e94\u3001\u590d\u6742\u903b\u8f91\u95e8\u3001\u5206\u7c7b\u5668\u3001\u632f\u8361\u5668\uff0c\u4ee5\u53ca\u5728\u786e\u5b9a\u6027\u548c\u968f\u673a\u8bbe\u7f6e\u4e0b\u7684\u9c81\u68d2\u5b8c\u7f8e\u9002\u5e94\uff08\u5305\u62ec\u566a\u58f0\u964d\u4f4e\uff09\u3002", "conclusion": "GenAI-Net\u901a\u8fc7\u5c06\u529f\u80fd\u89c4\u683c\u8f6c\u5316\u4e3a\u5019\u9009\u7535\u8def\u5bb6\u65cf\u548c\u53ef\u91cd\u7528\u6a21\u5757\uff0c\u4e3a\u53ef\u7f16\u7a0b\u751f\u7269\u5206\u5b50\u7535\u8def\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u901a\u7528\u9014\u5f84\uff0c\u52a0\u901f\u4e86\u4ece\u671f\u671b\u529f\u80fd\u5230\u53ef\u5b9e\u65bd\u673a\u5236\u7684\u8f6c\u5316\u8fc7\u7a0b\u3002"}}
{"id": "2601.17669", "pdf": "https://arxiv.org/pdf/2601.17669", "abs": "https://arxiv.org/abs/2601.17669", "authors": ["Lei Du", "Chenghang Li", "Jinzhi Lei"], "title": "Quantitative cancer-immunity cycle modeling to optimize bevacizumab and atezolizumab combination therapy for advanced renal cell carcinoma", "categories": ["q-bio.QM", "q-bio.TO"], "comment": "19 pages, 10 pages", "summary": "The incidence of advanced renal cell carcinoma(RCC) has been rising, presenting significant challenges due to the limited efficacy and severe side effects of traditional radiotherapy and chemotherapy. While combination immunotherapies show promise, optimizing treatment strategies remains difficult due to individual heterogeneity. To address this, we developed a Quantitative Cancer-Immunity Cycle (QCIC) model that integrates ordinary differential equations with stochastic modelling to quantitatively characterize and predict tumor evolution in patients with advanced RCC. By systematically integrating quantitative systems pharmacology principles with biological mechanistic knowledge, we constructed a virtual patient cohort and calibrated the model parameters using clinical immunohistochemistry data to ensure biological validity. To enhance predictive performance, we coupled the model with pharmacokinetic equations and defined the Tumor Response Index (TRI) as a quantitative metric of efficacy. Systematic analysis of the QCIC model allowed us to determine an optimal treatment regimen for the combination of bevacizumab and atezolizumab and identify tumor biomarkers with clinical predictive value. This study provides a theoretical framework and methodological support for precision medicine in the treatment of advanced RCC.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u5b9a\u91cf\u764c\u75c7-\u514d\u75ab\u5faa\u73af\uff08QCIC\uff09\u6a21\u578b\uff0c\u7ed3\u5408\u5fae\u5206\u65b9\u7a0b\u548c\u968f\u673a\u5efa\u6a21\uff0c\u7528\u4e8e\u9884\u6d4b\u665a\u671f\u80be\u7ec6\u80de\u764c\u7684\u80bf\u7624\u6f14\u5316\uff0c\u4f18\u5316\u8d1d\u4f10\u73e0\u5355\u6297\u548c\u963f\u7279\u73e0\u5355\u6297\u8054\u5408\u6cbb\u7597\u65b9\u6848\u3002", "motivation": "\u665a\u671f\u80be\u7ec6\u80de\u764c\u53d1\u75c5\u7387\u4e0a\u5347\uff0c\u4f20\u7edf\u653e\u5316\u7597\u6548\u679c\u6709\u9650\u4e14\u526f\u4f5c\u7528\u4e25\u91cd\uff0c\u8054\u5408\u514d\u75ab\u7597\u6cd5\u867d\u6709\u524d\u666f\u4f46\u4e2a\u4f53\u5f02\u8d28\u6027\u5bfc\u81f4\u6cbb\u7597\u7b56\u7565\u4f18\u5316\u56f0\u96be\u3002", "method": "\u6784\u5efaQCIC\u6a21\u578b\uff0c\u6574\u5408\u5e38\u5fae\u5206\u65b9\u7a0b\u548c\u968f\u673a\u5efa\u6a21\uff0c\u7ed3\u5408\u5b9a\u91cf\u7cfb\u7edf\u836f\u7406\u5b66\u539f\u7406\u548c\u751f\u7269\u5b66\u673a\u5236\u77e5\u8bc6\uff0c\u4f7f\u7528\u4e34\u5e8a\u514d\u75ab\u7ec4\u5316\u6570\u636e\u6821\u51c6\u53c2\u6570\uff0c\u8026\u5408\u836f\u4ee3\u52a8\u529b\u5b66\u65b9\u7a0b\uff0c\u5b9a\u4e49\u80bf\u7624\u53cd\u5e94\u6307\u6570\uff08TRI\uff09\u4f5c\u4e3a\u7597\u6548\u91cf\u5316\u6307\u6807\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u786e\u5b9a\u4e86\u8d1d\u4f10\u73e0\u5355\u6297\u548c\u963f\u7279\u73e0\u5355\u6297\u8054\u5408\u6cbb\u7597\u7684\u6700\u4f73\u65b9\u6848\uff0c\u8bc6\u522b\u4e86\u5177\u6709\u4e34\u5e8a\u9884\u6d4b\u4ef7\u503c\u7684\u80bf\u7624\u751f\u7269\u6807\u5fd7\u7269\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u665a\u671f\u80be\u7ec6\u80de\u764c\u7684\u7cbe\u51c6\u533b\u7597\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u65b9\u6cd5\u5b66\u652f\u6301\u3002"}}
{"id": "2601.18713", "pdf": "https://arxiv.org/pdf/2601.18713", "abs": "https://arxiv.org/abs/2601.18713", "authors": ["Muyuan Chen", "Muchen Li", "Renjie Liao"], "title": "Point transformer for protein structural heterogeneity analysis using CryoEM", "categories": ["q-bio.QM", "cs.AI"], "comment": null, "summary": "Structural dynamics of macromolecules is critical to their structural-function relationship. Cryogenic electron microscopy (CryoEM) provides snapshots of vitrified protein at different compositional and conformational states, and the structural heterogeneity of proteins can be characterized through computational analysis of the images. For protein systems with multiple degrees of freedom, it is still challenging to disentangle and interpret the different modes of dynamics. Here, by implementing Point Transformer, a self-attention network designed for point cloud analysis, we are able to improve the performance of heterogeneity analysis on CryoEM data, and characterize the dynamics of highly complex protein systems in a more human-interpretable way.", "AI": {"tldr": "\u4f7f\u7528Point Transformer\u81ea\u6ce8\u610f\u529b\u7f51\u7edc\u6539\u8fdb\u51b7\u51bb\u7535\u955c\u6570\u636e\u7684\u5f02\u8d28\u6027\u5206\u6790\uff0c\u4ee5\u66f4\u53ef\u89e3\u91ca\u7684\u65b9\u5f0f\u8868\u5f81\u590d\u6742\u86cb\u767d\u8d28\u7cfb\u7edf\u7684\u52a8\u529b\u5b66", "motivation": "\u86cb\u767d\u8d28\u7684\u7ed3\u6784\u52a8\u529b\u5b66\u5bf9\u5176\u7ed3\u6784-\u529f\u80fd\u5173\u7cfb\u81f3\u5173\u91cd\u8981\u3002\u51b7\u51bb\u7535\u955c\u63d0\u4f9b\u4e86\u86cb\u767d\u8d28\u5728\u4e0d\u540c\u7ec4\u6210\u548c\u6784\u8c61\u72b6\u6001\u4e0b\u7684\u5feb\u7167\uff0c\u4f46\u5177\u6709\u591a\u81ea\u7531\u5ea6\u7684\u86cb\u767d\u8d28\u7cfb\u7edf\u4ecd\u96be\u4ee5\u89e3\u6790\u548c\u89e3\u91ca\u4e0d\u540c\u7684\u52a8\u529b\u5b66\u6a21\u5f0f\u3002", "method": "\u5b9e\u73b0Point Transformer\uff0c\u8fd9\u662f\u4e00\u79cd\u4e3a\u70b9\u4e91\u5206\u6790\u8bbe\u8ba1\u7684\u81ea\u6ce8\u610f\u529b\u7f51\u7edc\uff0c\u7528\u4e8e\u6539\u8fdb\u51b7\u51bb\u7535\u955c\u6570\u636e\u7684\u5f02\u8d28\u6027\u5206\u6790\u3002", "result": "\u80fd\u591f\u63d0\u9ad8\u51b7\u51bb\u7535\u955c\u6570\u636e\u5f02\u8d28\u6027\u5206\u6790\u7684\u6027\u80fd\uff0c\u5e76\u4ee5\u66f4\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u65b9\u5f0f\u8868\u5f81\u9ad8\u5ea6\u590d\u6742\u86cb\u767d\u8d28\u7cfb\u7edf\u7684\u52a8\u529b\u5b66\u3002", "conclusion": "Point Transformer\u65b9\u6cd5\u80fd\u591f\u66f4\u597d\u5730\u89e3\u6790\u590d\u6742\u86cb\u767d\u8d28\u7cfb\u7edf\u7684\u7ed3\u6784\u5f02\u8d28\u6027\uff0c\u63d0\u4f9b\u66f4\u76f4\u89c2\u7684\u52a8\u529b\u5b66\u8868\u5f81\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u86cb\u767d\u8d28\u7684\u7ed3\u6784-\u529f\u80fd\u5173\u7cfb\u3002"}}
{"id": "2601.17184", "pdf": "https://arxiv.org/pdf/2601.17184", "abs": "https://arxiv.org/abs/2601.17184", "authors": ["Adrian Tkachenko", "Sepehr Salem", "Ayotomiwa Ezekiel Adeniyi", "Zulal Bingol", "Mohammed Nayeem Uddin", "Akshat Prasanna", "Alexander Zelikovsky", "Serghei Mangul", "Can Alkan", "Mohammed Alser"], "title": "FASTR: Reimagining FASTQ via Compact Image-inspired Representation", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "Motivation: High-throughput sequencing (HTS) enables population-scale genomics but generates massive datasets, creating bottlenecks in storage, transfer, and analysis. FASTQ, the standard format for over two decades, stores one byte per base and one byte per quality score, leading to inefficient I/O, high storage costs, and redundancy. Existing compression tools can mitigate some issues, but often introduce costly decompression or complex dependency issues. Results: We introduce FASTR, a lossless, computation-native successor to FASTQ that encodes each nucleotide together with its base quality score into a single 8-bit value. FASTR reduces file size by at least 2x while remaining fully reversible and directly usable for downstream analyses. Applying general-purpose compression tools on FASTR consistently yields higher compression ratios, 2.47, 3.64, and 4.8x faster compression, and 2.34, 1.96, 1.75x faster decompression than on FASTQ across Illumina, HiFi, and ONT reads. FASTR is machine-learning-ready, allowing reads to be consumed directly as numerical vectors or image-like representations. We provide a highly parallel software ecosystem for FASTQ-FASTR conversion and show that FASTR integrates with existing tools, such as minimap2, with minimal interface changes and no performance overhead. By eliminating decompression costs and reducing data movement, FASTR lays the foundation for scalable genomics analyses and real-time sequencing workflows. Availability and Implementation: https://github.com/ALSER-Lab/FASTR", "AI": {"tldr": "FASTR\u662f\u4e00\u79cd\u65b0\u7684\u65e0\u635f\u8ba1\u7b97\u539f\u751f\u683c\u5f0f\uff0c\u5c06\u6838\u82f7\u9178\u548c\u78b1\u57fa\u8d28\u91cf\u5206\u6570\u7f16\u7801\u4e3a\u5355\u4e2a8\u4f4d\u503c\uff0c\u76f8\u6bd4FASTQ\u51cf\u5c11\u81f3\u5c112\u500d\u6587\u4ef6\u5927\u5c0f\uff0c\u540c\u65f6\u4fdd\u6301\u5b8c\u5168\u53ef\u9006\u4e14\u53ef\u76f4\u63a5\u7528\u4e8e\u4e0b\u6e38\u5206\u6790\u3002", "motivation": "\u9ad8\u901a\u91cf\u6d4b\u5e8f\u4ea7\u751f\u6d77\u91cf\u6570\u636e\uff0cFASTQ\u683c\u5f0f\u5b58\u50a8\u6548\u7387\u4f4e\u4e0b\uff08\u6bcf\u4e2a\u78b1\u57fa\u548c\u8d28\u91cf\u5206\u6570\u5404\u53601\u5b57\u8282\uff09\uff0c\u5bfc\u81f4\u5b58\u50a8\u3001\u4f20\u8f93\u548c\u5206\u6790\u74f6\u9888\u3002\u73b0\u6709\u538b\u7f29\u5de5\u5177\u867d\u7136\u80fd\u7f13\u89e3\u90e8\u5206\u95ee\u9898\uff0c\u4f46\u901a\u5e38\u5f15\u5165\u6602\u8d35\u7684\u89e3\u538b\u7f29\u6210\u672c\u6216\u590d\u6742\u7684\u4f9d\u8d56\u95ee\u9898\u3002", "method": "FASTR\u5c06\u6bcf\u4e2a\u6838\u82f7\u9178\u4e0e\u5176\u78b1\u57fa\u8d28\u91cf\u5206\u6570\u4e00\u8d77\u7f16\u7801\u4e3a\u5355\u4e2a8\u4f4d\u503c\uff0c\u521b\u5efa\u4e86\u4e00\u79cd\u65e0\u635f\u3001\u8ba1\u7b97\u539f\u751f\u7684\u683c\u5f0f\u3002\u63d0\u4f9b\u4e86\u9ad8\u5ea6\u5e76\u884c\u7684\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u7528\u4e8eFASTQ-FASTR\u8f6c\u6362\uff0c\u5e76\u4e0e\u73b0\u6709\u5de5\u5177\uff08\u5982minimap2\uff09\u96c6\u6210\uff0c\u53ea\u9700\u6700\u5c0f\u63a5\u53e3\u66f4\u6539\u4e14\u65e0\u6027\u80fd\u5f00\u9500\u3002", "result": "FASTR\u5c06\u6587\u4ef6\u5927\u5c0f\u51cf\u5c11\u81f3\u5c112\u500d\uff0c\u5728Illumina\u3001HiFi\u548cONT reads\u4e0a\uff0c\u5bf9FASTR\u5e94\u7528\u901a\u7528\u538b\u7f29\u5de5\u5177\u76f8\u6bd4FASTQ\u5206\u522b\u83b7\u5f972.47\u30013.64\u548c4.8\u500d\u66f4\u5feb\u7684\u538b\u7f29\u901f\u5ea6\uff0c\u4ee5\u53ca2.34\u30011.96\u30011.75\u500d\u66f4\u5feb\u7684\u89e3\u538b\u7f29\u901f\u5ea6\u3002FASTR\u53ef\u76f4\u63a5\u4f5c\u4e3a\u6570\u503c\u5411\u91cf\u6216\u7c7b\u56fe\u50cf\u8868\u793a\u4f7f\u7528\uff0c\u9002\u5408\u673a\u5668\u5b66\u4e60\u5e94\u7528\u3002", "conclusion": "FASTR\u901a\u8fc7\u6d88\u9664\u89e3\u538b\u7f29\u6210\u672c\u548c\u51cf\u5c11\u6570\u636e\u79fb\u52a8\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u57fa\u56e0\u7ec4\u5b66\u5206\u6790\u548c\u5b9e\u65f6\u6d4b\u5e8f\u5de5\u4f5c\u6d41\u7a0b\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u662fFASTQ\u683c\u5f0f\u7684\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2601.17228", "pdf": "https://arxiv.org/pdf/2601.17228", "abs": "https://arxiv.org/abs/2601.17228", "authors": ["Tengyue Zhang", "Ruiwen Ding", "Luoting Zhuang", "Yuxiao Wu", "Erika F. Rodriguez", "William Hsu"], "title": "Semi-Supervised Domain Adaptation with Latent Diffusion for Pathology Image Classification", "categories": ["cs.CV", "q-bio.QM"], "comment": null, "summary": "Deep learning models in computational pathology often fail to generalize across cohorts and institutions due to domain shift. Existing approaches either fail to leverage unlabeled data from the target domain or rely on image-to-image translation, which can distort tissue structures and compromise model accuracy. In this work, we propose a semi-supervised domain adaptation (SSDA) framework that utilizes a latent diffusion model trained on unlabeled data from both the source and target domains to generate morphology-preserving and target-aware synthetic images. By conditioning the diffusion model on foundation model features, cohort identity, and tissue preparation method, we preserve tissue structure in the source domain while introducing target-domain appearance characteristics. The target-aware synthetic images, combined with real, labeled images from the source cohort, are subsequently used to train a downstream classifier, which is then tested on the target cohort. The effectiveness of the proposed SSDA framework is demonstrated on the task of lung adenocarcinoma prognostication. The proposed augmentation yielded substantially better performance on the held-out test set from the target cohort, without degrading source-cohort performance. The approach improved the weighted F1 score on the target-cohort held-out test set from 0.611 to 0.706 and the macro F1 score from 0.641 to 0.716. Our results demonstrate that target-aware diffusion-based synthetic data augmentation provides a promising and effective approach for improving domain generalization in computational pathology.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6f5c\u5728\u6269\u6563\u6a21\u578b\u7684\u534a\u76d1\u7763\u57df\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u4fdd\u7559\u6e90\u57df\u7ec4\u7ec7\u7ed3\u6784\u4e14\u5177\u6709\u76ee\u6807\u57df\u5916\u89c2\u7279\u5f81\u7684\u5408\u6210\u56fe\u50cf\uff0c\u6539\u5584\u8ba1\u7b97\u75c5\u7406\u5b66\u4e2d\u7684\u57df\u6cdb\u5316\u95ee\u9898\u3002", "motivation": "\u8ba1\u7b97\u75c5\u7406\u5b66\u4e2d\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5e38\u56e0\u57df\u504f\u79fb\u800c\u65e0\u6cd5\u5728\u4e0d\u540c\u961f\u5217\u548c\u673a\u6784\u95f4\u6cdb\u5316\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u65e0\u6cd5\u5229\u7528\u76ee\u6807\u57df\u7684\u65e0\u6807\u7b7e\u6570\u636e\uff0c\u8981\u4e48\u4f9d\u8d56\u53ef\u80fd\u626d\u66f2\u7ec4\u7ec7\u7ed3\u6784\u7684\u56fe\u50cf\u7ffb\u8bd1\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u534a\u76d1\u7763\u57df\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u4f7f\u7528\u5728\u6e90\u57df\u548c\u76ee\u6807\u57df\u65e0\u6807\u7b7e\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u6761\u4ef6\u5316\u57fa\u7840\u6a21\u578b\u7279\u5f81\u3001\u961f\u5217\u8eab\u4efd\u548c\u7ec4\u7ec7\u5236\u5907\u65b9\u6cd5\uff0c\u751f\u6210\u4fdd\u7559\u7ec4\u7ec7\u7ed3\u6784\u7684\u76ee\u6807\u611f\u77e5\u5408\u6210\u56fe\u50cf\uff0c\u7528\u4e8e\u8bad\u7ec3\u4e0b\u6e38\u5206\u7c7b\u5668\u3002", "result": "\u5728\u80ba\u817a\u764c\u9884\u540e\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u76ee\u6807\u57df\u6d4b\u8bd5\u96c6\u6027\u80fd\uff0c\u52a0\u6743F1\u5206\u6570\u4ece0.611\u63d0\u5347\u52300.706\uff0c\u5b8f\u89c2F1\u5206\u6570\u4ece0.641\u63d0\u5347\u52300.716\uff0c\u4e14\u672a\u964d\u4f4e\u6e90\u57df\u6027\u80fd\u3002", "conclusion": "\u76ee\u6807\u611f\u77e5\u7684\u6269\u6563\u6a21\u578b\u5408\u6210\u6570\u636e\u589e\u5f3a\u4e3a\u6539\u5584\u8ba1\u7b97\u75c5\u7406\u5b66\u4e2d\u7684\u57df\u6cdb\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u4e14\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.18640", "pdf": "https://arxiv.org/pdf/2601.18640", "abs": "https://arxiv.org/abs/2601.18640", "authors": ["Zhiwei Zheng", "Kevin Bryson"], "title": "TwinPurify: Purifying gene expression data to reveal tumor-intrinsic transcriptional programs via self-supervised learning", "categories": ["cs.LG", "q-bio.MN"], "comment": null, "summary": "Advances in single-cell and spatial transcriptomic technologies have transformed tumor ecosystem profiling at cellular resolution. However, large scale studies on patient cohorts continue to rely on bulk transcriptomic data, where variation in tumor purity obscures tumor-intrinsic transcriptional signals and constrains downstream discovery. Many deconvolution methods report strong performance on synthetic bulk mixtures but fail to generalize to real patient cohorts because of unmodeled biological and technical variation.\n  Here, we introduce TwinPurify, a representation learning framework that adapts the Barlow Twins self-supervised objective, representing a fundamental departure from the deconvolution paradigm. Rather than resolving the bulk mixture into discrete cell-type fractions, TwinPurify instead learns continuous, high-dimensional tumor embeddings by leveraging adjacent-normal profiles within the same cohort as \"background\" guidance, enabling the disentanglement of tumor-specific signals without relying on any external reference.\n  Benchmarked against multiple large cancer cohorts across RNA-seq and microarray platforms, TwinPurify outperforms conventional representation learning baselines like auto-encoders in recovering tumor-intrinsic and immune signals. The purified embeddings improve molecular subtype and grade classification, enhance survival model concordance, and uncover biologically meaningful pathway activities compared to raw bulk profiles. By providing a transferable framework for decontaminating bulk transcriptomics, TwinPurify extends the utility of existing clinical datasets for molecular discovery.", "AI": {"tldr": "TwinPurify\u662f\u4e00\u4e2a\u57fa\u4e8eBarlow Twins\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u6279\u91cf\u8f6c\u5f55\u7ec4\u6570\u636e\u4e2d\u5206\u79bb\u80bf\u7624\u7279\u5f02\u6027\u4fe1\u53f7\uff0c\u65e0\u9700\u5916\u90e8\u53c2\u8003\uff0c\u901a\u8fc7\u5229\u7528\u540c\u4e00\u961f\u5217\u4e2d\u7684\u76f8\u90bb\u6b63\u5e38\u7ec4\u7ec7\u4f5c\u4e3a\"\u80cc\u666f\"\u6307\u5bfc\u6765\u5b66\u4e60\u8fde\u7eed\u7684\u9ad8\u7ef4\u80bf\u7624\u5d4c\u5165\u3002", "motivation": "\u5927\u89c4\u6a21\u60a3\u8005\u961f\u5217\u7814\u7a76\u4ecd\u4f9d\u8d56\u6279\u91cf\u8f6c\u5f55\u7ec4\u6570\u636e\uff0c\u4f46\u80bf\u7624\u7eaf\u5ea6\u53d8\u5316\u4f1a\u63a9\u76d6\u80bf\u7624\u5185\u5728\u8f6c\u5f55\u4fe1\u53f7\u5e76\u9650\u5236\u4e0b\u6e38\u53d1\u73b0\u3002\u73b0\u6709\u7684\u53bb\u5377\u79ef\u65b9\u6cd5\u5728\u5408\u6210\u6df7\u5408\u7269\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u65e0\u6cd5\u63a8\u5e7f\u5230\u771f\u5b9e\u60a3\u8005\u961f\u5217\uff0c\u56e0\u4e3a\u672a\u5efa\u6a21\u7684\u751f\u7269\u548c\u6280\u672f\u53d8\u5f02\u3002", "method": "TwinPurify\u91c7\u7528Barlow Twins\u81ea\u76d1\u7763\u5b66\u4e60\u76ee\u6807\uff0c\u5229\u7528\u540c\u4e00\u961f\u5217\u4e2d\u7684\u76f8\u90bb\u6b63\u5e38\u7ec4\u7ec7\u4f5c\u4e3a\"\u80cc\u666f\"\u6307\u5bfc\uff0c\u5b66\u4e60\u8fde\u7eed\u7684\u9ad8\u7ef4\u80bf\u7624\u5d4c\u5165\uff0c\u800c\u4e0d\u662f\u5c06\u6279\u91cf\u6df7\u5408\u7269\u89e3\u6790\u4e3a\u79bb\u6563\u7684\u7ec6\u80de\u7c7b\u578b\u5206\u6570\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u4f9d\u8d56\u4efb\u4f55\u5916\u90e8\u53c2\u8003\u3002", "result": "\u5728\u591a\u4e2a\u5927\u578b\u764c\u75c7\u961f\u5217\u7684RNA-seq\u548c\u5fae\u9635\u5217\u5e73\u53f0\u4e0a\uff0cTwinPurify\u5728\u6062\u590d\u80bf\u7624\u5185\u5728\u548c\u514d\u75ab\u4fe1\u53f7\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff08\u5982\u81ea\u7f16\u7801\u5668\uff09\u3002\u7eaf\u5316\u7684\u5d4c\u5165\u6539\u5584\u4e86\u5206\u5b50\u4e9a\u578b\u548c\u5206\u7ea7\u5206\u7c7b\uff0c\u589e\u5f3a\u4e86\u751f\u5b58\u6a21\u578b\u4e00\u81f4\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u6bd4\u539f\u59cb\u6279\u91cf\u8c31\u66f4\u6709\u751f\u7269\u5b66\u610f\u4e49\u7684\u901a\u8def\u6d3b\u6027\u3002", "conclusion": "TwinPurify\u901a\u8fc7\u63d0\u4f9b\u53ef\u8f6c\u79fb\u7684\u6279\u91cf\u8f6c\u5f55\u7ec4\u53bb\u6c61\u67d3\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u4e34\u5e8a\u6570\u636e\u96c6\u5728\u5206\u5b50\u53d1\u73b0\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u4ee3\u8868\u4e86\u4e0e\u53bb\u5377\u79ef\u8303\u5f0f\u7684\u6839\u672c\u6027\u8f6c\u53d8\u3002"}}
{"id": "2601.17504", "pdf": "https://arxiv.org/pdf/2601.17504", "abs": "https://arxiv.org/abs/2601.17504", "authors": ["Yan Zhou", "Zhen Huang", "Yingqiu Li", "Yue Ouyang", "Suncheng Xiang", "Zehua Wang"], "title": "BMDS-Net: A Bayesian Multi-Modal Deep Supervision Network for Robust Brain Tumor Segmentation", "categories": ["cs.CV", "q-bio.QM"], "comment": "16 pages, 5 figures. Manuscript prepared for submission to ACM TOMM", "summary": "Accurate brain tumor segmentation from multi-modal magnetic resonance imaging (MRI) is a prerequisite for precise radiotherapy planning and surgical navigation. While recent Transformer-based models such as Swin UNETR have achieved impressive benchmark performance, their clinical utility is often compromised by two critical issues: sensitivity to missing modalities (common in clinical practice) and a lack of confidence calibration. Merely chasing higher Dice scores on idealized data fails to meet the safety requirements of real-world medical deployment. In this work, we propose BMDS-Net, a unified framework that prioritizes clinical robustness and trustworthiness over simple metric maximization. Our contribution is three-fold. First, we construct a robust deterministic backbone by integrating a Zero-Init Multimodal Contextual Fusion (MMCF) module and a Residual-Gated Deep Decoder Supervision (DDS) mechanism, enabling stable feature learning and precise boundary delineation with significantly reduced Hausdorff Distance, even under modality corruption. Second, and most importantly, we introduce a memory-efficient Bayesian fine-tuning strategy that transforms the network into a probabilistic predictor, providing voxel-wise uncertainty maps to highlight potential errors for clinicians. Third, comprehensive experiments on the BraTS 2021 dataset demonstrate that BMDS-Net not only maintains competitive accuracy but, more importantly, exhibits superior stability in missing-modality scenarios where baseline models fail. The source code is publicly available at https://github.com/RyanZhou168/BMDS-Net.", "AI": {"tldr": "BMDS-Net\u662f\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u4e34\u5e8a\u7a33\u5065\u6027\u548c\u53ef\u4fe1\u5ea6\u7684\u8111\u80bf\u7624\u5206\u5272\u6846\u67b6\uff0c\u901a\u8fc7\u96f6\u521d\u59cb\u5316\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u878d\u5408\u548c\u6b8b\u5dee\u95e8\u63a7\u6df1\u5ea6\u89e3\u7801\u5668\u76d1\u7763\u6784\u5efa\u7a33\u5065\u4e3b\u5e72\uff0c\u5e76\u91c7\u7528\u5185\u5b58\u9ad8\u6548\u7684\u8d1d\u53f6\u65af\u5fae\u8c03\u7b56\u7565\u63d0\u4f9b\u4f53\u7d20\u7ea7\u4e0d\u786e\u5b9a\u6027\u56fe\uff0c\u5728\u7f3a\u5931\u6a21\u6001\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eTransformer\u7684\u8111\u80bf\u7624\u5206\u5272\u6a21\u578b\uff08\u5982Swin UNETR\uff09\u867d\u7136\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u5bf9\u7f3a\u5931\u6a21\u6001\u7684\u654f\u611f\u6027\uff08\u4e34\u5e8a\u5e38\u89c1\u60c5\u51b5\uff09\u548c\u7f3a\u4e4f\u7f6e\u4fe1\u5ea6\u6821\u51c6\u3002\u5355\u7eaf\u8ffd\u6c42\u7406\u60f3\u5316\u6570\u636e\u4e0a\u7684\u66f4\u9ad8Dice\u5206\u6570\u65e0\u6cd5\u6ee1\u8db3\u771f\u5b9e\u533b\u7597\u90e8\u7f72\u7684\u5b89\u5168\u8981\u6c42\u3002", "method": "1. \u6784\u5efa\u7a33\u5065\u786e\u5b9a\u6027\u4e3b\u5e72\uff1a\u96c6\u6210\u96f6\u521d\u59cb\u5316\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u878d\u5408\uff08MMCF\uff09\u6a21\u5757\u548c\u6b8b\u5dee\u95e8\u63a7\u6df1\u5ea6\u89e3\u7801\u5668\u76d1\u7763\uff08DDS\uff09\u673a\u5236\uff0c\u5b9e\u73b0\u7a33\u5b9a\u7279\u5f81\u5b66\u4e60\u548c\u7cbe\u786e\u8fb9\u754c\u5212\u5206\uff1b2. \u5f15\u5165\u5185\u5b58\u9ad8\u6548\u7684\u8d1d\u53f6\u65af\u5fae\u8c03\u7b56\u7565\uff1a\u5c06\u7f51\u7edc\u8f6c\u6362\u4e3a\u6982\u7387\u9884\u6d4b\u5668\uff0c\u63d0\u4f9b\u4f53\u7d20\u7ea7\u4e0d\u786e\u5b9a\u6027\u56fe\uff1b3. \u5728BraTS 2021\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5168\u9762\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "BMDS-Net\u4e0d\u4ec5\u4fdd\u6301\u4e86\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\uff0c\u66f4\u91cd\u8981\u7684\u662f\u5728\u57fa\u7ebf\u6a21\u578b\u5931\u8d25\u7684\u7f3a\u5931\u6a21\u6001\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u7a33\u5b9a\u6027\uff0c\u663e\u8457\u51cf\u5c11\u4e86Hausdorff\u8ddd\u79bb\uff0c\u5e76\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u56fe\u5e2e\u52a9\u4e34\u5e8a\u533b\u751f\u8bc6\u522b\u6f5c\u5728\u9519\u8bef\u3002", "conclusion": "BMDS-Net\u662f\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u4f18\u5148\u8003\u8651\u4e34\u5e8a\u7a33\u5065\u6027\u548c\u53ef\u4fe1\u5ea6\u800c\u975e\u7b80\u5355\u7684\u6307\u6807\u6700\u5927\u5316\uff0c\u901a\u8fc7\u7ed3\u5408\u7a33\u5065\u4e3b\u5e72\u548c\u8d1d\u53f6\u65af\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u4e3a\u771f\u5b9e\u4e16\u754c\u533b\u7597\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u5b89\u5168\u53ef\u9760\u7684\u5206\u5272\u89e3\u51b3\u65b9\u6848\u3002"}}
