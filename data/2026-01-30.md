<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR](https://arxiv.org/abs/2601.22128)
*Irsyad Adam,Zekai Chen,David Laprade,Shaun Porwal,David Laub,Erik Reinertsen,Arda Pekis,Kevin Brown*

Main category: cs.AI

TL;DR: 提出SMB-Structure模型，结合联合嵌入预测架构(JEPA)和下一个token预测(SFT)，用于结构化电子健康记录(EHR)的世界建模，以模拟患者动态而非仅预测token。


<details>
  <summary>Details</summary>
Motivation: 现有基于下一个token预测的LLMs将患者视为需要总结的文档，而非需要模拟的动态系统。患者轨迹是由状态在干预和时间下演化产生的，需要能模拟动态而非仅预测token的模型。

Method: 提出SMB-Structure模型：1) 使用下一个token预测(SFT)使模型能在token空间重建未来患者状态；2) 使用联合嵌入预测架构(JEPA)在潜在空间中仅从初始患者表示预测未来状态，迫使轨迹动态在观察到下一个状态前被编码。

Result: 在两个大规模队列(MSK的23,319名肿瘤患者和INSPECT的19,402名肺栓塞患者)上验证。通过沿疾病轨迹多个点的线性探测，证明该方法学习的嵌入能捕捉自回归基线无法恢复的疾病动态，在高度异质性复杂任务上实现竞争性能。

Conclusion: SMB-Structure通过结合SFT和JEPA，能够更好地模拟患者动态系统，为结构化EHR建模提供了新范式，模型权重已开源。

Abstract: Large language models (LLMs) trained with next-word-prediction have achieved success as clinical foundation models. Representations from these language backbones yield strong linear probe performance across biomedical tasks, suggesting that patient semantics emerge from next-token prediction at scale. However, this paradigm treats patients as a document to be summarized rather than a dynamical system to be simulated; a patient's trajectory emerges from their state evolving under interventions and time, requiring models that simulate dynamics rather than predict tokens. To address this, we introduce SMB-Structure, a world model for structured EHR that grounds a joint-embedding prediction architecture (JEPA) with next-token prediction (SFT). SFT grounds our model to reconstruct future patient states in token space, while JEPA predicts those futures in latent space from the initial patient representation alone, forcing trajectory dynamics to be encoded before the next state is observed. We validate across two large-scale cohorts: Memorial Sloan Kettering (23,319 oncology patients; 323,000+ patient-years) and INSPECT (19,402 pulmonary embolism patients). Using a linear probe evaluated at multiple points along the disease trajectory, we demonstrate that our training paradigm learns embeddings that capture disease dynamics not recoverable by autoregressive baselines, enabling SMB-Structure to achieve competitive performance on complex tasks characterized by high patient heterogeneity. Model weights are available at https://huggingface.co/standardmodelbio/SMB-v1-1.7B-Structure.

</details>
