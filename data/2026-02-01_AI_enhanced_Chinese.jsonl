{"id": "2601.20869", "pdf": "https://arxiv.org/pdf/2601.20869", "abs": "https://arxiv.org/abs/2601.20869", "authors": ["M. A. Rasel", "Sameem Abdul Kareem", "Unaizah Obaidellah"], "title": "Integrating Color Histogram Analysis and Convolutional Neural Network for Skin Lesion Classification", "categories": ["q-bio.QM", "cs.AI", "eess.IV"], "comment": null, "summary": "The color of skin lesions is an important diagnostic feature for identifying malignant melanoma and other skin diseases. Typical colors associated with melanocytic lesions include tan, brown, black, red, white, and blue gray. This study introduces a novel feature: the number of colors present in a lesion, which can indicate the severity of disease and help distinguish melanomas from benign lesions. We propose a color histogram analysis method to examine lesion pixel values from three publicly available datasets: PH2, ISIC2016, and Med Node. The PH2 dataset contains ground truth annotations of lesion colors, while ISIC2016 and Med Node do not; our algorithm estimates the ground truth using color histogram analysis based on PH2. We then design and train a 19 layer Convolutional Neural Network (CNN) with residual skip connections to classify lesions into three categories based on the number of colors present. DeepDream visualization is used to interpret features learned by the network, and multiple CNN configurations are tested. The best model achieves a weighted F1 score of 75 percent. LIME is applied to identify important regions influencing model decisions. The results show that the number of colors in a lesion is a significant feature for describing skin conditions, and the proposed CNN with three skip connections demonstrates strong potential for clinical diagnostic support.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u989c\u8272\u6570\u91cf\u7684\u76ae\u80a4\u75c5\u53d8\u5206\u6790\u65b0\u7279\u5f81\uff0c\u4f7f\u7528CNN\u5206\u7c7b\u75c5\u53d8\u989c\u8272\u6570\u91cf\uff0c\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u6700\u4f73\u6a21\u578bF1\u5206\u657075%", "motivation": "\u76ae\u80a4\u75c5\u53d8\u989c\u8272\u662f\u8bca\u65ad\u9ed1\u8272\u7d20\u7624\u7b49\u76ae\u80a4\u75be\u75c5\u7684\u91cd\u8981\u7279\u5f81\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u672a\u5145\u5206\u5229\u7528\u989c\u8272\u6570\u91cf\u8fd9\u4e00\u7279\u5f81\u3002\u989c\u8272\u6570\u91cf\u53ef\u4ee5\u6307\u793a\u75be\u75c5\u4e25\u91cd\u7a0b\u5ea6\uff0c\u5e2e\u52a9\u533a\u5206\u6076\u6027\u9ed1\u8272\u7d20\u7624\u548c\u826f\u6027\u75c5\u53d8\u3002", "method": "1. \u63d0\u51fa\u989c\u8272\u76f4\u65b9\u56fe\u5206\u6790\u65b9\u6cd5\uff0c\u4ecePH2\u3001ISIC2016\u548cMed Node\u4e09\u4e2a\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u75c5\u53d8\u50cf\u7d20\u503c\uff1b2. \u57fa\u4e8ePH2\u7684\u771f\u5b9e\u6807\u6ce8\uff0c\u901a\u8fc7\u989c\u8272\u76f4\u65b9\u56fe\u5206\u6790\u4f30\u8ba1\u5176\u4ed6\u6570\u636e\u96c6\u7684\u771f\u5b9e\u989c\u8272\u6570\u91cf\uff1b3. \u8bbe\u8ba1\u5e76\u8bad\u7ec319\u5c42\u5e26\u6b8b\u5dee\u8df3\u8dc3\u8fde\u63a5\u7684CNN\uff0c\u5c06\u75c5\u53d8\u6309\u989c\u8272\u6570\u91cf\u5206\u4e3a\u4e09\u7c7b\uff1b4. \u4f7f\u7528DeepDream\u53ef\u89c6\u5316\u7f51\u7edc\u5b66\u4e60\u7279\u5f81\uff0c\u6d4b\u8bd5\u591a\u79cdCNN\u914d\u7f6e\uff1b5. \u5e94\u7528LIME\u8bc6\u522b\u5f71\u54cd\u6a21\u578b\u51b3\u7b56\u7684\u91cd\u8981\u533a\u57df\u3002", "result": "\u6700\u4f73\u6a21\u578b\u8fbe\u5230\u52a0\u6743F1\u5206\u657075%\u3002LIME\u5206\u6790\u663e\u793a\u6a21\u578b\u51b3\u7b56\u53d7\u7279\u5b9a\u533a\u57df\u5f71\u54cd\u3002\u7ed3\u679c\u8868\u660e\u75c5\u53d8\u989c\u8272\u6570\u91cf\u662f\u63cf\u8ff0\u76ae\u80a4\u72b6\u51b5\u7684\u91cd\u8981\u7279\u5f81\uff0c\u63d0\u51fa\u7684\u5e26\u4e09\u4e2a\u8df3\u8dc3\u8fde\u63a5\u7684CNN\u5728\u4e34\u5e8a\u8bca\u65ad\u652f\u6301\u65b9\u9762\u5177\u6709\u5f3a\u5927\u6f5c\u529b\u3002", "conclusion": "\u75c5\u53d8\u989c\u8272\u6570\u91cf\u662f\u76ae\u80a4\u75c5\u53d8\u5206\u6790\u7684\u91cd\u8981\u7279\u5f81\uff0c\u63d0\u51fa\u7684CNN\u65b9\u6cd5\u80fd\u6709\u6548\u5206\u7c7b\u75c5\u53d8\u989c\u8272\u6570\u91cf\uff0c\u4e3a\u4e34\u5e8a\u8bca\u65ad\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u652f\u6301\u5de5\u5177\u3002\u989c\u8272\u6570\u91cf\u7279\u5f81\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u76ae\u80a4\u75c5\u53d8\u8bca\u65ad\u4e2d\u5177\u6709\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2601.20878", "pdf": "https://arxiv.org/pdf/2601.20878", "abs": "https://arxiv.org/abs/2601.20878", "authors": ["Xingjian Zhang", "Claire Leclech", "Louison Blivet-Bailly", "Abdul I. Barakat", "Elsa D. Angelini"], "title": "Log Focal Frequency Loss for Bioimage Restoration", "categories": ["q-bio.QM"], "comment": "This paper has been accepted to IEEE ISBI 2026", "summary": "Image restoration of biological structures in microscopy poses unique challenges for preserving fine textures and sharp edges. While recent GAN-based image restoration formulations have introduced frequency-domain losses for natural images, microscopy images pose distinct challenges with large dynamic ranges and sparse but critical structures with spatially-variable contrast. Inspired by the principle of logarithmic perception in human vision, we propose a log focal frequency loss (LFFL) tailored for microscopy restoration. This loss combines adaptive spectral weighting from log-space differences with log-dampened error measurement, ensuring balanced reconstruction across all frequency bands while preserving both structural coherence and fine details. We tested our GAN-based framework on two use-cases with real ground-truths: deblurring of fluorescence images of cell nuclei on microgroove substrates and denoising of zebrafish embryo images from the FMD dataset. Compared to training with only spatial-domain losses and with existing frequency-domain losses, our method achieves improvements across several quality metrics. Code is available at github.com/xjzhaang/log-focal-frequency-loss.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u663e\u5fae\u955c\u56fe\u50cf\u6062\u590d\u7684\u5bf9\u6570\u7126\u70b9\u9891\u7387\u635f\u5931(LFFL)\uff0c\u7ed3\u5408\u5bf9\u6570\u611f\u77e5\u539f\u7406\uff0c\u5728\u8367\u5149\u7ec6\u80de\u6838\u53bb\u6a21\u7cca\u548c\u6591\u9a6c\u9c7c\u80da\u80ce\u53bb\u566a\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u663e\u5fae\u955c\u56fe\u50cf\u6062\u590d\u9762\u4e34\u72ec\u7279\u6311\u6218\uff1a\u9700\u8981\u4fdd\u62a4\u7cbe\u7ec6\u7eb9\u7406\u548c\u9510\u5229\u8fb9\u7f18\uff0c\u540c\u65f6\u5904\u7406\u5927\u52a8\u6001\u8303\u56f4\u548c\u7a7a\u95f4\u5bf9\u6bd4\u5ea6\u53d8\u5316\u7684\u5173\u952e\u7a00\u758f\u7ed3\u6784\u3002\u73b0\u6709GAN\u65b9\u6cd5\u4e2d\u7684\u9891\u7387\u57df\u635f\u5931\u4e3b\u8981\u9488\u5bf9\u81ea\u7136\u56fe\u50cf\u8bbe\u8ba1\uff0c\u4e0d\u9002\u7528\u4e8e\u663e\u5fae\u955c\u56fe\u50cf\u7684\u7279\u6b8a\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u5bf9\u6570\u7126\u70b9\u9891\u7387\u635f\u5931(LFFL)\uff0c\u57fa\u4e8e\u4eba\u7c7b\u89c6\u89c9\u7684\u5bf9\u6570\u611f\u77e5\u539f\u7406\uff0c\u7ed3\u5408\u5bf9\u6570\u7a7a\u95f4\u5dee\u5f02\u7684\u81ea\u9002\u5e94\u9891\u8c31\u52a0\u6743\u548c\u5bf9\u6570\u963b\u5c3c\u8bef\u5dee\u6d4b\u91cf\uff0c\u786e\u4fdd\u6240\u6709\u9891\u5e26\u7684\u5e73\u8861\u91cd\u5efa\uff0c\u540c\u65f6\u4fdd\u6301\u7ed3\u6784\u8fde\u8d2f\u6027\u548c\u7cbe\u7ec6\u7ec6\u8282\u3002", "result": "\u5728\u8367\u5149\u7ec6\u80de\u6838\u53bb\u6a21\u7cca\u548c\u6591\u9a6c\u9c7c\u80da\u80ce\u53bb\u566a\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u76f8\u6bd4\u4ec5\u4f7f\u7528\u7a7a\u95f4\u57df\u635f\u5931\u548c\u73b0\u6709\u9891\u7387\u57df\u635f\u5931\u7684\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u8d28\u91cf\u6307\u6807\u4e0a\u5747\u6709\u6539\u8fdb\u3002", "conclusion": "\u9488\u5bf9\u663e\u5fae\u955c\u56fe\u50cf\u6062\u590d\u8bbe\u8ba1\u7684\u5bf9\u6570\u7126\u70b9\u9891\u7387\u635f\u5931(LFFL)\u80fd\u6709\u6548\u5904\u7406\u5927\u52a8\u6001\u8303\u56f4\u548c\u7a00\u758f\u7ed3\u6784\uff0c\u5728\u4fdd\u6301\u7ed3\u6784\u8fde\u8d2f\u6027\u548c\u7cbe\u7ec6\u7ec6\u8282\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.20891", "pdf": "https://arxiv.org/pdf/2601.20891", "abs": "https://arxiv.org/abs/2601.20891", "authors": ["Hajung Kim", "Eunha Lee", "Sohyun Chung", "Jueon Park", "Seungheun Baek", "Jaewoo Kang"], "title": "ATTNSOM: Learning Cross-Isoform Attention for Cytochrome P450 Site-of-Metabolism", "categories": ["q-bio.QM", "cs.LG"], "comment": "14 pages", "summary": "Identifying metabolic sites where cytochrome P450 enzymes metabolize small-molecule drugs is essential for drug discovery. Although existing computational approaches have been proposed for site-of-metabolism prediction, they typically ignore cytochrome P450 isoform identity or model isoforms independently, thereby failing to fully capture inherent cross-isoform metabolic patterns. In addition, prior evaluations often rely on top-k metrics, where false positive atoms may be included among the top predictions, underscoring the need for complementary metrics that more directly assess binary atom-level discrimination under severe class imbalance. We propose ATTNSOM, an atom-level site-of-metabolism prediction framework that integrates intrinsic molecular reactivity with cross-isoform relationships. The model combines a shared graph encoder, molecule-conditioned atom representations, and a cross-attention mechanism to capture correlated metabolic patterns across cytochrome P450 isoforms. The model is evaluated on two benchmark datasets annotated with site-of-metabolism labels at atom resolution. Across these benchmarks, the model achieves consistently strong top-k performance across multiple cytochrome P450 isoforms. Relative to ablated variants, the model yields higher Matthews correlation coefficient, indicating improved discrimination of true metabolic sites. These results support the importance of explicitly modeling cross-isoform relationships for site-of-metabolism prediction. The code and datasets are available at https://github.com/dmis-lab/ATTNSOM.", "AI": {"tldr": "ATTNSOM\u662f\u4e00\u4e2a\u7528\u4e8e\u9884\u6d4b\u7ec6\u80de\u8272\u7d20P450\u9176\u4ee3\u8c22\u4f4d\u70b9\u7684\u539f\u5b50\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u56fe\u7f16\u7801\u5668\u3001\u5206\u5b50\u6761\u4ef6\u539f\u5b50\u8868\u793a\u548c\u8de8\u5f02\u6784\u4f53\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6574\u5408\u5206\u5b50\u56fa\u6709\u53cd\u5e94\u6027\u548c\u8de8\u5f02\u6784\u4f53\u5173\u7cfb\uff0c\u5728\u4e25\u91cd\u7c7b\u522b\u4e0d\u5e73\u8861\u4e0b\u6539\u5584\u4ee3\u8c22\u4f4d\u70b9\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8ba1\u7b97\u65b9\u6cd5\u901a\u5e38\u5ffd\u7565P450\u5f02\u6784\u4f53\u8eab\u4efd\u6216\u72ec\u7acb\u5efa\u6a21\u5f02\u6784\u4f53\uff0c\u672a\u80fd\u5145\u5206\u6355\u6349\u8de8\u5f02\u6784\u4f53\u4ee3\u8c22\u6a21\u5f0f\uff0c\u4e14\u8bc4\u4f30\u6307\u6807\u4e3b\u8981\u4f9d\u8d56top-k\u5ea6\u91cf\uff0c\u5728\u4e25\u91cd\u7c7b\u522b\u4e0d\u5e73\u8861\u4e0b\u9700\u8981\u66f4\u76f4\u63a5\u7684\u4e8c\u5143\u539f\u5b50\u7ea7\u5224\u522b\u6307\u6807\u3002", "method": "\u63d0\u51faATTNSOM\u6846\u67b6\uff0c\u7ed3\u5408\u5171\u4eab\u56fe\u7f16\u7801\u5668\u3001\u5206\u5b50\u6761\u4ef6\u539f\u5b50\u8868\u793a\u548c\u8de8\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6574\u5408\u5206\u5b50\u56fa\u6709\u53cd\u5e94\u6027\u4e0e\u8de8\u5f02\u6784\u4f53\u5173\u7cfb\uff0c\u6355\u6349P450\u5f02\u6784\u4f53\u95f4\u7684\u76f8\u5173\u4ee3\u8c22\u6a21\u5f0f\u3002", "result": "\u5728\u4e24\u4e2a\u539f\u5b50\u7ea7\u6807\u6ce8\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u5728\u591a\u4e2aP450\u5f02\u6784\u4f53\u4e0a\u5747\u53d6\u5f97\u4e00\u81f4\u7684\u5f3atop-k\u6027\u80fd\uff0c\u76f8\u6bd4\u6d88\u878d\u53d8\u4f53\u83b7\u5f97\u66f4\u9ad8\u7684\u9a6c\u4fee\u65af\u76f8\u5173\u7cfb\u6570\uff0c\u8868\u660e\u5bf9\u771f\u5b9e\u4ee3\u8c22\u4f4d\u70b9\u7684\u5224\u522b\u80fd\u529b\u6709\u6240\u6539\u5584\u3002", "conclusion": "\u7ed3\u679c\u652f\u6301\u663e\u5f0f\u5efa\u6a21\u8de8\u5f02\u6784\u4f53\u5173\u7cfb\u5bf9\u4ee3\u8c22\u4f4d\u70b9\u9884\u6d4b\u7684\u91cd\u8981\u6027\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.22128", "pdf": "https://arxiv.org/pdf/2601.22128", "abs": "https://arxiv.org/abs/2601.22128", "authors": ["Irsyad Adam", "Zekai Chen", "David Laprade", "Shaun Porwal", "David Laub", "Erik Reinertsen", "Arda Pekis", "Kevin Brown"], "title": "The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR", "categories": ["cs.AI", "cs.CE", "q-bio.QM"], "comment": null, "summary": "Large language models (LLMs) trained with next-word-prediction have achieved success as clinical foundation models. Representations from these language backbones yield strong linear probe performance across biomedical tasks, suggesting that patient semantics emerge from next-token prediction at scale. However, this paradigm treats patients as a document to be summarized rather than a dynamical system to be simulated; a patient's trajectory emerges from their state evolving under interventions and time, requiring models that simulate dynamics rather than predict tokens. To address this, we introduce SMB-Structure, a world model for structured EHR that grounds a joint-embedding prediction architecture (JEPA) with next-token prediction (SFT). SFT grounds our model to reconstruct future patient states in token space, while JEPA predicts those futures in latent space from the initial patient representation alone, forcing trajectory dynamics to be encoded before the next state is observed. We validate across two large-scale cohorts: Memorial Sloan Kettering (23,319 oncology patients; 323,000+ patient-years) and INSPECT (19,402 pulmonary embolism patients). Using a linear probe evaluated at multiple points along the disease trajectory, we demonstrate that our training paradigm learns embeddings that capture disease dynamics not recoverable by autoregressive baselines, enabling SMB-Structure to achieve competitive performance on complex tasks characterized by high patient heterogeneity. Model weights are available at https://huggingface.co/standardmodelbio/SMB-v1-1.7B-Structure.", "AI": {"tldr": "SMB-Structure\uff1a\u4e00\u79cd\u7528\u4e8e\u7ed3\u6784\u5316\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7684\u4e16\u754c\u6a21\u578b\uff0c\u7ed3\u5408\u8054\u5408\u5d4c\u5165\u9884\u6d4b\u67b6\u6784\u548c\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\uff0c\u80fd\u591f\u6a21\u62df\u60a3\u8005\u52a8\u6001\u800c\u975e\u4ec5\u9884\u6d4b\u6807\u8bb0", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\u7684LLMs\u5c06\u60a3\u8005\u89c6\u4e3a\u9700\u8981\u603b\u7ed3\u7684\u6587\u6863\uff0c\u800c\u975e\u9700\u8981\u6a21\u62df\u7684\u52a8\u6001\u7cfb\u7edf\u3002\u60a3\u8005\u8f68\u8ff9\u662f\u72b6\u6001\u5728\u5e72\u9884\u548c\u65f6\u95f4\u4f5c\u7528\u4e0b\u7684\u6f14\u5316\uff0c\u9700\u8981\u80fd\u591f\u6a21\u62df\u52a8\u6001\u800c\u975e\u4ec5\u9884\u6d4b\u6807\u8bb0\u7684\u6a21\u578b", "method": "\u63d0\u51faSMB-Structure\u6a21\u578b\uff0c\u7ed3\u5408\u8054\u5408\u5d4c\u5165\u9884\u6d4b\u67b6\u6784\u548c\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\u3002JEPA\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u4ece\u521d\u59cb\u60a3\u8005\u8868\u793a\u9884\u6d4b\u672a\u6765\u72b6\u6001\uff0c\u800cSFT\u5728\u6807\u8bb0\u7a7a\u95f4\u4e2d\u91cd\u5efa\u672a\u6765\u60a3\u8005\u72b6\u6001\uff0c\u8feb\u4f7f\u8f68\u8ff9\u52a8\u6001\u5728\u89c2\u5bdf\u5230\u4e0b\u4e00\u4e2a\u72b6\u6001\u4e4b\u524d\u5c31\u88ab\u7f16\u7801", "result": "\u5728\u4e24\u4e2a\u5927\u89c4\u6a21\u961f\u5217\uff08MSK\u764c\u75c7\u60a3\u8005\u548cINSPECT\u80ba\u6813\u585e\u60a3\u8005\uff09\u4e0a\u9a8c\u8bc1\uff0c\u7ebf\u6027\u63a2\u9488\u8bc4\u4f30\u663e\u793a\u8be5\u8bad\u7ec3\u8303\u5f0f\u5b66\u4e60\u7684\u5d4c\u5165\u80fd\u6355\u6349\u81ea\u56de\u5f52\u57fa\u7ebf\u65e0\u6cd5\u6062\u590d\u7684\u75be\u75c5\u52a8\u6001\uff0c\u5728\u9ad8\u5ea6\u5f02\u8d28\u6027\u60a3\u8005\u7fa4\u4f53\u7684\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02", "conclusion": "SMB-Structure\u901a\u8fc7\u7ed3\u5408JEPA\u548cSFT\uff0c\u80fd\u591f\u6709\u6548\u6a21\u62df\u60a3\u8005\u52a8\u6001\uff0c\u4e3a\u4e34\u5e8a\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u8303\u5f0f\uff0c\u6a21\u578b\u6743\u91cd\u5df2\u5f00\u6e90"}}
