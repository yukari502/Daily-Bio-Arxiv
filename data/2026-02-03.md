<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 6]
- [q-bio.MN](#q-bio.MN) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 6]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [Toward Interpretable and Generalizable AI in Regulatory Genomics](https://arxiv.org/abs/2602.01230)
*Masayuki Nagai,Alan E. Murphy,Kaeli Rizzo,Peter K. Koo*

Main category: q-bio.GN

TL;DR: 该论文探讨了序列到功能（seq2func）模型在基因调控预测中的现状、局限性和未来发展方向，强调需要建立AI-实验反馈循环来提升模型的机制理解和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管序列到功能模型在预测分子调控输出方面表现出色，但它们在遗传变异和细胞环境中的泛化能力不一致，且预测准确性并不总能转化为可靠的调控机制理解。

Method: 通过分析架构选择、训练数据和预测任务如何影响seq2func模型的行为，综合可解释性方法和评估实践来探究学习到的顺式调控组织，并识别系统性失败模式。

Result: 研究发现，尽管seq2func模型在保留基因组区域上表现良好，但其泛化能力有限，且预测准确性并不总能转化为对调控机制的深入理解。

Conclusion: 需要将seq2func模型重构为持续优化的系统，通过AI-实验反馈循环将靶向扰动实验、系统评估和迭代模型更新紧密结合，使模型成为具有自我改进能力、机制基础不断深化、更可靠支持生物学发现的工具。

Abstract: Deciphering how DNA sequence encodes gene regulation remains a central challenge in biology. Advances in machine learning and functional genomics have enabled sequence-to-function (seq2func) models that predict molecular regulatory readouts directly from DNA sequence. These models are now widely used for variant effect prediction, mechanistic interpretation, and regulatory sequence design. Despite strong performance on held-out genomic regions, their ability to generalize across genetic variation and cellular contexts remains inconsistent. Here we examine how architectural choices, training data, and prediction tasks shape the behavior of seq2func models. We synthesize how interpretability methods and evaluation practices have probed learned cis-regulatory organization and highlighted systematic failure modes, clarifying why strong predictive accuracy can fail to translate into robust regulatory understanding. We argue that progress will require reframing seq2func models as continually refined systems, in which targeted perturbation experiments, systematic evaluation, and iterative model updates are tightly coupled through AI-experiment feedback loops. Under this framework, seq2func models become self-improving tools that progressively deepen their mechanistic grounding and more reliably support biological discovery.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [2] [Early warning prediction: Onsager-Machlup vs Schrödinger](https://arxiv.org/abs/2602.00143)
*Xiaoai Xu,Yixuan Zhou,Xiang Zhou,Jingqiao Duan,Ting Gao*

Main category: q-bio.QM

TL;DR: 提出结合流形学习和随机动力系统建模的癫痫发作早期预警框架，通过降维和概率演化评分函数实现更早、更鲁棒的预测


<details>
  <summary>Details</summary>
Motivation: 复杂系统（如大脑癫痫发作）的关键转变预测具有挑战性，高维特性和隐藏的关键信号使早期预警任务更加复杂

Method: 集成流形学习与随机动力系统建模：1）选择扩散映射等6种方法构建低维表示；2）建立数据驱动的随机微分方程模型估计系统概率演化评分函数；3）结合薛定谔桥理论定义新的评分函数指标量化系统状态转变可能性

Result: 该指标在癫痫预测中表现出更高的敏感性和鲁棒性，能够更早识别关键点，清晰捕捉癫痫发作前后各阶段的动态特征

Conclusion: 为从高维数据中提取早期预警信号提供了系统的理论框架和实用方法

Abstract: Predicting critical transitions in complex systems, such as epileptic seizures in the brain, represents a major challenge in scientific research. The high-dimensional characteristics and hidden critical signals further complicate early-warning tasks. This study proposes a novel early-warning framework that integrates manifold learning with stochastic dynamical system modeling. Through systematic comparison, six methods including diffusion maps (DM) are selected to construct low-dimensional representations. Based on these, a data-driven stochastic differential equation model is established to robustly estimate the probability evolution scoring function of the system. Building on this, a new Score Function (SF) indicator is defined by incorporating Schrödinger bridge theory to quantify the likelihood of significant state transitions in the system. Experiments demonstrate that this indicator exhibits higher sensitivity and robustness in epilepsy prediction, enables earlier identification of critical points, and clearly captures dynamic features across various stages before and after seizure onset. This work provides a systematic theoretical framework and practical methodology for extracting early-warning signals from high-dimensional data.

</details>


### [3] [ProDCARL: Reinforcement Learning-Aligned Diffusion Models for De Novo Antimicrobial Peptide Design](https://arxiv.org/abs/2602.00157)
*Fang Sheng,Mohammad Noaeen,Zahra Shakeri*

Main category: q-bio.QM

TL;DR: ProDCARL是一个强化学习框架，通过扩散模型生成具有高抗菌活性和低毒性的抗菌肽，显著提升了预测质量。


<details>
  <summary>Details</summary>
Motivation: 抗菌素耐药性威胁医疗可持续性，需要低成本计算发现抗菌肽。传统基于似然的生成器无法明确优化抗菌活性和安全性目标。

Method: 提出ProDCARL强化学习对齐框架，结合扩散蛋白生成器(EvoDiff OA-DM 38M)和序列性质预测器，通过微调扩散先验获得领域感知生成器，使用top-k策略梯度更新、分类器奖励、熵正则化和早停来保持多样性。

Result: 预测AMP分数从微调后的0.081提升到0.178，联合高质量命中率达到6.3%，保持高多样性(1-平均成对同一性=0.929)，AlphaFold3和ProtBERT分析显示候选肽具有合理的AMP样结构和语义特征。

Conclusion: ProDCARL作为候选生成器能缩小实验搜索空间，但实验验证仍需未来工作。

Abstract: Antimicrobial resistance threatens healthcare sustainability and motivates low-cost computational discovery of antimicrobial peptides (AMPs). De novo peptide generation must optimize antimicrobial activity and safety through low predicted toxicity, but likelihood-trained generators do not enforce these goals explicitly. We introduce ProDCARL, a reinforcement-learning alignment framework that couples a diffusion-based protein generator (EvoDiff OA-DM 38M) with sequence property predictors for AMP activity and peptide toxicity. We fine-tune the diffusion prior on AMP sequences to obtain a domain-aware generator. Top-k policy-gradient updates use classifier-derived rewards plus entropy regularization and early stopping to preserve diversity and reduce reward hacking. In silico experiments show ProDCARL increases the mean predicted AMP score from 0.081 after fine-tuning to 0.178. The joint high-quality hit rate reaches 6.3\% with pAMP $>$0.7 and pTox $<$0.3. ProDCARL maintains high diversity, with $1-$mean pairwise identity equal to 0.929. Qualitative analyses with AlphaFold3 and ProtBERT embeddings suggest candidates show plausible AMP-like structural and semantic characteristics. ProDCARL serves as a candidate generator that narrows experimental search space, and experimental validation remains future work.

</details>


### [4] [Rank-and-Reason: Multi-Agent Collaboration Accelerates Zero-Shot Protein Mutation Prediction](https://arxiv.org/abs/2602.00197)
*Yang Tan,Yuyuan Xi,Can Wu,Bozitao Zhong,Mingchen Li,Guisheng Fan,Jiankang Zhu,Yafeng Liang,Nanqing Dong,Liang Hong*

Main category: q-bio.QM

TL;DR: VenusRAR是一个两阶段代理框架，用于自动化蛋白质突变预测，通过排序和推理阶段提高湿实验室验证成功率


<details>
  <summary>Details</summary>
Motivation: 现有蛋白质语言模型（PLMs）的预测结果虽然统计置信度高，但忽略了基本的生物物理约束。目前依赖专家手动审核PLM输出的方式效率低下、主观性强且高度依赖领域专业知识。

Method: 提出Rank-and-Reason（VenusRAR）两阶段代理框架：1）排序阶段：计算专家和虚拟生物学家聚合上下文感知的多模态集成；2）推理阶段：专家小组使用思维链推理审核候选突变是否符合几何和结构约束。

Result: 在ProteinGym上创造了0.551的Spearman相关新记录（vs. 0.518）；在ProteinGym-DMS99上将Top-5命中率提高了367%；Cas12i3核酸酶的湿实验室验证显示46.7%阳性率，并发现两个具有4.23倍和5.05倍活性提升的新突变体。

Conclusion: VenusRAR框架通过自动化蛋白质突变预测工作流程，显著提高了湿实验室验证的成功率，为低资源蛋白质工程提供了有效的解决方案。

Abstract: Zero-shot mutation prediction is vital for low-resource protein engineering, yet existing protein language models (PLMs) often yield statistically confident results that ignore fundamental biophysical constraints. Currently, selecting candidates for wet-lab validation relies on manual expert auditing of PLM outputs, a process that is inefficient, subjective, and highly dependent on domain expertise. To address this, we propose Rank-and-Reason (VenusRAR), a two-stage agentic framework to automate this workflow and maximize expected wet-lab fitness. In the Rank-Stage, a Computational Expert and Virtual Biologist aggregate a context-aware multi-modal ensemble, establishing a new Spearman correlation record of 0.551 (vs. 0.518) on ProteinGym. In the Reason-Stage, an agentic Expert Panel employs chain-of-thought reasoning to audit candidates against geometric and structural constraints, improving the Top-5 Hit Rate by up to 367% on ProteinGym-DMS99. The wet-lab validation on Cas12i3 nuclease further confirms the framework's efficacy, achieving a 46.7% positive rate and identifying two novel mutants with 4.23-fold and 5.05-fold activity improvements. Code and datasets are released on GitHub (https://github.com/ai4protein/VenusRAR/).

</details>


### [5] [A 30-item Test for Assessing Chinese Character Amnesia in Child Handwriters](https://arxiv.org/abs/2602.00464)
*Zebo Xu,Steven Langsford,Zhuang Qiu,Zhenguang Cai*

Main category: q-bio.QM

TL;DR: 开发了一个评估汉语儿童汉字失写症的30项简短测试，通过IRT模型和项目选择方案优化，能有效识别早期书写困难


<details>
  <summary>Details</summary>
Motivation: 在数字时代，手写能力下降，特别是非字母文字系统。学习汉语的儿童中，越来越多出现"汉字失写症"（能认字但不会写），目前缺乏标准化的诊断工具

Method: 使用40名儿童听写800个汉字的大规模数据集，采用双参数项目反应理论模型分析汉字失写症和正确书写反应。比较了四种项目选择方案：随机基线、最大区分度、难度多样性、上下三分之一区分度评分

Result: 上下三分之一区分度程序产生了30个项目的紧凑测试，保留了个体差异结构，并能泛化到未见过的测试者（交叉验证平均r=0.74与完整800项测试；样本内r=0.93）

Conclusion: 这个简短测试为评估儿童汉字失写症提供了可靠高效的工具，可用于识别早期书写和正字法学习困难，有助于早期发现发展性书写障碍和相关读写挑战

Abstract: Handwriting literacy is an important skill for learning and communication in school-age children. In the digital age, handwriting has been largely replaced by typing, leading to a decline in handwriting proficiency, particularly in non-alphabetic writing systems. Among children learning Chinese, a growing number have reported experiencing character amnesia: difficulty in correctly handwriting a character despite being able to recognize it. Given that there is currently no standardized diagnostic tool for assessing character amnesia in children, we developed an assessment to measure Chinese character amnesia in Mandarin-speaking school-age population. We utilised a large-scale handwriting dataset in which 40 children handwrote 800 characters from dictation prompts. Character amnesia and correct handwriting responses were analysed using a two-parameter Item Response Theory model. Four item-selection schemes were compared: random baseline, maximum discrimination, diverse difficulty, and an upper-and-lower-thirds discrimination score. Candidate item subsets were evaluated using out-of-sample prediction. Among these selection schemes, the upper-and-lower-thirds discrimination procedure yields a compact 30-item test that preserves individual-difference structure and generalizes to unseen test-takers (cross-validated mean r =.74 with full 800-item-test; within-sample r =.93). This short-form test provides a reliable and efficient tool of assessing Chinese character amnesia in children and can be used to identify early handwriting and orthographic learning difficulties, contributing to the early detection of developmental dysgraphia and related literacy challenges.

</details>


### [6] [INDIGENA: inductive prediction of disease-gene associations using phenotype ontologies](https://arxiv.org/abs/2602.01088)
*Fernando Zhapa-Camacho,Robert Hoehndorf*

Main category: q-bio.QM

TL;DR: INDIGENA是一种基于表型集合的基因-疾病关联预测方法，使用图嵌入和显式聚合策略，能够推广到新的疾病表型集合，性能接近转导方法但更具通用性。


<details>
  <summary>Details</summary>
Motivation: 预测基因-疾病关联（GDA）是一个排序问题，传统基于本体语义相似性的方法只使用本体分类结构，而基于本体嵌入的方法虽然能利用所有本体公理和监督信号，但本质上是转导式的，无法推广到推理时的新疾病（表型集合）。

Method: 首先通过图投影将表型本体公理映射到图结构，然后使用图嵌入创建表型的潜在表示。采用显式聚合策略将表型嵌入组合成基因或疾病的表示，从而能够推广到新的表型集合。还开发了方法通过已知基因-疾病关联的监督信号使表型嵌入和相似性度量具有任务特异性。

Result: 应用于人类疾病小鼠模型时，该方法显著优于归纳语义相似性基线方法，在预测基因-疾病关联方面达到与转导方法相似的性能，同时更具通用性。

Conclusion: INDIGENA是一种有效的归纳式基因-疾病关联预测方法，能够处理新的疾病表型集合，在保持性能的同时提高了方法的通用性和可推广性。

Abstract: Motivation: Predicting gene-disease associations (GDAs) is the problem to determine which gene is associated with a disease. GDA prediction can be framed as a ranking problem where genes are ranked for a query disease, based on features such as phenotypic similarity. By describing phenotypes using phenotype ontologies, ontology-based semantic similarity measures can be used. However, traditional semantic similarity measures use only the ontology taxonomy. Recent methods based on ontology embeddings compare phenotypes in latent space; these methods can use all ontology axioms as well as a supervised signal, but are inherently transductive, i.e., query entities must already be known at the time of learning embeddings, and therefore these methods do not generalize to novel diseases (sets of phenotypes) at inference time.
  Results: We developed INDIGENA, an inductive disease-gene association method for ranking genes based on a set of phenotypes. Our method first uses a graph projection to map axioms from phenotype ontologies to a graph structure, and then uses graph embeddings to create latent representations of phenotypes. We use an explicit aggregation strategy to combine phenotype embeddings into representations of genes or diseases, allowing us to generalize to novel sets of phenotypes. We also develop a method to make the phenotype embeddings and the similarity measure task-specific by including a supervised signal from known gene-disease associations. We apply our method to mouse models of human disease and demonstrate that we can significantly improve over the inductive semantic similarity baseline measures, and reach a performance similar to transductive methods for predicting gene-disease associations while being more general.
  Availability and Implementation: https://github.com/bio-ontology-research-group/indigena

</details>


### [7] [Is Normalized Biomass Really Abundance? Pitfalls, Artifacts, and Misconceptions in the Field of Size Spectra Analysis -- A Case for Back-Transformed Spectra](https://arxiv.org/abs/2602.01496)
*Ralf Schwamborn*

Main category: q-bio.QM

TL;DR: 该研究揭示了传统归一化生物量大小谱(NBSS)方法存在单位混淆和偏差问题，提出了新的概念框架、术语、反变换方法和计算方法，开发了反变换归一化生物量谱(bNBS)作为改进方案。


<details>
  <summary>Details</summary>
Motivation: 尽管NBSS是研究自然生态系统的常用直观方法，但很少有研究验证该方法可能存在的偏差、缺陷和悖论。一个明显问题是NBSS图中使用了非生物量单位（如丰度、生物量通量或伪丰度单位），而该图本应可视化生物量谱。需要验证NBSS是否真正代表生物量而非丰度或生物量通量。

Method: 研究通过现场数据和合成（模拟）数据验证了导致流行NBSS图的变换过程，比较了原始生物量分布数据与分箱输出。开发了新的概念框架、术语、反变换方法和简单的新计算方法，保留了原始生物量单位和维度。

Result: 提出了反变换归一化生物量谱(bNBS)，该方法能最好地（即偏差最小）表示原始生物量随体重分布的形态、数值、维度和单位。bNBS保留了原始生物量单位和维度，允许跨区域和时间段的生物量谱定量比较。

Conclusion: bNBS构成了一个改进的、稳健的大小谱科学新方法，解决了传统NBSS的单位混淆和偏差问题，为生态系统生物量谱的定量比较提供了可靠工具。

Abstract: The NBSS (normalized biomass size spectrum) is a common, intuitive approach for the study of natural ecosystems. However, very few studies have been dedicated to verifying possible bias, flaws, and paradoxes in this widely used method. An evident issue of this method, that best exemplifies its discrepancies and paradoxes, is the use of intriguing non-biomass units (such as abundance, biomass flux, or pseudo-abundance units) on NBSS plots, that are intended to visualize biomass spectra. The main objectives of this study were to verify, test and analyze the procedures involved in transformations that lead to the popular NBSS plot, and to check for the correctness of currently used units, while testing the hypothesis that NBSS indeed represents biomass, not abundance or biomass flux (dB/dM), while developing i.) a new conceptual framework, ii.) new terminology, iii.) a novel back-transformation method, iv.) a simple, new calculation method, that yields the best (i.e., least biased) representation of the original biomass vs body mass distribution shape, numerical values, dimensions, and units. Extensive tests with in-situ and synthetic (simulated) data were used to verify the procedures involved in transformations that lead to the popular NBSS plots, and to compare the original biomass distribution data with the binned outputs. Original biomass units and dimensions are retained in the novel backtransformed normalized biomass spectrum (bNBS), proposed and described herein. The proposed bNBS constitutes a new, improved approach of robust size spectra science, that allows for quantitative inter-comparisons of biomass spectra across regions and time periods.

</details>


<div id='q-bio.MN'></div>

# q-bio.MN [[Back]](#toc)

### [8] [RAG-GNN: Integrating Retrieved Knowledge with Graph Neural Networks for Precision Medicine](https://arxiv.org/abs/2602.00586)
*Hasi Hays,William J. Richardson*

Main category: q-bio.MN

TL;DR: 提出结合图神经网络与文献检索的RAG-GNN框架，在生物医学网络分析中实现拓扑结构与功能语义的互补：拓扑方法擅长结构预测，而检索增强方法在功能聚类上表现独特优势。


<details>
  <summary>Details</summary>
Motivation: 传统网络拓扑方法能很好预测结构关系，但无法捕捉生物医学文献中编码的功能语义信息。需要开发能同时利用结构拓扑和文献知识的方法来提升生物医学网络的功能解释能力。

Method: 提出检索增强生成(RAG)嵌入框架，通过对比学习将图神经网络表示与动态检索的文献知识相结合。使用信息论分解分析不同信息源的贡献，并在癌症信号网络(379个蛋白，3,498个相互作用)上进行应用验证。

Result: 基准测试显示：拓扑方法在链接预测上表现优异(GCN: 0.983 AUROC)，而RAG-GNN是唯一在功能聚类上获得正轮廓系数的方法(0.001 vs. 所有基线均为负值)。信息论分解表明网络拓扑贡献77.3%预测信息，检索文档提供8.6%独特信息。应用中发现DDR1作为KRAS突变合成致死疗法的潜在靶点。

Conclusion: 拓扑方法和检索增强方法具有互补性：结构预测任务可由网络拓扑单独解决，而功能解释任务则独特受益于检索知识。RAG-GNN框架为生物医学网络分析提供了同时利用结构和语义信息的新途径。

Abstract: Network topology excels at structural predictions but fails to capture functional semantics encoded in biomedical literature. We present a retrieval-augmented generation (RAG) embedding framework that integrates graph neural network representations with dynamically retrieved literature-derived knowledge through contrastive learning. Benchmarking against ten embedding methods reveals task-specific complementarity: topology-focused methods achieve near-perfect link prediction (GCN: 0.983 AUROC), while RAG-GNN is the only method achieving positive silhouette scores for functional clustering (0.001 vs. negative scores for all baselines). Information-theoretic decomposition shows network topology contributes 77.3% of predictive information, while retrieved documents provide 8.6% unique information. Applied to cancer signaling networks (379 proteins, 3,498 interactions), the framework identifies DDR1 as a therapeutic target based on retrieved evidence of synthetic lethality with KRAS mutations. These results establish that topology-only and retrieval-augmented approaches serve complementary purposes: structural prediction tasks are solved by network topology alone, while functional interpretation uniquely benefits from retrieved knowledge.

</details>


### [9] [Recurrent neural chemical reaction networks trained to switch dynamical behaviours through learned bifurcations](https://arxiv.org/abs/2602.02374)
*Alexander Dack,Tomislav Plesa,Thomas E. Ouldridge*

Main category: q-bio.MN

TL;DR: RNCRNs（循环神经化学反应网络）可以被训练来展示分岔行为，包括继承平滑ODE的分岔和通过训练推断不连续参数空间中的分岔。


<details>
  <summary>Details</summary>
Motivation: 自然和合成化学系统在不同环境参数下会表现出不同的动力学行为，这种转变称为分岔。研究如何让化学反应网络展示分岔行为，有助于理解复杂化学系统的动力学特性。

Method: 使用循环神经化学反应网络（RNCRNs），通过两种方法：1）继承平滑ODE定义的分岔；2）训练网络推断分岔，使其在不同参数区域近似不同目标行为，甚至使用ODE-free算法训练特定振荡模式。

Result: RNCRNs能够成功展示分岔行为，包括继承平滑ODE的分岔，以及通过训练推断不连续参数空间中的分岔。网络可以学习产生特定振荡模式，如心形极限环或共存极限环。

Conclusion: RNCRNs不仅可以被训练来重现给定动力学行为，还可以被训练来展示分岔，这为设计和理解复杂化学系统的动力学特性提供了新工具。

Abstract: Both natural and synthetic chemical systems not only exhibit a range of non-trivial dynamics, but also transition between qualitatively different dynamical behaviours as environmental parameters change. Such transitions are called bifurcations. Here, we show that recurrent neural chemical reaction networks (RNCRNs), a class of chemical reaction networks based on recurrent artificial neural networks that can be trained to reproduce a given dynamical behaviour, can also be trained to exhibit bifurcations. First, we show that RNCRNs can inherit some bifurcations defined by smooth ordinary differential equations (ODEs). Second, we demonstrate that the RNCRN can be trained to infer bifurcations that allow it to approximate different target behaviours within different regions of parameter space, without explicitly providing the bifurcation itself in the training. These behaviours can be specified using target ODEs that are discontinuous with respect to the parameters, or even simply by specifying certain desired dynamical features in certain regions of the parameter space. To achieve the latter, we introduce an ODE-free algorithm for training the RNCRN to display designer oscillations, such as a heart-shaped limit cycle or two coexisting limit cycles.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [10] [Accelerating De Novo Genome Assembly via Quantum-Assisted Graph Optimization with Bitstring Recovery](https://arxiv.org/abs/2602.00156)
*Jaya Vasavi Pamidimukkala,Himanshu Sahu,Ashwini Kannan,Janani Ananthanarayanan,Kalyan Dasgupta,Sanjib Senapati*

Main category: quant-ph

TL;DR: 提出了一种结合量子计算优化算法与经典预处理的新方法，用于加速基因组组装过程，通过HOBO公式和VQE算法解决基因组组装图中的哈密顿和欧拉路径问题。


<details>
  <summary>Details</summary>
Motivation: 基因组组装是基因组测序的关键步骤，但传统的从头组装方法计算复杂度高，影响时间和准确性。量子计算的发展为解决这一复杂问题提供了新的可能性。

Method: 采用混合方法：结合量子计算优化算法（基于门的量子计算）和经典预处理。使用高阶二进制优化（HOBO）公式和变分量子本征求解器（VQE）算法解决基因组组装图中的哈密顿和欧拉路径问题，并引入新的比特串恢复机制以改进优化器在解空间中的遍历。

Result: 与经典优化技术进行比较分析，结果表明随着量子硬件的不断发展和噪声水平的降低，该方法在加速基因组测序方面具有显著潜力，能够为基因组研究中的复杂挑战提供更快、更准确的解决方案。

Conclusion: 量子计算与经典预处理相结合的混合方法在基因组组装中展现出巨大潜力，随着量子技术的进步，有望显著加速基因组测序过程并提高准确性。

Abstract: Genome sequencing is essential to decode genetic information, identify organisms, understand diseases and advance personalized medicine. A critical step in any genome sequencing technique is genome assembly. However, de novo genome assembly, which involves constructing an entire genome sequence from scratch without a reference genome, presents significant challenges due to its high computational complexity, affecting both time and accuracy. In this study, we propose a hybrid approach utilizing a quantum computing-based optimization algorithm integrated with classical pre-processing to expedite the genome assembly process. Specifically, we present a method to solve the Hamiltonian and Eulerian paths within the genome assembly graph using gate-based quantum computing through a Higher-Order Binary Optimization (HOBO) formulation with the Variational Quantum Eigensolver algorithm (VQE), in addition to a novel bitstring recovery mechanism to improve optimizer traversal of the solution space. A comparative analysis with classical optimization techniques was performed to assess the effectiveness of our quantum-based approach in genome assembly. The results indicate that, as quantum hardware continues to evolve and noise levels diminish, our formulation holds a significant potential to accelerate genome sequencing by offering faster and more accurate solutions to the complex challenges in genomic research.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [11] [DOGMA: Weaving Structural Information into Data-centric Single-cell Transcriptomics Analysis](https://arxiv.org/abs/2602.01839)
*Ru Zhang,Xunkai Li,Yaxin Deng,Sicheng Liu,Daohan Su,Qiangqiang Dai,Hongchao Qin,Rong-Hua Li,Guoren Wang,Jia Li*

Main category: cs.LG

TL;DR: DOGMA是一个数据中心的单细胞转录组学分析框架，通过整合多层次的生物学先验知识来重塑数据结构和增强语义，超越了依赖随机启发式的方法，在跨物种和多器官基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有单细胞转录组学分析方法存在两个主要问题：1）早期序列方法将细胞视为独立实体，忽略了生物系统功能机制驱动的细胞间潜在关系；2）结构化方法虽然尝试捕捉细胞间关系，但往往忽视生物学先验知识，导致计算开销大且图表示效果不佳。

Method: DOGMA框架通过整合多层次的生物学先验知识：1）使用统计锚点、细胞本体和系统发育树进行确定性结构发现和稳健的跨物种对齐，重新定义图构建；2）利用基因本体通过功能先验知识弥合特征级语义鸿沟。

Result: 在复杂的多物种和多器官基准测试中，DOGMA实现了最先进的性能，表现出卓越的零样本鲁棒性和样本效率，同时以显著更低的计算成本运行。

Conclusion: DOGMA通过系统性地整合生物学先验知识，为单细胞转录组学分析提供了一个高效的数据中心解决方案，超越了依赖随机启发式的方法，在保持低计算成本的同时实现了优越的性能。

Abstract: Recently, data-centric AI methodology has been a dominant paradigm in single-cell transcriptomics analysis, which treats data representation rather than model complexity as the fundamental bottleneck. In the review of current studies, earlier sequence methods treat cells as independent entities and adapt prevalent ML models to analyze their directly inherited sequence data. Despite their simplicity and intuition, these methods overlook the latent intercellular relationships driven by the functional mechanisms of biological systems and the inherent quality issues of the raw sequence data. Therefore, a series of structured methods has emerged. Although they employ various heuristic rules to capture intricate intercellular relationships and enhance the raw sequencing data, these methods often neglect biological prior knowledge. This omission incurs substantial overhead and yields suboptimal graph representations, thereby hindering the utility of ML models.
  To address them, we propose DOGMA, a holistic data-centric framework designed for the structural reshaping and semantic enhancement of raw data through multi-level biological prior knowledge. Transcending reliance on stochastic heuristics, DOGMA redefines graph construction by integrating Statistical Anchors with Cell Ontology and Phylogenetic Trees to enable deterministic structure discovery and robust cross-species alignment. Furthermore, Gene Ontology is utilized to bridge the feature-level semantic gap by incorporating functional priors. In complex multi-species and multi-organ benchmarks, DOGMA achieves SOTA performance, exhibiting superior zero-shot robustness and sample efficiency while operating with significantly lower computational cost.

</details>


### [12] [MGKAN: Predicting Asymmetric Drug-Drug Interactions via a Multimodal Graph Kolmogorov-Arnold Network](https://arxiv.org/abs/2602.01751)
*Kunyi Fan,Mengjie Chen,Longlong Li,Cunquan Qu*

Main category: cs.LG

TL;DR: MGKAN：基于图Kolmogorov-Arnold网络的药物相互作用预测模型，通过可学习基函数和非对称网络建模提升预测性能


<details>
  <summary>Details</summary>
Motivation: 现有GNN模型主要依赖线性聚合和对称假设，难以捕捉药物相互作用的非线性和异质性模式，限制了DDI预测的准确性

Method: 提出MGKAN模型：1) 用KAN驱动的基函数替代传统MLP变换；2) 整合三个网络视图（非对称DDI网络、共相互作用网络、生化相似性网络）；3) 使用角色特定嵌入保持方向语义；4) 融合线性注意力和非线性变换的融合模块

Result: 在两个基准数据集上，MGKAN超越了七个最先进的基线模型，消融研究和案例研究证实了其预测准确性和建模方向性药物效应的有效性

Conclusion: MGKAN通过引入可学习基函数和非对称网络建模，显著提升了DDI预测的性能，为药物安全性评估提供了更有效的工具

Abstract: Predicting drug-drug interactions (DDIs) is essential for safe pharmacological treatments. Previous graph neural network (GNN) models leverage molecular structures and interaction networks but mostly rely on linear aggregation and symmetric assumptions, limiting their ability to capture nonlinear and heterogeneous patterns. We propose MGKAN, a Graph Kolmogorov-Arnold Network that introduces learnable basis functions into asymmetric DDI prediction. MGKAN replaces conventional MLP transformations with KAN-driven basis functions, enabling more expressive and nonlinear modeling of drug relationships. To capture pharmacological dependencies, MGKAN integrates three network views-an asymmetric DDI network, a co-interaction network, and a biochemical similarity network-with role-specific embeddings to preserve directional semantics. A fusion module combines linear attention and nonlinear transformation to enhance representational capacity. On two benchmark datasets, MGKAN outperforms seven state-of-the-art baselines. Ablation studies and case studies confirm its predictive accuracy and effectiveness in modeling directional drug effects.

</details>


### [13] [DIA-CLIP: a universal representation learning framework for zero-shot DIA proteomics](https://arxiv.org/abs/2602.01772)
*Yucheng Liao,Han Wen,Weinan E,Weijie Zhang*

Main category: cs.LG

TL;DR: DIA-CLIP是一个基于预训练模型的数据非依赖采集质谱分析工具，通过跨模态表示学习实现零样本肽段-谱图匹配，显著提升蛋白质鉴定性能。


<details>
  <summary>Details</summary>
Motivation: 当前DIA-MS分析框架需要每个实验的监督训练，容易过拟合且缺乏跨物种和实验条件的通用性，需要更通用的分析方法。

Method: 采用双编码器对比学习框架与编码器-解码器架构相结合，建立肽段和对应谱图特征的统一跨模态表示，实现高精度零样本PSM推断。

Result: 在多个基准测试中，DIA-CLIP始终优于现有最先进工具，蛋白质鉴定数量增加高达45%，同时诱饵鉴定减少12%。

Conclusion: DIA-CLIP将DIA分析范式从半监督训练转向通用跨模态表示学习，在单细胞和空间蛋白质组学等应用中具有巨大潜力。

Abstract: Data-independent acquisition mass spectrometry (DIA-MS) has established itself as a cornerstone of proteomic profiling and large-scale systems biology, offering unparalleled depth and reproducibility. Current DIA analysis frameworks, however, require semi-supervised training within each run for peptide-spectrum match (PSM) re-scoring. This approach is prone to overfitting and lacks generalizability across diverse species and experimental conditions. Here, we present DIA-CLIP, a pre-trained model shifting the DIA analysis paradigm from semi-supervised training to universal cross-modal representation learning. By integrating dual-encoder contrastive learning framework with encoder-decoder architecture, DIA-CLIP establishes a unified cross-modal representation for peptides and corresponding spectral features, achieving high-precision, zero-shot PSM inference. Extensive evaluations across diverse benchmarks demonstrate that DIA-CLIP consistently outperforms state-of-the-art tools, yielding up to a 45% increase in protein identification while achieving a 12% reduction in entrapment identifications. Moreover, DIA-CLIP holds immense potential for diverse practical applications, such as single-cell and spatial proteomics, where its enhanced identification depth facilitates the discovery of novel biomarkers and the elucidates of intricate cellular mechanisms.

</details>


### [14] [No Generation without Representation: Efficient Causal Protein Language Models Enable Zero-Shot Fitness Estimation](https://arxiv.org/abs/2602.01845)
*Furkan Eris*

Main category: cs.LG

TL;DR: Proust是一个309M参数的因果蛋白质语言模型，通过架构创新在适应度预测和生成能力之间取得平衡，在多项蛋白质基准测试中表现优异，同时保持原生生成能力。


<details>
  <summary>Details</summary>
Motivation: 解决蛋白质语言模型中存在的根本性分歧：掩码语言模型擅长适应度预测但无法生成，因果模型能生成但不擅长预测，迫使研究人员维护两套分离的架构。

Method: 采用因果模型架构，融入LLM研究中的创新：分组查询注意力（共享K/V投影）、跨层值残差和深度因果卷积。在33B tokens上训练，耗时40 B200 GPU小时。

Result: 在ProteinGym替换任务上达到Spearman ρ=0.390，与需要50-200倍计算量的MLMs相当；在indels任务上创下新SOTA，优于大20倍的模型；在EVEREST病毒适应度基准上接近结构感知方法。

Conclusion: Proust在适应度预测和生成能力之间找到了平衡点，同时可解释性分析显示位置熵方差能预测检索增强的效果，这些见解可扩展并指导测试时扩展等能力。

Abstract: Protein language models (PLMs) face a fundamental divide: masked language models (MLMs) excel at fitness prediction while causal models enable generation, forcing practitioners to maintain separate architectures. We introduce \textbf{Proust}, a 309M-parameter causal PLM that bridges this gap through architectural innovations adapted from recent LLM research, including grouped-query attention with shared K/V projections, cross-layer value residuals, and depthwise causal convolutions. Trained on 33B tokens in 40 B200 GPU-hours, Proust achieves Spearman $ρ= 0.390$ on ProteinGym substitutions, competitive with MLMs requiring 50--200$\times$ the compute. On indels, Proust sets a new state-of-the-art, outperforming models up to 20$\times$ larger. On EVEREST viral fitness benchmarks, it approaches structure-aware methods using sequence alone. These powerful representations position Proust in a sweet spot as it also retains native generative capabilities that MLMs lack by design. Interpretability analysis reveals that per-position entropy variance predicts, to an extent, when retrieval augmentation helps and hurts. Such insights can grow in both quantity and quality at scale and inform capabilities such as test-time scaling. Code and weights are available at https://github.com/Furkan9015/proust-inference

</details>


### [15] [Scalable Spatio-Temporal SE(3) Diffusion for Long-Horizon Protein Dynamics](https://arxiv.org/abs/2602.02128)
*Nima Shoghi,Yuxuan Liu,Yuning Shen,Rob Brekelmans,Pan Li,Quanquan Gu*

Main category: cs.LG

TL;DR: STAR-MD是一个SE(3)-等变的扩散模型，通过联合时空注意力机制生成微秒级蛋白质轨迹，在ATLAS基准测试中取得SOTA性能，解决了现有生成模型在长时间尺度模拟中的局限性。


<details>
  <summary>Details</summary>
Motivation: 分子动力学模拟计算成本高，难以达到生物相关时间尺度；现有生成模型在长时间尺度生成中存在架构限制、误差累积和时空动态建模不足等问题。

Method: 提出STAR-MD：可扩展的SE(3)-等变扩散模型，采用具有联合时空注意力的因果扩散transformer，高效捕捉复杂时空依赖关系，避免现有方法的内存瓶颈。

Result: 在ATLAS基准测试中所有指标均达到SOTA性能，显著改善构象覆盖、结构有效性和动态保真度；能够生成稳定的微秒级轨迹，而基线方法完全失败。

Conclusion: STAR-MD的联合时空建模能够在生物相关时间尺度上实现稳健的动力学模拟，为加速探索蛋白质功能开辟了新途径。

Abstract: Molecular dynamics (MD) simulations remain the gold standard for studying protein dynamics, but their computational cost limits access to biologically relevant timescales. Recent generative models have shown promise in accelerating simulations, yet they struggle with long-horizon generation due to architectural constraints, error accumulation, and inadequate modeling of spatio-temporal dynamics. We present STAR-MD (Spatio-Temporal Autoregressive Rollout for Molecular Dynamics), a scalable SE(3)-equivariant diffusion model that generates physically plausible protein trajectories over microsecond timescales. Our key innovation is a causal diffusion transformer with joint spatio-temporal attention that efficiently captures complex space-time dependencies while avoiding the memory bottlenecks of existing methods. On the standard ATLAS benchmark, STAR-MD achieves state-of-the-art performance across all metrics--substantially improving conformational coverage, structural validity, and dynamic fidelity compared to previous methods. STAR-MD successfully extrapolates to generate stable microsecond-scale trajectories where baseline methods fail catastrophically, maintaining high structural quality throughout the extended rollout. Our comprehensive evaluation reveals severe limitations in current models for long-horizon generation, while demonstrating that STAR-MD's joint spatio-temporal modeling enables robust dynamics simulation at biologically relevant timescales, paving the way for accelerated exploration of protein function.

</details>


### [16] [Repurposing Protein Language Models for Latent Flow-Based Fitness Optimization](https://arxiv.org/abs/2602.02425)
*Amaru Caceres Arroyo,Lea Bogensperger,Ahmed Allam,Michael Krauthammer,Konrad Schindler,Dominik Narnhofer*

Main category: cs.LG

TL;DR: CHASE：利用预训练蛋白质语言模型的进化知识，通过压缩嵌入到紧凑潜在空间，无需预测器引导即可直接生成高适应性蛋白质变体的框架


<details>
  <summary>Details</summary>
Motivation: 蛋白质适应性优化面临组合爆炸的挑战，高适应性变体极其稀疏。现有方法要么性能不足，要么需要计算昂贵的基于梯度的采样

Method: 将预训练蛋白质语言模型的嵌入压缩到紧凑潜在空间，训练带有分类器自由引导的条件流匹配模型，在ODE采样步骤中无需预测器引导即可直接生成高适应性变体

Result: 在AAV和GFP蛋白质设计基准测试中达到最先进性能，在数据受限场景中通过合成数据引导可以进一步提升性能

Conclusion: CHASE框架成功利用预训练蛋白质语言模型的进化知识，实现了高效且无需预测器引导的高适应性蛋白质变体生成，为蛋白质设计提供了新方法

Abstract: Protein fitness optimization is challenged by a vast combinatorial landscape where high-fitness variants are extremely sparse. Many current methods either underperform or require computationally expensive gradient-based sampling. We present CHASE, a framework that repurposes the evolutionary knowledge of pretrained protein language models by compressing their embeddings into a compact latent space. By training a conditional flow-matching model with classifier-free guidance, we enable the direct generation of high-fitness variants without predictor-based guidance during the ODE sampling steps. CHASE achieves state-of-the-art performance on AAV and GFP protein design benchmarks. Finally, we show that bootstrapping with synthetic data can further enhance performance in data-constrained settings.

</details>
