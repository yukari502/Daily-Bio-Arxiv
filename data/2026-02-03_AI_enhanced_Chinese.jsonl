{"id": "2602.00586", "pdf": "https://arxiv.org/pdf/2602.00586", "abs": "https://arxiv.org/abs/2602.00586", "authors": ["Hasi Hays", "William J. Richardson"], "title": "RAG-GNN: Integrating Retrieved Knowledge with Graph Neural Networks for Precision Medicine", "categories": ["q-bio.MN", "cs.AI", "cs.LG"], "comment": null, "summary": "Network topology excels at structural predictions but fails to capture functional semantics encoded in biomedical literature. We present a retrieval-augmented generation (RAG) embedding framework that integrates graph neural network representations with dynamically retrieved literature-derived knowledge through contrastive learning. Benchmarking against ten embedding methods reveals task-specific complementarity: topology-focused methods achieve near-perfect link prediction (GCN: 0.983 AUROC), while RAG-GNN is the only method achieving positive silhouette scores for functional clustering (0.001 vs. negative scores for all baselines). Information-theoretic decomposition shows network topology contributes 77.3% of predictive information, while retrieved documents provide 8.6% unique information. Applied to cancer signaling networks (379 proteins, 3,498 interactions), the framework identifies DDR1 as a therapeutic target based on retrieved evidence of synthetic lethality with KRAS mutations. These results establish that topology-only and retrieval-augmented approaches serve complementary purposes: structural prediction tasks are solved by network topology alone, while functional interpretation uniquely benefits from retrieved knowledge.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u4e0e\u6587\u732e\u68c0\u7d22\u7684RAG-GNN\u6846\u67b6\uff0c\u5728\u751f\u7269\u533b\u5b66\u7f51\u7edc\u5206\u6790\u4e2d\u5b9e\u73b0\u62d3\u6251\u7ed3\u6784\u4e0e\u529f\u80fd\u8bed\u4e49\u7684\u4e92\u8865\uff1a\u62d3\u6251\u65b9\u6cd5\u64c5\u957f\u7ed3\u6784\u9884\u6d4b\uff0c\u800c\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u5728\u529f\u80fd\u805a\u7c7b\u4e0a\u8868\u73b0\u72ec\u7279\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u7f51\u7edc\u62d3\u6251\u65b9\u6cd5\u80fd\u5f88\u597d\u9884\u6d4b\u7ed3\u6784\u5173\u7cfb\uff0c\u4f46\u65e0\u6cd5\u6355\u6349\u751f\u7269\u533b\u5b66\u6587\u732e\u4e2d\u7f16\u7801\u7684\u529f\u80fd\u8bed\u4e49\u4fe1\u606f\u3002\u9700\u8981\u5f00\u53d1\u80fd\u540c\u65f6\u5229\u7528\u7ed3\u6784\u62d3\u6251\u548c\u6587\u732e\u77e5\u8bc6\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u751f\u7269\u533b\u5b66\u7f51\u7edc\u7684\u529f\u80fd\u89e3\u91ca\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u5d4c\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u5c06\u56fe\u795e\u7ecf\u7f51\u7edc\u8868\u793a\u4e0e\u52a8\u6001\u68c0\u7d22\u7684\u6587\u732e\u77e5\u8bc6\u76f8\u7ed3\u5408\u3002\u4f7f\u7528\u4fe1\u606f\u8bba\u5206\u89e3\u5206\u6790\u4e0d\u540c\u4fe1\u606f\u6e90\u7684\u8d21\u732e\uff0c\u5e76\u5728\u764c\u75c7\u4fe1\u53f7\u7f51\u7edc(379\u4e2a\u86cb\u767d\uff0c3,498\u4e2a\u76f8\u4e92\u4f5c\u7528)\u4e0a\u8fdb\u884c\u5e94\u7528\u9a8c\u8bc1\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff1a\u62d3\u6251\u65b9\u6cd5\u5728\u94fe\u63a5\u9884\u6d4b\u4e0a\u8868\u73b0\u4f18\u5f02(GCN: 0.983 AUROC)\uff0c\u800cRAG-GNN\u662f\u552f\u4e00\u5728\u529f\u80fd\u805a\u7c7b\u4e0a\u83b7\u5f97\u6b63\u8f6e\u5ed3\u7cfb\u6570\u7684\u65b9\u6cd5(0.001 vs. \u6240\u6709\u57fa\u7ebf\u5747\u4e3a\u8d1f\u503c)\u3002\u4fe1\u606f\u8bba\u5206\u89e3\u8868\u660e\u7f51\u7edc\u62d3\u6251\u8d21\u732e77.3%\u9884\u6d4b\u4fe1\u606f\uff0c\u68c0\u7d22\u6587\u6863\u63d0\u4f9b8.6%\u72ec\u7279\u4fe1\u606f\u3002\u5e94\u7528\u4e2d\u53d1\u73b0DDR1\u4f5c\u4e3aKRAS\u7a81\u53d8\u5408\u6210\u81f4\u6b7b\u7597\u6cd5\u7684\u6f5c\u5728\u9776\u70b9\u3002", "conclusion": "\u62d3\u6251\u65b9\u6cd5\u548c\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u5177\u6709\u4e92\u8865\u6027\uff1a\u7ed3\u6784\u9884\u6d4b\u4efb\u52a1\u53ef\u7531\u7f51\u7edc\u62d3\u6251\u5355\u72ec\u89e3\u51b3\uff0c\u800c\u529f\u80fd\u89e3\u91ca\u4efb\u52a1\u5219\u72ec\u7279\u53d7\u76ca\u4e8e\u68c0\u7d22\u77e5\u8bc6\u3002RAG-GNN\u6846\u67b6\u4e3a\u751f\u7269\u533b\u5b66\u7f51\u7edc\u5206\u6790\u63d0\u4f9b\u4e86\u540c\u65f6\u5229\u7528\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.02374", "pdf": "https://arxiv.org/pdf/2602.02374", "abs": "https://arxiv.org/abs/2602.02374", "authors": ["Alexander Dack", "Tomislav Plesa", "Thomas E. Ouldridge"], "title": "Recurrent neural chemical reaction networks trained to switch dynamical behaviours through learned bifurcations", "categories": ["q-bio.MN", "math.DS"], "comment": null, "summary": "Both natural and synthetic chemical systems not only exhibit a range of non-trivial dynamics, but also transition between qualitatively different dynamical behaviours as environmental parameters change. Such transitions are called bifurcations. Here, we show that recurrent neural chemical reaction networks (RNCRNs), a class of chemical reaction networks based on recurrent artificial neural networks that can be trained to reproduce a given dynamical behaviour, can also be trained to exhibit bifurcations. First, we show that RNCRNs can inherit some bifurcations defined by smooth ordinary differential equations (ODEs). Second, we demonstrate that the RNCRN can be trained to infer bifurcations that allow it to approximate different target behaviours within different regions of parameter space, without explicitly providing the bifurcation itself in the training. These behaviours can be specified using target ODEs that are discontinuous with respect to the parameters, or even simply by specifying certain desired dynamical features in certain regions of the parameter space. To achieve the latter, we introduce an ODE-free algorithm for training the RNCRN to display designer oscillations, such as a heart-shaped limit cycle or two coexisting limit cycles.", "AI": {"tldr": "RNCRNs\uff08\u5faa\u73af\u795e\u7ecf\u5316\u5b66\u53cd\u5e94\u7f51\u7edc\uff09\u53ef\u4ee5\u88ab\u8bad\u7ec3\u6765\u5c55\u793a\u5206\u5c94\u884c\u4e3a\uff0c\u5305\u62ec\u7ee7\u627f\u5e73\u6ed1ODE\u7684\u5206\u5c94\u548c\u901a\u8fc7\u8bad\u7ec3\u63a8\u65ad\u4e0d\u8fde\u7eed\u53c2\u6570\u7a7a\u95f4\u4e2d\u7684\u5206\u5c94\u3002", "motivation": "\u81ea\u7136\u548c\u5408\u6210\u5316\u5b66\u7cfb\u7edf\u5728\u4e0d\u540c\u73af\u5883\u53c2\u6570\u4e0b\u4f1a\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u8fd9\u79cd\u8f6c\u53d8\u79f0\u4e3a\u5206\u5c94\u3002\u7814\u7a76\u5982\u4f55\u8ba9\u5316\u5b66\u53cd\u5e94\u7f51\u7edc\u5c55\u793a\u5206\u5c94\u884c\u4e3a\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u590d\u6742\u5316\u5b66\u7cfb\u7edf\u7684\u52a8\u529b\u5b66\u7279\u6027\u3002", "method": "\u4f7f\u7528\u5faa\u73af\u795e\u7ecf\u5316\u5b66\u53cd\u5e94\u7f51\u7edc\uff08RNCRNs\uff09\uff0c\u901a\u8fc7\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09\u7ee7\u627f\u5e73\u6ed1ODE\u5b9a\u4e49\u7684\u5206\u5c94\uff1b2\uff09\u8bad\u7ec3\u7f51\u7edc\u63a8\u65ad\u5206\u5c94\uff0c\u4f7f\u5176\u5728\u4e0d\u540c\u53c2\u6570\u533a\u57df\u8fd1\u4f3c\u4e0d\u540c\u76ee\u6807\u884c\u4e3a\uff0c\u751a\u81f3\u4f7f\u7528ODE-free\u7b97\u6cd5\u8bad\u7ec3\u7279\u5b9a\u632f\u8361\u6a21\u5f0f\u3002", "result": "RNCRNs\u80fd\u591f\u6210\u529f\u5c55\u793a\u5206\u5c94\u884c\u4e3a\uff0c\u5305\u62ec\u7ee7\u627f\u5e73\u6ed1ODE\u7684\u5206\u5c94\uff0c\u4ee5\u53ca\u901a\u8fc7\u8bad\u7ec3\u63a8\u65ad\u4e0d\u8fde\u7eed\u53c2\u6570\u7a7a\u95f4\u4e2d\u7684\u5206\u5c94\u3002\u7f51\u7edc\u53ef\u4ee5\u5b66\u4e60\u4ea7\u751f\u7279\u5b9a\u632f\u8361\u6a21\u5f0f\uff0c\u5982\u5fc3\u5f62\u6781\u9650\u73af\u6216\u5171\u5b58\u6781\u9650\u73af\u3002", "conclusion": "RNCRNs\u4e0d\u4ec5\u53ef\u4ee5\u88ab\u8bad\u7ec3\u6765\u91cd\u73b0\u7ed9\u5b9a\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u8fd8\u53ef\u4ee5\u88ab\u8bad\u7ec3\u6765\u5c55\u793a\u5206\u5c94\uff0c\u8fd9\u4e3a\u8bbe\u8ba1\u548c\u7406\u89e3\u590d\u6742\u5316\u5b66\u7cfb\u7edf\u7684\u52a8\u529b\u5b66\u7279\u6027\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2602.00143", "pdf": "https://arxiv.org/pdf/2602.00143", "abs": "https://arxiv.org/abs/2602.00143", "authors": ["Xiaoai Xu", "Yixuan Zhou", "Xiang Zhou", "Jingqiao Duan", "Ting Gao"], "title": "Early warning prediction: Onsager-Machlup vs Schr\u00f6dinger", "categories": ["q-bio.QM", "cs.LG", "stat.ML"], "comment": "20 pages", "summary": "Predicting critical transitions in complex systems, such as epileptic seizures in the brain, represents a major challenge in scientific research. The high-dimensional characteristics and hidden critical signals further complicate early-warning tasks. This study proposes a novel early-warning framework that integrates manifold learning with stochastic dynamical system modeling. Through systematic comparison, six methods including diffusion maps (DM) are selected to construct low-dimensional representations. Based on these, a data-driven stochastic differential equation model is established to robustly estimate the probability evolution scoring function of the system. Building on this, a new Score Function (SF) indicator is defined by incorporating Schr\u00f6dinger bridge theory to quantify the likelihood of significant state transitions in the system. Experiments demonstrate that this indicator exhibits higher sensitivity and robustness in epilepsy prediction, enables earlier identification of critical points, and clearly captures dynamic features across various stages before and after seizure onset. This work provides a systematic theoretical framework and practical methodology for extracting early-warning signals from high-dimensional data.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u6d41\u5f62\u5b66\u4e60\u548c\u968f\u673a\u52a8\u529b\u7cfb\u7edf\u5efa\u6a21\u7684\u766b\u75eb\u53d1\u4f5c\u65e9\u671f\u9884\u8b66\u6846\u67b6\uff0c\u901a\u8fc7\u964d\u7ef4\u548c\u6982\u7387\u6f14\u5316\u8bc4\u5206\u51fd\u6570\u5b9e\u73b0\u66f4\u65e9\u3001\u66f4\u9c81\u68d2\u7684\u9884\u6d4b", "motivation": "\u590d\u6742\u7cfb\u7edf\uff08\u5982\u5927\u8111\u766b\u75eb\u53d1\u4f5c\uff09\u7684\u5173\u952e\u8f6c\u53d8\u9884\u6d4b\u5177\u6709\u6311\u6218\u6027\uff0c\u9ad8\u7ef4\u7279\u6027\u548c\u9690\u85cf\u7684\u5173\u952e\u4fe1\u53f7\u4f7f\u65e9\u671f\u9884\u8b66\u4efb\u52a1\u66f4\u52a0\u590d\u6742", "method": "\u96c6\u6210\u6d41\u5f62\u5b66\u4e60\u4e0e\u968f\u673a\u52a8\u529b\u7cfb\u7edf\u5efa\u6a21\uff1a1\uff09\u9009\u62e9\u6269\u6563\u6620\u5c04\u7b496\u79cd\u65b9\u6cd5\u6784\u5efa\u4f4e\u7ef4\u8868\u793a\uff1b2\uff09\u5efa\u7acb\u6570\u636e\u9a71\u52a8\u7684\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u6a21\u578b\u4f30\u8ba1\u7cfb\u7edf\u6982\u7387\u6f14\u5316\u8bc4\u5206\u51fd\u6570\uff1b3\uff09\u7ed3\u5408\u859b\u5b9a\u8c14\u6865\u7406\u8bba\u5b9a\u4e49\u65b0\u7684\u8bc4\u5206\u51fd\u6570\u6307\u6807\u91cf\u5316\u7cfb\u7edf\u72b6\u6001\u8f6c\u53d8\u53ef\u80fd\u6027", "result": "\u8be5\u6307\u6807\u5728\u766b\u75eb\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u654f\u611f\u6027\u548c\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u66f4\u65e9\u8bc6\u522b\u5173\u952e\u70b9\uff0c\u6e05\u6670\u6355\u6349\u766b\u75eb\u53d1\u4f5c\u524d\u540e\u5404\u9636\u6bb5\u7684\u52a8\u6001\u7279\u5f81", "conclusion": "\u4e3a\u4ece\u9ad8\u7ef4\u6570\u636e\u4e2d\u63d0\u53d6\u65e9\u671f\u9884\u8b66\u4fe1\u53f7\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7684\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u65b9\u6cd5"}}
{"id": "2602.00157", "pdf": "https://arxiv.org/pdf/2602.00157", "abs": "https://arxiv.org/abs/2602.00157", "authors": ["Fang Sheng", "Mohammad Noaeen", "Zahra Shakeri"], "title": "ProDCARL: Reinforcement Learning-Aligned Diffusion Models for De Novo Antimicrobial Peptide Design", "categories": ["q-bio.QM", "cs.AI", "q-bio.BM"], "comment": null, "summary": "Antimicrobial resistance threatens healthcare sustainability and motivates low-cost computational discovery of antimicrobial peptides (AMPs). De novo peptide generation must optimize antimicrobial activity and safety through low predicted toxicity, but likelihood-trained generators do not enforce these goals explicitly. We introduce ProDCARL, a reinforcement-learning alignment framework that couples a diffusion-based protein generator (EvoDiff OA-DM 38M) with sequence property predictors for AMP activity and peptide toxicity. We fine-tune the diffusion prior on AMP sequences to obtain a domain-aware generator. Top-k policy-gradient updates use classifier-derived rewards plus entropy regularization and early stopping to preserve diversity and reduce reward hacking. In silico experiments show ProDCARL increases the mean predicted AMP score from 0.081 after fine-tuning to 0.178. The joint high-quality hit rate reaches 6.3\\% with pAMP $>$0.7 and pTox $<$0.3. ProDCARL maintains high diversity, with $1-$mean pairwise identity equal to 0.929. Qualitative analyses with AlphaFold3 and ProtBERT embeddings suggest candidates show plausible AMP-like structural and semantic characteristics. ProDCARL serves as a candidate generator that narrows experimental search space, and experimental validation remains future work.", "AI": {"tldr": "ProDCARL\u662f\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u751f\u6210\u5177\u6709\u9ad8\u6297\u83cc\u6d3b\u6027\u548c\u4f4e\u6bd2\u6027\u7684\u6297\u83cc\u80bd\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u8d28\u91cf\u3002", "motivation": "\u6297\u83cc\u7d20\u8010\u836f\u6027\u5a01\u80c1\u533b\u7597\u53ef\u6301\u7eed\u6027\uff0c\u9700\u8981\u4f4e\u6210\u672c\u8ba1\u7b97\u53d1\u73b0\u6297\u83cc\u80bd\u3002\u4f20\u7edf\u57fa\u4e8e\u4f3c\u7136\u7684\u751f\u6210\u5668\u65e0\u6cd5\u660e\u786e\u4f18\u5316\u6297\u83cc\u6d3b\u6027\u548c\u5b89\u5168\u6027\u76ee\u6807\u3002", "method": "\u63d0\u51faProDCARL\u5f3a\u5316\u5b66\u4e60\u5bf9\u9f50\u6846\u67b6\uff0c\u7ed3\u5408\u6269\u6563\u86cb\u767d\u751f\u6210\u5668(EvoDiff OA-DM 38M)\u548c\u5e8f\u5217\u6027\u8d28\u9884\u6d4b\u5668\uff0c\u901a\u8fc7\u5fae\u8c03\u6269\u6563\u5148\u9a8c\u83b7\u5f97\u9886\u57df\u611f\u77e5\u751f\u6210\u5668\uff0c\u4f7f\u7528top-k\u7b56\u7565\u68af\u5ea6\u66f4\u65b0\u3001\u5206\u7c7b\u5668\u5956\u52b1\u3001\u71b5\u6b63\u5219\u5316\u548c\u65e9\u505c\u6765\u4fdd\u6301\u591a\u6837\u6027\u3002", "result": "\u9884\u6d4bAMP\u5206\u6570\u4ece\u5fae\u8c03\u540e\u76840.081\u63d0\u5347\u52300.178\uff0c\u8054\u5408\u9ad8\u8d28\u91cf\u547d\u4e2d\u7387\u8fbe\u52306.3%\uff0c\u4fdd\u6301\u9ad8\u591a\u6837\u6027(1-\u5e73\u5747\u6210\u5bf9\u540c\u4e00\u6027=0.929)\uff0cAlphaFold3\u548cProtBERT\u5206\u6790\u663e\u793a\u5019\u9009\u80bd\u5177\u6709\u5408\u7406\u7684AMP\u6837\u7ed3\u6784\u548c\u8bed\u4e49\u7279\u5f81\u3002", "conclusion": "ProDCARL\u4f5c\u4e3a\u5019\u9009\u751f\u6210\u5668\u80fd\u7f29\u5c0f\u5b9e\u9a8c\u641c\u7d22\u7a7a\u95f4\uff0c\u4f46\u5b9e\u9a8c\u9a8c\u8bc1\u4ecd\u9700\u672a\u6765\u5de5\u4f5c\u3002"}}
{"id": "2602.01230", "pdf": "https://arxiv.org/pdf/2602.01230", "abs": "https://arxiv.org/abs/2602.01230", "authors": ["Masayuki Nagai", "Alan E. Murphy", "Kaeli Rizzo", "Peter K. Koo"], "title": "Toward Interpretable and Generalizable AI in Regulatory Genomics", "categories": ["q-bio.GN"], "comment": "5 figures, 1 table", "summary": "Deciphering how DNA sequence encodes gene regulation remains a central challenge in biology. Advances in machine learning and functional genomics have enabled sequence-to-function (seq2func) models that predict molecular regulatory readouts directly from DNA sequence. These models are now widely used for variant effect prediction, mechanistic interpretation, and regulatory sequence design. Despite strong performance on held-out genomic regions, their ability to generalize across genetic variation and cellular contexts remains inconsistent. Here we examine how architectural choices, training data, and prediction tasks shape the behavior of seq2func models. We synthesize how interpretability methods and evaluation practices have probed learned cis-regulatory organization and highlighted systematic failure modes, clarifying why strong predictive accuracy can fail to translate into robust regulatory understanding. We argue that progress will require reframing seq2func models as continually refined systems, in which targeted perturbation experiments, systematic evaluation, and iterative model updates are tightly coupled through AI-experiment feedback loops. Under this framework, seq2func models become self-improving tools that progressively deepen their mechanistic grounding and more reliably support biological discovery.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5e8f\u5217\u5230\u529f\u80fd\uff08seq2func\uff09\u6a21\u578b\u5728\u57fa\u56e0\u8c03\u63a7\u9884\u6d4b\u4e2d\u7684\u73b0\u72b6\u3001\u5c40\u9650\u6027\u548c\u672a\u6765\u53d1\u5c55\u65b9\u5411\uff0c\u5f3a\u8c03\u9700\u8981\u5efa\u7acbAI-\u5b9e\u9a8c\u53cd\u9988\u5faa\u73af\u6765\u63d0\u5347\u6a21\u578b\u7684\u673a\u5236\u7406\u89e3\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5e8f\u5217\u5230\u529f\u80fd\u6a21\u578b\u5728\u9884\u6d4b\u5206\u5b50\u8c03\u63a7\u8f93\u51fa\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5728\u9057\u4f20\u53d8\u5f02\u548c\u7ec6\u80de\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u4e00\u81f4\uff0c\u4e14\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u4e0d\u603b\u80fd\u8f6c\u5316\u4e3a\u53ef\u9760\u7684\u8c03\u63a7\u673a\u5236\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5206\u6790\u67b6\u6784\u9009\u62e9\u3001\u8bad\u7ec3\u6570\u636e\u548c\u9884\u6d4b\u4efb\u52a1\u5982\u4f55\u5f71\u54cdseq2func\u6a21\u578b\u7684\u884c\u4e3a\uff0c\u7efc\u5408\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u548c\u8bc4\u4f30\u5b9e\u8df5\u6765\u63a2\u7a76\u5b66\u4e60\u5230\u7684\u987a\u5f0f\u8c03\u63a7\u7ec4\u7ec7\uff0c\u5e76\u8bc6\u522b\u7cfb\u7edf\u6027\u5931\u8d25\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1seq2func\u6a21\u578b\u5728\u4fdd\u7559\u57fa\u56e0\u7ec4\u533a\u57df\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5176\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u4e14\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u4e0d\u603b\u80fd\u8f6c\u5316\u4e3a\u5bf9\u8c03\u63a7\u673a\u5236\u7684\u6df1\u5165\u7406\u89e3\u3002", "conclusion": "\u9700\u8981\u5c06seq2func\u6a21\u578b\u91cd\u6784\u4e3a\u6301\u7eed\u4f18\u5316\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7AI-\u5b9e\u9a8c\u53cd\u9988\u5faa\u73af\u5c06\u9776\u5411\u6270\u52a8\u5b9e\u9a8c\u3001\u7cfb\u7edf\u8bc4\u4f30\u548c\u8fed\u4ee3\u6a21\u578b\u66f4\u65b0\u7d27\u5bc6\u7ed3\u5408\uff0c\u4f7f\u6a21\u578b\u6210\u4e3a\u5177\u6709\u81ea\u6211\u6539\u8fdb\u80fd\u529b\u3001\u673a\u5236\u57fa\u7840\u4e0d\u65ad\u6df1\u5316\u3001\u66f4\u53ef\u9760\u652f\u6301\u751f\u7269\u5b66\u53d1\u73b0\u7684\u5de5\u5177\u3002"}}
{"id": "2602.00197", "pdf": "https://arxiv.org/pdf/2602.00197", "abs": "https://arxiv.org/abs/2602.00197", "authors": ["Yang Tan", "Yuyuan Xi", "Can Wu", "Bozitao Zhong", "Mingchen Li", "Guisheng Fan", "Jiankang Zhu", "Yafeng Liang", "Nanqing Dong", "Liang Hong"], "title": "Rank-and-Reason: Multi-Agent Collaboration Accelerates Zero-Shot Protein Mutation Prediction", "categories": ["q-bio.QM", "cs.AI", "cs.CL"], "comment": "22 pages, 5 figures, 15 tables", "summary": "Zero-shot mutation prediction is vital for low-resource protein engineering, yet existing protein language models (PLMs) often yield statistically confident results that ignore fundamental biophysical constraints. Currently, selecting candidates for wet-lab validation relies on manual expert auditing of PLM outputs, a process that is inefficient, subjective, and highly dependent on domain expertise. To address this, we propose Rank-and-Reason (VenusRAR), a two-stage agentic framework to automate this workflow and maximize expected wet-lab fitness. In the Rank-Stage, a Computational Expert and Virtual Biologist aggregate a context-aware multi-modal ensemble, establishing a new Spearman correlation record of 0.551 (vs. 0.518) on ProteinGym. In the Reason-Stage, an agentic Expert Panel employs chain-of-thought reasoning to audit candidates against geometric and structural constraints, improving the Top-5 Hit Rate by up to 367% on ProteinGym-DMS99. The wet-lab validation on Cas12i3 nuclease further confirms the framework's efficacy, achieving a 46.7% positive rate and identifying two novel mutants with 4.23-fold and 5.05-fold activity improvements. Code and datasets are released on GitHub (https://github.com/ai4protein/VenusRAR/).", "AI": {"tldr": "VenusRAR\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u86cb\u767d\u8d28\u7a81\u53d8\u9884\u6d4b\uff0c\u901a\u8fc7\u6392\u5e8f\u548c\u63a8\u7406\u9636\u6bb5\u63d0\u9ad8\u6e7f\u5b9e\u9a8c\u5ba4\u9a8c\u8bc1\u6210\u529f\u7387", "motivation": "\u73b0\u6709\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\uff08PLMs\uff09\u7684\u9884\u6d4b\u7ed3\u679c\u867d\u7136\u7edf\u8ba1\u7f6e\u4fe1\u5ea6\u9ad8\uff0c\u4f46\u5ffd\u7565\u4e86\u57fa\u672c\u7684\u751f\u7269\u7269\u7406\u7ea6\u675f\u3002\u76ee\u524d\u4f9d\u8d56\u4e13\u5bb6\u624b\u52a8\u5ba1\u6838PLM\u8f93\u51fa\u7684\u65b9\u5f0f\u6548\u7387\u4f4e\u4e0b\u3001\u4e3b\u89c2\u6027\u5f3a\u4e14\u9ad8\u5ea6\u4f9d\u8d56\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3002", "method": "\u63d0\u51faRank-and-Reason\uff08VenusRAR\uff09\u4e24\u9636\u6bb5\u4ee3\u7406\u6846\u67b6\uff1a1\uff09\u6392\u5e8f\u9636\u6bb5\uff1a\u8ba1\u7b97\u4e13\u5bb6\u548c\u865a\u62df\u751f\u7269\u5b66\u5bb6\u805a\u5408\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u591a\u6a21\u6001\u96c6\u6210\uff1b2\uff09\u63a8\u7406\u9636\u6bb5\uff1a\u4e13\u5bb6\u5c0f\u7ec4\u4f7f\u7528\u601d\u7ef4\u94fe\u63a8\u7406\u5ba1\u6838\u5019\u9009\u7a81\u53d8\u662f\u5426\u7b26\u5408\u51e0\u4f55\u548c\u7ed3\u6784\u7ea6\u675f\u3002", "result": "\u5728ProteinGym\u4e0a\u521b\u9020\u4e860.551\u7684Spearman\u76f8\u5173\u65b0\u8bb0\u5f55\uff08vs. 0.518\uff09\uff1b\u5728ProteinGym-DMS99\u4e0a\u5c06Top-5\u547d\u4e2d\u7387\u63d0\u9ad8\u4e86367%\uff1bCas12i3\u6838\u9178\u9176\u7684\u6e7f\u5b9e\u9a8c\u5ba4\u9a8c\u8bc1\u663e\u793a46.7%\u9633\u6027\u7387\uff0c\u5e76\u53d1\u73b0\u4e24\u4e2a\u5177\u67094.23\u500d\u548c5.05\u500d\u6d3b\u6027\u63d0\u5347\u7684\u65b0\u7a81\u53d8\u4f53\u3002", "conclusion": "VenusRAR\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u5316\u86cb\u767d\u8d28\u7a81\u53d8\u9884\u6d4b\u5de5\u4f5c\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6e7f\u5b9e\u9a8c\u5ba4\u9a8c\u8bc1\u7684\u6210\u529f\u7387\uff0c\u4e3a\u4f4e\u8d44\u6e90\u86cb\u767d\u8d28\u5de5\u7a0b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00156", "pdf": "https://arxiv.org/pdf/2602.00156", "abs": "https://arxiv.org/abs/2602.00156", "authors": ["Jaya Vasavi Pamidimukkala", "Himanshu Sahu", "Ashwini Kannan", "Janani Ananthanarayanan", "Kalyan Dasgupta", "Sanjib Senapati"], "title": "Accelerating De Novo Genome Assembly via Quantum-Assisted Graph Optimization with Bitstring Recovery", "categories": ["quant-ph", "q-bio.GN"], "comment": null, "summary": "Genome sequencing is essential to decode genetic information, identify organisms, understand diseases and advance personalized medicine. A critical step in any genome sequencing technique is genome assembly. However, de novo genome assembly, which involves constructing an entire genome sequence from scratch without a reference genome, presents significant challenges due to its high computational complexity, affecting both time and accuracy. In this study, we propose a hybrid approach utilizing a quantum computing-based optimization algorithm integrated with classical pre-processing to expedite the genome assembly process. Specifically, we present a method to solve the Hamiltonian and Eulerian paths within the genome assembly graph using gate-based quantum computing through a Higher-Order Binary Optimization (HOBO) formulation with the Variational Quantum Eigensolver algorithm (VQE), in addition to a novel bitstring recovery mechanism to improve optimizer traversal of the solution space. A comparative analysis with classical optimization techniques was performed to assess the effectiveness of our quantum-based approach in genome assembly. The results indicate that, as quantum hardware continues to evolve and noise levels diminish, our formulation holds a significant potential to accelerate genome sequencing by offering faster and more accurate solutions to the complex challenges in genomic research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u4f18\u5316\u7b97\u6cd5\u4e0e\u7ecf\u5178\u9884\u5904\u7406\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u52a0\u901f\u57fa\u56e0\u7ec4\u7ec4\u88c5\u8fc7\u7a0b\uff0c\u901a\u8fc7HOBO\u516c\u5f0f\u548cVQE\u7b97\u6cd5\u89e3\u51b3\u57fa\u56e0\u7ec4\u7ec4\u88c5\u56fe\u4e2d\u7684\u54c8\u5bc6\u987f\u548c\u6b27\u62c9\u8def\u5f84\u95ee\u9898\u3002", "motivation": "\u57fa\u56e0\u7ec4\u7ec4\u88c5\u662f\u57fa\u56e0\u7ec4\u6d4b\u5e8f\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u4f46\u4f20\u7edf\u7684\u4ece\u5934\u7ec4\u88c5\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u5f71\u54cd\u65f6\u95f4\u548c\u51c6\u786e\u6027\u3002\u91cf\u5b50\u8ba1\u7b97\u7684\u53d1\u5c55\u4e3a\u89e3\u51b3\u8fd9\u4e00\u590d\u6742\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u4f18\u5316\u7b97\u6cd5\uff08\u57fa\u4e8e\u95e8\u7684\u91cf\u5b50\u8ba1\u7b97\uff09\u548c\u7ecf\u5178\u9884\u5904\u7406\u3002\u4f7f\u7528\u9ad8\u9636\u4e8c\u8fdb\u5236\u4f18\u5316\uff08HOBO\uff09\u516c\u5f0f\u548c\u53d8\u5206\u91cf\u5b50\u672c\u5f81\u6c42\u89e3\u5668\uff08VQE\uff09\u7b97\u6cd5\u89e3\u51b3\u57fa\u56e0\u7ec4\u7ec4\u88c5\u56fe\u4e2d\u7684\u54c8\u5bc6\u987f\u548c\u6b27\u62c9\u8def\u5f84\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u6bd4\u7279\u4e32\u6062\u590d\u673a\u5236\u4ee5\u6539\u8fdb\u4f18\u5316\u5668\u5728\u89e3\u7a7a\u95f4\u4e2d\u7684\u904d\u5386\u3002", "result": "\u4e0e\u7ecf\u5178\u4f18\u5316\u6280\u672f\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\uff0c\u7ed3\u679c\u8868\u660e\u968f\u7740\u91cf\u5b50\u786c\u4ef6\u7684\u4e0d\u65ad\u53d1\u5c55\u548c\u566a\u58f0\u6c34\u5e73\u7684\u964d\u4f4e\uff0c\u8be5\u65b9\u6cd5\u5728\u52a0\u901f\u57fa\u56e0\u7ec4\u6d4b\u5e8f\u65b9\u9762\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u80fd\u591f\u4e3a\u57fa\u56e0\u7ec4\u7814\u7a76\u4e2d\u7684\u590d\u6742\u6311\u6218\u63d0\u4f9b\u66f4\u5feb\u3001\u66f4\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u91cf\u5b50\u8ba1\u7b97\u4e0e\u7ecf\u5178\u9884\u5904\u7406\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u65b9\u6cd5\u5728\u57fa\u56e0\u7ec4\u7ec4\u88c5\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u968f\u7740\u91cf\u5b50\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u6709\u671b\u663e\u8457\u52a0\u901f\u57fa\u56e0\u7ec4\u6d4b\u5e8f\u8fc7\u7a0b\u5e76\u63d0\u9ad8\u51c6\u786e\u6027\u3002"}}
{"id": "2602.00464", "pdf": "https://arxiv.org/pdf/2602.00464", "abs": "https://arxiv.org/abs/2602.00464", "authors": ["Zebo Xu", "Steven Langsford", "Zhuang Qiu", "Zhenguang Cai"], "title": "A 30-item Test for Assessing Chinese Character Amnesia in Child Handwriters", "categories": ["q-bio.QM", "cs.CV"], "comment": null, "summary": "Handwriting literacy is an important skill for learning and communication in school-age children. In the digital age, handwriting has been largely replaced by typing, leading to a decline in handwriting proficiency, particularly in non-alphabetic writing systems. Among children learning Chinese, a growing number have reported experiencing character amnesia: difficulty in correctly handwriting a character despite being able to recognize it. Given that there is currently no standardized diagnostic tool for assessing character amnesia in children, we developed an assessment to measure Chinese character amnesia in Mandarin-speaking school-age population. We utilised a large-scale handwriting dataset in which 40 children handwrote 800 characters from dictation prompts. Character amnesia and correct handwriting responses were analysed using a two-parameter Item Response Theory model. Four item-selection schemes were compared: random baseline, maximum discrimination, diverse difficulty, and an upper-and-lower-thirds discrimination score. Candidate item subsets were evaluated using out-of-sample prediction. Among these selection schemes, the upper-and-lower-thirds discrimination procedure yields a compact 30-item test that preserves individual-difference structure and generalizes to unseen test-takers (cross-validated mean r =.74 with full 800-item-test; within-sample r =.93). This short-form test provides a reliable and efficient tool of assessing Chinese character amnesia in children and can be used to identify early handwriting and orthographic learning difficulties, contributing to the early detection of developmental dysgraphia and related literacy challenges.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6c49\u8bed\u513f\u7ae5\u6c49\u5b57\u5931\u5199\u75c7\u768430\u9879\u7b80\u77ed\u6d4b\u8bd5\uff0c\u901a\u8fc7IRT\u6a21\u578b\u548c\u9879\u76ee\u9009\u62e9\u65b9\u6848\u4f18\u5316\uff0c\u80fd\u6709\u6548\u8bc6\u522b\u65e9\u671f\u4e66\u5199\u56f0\u96be", "motivation": "\u5728\u6570\u5b57\u65f6\u4ee3\uff0c\u624b\u5199\u80fd\u529b\u4e0b\u964d\uff0c\u7279\u522b\u662f\u975e\u5b57\u6bcd\u6587\u5b57\u7cfb\u7edf\u3002\u5b66\u4e60\u6c49\u8bed\u7684\u513f\u7ae5\u4e2d\uff0c\u8d8a\u6765\u8d8a\u591a\u51fa\u73b0\"\u6c49\u5b57\u5931\u5199\u75c7\"\uff08\u80fd\u8ba4\u5b57\u4f46\u4e0d\u4f1a\u5199\uff09\uff0c\u76ee\u524d\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u8bca\u65ad\u5de5\u5177", "method": "\u4f7f\u752840\u540d\u513f\u7ae5\u542c\u5199800\u4e2a\u6c49\u5b57\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u91c7\u7528\u53cc\u53c2\u6570\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u6a21\u578b\u5206\u6790\u6c49\u5b57\u5931\u5199\u75c7\u548c\u6b63\u786e\u4e66\u5199\u53cd\u5e94\u3002\u6bd4\u8f83\u4e86\u56db\u79cd\u9879\u76ee\u9009\u62e9\u65b9\u6848\uff1a\u968f\u673a\u57fa\u7ebf\u3001\u6700\u5927\u533a\u5206\u5ea6\u3001\u96be\u5ea6\u591a\u6837\u6027\u3001\u4e0a\u4e0b\u4e09\u5206\u4e4b\u4e00\u533a\u5206\u5ea6\u8bc4\u5206", "result": "\u4e0a\u4e0b\u4e09\u5206\u4e4b\u4e00\u533a\u5206\u5ea6\u7a0b\u5e8f\u4ea7\u751f\u4e8630\u4e2a\u9879\u76ee\u7684\u7d27\u51d1\u6d4b\u8bd5\uff0c\u4fdd\u7559\u4e86\u4e2a\u4f53\u5dee\u5f02\u7ed3\u6784\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u6d4b\u8bd5\u8005\uff08\u4ea4\u53c9\u9a8c\u8bc1\u5e73\u5747r=0.74\u4e0e\u5b8c\u6574800\u9879\u6d4b\u8bd5\uff1b\u6837\u672c\u5185r=0.93\uff09", "conclusion": "\u8fd9\u4e2a\u7b80\u77ed\u6d4b\u8bd5\u4e3a\u8bc4\u4f30\u513f\u7ae5\u6c49\u5b57\u5931\u5199\u75c7\u63d0\u4f9b\u4e86\u53ef\u9760\u9ad8\u6548\u7684\u5de5\u5177\uff0c\u53ef\u7528\u4e8e\u8bc6\u522b\u65e9\u671f\u4e66\u5199\u548c\u6b63\u5b57\u6cd5\u5b66\u4e60\u56f0\u96be\uff0c\u6709\u52a9\u4e8e\u65e9\u671f\u53d1\u73b0\u53d1\u5c55\u6027\u4e66\u5199\u969c\u788d\u548c\u76f8\u5173\u8bfb\u5199\u6311\u6218"}}
{"id": "2602.01839", "pdf": "https://arxiv.org/pdf/2602.01839", "abs": "https://arxiv.org/abs/2602.01839", "authors": ["Ru Zhang", "Xunkai Li", "Yaxin Deng", "Sicheng Liu", "Daohan Su", "Qiangqiang Dai", "Hongchao Qin", "Rong-Hua Li", "Guoren Wang", "Jia Li"], "title": "DOGMA: Weaving Structural Information into Data-centric Single-cell Transcriptomics Analysis", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": "12 pages, 4 figures", "summary": "Recently, data-centric AI methodology has been a dominant paradigm in single-cell transcriptomics analysis, which treats data representation rather than model complexity as the fundamental bottleneck. In the review of current studies, earlier sequence methods treat cells as independent entities and adapt prevalent ML models to analyze their directly inherited sequence data. Despite their simplicity and intuition, these methods overlook the latent intercellular relationships driven by the functional mechanisms of biological systems and the inherent quality issues of the raw sequence data. Therefore, a series of structured methods has emerged. Although they employ various heuristic rules to capture intricate intercellular relationships and enhance the raw sequencing data, these methods often neglect biological prior knowledge. This omission incurs substantial overhead and yields suboptimal graph representations, thereby hindering the utility of ML models.\n  To address them, we propose DOGMA, a holistic data-centric framework designed for the structural reshaping and semantic enhancement of raw data through multi-level biological prior knowledge. Transcending reliance on stochastic heuristics, DOGMA redefines graph construction by integrating Statistical Anchors with Cell Ontology and Phylogenetic Trees to enable deterministic structure discovery and robust cross-species alignment. Furthermore, Gene Ontology is utilized to bridge the feature-level semantic gap by incorporating functional priors. In complex multi-species and multi-organ benchmarks, DOGMA achieves SOTA performance, exhibiting superior zero-shot robustness and sample efficiency while operating with significantly lower computational cost.", "AI": {"tldr": "DOGMA\u662f\u4e00\u4e2a\u6570\u636e\u4e2d\u5fc3\u7684\u5355\u7ec6\u80de\u8f6c\u5f55\u7ec4\u5b66\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u591a\u5c42\u6b21\u7684\u751f\u7269\u5b66\u5148\u9a8c\u77e5\u8bc6\u6765\u91cd\u5851\u6570\u636e\u7ed3\u6784\u548c\u589e\u5f3a\u8bed\u4e49\uff0c\u8d85\u8d8a\u4e86\u4f9d\u8d56\u968f\u673a\u542f\u53d1\u5f0f\u7684\u65b9\u6cd5\uff0c\u5728\u8de8\u7269\u79cd\u548c\u591a\u5668\u5b98\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5355\u7ec6\u80de\u8f6c\u5f55\u7ec4\u5b66\u5206\u6790\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u65e9\u671f\u5e8f\u5217\u65b9\u6cd5\u5c06\u7ec6\u80de\u89c6\u4e3a\u72ec\u7acb\u5b9e\u4f53\uff0c\u5ffd\u7565\u4e86\u751f\u7269\u7cfb\u7edf\u529f\u80fd\u673a\u5236\u9a71\u52a8\u7684\u7ec6\u80de\u95f4\u6f5c\u5728\u5173\u7cfb\uff1b2\uff09\u7ed3\u6784\u5316\u65b9\u6cd5\u867d\u7136\u5c1d\u8bd5\u6355\u6349\u7ec6\u80de\u95f4\u5173\u7cfb\uff0c\u4f46\u5f80\u5f80\u5ffd\u89c6\u751f\u7269\u5b66\u5148\u9a8c\u77e5\u8bc6\uff0c\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u5927\u4e14\u56fe\u8868\u793a\u6548\u679c\u4e0d\u4f73\u3002", "method": "DOGMA\u6846\u67b6\u901a\u8fc7\u6574\u5408\u591a\u5c42\u6b21\u7684\u751f\u7269\u5b66\u5148\u9a8c\u77e5\u8bc6\uff1a1\uff09\u4f7f\u7528\u7edf\u8ba1\u951a\u70b9\u3001\u7ec6\u80de\u672c\u4f53\u548c\u7cfb\u7edf\u53d1\u80b2\u6811\u8fdb\u884c\u786e\u5b9a\u6027\u7ed3\u6784\u53d1\u73b0\u548c\u7a33\u5065\u7684\u8de8\u7269\u79cd\u5bf9\u9f50\uff0c\u91cd\u65b0\u5b9a\u4e49\u56fe\u6784\u5efa\uff1b2\uff09\u5229\u7528\u57fa\u56e0\u672c\u4f53\u901a\u8fc7\u529f\u80fd\u5148\u9a8c\u77e5\u8bc6\u5f25\u5408\u7279\u5f81\u7ea7\u8bed\u4e49\u9e3f\u6c9f\u3002", "result": "\u5728\u590d\u6742\u7684\u591a\u7269\u79cd\u548c\u591a\u5668\u5b98\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDOGMA\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u96f6\u6837\u672c\u9c81\u68d2\u6027\u548c\u6837\u672c\u6548\u7387\uff0c\u540c\u65f6\u4ee5\u663e\u8457\u66f4\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u8fd0\u884c\u3002", "conclusion": "DOGMA\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u6574\u5408\u751f\u7269\u5b66\u5148\u9a8c\u77e5\u8bc6\uff0c\u4e3a\u5355\u7ec6\u80de\u8f6c\u5f55\u7ec4\u5b66\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u6570\u636e\u4e2d\u5fc3\u89e3\u51b3\u65b9\u6848\uff0c\u8d85\u8d8a\u4e86\u4f9d\u8d56\u968f\u673a\u542f\u53d1\u5f0f\u7684\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2602.01088", "pdf": "https://arxiv.org/pdf/2602.01088", "abs": "https://arxiv.org/abs/2602.01088", "authors": ["Fernando Zhapa-Camacho", "Robert Hoehndorf"], "title": "INDIGENA: inductive prediction of disease-gene associations using phenotype ontologies", "categories": ["q-bio.QM"], "comment": null, "summary": "Motivation: Predicting gene-disease associations (GDAs) is the problem to determine which gene is associated with a disease. GDA prediction can be framed as a ranking problem where genes are ranked for a query disease, based on features such as phenotypic similarity. By describing phenotypes using phenotype ontologies, ontology-based semantic similarity measures can be used. However, traditional semantic similarity measures use only the ontology taxonomy. Recent methods based on ontology embeddings compare phenotypes in latent space; these methods can use all ontology axioms as well as a supervised signal, but are inherently transductive, i.e., query entities must already be known at the time of learning embeddings, and therefore these methods do not generalize to novel diseases (sets of phenotypes) at inference time.\n  Results: We developed INDIGENA, an inductive disease-gene association method for ranking genes based on a set of phenotypes. Our method first uses a graph projection to map axioms from phenotype ontologies to a graph structure, and then uses graph embeddings to create latent representations of phenotypes. We use an explicit aggregation strategy to combine phenotype embeddings into representations of genes or diseases, allowing us to generalize to novel sets of phenotypes. We also develop a method to make the phenotype embeddings and the similarity measure task-specific by including a supervised signal from known gene-disease associations. We apply our method to mouse models of human disease and demonstrate that we can significantly improve over the inductive semantic similarity baseline measures, and reach a performance similar to transductive methods for predicting gene-disease associations while being more general.\n  Availability and Implementation: https://github.com/bio-ontology-research-group/indigena", "AI": {"tldr": "INDIGENA\u662f\u4e00\u79cd\u57fa\u4e8e\u8868\u578b\u96c6\u5408\u7684\u57fa\u56e0-\u75be\u75c5\u5173\u8054\u9884\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u7528\u56fe\u5d4c\u5165\u548c\u663e\u5f0f\u805a\u5408\u7b56\u7565\uff0c\u80fd\u591f\u63a8\u5e7f\u5230\u65b0\u7684\u75be\u75c5\u8868\u578b\u96c6\u5408\uff0c\u6027\u80fd\u63a5\u8fd1\u8f6c\u5bfc\u65b9\u6cd5\u4f46\u66f4\u5177\u901a\u7528\u6027\u3002", "motivation": "\u9884\u6d4b\u57fa\u56e0-\u75be\u75c5\u5173\u8054\uff08GDA\uff09\u662f\u4e00\u4e2a\u6392\u5e8f\u95ee\u9898\uff0c\u4f20\u7edf\u57fa\u4e8e\u672c\u4f53\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5\u53ea\u4f7f\u7528\u672c\u4f53\u5206\u7c7b\u7ed3\u6784\uff0c\u800c\u57fa\u4e8e\u672c\u4f53\u5d4c\u5165\u7684\u65b9\u6cd5\u867d\u7136\u80fd\u5229\u7528\u6240\u6709\u672c\u4f53\u516c\u7406\u548c\u76d1\u7763\u4fe1\u53f7\uff0c\u4f46\u672c\u8d28\u4e0a\u662f\u8f6c\u5bfc\u5f0f\u7684\uff0c\u65e0\u6cd5\u63a8\u5e7f\u5230\u63a8\u7406\u65f6\u7684\u65b0\u75be\u75c5\uff08\u8868\u578b\u96c6\u5408\uff09\u3002", "method": "\u9996\u5148\u901a\u8fc7\u56fe\u6295\u5f71\u5c06\u8868\u578b\u672c\u4f53\u516c\u7406\u6620\u5c04\u5230\u56fe\u7ed3\u6784\uff0c\u7136\u540e\u4f7f\u7528\u56fe\u5d4c\u5165\u521b\u5efa\u8868\u578b\u7684\u6f5c\u5728\u8868\u793a\u3002\u91c7\u7528\u663e\u5f0f\u805a\u5408\u7b56\u7565\u5c06\u8868\u578b\u5d4c\u5165\u7ec4\u5408\u6210\u57fa\u56e0\u6216\u75be\u75c5\u7684\u8868\u793a\uff0c\u4ece\u800c\u80fd\u591f\u63a8\u5e7f\u5230\u65b0\u7684\u8868\u578b\u96c6\u5408\u3002\u8fd8\u5f00\u53d1\u4e86\u65b9\u6cd5\u901a\u8fc7\u5df2\u77e5\u57fa\u56e0-\u75be\u75c5\u5173\u8054\u7684\u76d1\u7763\u4fe1\u53f7\u4f7f\u8868\u578b\u5d4c\u5165\u548c\u76f8\u4f3c\u6027\u5ea6\u91cf\u5177\u6709\u4efb\u52a1\u7279\u5f02\u6027\u3002", "result": "\u5e94\u7528\u4e8e\u4eba\u7c7b\u75be\u75c5\u5c0f\u9f20\u6a21\u578b\u65f6\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u5f52\u7eb3\u8bed\u4e49\u76f8\u4f3c\u6027\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u9884\u6d4b\u57fa\u56e0-\u75be\u75c5\u5173\u8054\u65b9\u9762\u8fbe\u5230\u4e0e\u8f6c\u5bfc\u65b9\u6cd5\u76f8\u4f3c\u7684\u6027\u80fd\uff0c\u540c\u65f6\u66f4\u5177\u901a\u7528\u6027\u3002", "conclusion": "INDIGENA\u662f\u4e00\u79cd\u6709\u6548\u7684\u5f52\u7eb3\u5f0f\u57fa\u56e0-\u75be\u75c5\u5173\u8054\u9884\u6d4b\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u65b0\u7684\u75be\u75c5\u8868\u578b\u96c6\u5408\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u65b9\u6cd5\u7684\u901a\u7528\u6027\u548c\u53ef\u63a8\u5e7f\u6027\u3002"}}
{"id": "2602.01496", "pdf": "https://arxiv.org/pdf/2602.01496", "abs": "https://arxiv.org/abs/2602.01496", "authors": ["Ralf Schwamborn"], "title": "Is Normalized Biomass Really Abundance? Pitfalls, Artifacts, and Misconceptions in the Field of Size Spectra Analysis -- A Case for Back-Transformed Spectra", "categories": ["q-bio.QM"], "comment": null, "summary": "The NBSS (normalized biomass size spectrum) is a common, intuitive approach for the study of natural ecosystems. However, very few studies have been dedicated to verifying possible bias, flaws, and paradoxes in this widely used method. An evident issue of this method, that best exemplifies its discrepancies and paradoxes, is the use of intriguing non-biomass units (such as abundance, biomass flux, or pseudo-abundance units) on NBSS plots, that are intended to visualize biomass spectra. The main objectives of this study were to verify, test and analyze the procedures involved in transformations that lead to the popular NBSS plot, and to check for the correctness of currently used units, while testing the hypothesis that NBSS indeed represents biomass, not abundance or biomass flux (dB/dM), while developing i.) a new conceptual framework, ii.) new terminology, iii.) a novel back-transformation method, iv.) a simple, new calculation method, that yields the best (i.e., least biased) representation of the original biomass vs body mass distribution shape, numerical values, dimensions, and units. Extensive tests with in-situ and synthetic (simulated) data were used to verify the procedures involved in transformations that lead to the popular NBSS plots, and to compare the original biomass distribution data with the binned outputs. Original biomass units and dimensions are retained in the novel backtransformed normalized biomass spectrum (bNBS), proposed and described herein. The proposed bNBS constitutes a new, improved approach of robust size spectra science, that allows for quantitative inter-comparisons of biomass spectra across regions and time periods.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u4f20\u7edf\u5f52\u4e00\u5316\u751f\u7269\u91cf\u5927\u5c0f\u8c31(NBSS)\u65b9\u6cd5\u5b58\u5728\u5355\u4f4d\u6df7\u6dc6\u548c\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u6982\u5ff5\u6846\u67b6\u3001\u672f\u8bed\u3001\u53cd\u53d8\u6362\u65b9\u6cd5\u548c\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u53cd\u53d8\u6362\u5f52\u4e00\u5316\u751f\u7269\u91cf\u8c31(bNBS)\u4f5c\u4e3a\u6539\u8fdb\u65b9\u6848\u3002", "motivation": "\u5c3d\u7ba1NBSS\u662f\u7814\u7a76\u81ea\u7136\u751f\u6001\u7cfb\u7edf\u7684\u5e38\u7528\u76f4\u89c2\u65b9\u6cd5\uff0c\u4f46\u5f88\u5c11\u6709\u7814\u7a76\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u53ef\u80fd\u5b58\u5728\u7684\u504f\u5dee\u3001\u7f3a\u9677\u548c\u6096\u8bba\u3002\u4e00\u4e2a\u660e\u663e\u95ee\u9898\u662fNBSS\u56fe\u4e2d\u4f7f\u7528\u4e86\u975e\u751f\u7269\u91cf\u5355\u4f4d\uff08\u5982\u4e30\u5ea6\u3001\u751f\u7269\u91cf\u901a\u91cf\u6216\u4f2a\u4e30\u5ea6\u5355\u4f4d\uff09\uff0c\u800c\u8be5\u56fe\u672c\u5e94\u53ef\u89c6\u5316\u751f\u7269\u91cf\u8c31\u3002\u9700\u8981\u9a8c\u8bc1NBSS\u662f\u5426\u771f\u6b63\u4ee3\u8868\u751f\u7269\u91cf\u800c\u975e\u4e30\u5ea6\u6216\u751f\u7269\u91cf\u901a\u91cf\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u73b0\u573a\u6570\u636e\u548c\u5408\u6210\uff08\u6a21\u62df\uff09\u6570\u636e\u9a8c\u8bc1\u4e86\u5bfc\u81f4\u6d41\u884cNBSS\u56fe\u7684\u53d8\u6362\u8fc7\u7a0b\uff0c\u6bd4\u8f83\u4e86\u539f\u59cb\u751f\u7269\u91cf\u5206\u5e03\u6570\u636e\u4e0e\u5206\u7bb1\u8f93\u51fa\u3002\u5f00\u53d1\u4e86\u65b0\u7684\u6982\u5ff5\u6846\u67b6\u3001\u672f\u8bed\u3001\u53cd\u53d8\u6362\u65b9\u6cd5\u548c\u7b80\u5355\u7684\u65b0\u8ba1\u7b97\u65b9\u6cd5\uff0c\u4fdd\u7559\u4e86\u539f\u59cb\u751f\u7269\u91cf\u5355\u4f4d\u548c\u7ef4\u5ea6\u3002", "result": "\u63d0\u51fa\u4e86\u53cd\u53d8\u6362\u5f52\u4e00\u5316\u751f\u7269\u91cf\u8c31(bNBS)\uff0c\u8be5\u65b9\u6cd5\u80fd\u6700\u597d\u5730\uff08\u5373\u504f\u5dee\u6700\u5c0f\uff09\u8868\u793a\u539f\u59cb\u751f\u7269\u91cf\u968f\u4f53\u91cd\u5206\u5e03\u7684\u5f62\u6001\u3001\u6570\u503c\u3001\u7ef4\u5ea6\u548c\u5355\u4f4d\u3002bNBS\u4fdd\u7559\u4e86\u539f\u59cb\u751f\u7269\u91cf\u5355\u4f4d\u548c\u7ef4\u5ea6\uff0c\u5141\u8bb8\u8de8\u533a\u57df\u548c\u65f6\u95f4\u6bb5\u7684\u751f\u7269\u91cf\u8c31\u5b9a\u91cf\u6bd4\u8f83\u3002", "conclusion": "bNBS\u6784\u6210\u4e86\u4e00\u4e2a\u6539\u8fdb\u7684\u3001\u7a33\u5065\u7684\u5927\u5c0f\u8c31\u79d1\u5b66\u65b0\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfNBSS\u7684\u5355\u4f4d\u6df7\u6dc6\u548c\u504f\u5dee\u95ee\u9898\uff0c\u4e3a\u751f\u6001\u7cfb\u7edf\u751f\u7269\u91cf\u8c31\u7684\u5b9a\u91cf\u6bd4\u8f83\u63d0\u4f9b\u4e86\u53ef\u9760\u5de5\u5177\u3002"}}
{"id": "2602.01751", "pdf": "https://arxiv.org/pdf/2602.01751", "abs": "https://arxiv.org/abs/2602.01751", "authors": ["Kunyi Fan", "Mengjie Chen", "Longlong Li", "Cunquan Qu"], "title": "MGKAN: Predicting Asymmetric Drug-Drug Interactions via a Multimodal Graph Kolmogorov-Arnold Network", "categories": ["cs.LG", "q-bio.QM"], "comment": "Submitted to ICASSP 2026", "summary": "Predicting drug-drug interactions (DDIs) is essential for safe pharmacological treatments. Previous graph neural network (GNN) models leverage molecular structures and interaction networks but mostly rely on linear aggregation and symmetric assumptions, limiting their ability to capture nonlinear and heterogeneous patterns. We propose MGKAN, a Graph Kolmogorov-Arnold Network that introduces learnable basis functions into asymmetric DDI prediction. MGKAN replaces conventional MLP transformations with KAN-driven basis functions, enabling more expressive and nonlinear modeling of drug relationships. To capture pharmacological dependencies, MGKAN integrates three network views-an asymmetric DDI network, a co-interaction network, and a biochemical similarity network-with role-specific embeddings to preserve directional semantics. A fusion module combines linear attention and nonlinear transformation to enhance representational capacity. On two benchmark datasets, MGKAN outperforms seven state-of-the-art baselines. Ablation studies and case studies confirm its predictive accuracy and effectiveness in modeling directional drug effects.", "AI": {"tldr": "MGKAN\uff1a\u57fa\u4e8e\u56feKolmogorov-Arnold\u7f51\u7edc\u7684\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u57fa\u51fd\u6570\u548c\u975e\u5bf9\u79f0\u7f51\u7edc\u5efa\u6a21\u63d0\u5347\u9884\u6d4b\u6027\u80fd", "motivation": "\u73b0\u6709GNN\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u7ebf\u6027\u805a\u5408\u548c\u5bf9\u79f0\u5047\u8bbe\uff0c\u96be\u4ee5\u6355\u6349\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u7684\u975e\u7ebf\u6027\u548c\u5f02\u8d28\u6027\u6a21\u5f0f\uff0c\u9650\u5236\u4e86DDI\u9884\u6d4b\u7684\u51c6\u786e\u6027", "method": "\u63d0\u51faMGKAN\u6a21\u578b\uff1a1) \u7528KAN\u9a71\u52a8\u7684\u57fa\u51fd\u6570\u66ff\u4ee3\u4f20\u7edfMLP\u53d8\u6362\uff1b2) \u6574\u5408\u4e09\u4e2a\u7f51\u7edc\u89c6\u56fe\uff08\u975e\u5bf9\u79f0DDI\u7f51\u7edc\u3001\u5171\u76f8\u4e92\u4f5c\u7528\u7f51\u7edc\u3001\u751f\u5316\u76f8\u4f3c\u6027\u7f51\u7edc\uff09\uff1b3) \u4f7f\u7528\u89d2\u8272\u7279\u5b9a\u5d4c\u5165\u4fdd\u6301\u65b9\u5411\u8bed\u4e49\uff1b4) \u878d\u5408\u7ebf\u6027\u6ce8\u610f\u529b\u548c\u975e\u7ebf\u6027\u53d8\u6362\u7684\u878d\u5408\u6a21\u5757", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cMGKAN\u8d85\u8d8a\u4e86\u4e03\u4e2a\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u6d88\u878d\u7814\u7a76\u548c\u6848\u4f8b\u7814\u7a76\u8bc1\u5b9e\u4e86\u5176\u9884\u6d4b\u51c6\u786e\u6027\u548c\u5efa\u6a21\u65b9\u5411\u6027\u836f\u7269\u6548\u5e94\u7684\u6709\u6548\u6027", "conclusion": "MGKAN\u901a\u8fc7\u5f15\u5165\u53ef\u5b66\u4e60\u57fa\u51fd\u6570\u548c\u975e\u5bf9\u79f0\u7f51\u7edc\u5efa\u6a21\uff0c\u663e\u8457\u63d0\u5347\u4e86DDI\u9884\u6d4b\u7684\u6027\u80fd\uff0c\u4e3a\u836f\u7269\u5b89\u5168\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u5de5\u5177"}}
{"id": "2602.01772", "pdf": "https://arxiv.org/pdf/2602.01772", "abs": "https://arxiv.org/abs/2602.01772", "authors": ["Yucheng Liao", "Han Wen", "Weinan E", "Weijie Zhang"], "title": "DIA-CLIP: a universal representation learning framework for zero-shot DIA proteomics", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": "21 pages, 5 figures", "summary": "Data-independent acquisition mass spectrometry (DIA-MS) has established itself as a cornerstone of proteomic profiling and large-scale systems biology, offering unparalleled depth and reproducibility. Current DIA analysis frameworks, however, require semi-supervised training within each run for peptide-spectrum match (PSM) re-scoring. This approach is prone to overfitting and lacks generalizability across diverse species and experimental conditions. Here, we present DIA-CLIP, a pre-trained model shifting the DIA analysis paradigm from semi-supervised training to universal cross-modal representation learning. By integrating dual-encoder contrastive learning framework with encoder-decoder architecture, DIA-CLIP establishes a unified cross-modal representation for peptides and corresponding spectral features, achieving high-precision, zero-shot PSM inference. Extensive evaluations across diverse benchmarks demonstrate that DIA-CLIP consistently outperforms state-of-the-art tools, yielding up to a 45% increase in protein identification while achieving a 12% reduction in entrapment identifications. Moreover, DIA-CLIP holds immense potential for diverse practical applications, such as single-cell and spatial proteomics, where its enhanced identification depth facilitates the discovery of novel biomarkers and the elucidates of intricate cellular mechanisms.", "AI": {"tldr": "DIA-CLIP\u662f\u4e00\u4e2a\u57fa\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6570\u636e\u975e\u4f9d\u8d56\u91c7\u96c6\u8d28\u8c31\u5206\u6790\u5de5\u5177\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u8868\u793a\u5b66\u4e60\u5b9e\u73b0\u96f6\u6837\u672c\u80bd\u6bb5-\u8c31\u56fe\u5339\u914d\uff0c\u663e\u8457\u63d0\u5347\u86cb\u767d\u8d28\u9274\u5b9a\u6027\u80fd\u3002", "motivation": "\u5f53\u524dDIA-MS\u5206\u6790\u6846\u67b6\u9700\u8981\u6bcf\u4e2a\u5b9e\u9a8c\u7684\u76d1\u7763\u8bad\u7ec3\uff0c\u5bb9\u6613\u8fc7\u62df\u5408\u4e14\u7f3a\u4e4f\u8de8\u7269\u79cd\u548c\u5b9e\u9a8c\u6761\u4ef6\u7684\u901a\u7528\u6027\uff0c\u9700\u8981\u66f4\u901a\u7528\u7684\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u53cc\u7f16\u7801\u5668\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u4e0e\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u76f8\u7ed3\u5408\uff0c\u5efa\u7acb\u80bd\u6bb5\u548c\u5bf9\u5e94\u8c31\u56fe\u7279\u5f81\u7684\u7edf\u4e00\u8de8\u6a21\u6001\u8868\u793a\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u96f6\u6837\u672cPSM\u63a8\u65ad\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDIA-CLIP\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u5de5\u5177\uff0c\u86cb\u767d\u8d28\u9274\u5b9a\u6570\u91cf\u589e\u52a0\u9ad8\u8fbe45%\uff0c\u540c\u65f6\u8bf1\u9975\u9274\u5b9a\u51cf\u5c1112%\u3002", "conclusion": "DIA-CLIP\u5c06DIA\u5206\u6790\u8303\u5f0f\u4ece\u534a\u76d1\u7763\u8bad\u7ec3\u8f6c\u5411\u901a\u7528\u8de8\u6a21\u6001\u8868\u793a\u5b66\u4e60\uff0c\u5728\u5355\u7ec6\u80de\u548c\u7a7a\u95f4\u86cb\u767d\u8d28\u7ec4\u5b66\u7b49\u5e94\u7528\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2602.01845", "pdf": "https://arxiv.org/pdf/2602.01845", "abs": "https://arxiv.org/abs/2602.01845", "authors": ["Furkan Eris"], "title": "No Generation without Representation: Efficient Causal Protein Language Models Enable Zero-Shot Fitness Estimation", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Protein language models (PLMs) face a fundamental divide: masked language models (MLMs) excel at fitness prediction while causal models enable generation, forcing practitioners to maintain separate architectures. We introduce \\textbf{Proust}, a 309M-parameter causal PLM that bridges this gap through architectural innovations adapted from recent LLM research, including grouped-query attention with shared K/V projections, cross-layer value residuals, and depthwise causal convolutions. Trained on 33B tokens in 40 B200 GPU-hours, Proust achieves Spearman $\u03c1= 0.390$ on ProteinGym substitutions, competitive with MLMs requiring 50--200$\\times$ the compute. On indels, Proust sets a new state-of-the-art, outperforming models up to 20$\\times$ larger. On EVEREST viral fitness benchmarks, it approaches structure-aware methods using sequence alone. These powerful representations position Proust in a sweet spot as it also retains native generative capabilities that MLMs lack by design. Interpretability analysis reveals that per-position entropy variance predicts, to an extent, when retrieval augmentation helps and hurts. Such insights can grow in both quantity and quality at scale and inform capabilities such as test-time scaling. Code and weights are available at https://github.com/Furkan9015/proust-inference", "AI": {"tldr": "Proust\u662f\u4e00\u4e2a309M\u53c2\u6570\u7684\u56e0\u679c\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u67b6\u6784\u521b\u65b0\u5728\u9002\u5e94\u5ea6\u9884\u6d4b\u548c\u751f\u6210\u80fd\u529b\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u5728\u591a\u9879\u86cb\u767d\u8d28\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u751f\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u6839\u672c\u6027\u5206\u6b67\uff1a\u63a9\u7801\u8bed\u8a00\u6a21\u578b\u64c5\u957f\u9002\u5e94\u5ea6\u9884\u6d4b\u4f46\u65e0\u6cd5\u751f\u6210\uff0c\u56e0\u679c\u6a21\u578b\u80fd\u751f\u6210\u4f46\u4e0d\u64c5\u957f\u9884\u6d4b\uff0c\u8feb\u4f7f\u7814\u7a76\u4eba\u5458\u7ef4\u62a4\u4e24\u5957\u5206\u79bb\u7684\u67b6\u6784\u3002", "method": "\u91c7\u7528\u56e0\u679c\u6a21\u578b\u67b6\u6784\uff0c\u878d\u5165LLM\u7814\u7a76\u4e2d\u7684\u521b\u65b0\uff1a\u5206\u7ec4\u67e5\u8be2\u6ce8\u610f\u529b\uff08\u5171\u4eabK/V\u6295\u5f71\uff09\u3001\u8de8\u5c42\u503c\u6b8b\u5dee\u548c\u6df1\u5ea6\u56e0\u679c\u5377\u79ef\u3002\u572833B tokens\u4e0a\u8bad\u7ec3\uff0c\u8017\u65f640 B200 GPU\u5c0f\u65f6\u3002", "result": "\u5728ProteinGym\u66ff\u6362\u4efb\u52a1\u4e0a\u8fbe\u5230Spearman \u03c1=0.390\uff0c\u4e0e\u9700\u898150-200\u500d\u8ba1\u7b97\u91cf\u7684MLMs\u76f8\u5f53\uff1b\u5728indels\u4efb\u52a1\u4e0a\u521b\u4e0b\u65b0SOTA\uff0c\u4f18\u4e8e\u592720\u500d\u7684\u6a21\u578b\uff1b\u5728EVEREST\u75c5\u6bd2\u9002\u5e94\u5ea6\u57fa\u51c6\u4e0a\u63a5\u8fd1\u7ed3\u6784\u611f\u77e5\u65b9\u6cd5\u3002", "conclusion": "Proust\u5728\u9002\u5e94\u5ea6\u9884\u6d4b\u548c\u751f\u6210\u80fd\u529b\u4e4b\u95f4\u627e\u5230\u4e86\u5e73\u8861\u70b9\uff0c\u540c\u65f6\u53ef\u89e3\u91ca\u6027\u5206\u6790\u663e\u793a\u4f4d\u7f6e\u71b5\u65b9\u5dee\u80fd\u9884\u6d4b\u68c0\u7d22\u589e\u5f3a\u7684\u6548\u679c\uff0c\u8fd9\u4e9b\u89c1\u89e3\u53ef\u6269\u5c55\u5e76\u6307\u5bfc\u6d4b\u8bd5\u65f6\u6269\u5c55\u7b49\u80fd\u529b\u3002"}}
{"id": "2602.02128", "pdf": "https://arxiv.org/pdf/2602.02128", "abs": "https://arxiv.org/abs/2602.02128", "authors": ["Nima Shoghi", "Yuxuan Liu", "Yuning Shen", "Rob Brekelmans", "Pan Li", "Quanquan Gu"], "title": "Scalable Spatio-Temporal SE(3) Diffusion for Long-Horizon Protein Dynamics", "categories": ["cs.LG", "cs.AI", "physics.bio-ph", "q-bio.BM", "q-bio.QM"], "comment": "For associated project page, see https://bytedance-seed.github.io/ConfRover/starmd", "summary": "Molecular dynamics (MD) simulations remain the gold standard for studying protein dynamics, but their computational cost limits access to biologically relevant timescales. Recent generative models have shown promise in accelerating simulations, yet they struggle with long-horizon generation due to architectural constraints, error accumulation, and inadequate modeling of spatio-temporal dynamics. We present STAR-MD (Spatio-Temporal Autoregressive Rollout for Molecular Dynamics), a scalable SE(3)-equivariant diffusion model that generates physically plausible protein trajectories over microsecond timescales. Our key innovation is a causal diffusion transformer with joint spatio-temporal attention that efficiently captures complex space-time dependencies while avoiding the memory bottlenecks of existing methods. On the standard ATLAS benchmark, STAR-MD achieves state-of-the-art performance across all metrics--substantially improving conformational coverage, structural validity, and dynamic fidelity compared to previous methods. STAR-MD successfully extrapolates to generate stable microsecond-scale trajectories where baseline methods fail catastrophically, maintaining high structural quality throughout the extended rollout. Our comprehensive evaluation reveals severe limitations in current models for long-horizon generation, while demonstrating that STAR-MD's joint spatio-temporal modeling enables robust dynamics simulation at biologically relevant timescales, paving the way for accelerated exploration of protein function.", "AI": {"tldr": "STAR-MD\u662f\u4e00\u4e2aSE(3)-\u7b49\u53d8\u7684\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u8054\u5408\u65f6\u7a7a\u6ce8\u610f\u529b\u673a\u5236\u751f\u6210\u5fae\u79d2\u7ea7\u86cb\u767d\u8d28\u8f68\u8ff9\uff0c\u5728ATLAS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u957f\u65f6\u95f4\u5c3a\u5ea6\u6a21\u62df\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u8fbe\u5230\u751f\u7269\u76f8\u5173\u65f6\u95f4\u5c3a\u5ea6\uff1b\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u957f\u65f6\u95f4\u5c3a\u5ea6\u751f\u6210\u4e2d\u5b58\u5728\u67b6\u6784\u9650\u5236\u3001\u8bef\u5dee\u7d2f\u79ef\u548c\u65f6\u7a7a\u52a8\u6001\u5efa\u6a21\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faSTAR-MD\uff1a\u53ef\u6269\u5c55\u7684SE(3)-\u7b49\u53d8\u6269\u6563\u6a21\u578b\uff0c\u91c7\u7528\u5177\u6709\u8054\u5408\u65f6\u7a7a\u6ce8\u610f\u529b\u7684\u56e0\u679c\u6269\u6563transformer\uff0c\u9ad8\u6548\u6355\u6349\u590d\u6742\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\uff0c\u907f\u514d\u73b0\u6709\u65b9\u6cd5\u7684\u5185\u5b58\u74f6\u9888\u3002", "result": "\u5728ATLAS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6240\u6709\u6307\u6807\u5747\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u663e\u8457\u6539\u5584\u6784\u8c61\u8986\u76d6\u3001\u7ed3\u6784\u6709\u6548\u6027\u548c\u52a8\u6001\u4fdd\u771f\u5ea6\uff1b\u80fd\u591f\u751f\u6210\u7a33\u5b9a\u7684\u5fae\u79d2\u7ea7\u8f68\u8ff9\uff0c\u800c\u57fa\u7ebf\u65b9\u6cd5\u5b8c\u5168\u5931\u8d25\u3002", "conclusion": "STAR-MD\u7684\u8054\u5408\u65f6\u7a7a\u5efa\u6a21\u80fd\u591f\u5728\u751f\u7269\u76f8\u5173\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u5b9e\u73b0\u7a33\u5065\u7684\u52a8\u529b\u5b66\u6a21\u62df\uff0c\u4e3a\u52a0\u901f\u63a2\u7d22\u86cb\u767d\u8d28\u529f\u80fd\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.02425", "pdf": "https://arxiv.org/pdf/2602.02425", "abs": "https://arxiv.org/abs/2602.02425", "authors": ["Amaru Caceres Arroyo", "Lea Bogensperger", "Ahmed Allam", "Michael Krauthammer", "Konrad Schindler", "Dominik Narnhofer"], "title": "Repurposing Protein Language Models for Latent Flow-Based Fitness Optimization", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Protein fitness optimization is challenged by a vast combinatorial landscape where high-fitness variants are extremely sparse. Many current methods either underperform or require computationally expensive gradient-based sampling. We present CHASE, a framework that repurposes the evolutionary knowledge of pretrained protein language models by compressing their embeddings into a compact latent space. By training a conditional flow-matching model with classifier-free guidance, we enable the direct generation of high-fitness variants without predictor-based guidance during the ODE sampling steps. CHASE achieves state-of-the-art performance on AAV and GFP protein design benchmarks. Finally, we show that bootstrapping with synthetic data can further enhance performance in data-constrained settings.", "AI": {"tldr": "CHASE\uff1a\u5229\u7528\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u5316\u77e5\u8bc6\uff0c\u901a\u8fc7\u538b\u7f29\u5d4c\u5165\u5230\u7d27\u51d1\u6f5c\u5728\u7a7a\u95f4\uff0c\u65e0\u9700\u9884\u6d4b\u5668\u5f15\u5bfc\u5373\u53ef\u76f4\u63a5\u751f\u6210\u9ad8\u9002\u5e94\u6027\u86cb\u767d\u8d28\u53d8\u4f53\u7684\u6846\u67b6", "motivation": "\u86cb\u767d\u8d28\u9002\u5e94\u6027\u4f18\u5316\u9762\u4e34\u7ec4\u5408\u7206\u70b8\u7684\u6311\u6218\uff0c\u9ad8\u9002\u5e94\u6027\u53d8\u4f53\u6781\u5176\u7a00\u758f\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u6027\u80fd\u4e0d\u8db3\uff0c\u8981\u4e48\u9700\u8981\u8ba1\u7b97\u6602\u8d35\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u91c7\u6837", "method": "\u5c06\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u7684\u5d4c\u5165\u538b\u7f29\u5230\u7d27\u51d1\u6f5c\u5728\u7a7a\u95f4\uff0c\u8bad\u7ec3\u5e26\u6709\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\u7684\u6761\u4ef6\u6d41\u5339\u914d\u6a21\u578b\uff0c\u5728ODE\u91c7\u6837\u6b65\u9aa4\u4e2d\u65e0\u9700\u9884\u6d4b\u5668\u5f15\u5bfc\u5373\u53ef\u76f4\u63a5\u751f\u6210\u9ad8\u9002\u5e94\u6027\u53d8\u4f53", "result": "\u5728AAV\u548cGFP\u86cb\u767d\u8d28\u8bbe\u8ba1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u6570\u636e\u53d7\u9650\u573a\u666f\u4e2d\u901a\u8fc7\u5408\u6210\u6570\u636e\u5f15\u5bfc\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd", "conclusion": "CHASE\u6846\u67b6\u6210\u529f\u5229\u7528\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u5316\u77e5\u8bc6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u65e0\u9700\u9884\u6d4b\u5668\u5f15\u5bfc\u7684\u9ad8\u9002\u5e94\u6027\u86cb\u767d\u8d28\u53d8\u4f53\u751f\u6210\uff0c\u4e3a\u86cb\u767d\u8d28\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5"}}
