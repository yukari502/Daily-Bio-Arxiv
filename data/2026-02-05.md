<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 2]
- [cs.LG](#cs.LG) [Total: 5]
- [eess.IV](#eess.IV) [Total: 1]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [RareCollab -- An Agentic System Diagnosing Mendelian Disorders with Integrated Phenotypic and Molecular Evidence](https://arxiv.org/abs/2602.04058)
*Guantong Qi,Jiasheng Wang,Mei Ling Chong,Zahid Shaik,Shenglan Li,Shinya Yamamoto,Undiagnosed Diseases Network,Pengfei Liu,Hu Chen,Zhandong Liu*

Main category: q-bio.GN

TL;DR: RareCollab是一个基于AI的多模态罕见病诊断框架，结合基因组、转录组和表型数据，通过LLM专家模块提高诊断准确性，在UDN基准测试中达到77%的top-5诊断准确率。


<details>
  <summary>Details</summary>
Motivation: 目前全球数百万儿童患有罕见孟德尔疾病，但外显子组和基因组测序仍无法为大量患者提供明确分子诊断，延长了诊断历程。需要从仅基于DNA的解释转向结合基因组、转录组和表型信息的多模态诊断推理，但现有计算框架有限。

Method: 提出RareCollab框架：包含稳定的定量诊断引擎和基于大语言模型（LLM）的专家模块。这些模块从转录组信号、表型、变异数据库和文献中生成高分辨率、可解释的评估，以优先考虑潜在诊断变异。

Result: 在未诊断疾病网络（UDN）患者基因组和转录组配对数据的严格基准测试中，RareCollab实现了77%的top-5诊断准确率，相比广泛使用的变异优先排序方法，top-1到top-5准确率提高了约20%。

Conclusion: RareCollab展示了模块化人工智能如何操作多模态证据进行准确、可扩展的罕见病诊断，为减少受影响家庭的诊断历程提供了有希望的途径。

Abstract: Millions of children worldwide are affected by severe rare Mendelian disorders, yet exome and genome sequencing still fail to provide a definitive molecular diagnosis for a large fraction of patients, prolonging the diagnostic odyssey. Bridging this gap increasingly requires transitioning from DNA-only interpretation to multi-modal diagnostic reasoning that combines genomic data, transcriptomic sequencing (RNA-seq), and phenotype information; however, computational frameworks that coherently integrate these signals remain limited. Here we present RareCollab, an agentic diagnostic framework that pairs a stable quantitative Diagnostic Engine with Large Language Model (LLM)-based specialist modules that produce high-resolution, interpretable assessments from transcriptomic signals, phenotypes, variant databases, and the literature to prioritize potential diagnostic variants. In a rigorously curated benchmark of Undiagnosed Diseases Network (UDN) patients with paired genomic and transcriptomic data, RareCollab achieved 77% top-5 diagnostic accuracy and improved top-1 to top-5 accuracy by ~20% over widely used variant-prioritization approaches. RareCollab illustrates how modular artificial intelligence (AI) can operationalize multi-modal evidence for accurate, scalable rare disease diagnosis, offering a promising path toward reducing the diagnostic odyssey for affected families.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [2] [Prenatal Stress Detection from Electrocardiography Using Self-Supervised Deep Learning: Development and External Validation](https://arxiv.org/abs/2602.03886)
*Martin G. Frasch,Marlene J. E. Mayer,Clara Becker,Peter Zimmermann,Camilla Zelgert,Marta C. Antonelli,Silvia M. Lobmaier*

Main category: q-bio.QM

TL;DR: 开发基于心电图的深度学习模型，通过自监督对比学习检测孕期心理压力，在内部验证中达到99.8%准确率，外部验证中77.3%准确率，显著优于传统问卷方法。


<details>
  <summary>Details</summary>
Motivation: 孕期心理压力影响15-25%的孕妇，增加早产、低出生体重和神经发育不良风险。目前依赖主观问卷（PSS-10）筛查，缺乏连续监测能力，需要客观、连续的评估方法。

Method: 使用FELICITy 1队列（151名孕妇，32-38周）的心电图数据，通过SimCLR对比学习预训练ResNet-34编码器，对每位受试者的40,692个ECG片段进行特征提取。采用多层特征提取实现二元分类和连续PSS预测，覆盖母体ECG、胎儿ECG和腹部ECG。外部验证使用FELICITy 2 RCT（28名受试者，不同ECG设备，瑜伽干预vs对照组）。

Result: FELICITy 1（5折交叉验证）：母体ECG 98.6%准确率（R2=0.88，MAE=1.90），胎儿ECG 99.8%（R2=0.95，MAE=1.19），腹部ECG 95.5%（R2=0.75，MAE=2.80）。外部验证：母体ECG 77.3%准确率（R2=0.62，MAE=3.54，AUC=0.826），腹部ECG 63.6%（R2=0.29，AUC=0.705）。基于信号质量的通道选择优于全通道平均（R2提升12%）。混合效应模型检测到显著的干预响应（p=0.041）。

Conclusion: 基于心电图的自我监督深度学习能够实现准确、客观的孕期压力评估，多层特征提取方法显著优于单嵌入方法，为连续监测孕期心理压力提供了可行的技术方案。

Abstract: Prenatal psychological stress affects 15-25% of pregnancies and increases risks of preterm birth, low birth weight, and adverse neurodevelopmental outcomes. Current screening relies on subjective questionnaires (PSS-10), limiting continuous monitoring. We developed deep learning models for stress detection from electrocardiography (ECG) using the FELICITy 1 cohort (151 pregnant women, 32-38 weeks gestation). A ResNet-34 encoder was pretrained via SimCLR contrastive learning on 40,692 ECG segments per subject. Multi-layer feature extraction enabled binary classification and continuous PSS prediction across maternal (mECG), fetal (fECG), and abdominal ECG (aECG). External validation used the FELICITy 2 RCT (28 subjects, different ECG device, yoga intervention vs. control). On FELICITy 1 (5-fold CV): mECG 98.6% accuracy (R2=0.88, MAE=1.90), fECG 99.8% (R2=0.95, MAE=1.19), aECG 95.5% (R2=0.75, MAE=2.80). External validation on FELICITy 2: mECG 77.3% accuracy (R2=0.62, MAE=3.54, AUC=0.826), aECG 63.6% (R2=0.29, AUC=0.705). Signal quality-based channel selection outperformed all-channel averaging (+12% R2 improvement). Mixed-effects models detected a significant intervention response (p=0.041). Self-supervised deep learning on pregnancy ECG enables accurate, objective stress assessment, with multi-layer feature extraction substantially outperforming single embedding approaches.

</details>


### [3] [All-Atom GPCR-Ligand Simulation via Residual Isometric Latent Flow](https://arxiv.org/abs/2602.03902)
*Jiying Zhang,Shuhao Zhang,Pierre Vandergheynst,Patrick Barth*

Main category: q-bio.QM

TL;DR: GPCRLMD：基于深度生成框架的高效GPCR-配体全原子模拟方法，通过HP-VAE和残差潜在流实现计算高效的构象动力学模拟


<details>
  <summary>Details</summary>
Motivation: GPCR是三分之一以上已批准药物的主要靶点，其信号转导依赖于复杂的构象转变。传统全原子分子动力学模拟计算成本过高，限制了GPCR-配体复合物动力学的研究。

Method: 提出GPCRLMD框架：1) 使用谐波先验变分自编码器(HP-VAE)将复合物映射到正则化等距潜在空间，通过物理信息约束保持几何拓扑；2) 在潜在空间中使用残差潜在流采样演化轨迹；3) 通过相对位移机制将静态拓扑与动态涨落解耦，最后解码回原子坐标。

Result: GPCRLMD在GPCR-配体动力学模拟中达到最先进性能，能够准确复现热力学可观测量和关键的配体-受体相互作用。

Conclusion: GPCRLMD为高效的全原子GPCR-配体模拟提供了有效的深度生成框架，克服了传统MD模拟的计算限制，有望促进GPCR信号转导机制的研究和药物发现。

Abstract: G-protein-coupled receptors (GPCRs), primary targets for over one-third of approved therapeutics, rely on intricate conformational transitions to transduce signals. While Molecular Dynamics (MD) is essential for elucidating this transduction process, particularly within ligand-bound complexes, conventional all-atom MD simulation is computationally prohibitive. In this paper, we introduce GPCRLMD, a deep generative framework for efficient all-atom GPCR-ligand simulation.GPCRLMD employs a Harmonic-Prior Variational Autoencoder (HP-VAE) to first map the complex into a regularized isometric latent space, preserving geometric topology via physics-informed constraints. Within this latent space, a Residual Latent Flow samples evolution trajectories, which are subsequently decoded back to atomic coordinates. By capturing temporal dynamics via relative displacements anchored to the initial structure, this residual mechanism effectively decouples static topology from dynamic fluctuations. Experimental results demonstrate that GPCRLMD achieves state-of-the-art performance in GPCR-ligand dynamics simulation, faithfully reproducing thermodynamic observables and critical ligand-receptor interactions.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Reversible Deep Learning for 13C NMR in Chemoinformatics: On Structures and Spectra](https://arxiv.org/abs/2602.03875)
*Stefan Kuhn,Vandana Dwarka,Przemyslaw Karol Grenda,Eero Vainikko*

Main category: cs.LG

TL;DR: 提出一种可逆深度学习方法，使用单一条件可逆神经网络实现分子结构与13C NMR谱之间的双向预测


<details>
  <summary>Details</summary>
Motivation: 传统方法通常需要分别训练正向（结构到谱）和逆向（谱到结构）模型，缺乏统一框架来处理谱到结构推断中的一对多不确定性

Method: 基于i-RevNet风格的双射块构建条件可逆神经网络，训练网络从图结构编码预测128位分箱谱码，剩余潜在维度捕捉残差变异性

Result: 模型在训练示例上数值可逆，谱码预测优于随机，在验证谱上逆向生成具有意义的结构信号，能显式表示谱到结构的一对多关系

Conclusion: 可逆架构能在单一端到端模型中统一谱预测和不确定性感知的候选结构生成

Abstract: We introduce a reversible deep learning model for 13C NMR that uses a single conditional invertible neural network for both directions between molecular structures and spectra. The network is built from i-RevNet style bijective blocks, so the forward map and its inverse are available by construction. We train the model to predict a 128-bit binned spectrum code from a graph-based structure encoding, while the remaining latent dimensions capture residual variability. At inference time, we invert the same trained network to generate structure candidates from a spectrum code, which explicitly represents the one-to-many nature of spectrum-to-structure inference. On a filtered subset, the model is numerically invertible on trained examples, achieves spectrum-code prediction above chance, and produces coarse but meaningful structural signals when inverted on validation spectra. These results demonstrate that invertible architectures can unify spectrum prediction and uncertainty-aware candidate generation within one end-to-end model.

</details>


### [5] [Group Contrastive Learning for Weakly Paired Multimodal Data](https://arxiv.org/abs/2602.04021)
*Aditya Gorla,Hugues Van Assel,Jan-Christian Huetter,Heming Yao,Kyunghyun Cho,Aviv Regev,Russell Littman*

Main category: cs.LG

TL;DR: GROOVE是一种半监督多模态表示学习方法，针对弱配对的高通量扰动数据，通过GroupCLIP损失函数和动态反向翻译自编码器框架，在共享潜在空间中学习纠缠表示。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理高通量扰动数据时面临挑战，这些数据中不同模态的样本仅通过共享的扰动标签弱配对，缺乏直接对应关系。需要开发能够有效利用这种弱配对信息的表示学习方法。

Method: 提出GroupCLIP损失函数，桥接CLIP（配对跨模态）和SupCon（单模态监督对比学习）的差距；结合动态反向翻译自编码器框架，在共享潜在空间中保持组级一致性；引入组合评估框架，系统评估不同最优传输对齐器的性能。

Result: 在模拟数据和两个真实单细胞遗传扰动数据集上，GROOVE在跨模态匹配和插补任务中表现优于或与现有方法相当；组合基准测试显示尚无对齐器在所有设置或模态对中占主导地位；消融研究表明GroupCLIP是性能提升的关键因素。

Conclusion: 在弱配对场景中，利用组级约束对于有效的多模态表示学习至关重要；GroupCLIP成功解决了弱配对对比学习的基本差距；提出的组合评估框架为系统评估表示学习方法提供了更全面的工具。

Abstract: We present GROOVE, a semi-supervised multi-modal representation learning approach for high-content perturbation data where samples across modalities are weakly paired through shared perturbation labels but lack direct correspondence. Our primary contribution is GroupCLIP, a novel group-level contrastive loss that bridges the gap between CLIP for paired cross-modal data and SupCon for uni-modal supervised contrastive learning, addressing a fundamental gap in contrastive learning for weakly-paired settings. We integrate GroupCLIP with an on-the-fly backtranslating autoencoder framework to encourage cross-modally entangled representations while maintaining group-level coherence within a shared latent space. Critically, we introduce a comprehensive combinatorial evaluation framework that systematically assesses representation learners across multiple optimal transport aligners, addressing key limitations in existing evaluation strategies. This framework includes novel simulations that systematically vary shared versus modality-specific perturbation effects enabling principled assessment of method robustness. Our combinatorial benchmarking reveals that there is not yet an aligner that uniformly dominates across settings or modality pairs. Across simulations and two real single-cell genetic perturbation datasets, GROOVE performs on par with or outperforms existing approaches for downstream cross-modal matching and imputation tasks. Our ablation studies demonstrate that GroupCLIP is the key component driving performance gains. These results highlight the importance of leveraging group-level constraints for effective multi-modal representation learning in scenarios where only weak pairing is available.

</details>


### [6] [Synthesizable Molecular Generation via Soft-constrained GFlowNets with Rich Chemical Priors](https://arxiv.org/abs/2602.04119)
*Hyeonah Kim,Minsu Kim,Celine Roget,Dionessa Biton,Louis Vaillancourt,Yves V. Brun,Yoshua Bengio,Alex Hernandez-Garcia*

Main category: cs.LG

TL;DR: S3-GFN：通过软正则化序列GFlowNet生成可合成SMILES分子，避免硬约束限制


<details>
  <summary>Details</summary>
Motivation: 现有基于反应模板和构建块的硬约束方法缺乏灵活性和可扩展性，限制了生成模型在实验药物发现中的应用

Method: 提出S3-GFN，通过简单软正则化序列GFlowNet生成可合成SMILES分子，利用大规模SMILES语料库学习分子先验，通过基于可合成/不可合成样本缓冲区的对比学习信号进行离策略回放训练

Result: S3-GFN能够生成高比例可合成分子（≥95%）并在多样化任务中获得更高奖励

Conclusion: 软正则化方法比硬约束方法更灵活有效，能够引导分子生成到高奖励、可合成的化学空间

Abstract: The application of generative models for experimental drug discovery campaigns is severely limited by the difficulty of designing molecules de novo that can be synthesized in practice. Previous works have leveraged Generative Flow Networks (GFlowNets) to impose hard synthesizability constraints through the design of state and action spaces based on predefined reaction templates and building blocks. Despite the promising prospects of this approach, it currently lacks flexibility and scalability. As an alternative, we propose S3-GFN, which generates synthesizable SMILES molecules via simple soft regularization of a sequence-based GFlowNet. Our approach leverages rich molecular priors learned from large-scale SMILES corpora to steer molecular generation towards high-reward, synthesizable chemical spaces. The model induces constraints through off-policy replay training with a contrastive learning signal based on separate buffers of synthesizable and unsynthesizable samples. Our experiments show that S3-GFN learns to generate synthesizable molecules ($\geq 95\%$) with higher rewards in diverse tasks.

</details>


### [7] [Multi-Integration of Labels across Categories for Component Identification (MILCCI)](https://arxiv.org/abs/2602.04270)
*Noga Mudrik,Yuxi Chen,Gal Mishne,Adam S. Charles*

Main category: cs.LG

TL;DR: MILCCI是一种新的数据驱动方法，用于分析带有多类别元数据标签的重复测量时间序列数据，能够识别可解释的组件、捕捉跨试验变异性，并整合标签信息来理解每个类别在数据中的表示。


<details>
  <summary>Details</summary>
Motivation: 许多领域通过重复测量收集大规模时间序列数据，每个试验都带有跨越多个类别的元数据变量。关键挑战是理解这些标签如何在多试验观测中被编码，并区分每个标签条目在不同类别中的不同影响。

Method: MILCCI扩展了稀疏的每试验分解方法，利用每个类别内的标签相似性来实现细微的、标签驱动的跨试验组件组成调整，并区分每个类别的贡献。同时学习每个组件对应的时间轨迹，这些轨迹在每个试验内随时间演化并在不同试验间灵活变化。

Result: 通过合成和真实世界示例（包括投票模式、在线页面浏览趋势和神经元记录）展示了MILCCI的性能。

Conclusion: MILCCI提供了一种有效的方法来分析带有多类别元数据标签的时间序列数据，能够识别可解释的组件并理解不同类别标签在数据中的表示方式。

Abstract: Many fields collect large-scale temporal data through repeated measurements (trials), where each trial is labeled with a set of metadata variables spanning several categories. For example, a trial in a neuroscience study may be linked to a value from category (a): task difficulty, and category (b): animal choice. A critical challenge in time-series analysis is to understand how these labels are encoded within the multi-trial observations, and disentangle the distinct effect of each label entry across categories. Here, we present MILCCI, a novel data-driven method that i) identifies the interpretable components underlying the data, ii) captures cross-trial variability, and iii) integrates label information to understand each category's representation within the data. MILCCI extends a sparse per-trial decomposition that leverages label similarities within each category to enable subtle, label-driven cross-trial adjustments in component compositions and to distinguish the contribution of each category. MILCCI also learns each component's corresponding temporal trace, which evolves over time within each trial and varies flexibly across trials. We demonstrate MILCCI's performance through both synthetic and real-world examples, including voting patterns, online page view trends, and neuronal recordings.

</details>


### [8] [Protein Autoregressive Modeling via Multiscale Structure Generation](https://arxiv.org/abs/2602.04883)
*Yanru Qu,Cheng-Yen Hsieh,Zaixiang Zheng,Ge Liu,Quanquan Gu*

Main category: cs.LG

TL;DR: PAR是首个多尺度自回归蛋白质骨架生成框架，通过从粗到细的逐尺度预测生成蛋白质结构，采用噪声上下文学习和调度采样缓解暴露偏差，在无条件生成基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 利用蛋白质的层次性本质，模仿雕塑过程从粗到细生成蛋白质结构，解决现有自回归模型中的暴露偏差问题，实现高质量的蛋白质骨架生成。

Method: 1) 多尺度下采样操作表示不同尺度的蛋白质结构；2) 自回归Transformer编码多尺度信息并产生条件嵌入；3) 基于流的骨架解码器根据嵌入生成骨架原子；4) 采用噪声上下文学习和调度采样缓解暴露偏差。

Result: PAR有效学习蛋白质分布，生成高质量的骨架结构，表现出良好的缩放行为，具有强大的零样本泛化能力，支持灵活的人类提示条件生成和基序支架，无需微调。

Conclusion: PAR作为一个有前景的蛋白质结构生成框架，通过多尺度自回归方法解决了暴露偏差问题，在无条件生成和条件生成任务上都表现出色。

Abstract: We present protein autoregressive modeling (PAR), the first multi-scale autoregressive framework for protein backbone generation via coarse-to-fine next-scale prediction. Using the hierarchical nature of proteins, PAR generates structures that mimic sculpting a statue, forming a coarse topology and refining structural details over scales. To achieve this, PAR consists of three key components: (i) multi-scale downsampling operations that represent protein structures across multiple scales during training; (ii) an autoregressive transformer that encodes multi-scale information and produces conditional embeddings to guide structure generation; (iii) a flow-based backbone decoder that generates backbone atoms conditioned on these embeddings. Moreover, autoregressive models suffer from exposure bias, caused by the training and the generation procedure mismatch, and substantially degrades structure generation quality. We effectively alleviate this issue by adopting noisy context learning and scheduled sampling, enabling robust backbone generation. Notably, PAR exhibits strong zero-shot generalization, supporting flexible human-prompted conditional generation and motif scaffolding without requiring fine-tuning. On the unconditional generation benchmark, PAR effectively learns protein distributions and produces backbones of high design quality, and exhibits favorable scaling behavior. Together, these properties establish PAR as a promising framework for protein structure generation.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [9] [AtlasPatch: An Efficient and Scalable Tool for Whole Slide Image Preprocessing in Computational Pathology](https://arxiv.org/abs/2602.03998)
*Ahmed Alagha,Christopher Leclerc,Yousef Kotp,Omar Metwally,Calvin Moras,Peter Rentopoulos,Ghodsiyeh Rostami,Bich Ngoc Nguyen,Jumanah Baig,Abdelhakim Khellaf,Vincent Quoc-Huy Trinh,Rabeb Mizouni,Hadi Otrok,Jamal Bentahar,Mahdi S. Hosseini*

Main category: eess.IV

TL;DR: AtlasPatch是一个高效可扩展的WSI预处理框架，通过SAM模型微调实现准确组织检测，显著降低计算成本


<details>
  <summary>Details</summary>
Motivation: 现有WSI预处理工具存在两大问题：要么依赖不准确的启发式阈值进行组织检测，要么采用基于AI的方法但训练数据多样性有限且在补丁级别操作，计算复杂度高

Method: 1) 在约30,000个WSI缩略图的异构半手动标注数据集上训练组织检测模块，使用Segment-Anything模型的高效微调；2) 从缩略图外推组织掩码到全分辨率切片；3) 在用户指定放大倍数下提取补丁坐标；4) 支持将补丁直接流式传输到常见图像编码器或存储补丁图像；5) 在CPU和GPU上高效并行化

Result: 在分割精度、计算复杂度和下游多实例学习方面进行评估，匹配最先进性能，同时仅需其计算成本的一小部分

Conclusion: AtlasPatch是一个开源的高效可扩展WSI预处理框架，解决了计算病理学中的主要计算瓶颈，提供准确组织检测和高通量补丁提取

Abstract: Whole-slide image (WSI) preprocessing, typically comprising tissue detection followed by patch extraction, is foundational to AI-driven computational pathology workflows. This remains a major computational bottleneck as existing tools either rely on inaccurate heuristic thresholding for tissue detection, or adopt AI-based approaches trained on limited-diversity data that operate at the patch level, incurring substantial computational complexity. We present AtlasPatch, an efficient and scalable slide preprocessing framework for accurate tissue detection and high-throughput patch extraction with minimal computational overhead. AtlasPatch's tissue detection module is trained on a heterogeneous and semi-manually annotated dataset of ~30,000 WSI thumbnails, using efficient fine-tuning of the Segment-Anything model. The tool extrapolates tissue masks from thumbnails to full-resolution slides to extract patch coordinates at user-specified magnifications, with options to stream patches directly into common image encoders for embedding or store patch images, all efficiently parallelized across CPUs and GPUs. We assess AtlasPatch across segmentation precision, computational complexity, and downstream multiple-instance learning, matching state-of-the-art performance while operating at a fraction of their computational cost. AtlasPatch is open-source and available at https://github.com/AtlasAnalyticsLab/AtlasPatch.

</details>
