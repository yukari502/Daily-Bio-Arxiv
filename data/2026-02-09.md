<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Internalized Morphogenesis: A Self-Organizing Model for Growth, Replication, and Regeneration via Local Token Exchange in Modular Systems](https://arxiv.org/abs/2602.06296)
*Takeshi Ishida*

Main category: cs.RO

TL;DR: 提出一种内部化形态发生模型，通过模块间的局部交互实现复杂形态生成，无需外部空间计算，适用于资源受限的自主系统。


<details>
  <summary>Details</summary>
Motivation: 传统自组织模型需要在整个坐标空间进行计算，包括空区域，这对于资源受限的物理模块（如群体机器人、微纳机器）不切实际。需要一种仅依赖局部交互的内部化方法。

Method: 扩展"Ishida token模型"，模块通过相邻模块交换整数值，采用RD启发的离散模拟而不求解微分方程。内部电位由token积累和老化产生，指导自主生长、收缩和复制。

Result: 在六边形网格上的模拟展示了肢体样延伸、自我分裂和结构截肢后的鲁棒再生能力。利用身体边界作为信息熵（token）的自然汇来维持动态平衡。

Conclusion: 复杂形态行为可以从最小化、仅内部规则中涌现。该框架为开发自修复、自适应和自主硬件提供了计算高效且生物学合理的方法。

Abstract: This study presents an internalized morphogenesis model for autonomous systems, such as swarm robotics and micro-nanomachines, that eliminates the need for external spatial computation. Traditional self-organizing models often require calculations across the entire coordinate space, including empty areas, which is impractical for resource-constrained physical modules. Our proposed model achieves complex morphogenesis through strictly local interactions between adjacent modules within the "body." By extending the "Ishida token model," modules exchange integer values using an RD-inspired discrete analogue without solving differential equations. The internal potential, derived from token accumulation and aging, guides autonomous growth, shrinkage, and replication. Simulations on a hexagonal grid demonstrated the emergence of limb-like extensions, self-division, and robust regeneration capabilities following structural amputation. A key feature is the use of the body boundary as a natural sink for information entropy (tokens) to maintain a dynamic equilibrium. These results indicate that sophisticated morphological behaviors can emerge from minimal, internal-only rules. This framework offers a computationally efficient and biologically plausible approach to developing self-repairing, adaptive, and autonomous hardware.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization](https://arxiv.org/abs/2602.06394)
*Arvid E. Gollwitzer,Paridhi Latawa,David de Gruijl,Deepak A. Subramanian,Adrián Noriega de la Colina*

Main category: cs.AI

TL;DR: QA-Token：一种质量感知的分词方法，通过双层优化和强化学习将数据可靠性纳入词汇表构建，在基因组学和金融领域显著提升性能


<details>
  <summary>Details</summary>
Motivation: 当前的分词方法在处理序列数据时未考虑信号质量，限制了其在嘈杂真实世界语料库上的有效性。需要一种能直接纳入数据可靠性的分词方法。

Method: 提出QA-Token方法，包含三个关键贡献：(1) 双层优化公式，联合优化词汇表构建和下游性能；(2) 强化学习方法，通过质量感知奖励学习合并策略并保证收敛；(3) 通过Gumbel-Softmax松弛的自适应参数学习机制，实现端到端优化。

Result: 实验评估显示一致改进：基因组学（变异检测F1分数比BPE提高6.7个百分点）、金融（夏普比率提高30%）。在基础模型规模上，分词了1.7万亿碱基对的预训练语料，实现最先进的病原体检测（94.53 MCC），同时减少15%的token数量。

Conclusion: QA-Token解锁了嘈杂的真实世界语料库（包括数petabase的基因组序列和数TB的金融时间序列），用于基础模型训练，且推理时无额外开销。

Abstract: Current tokenization methods process sequential data without accounting for signal quality, limiting their effectiveness on noisy real-world corpora. We present QA-Token (Quality-Aware Tokenization), which incorporates data reliability directly into vocabulary construction. We make three key contributions: (i) a bilevel optimization formulation that jointly optimizes vocabulary construction and downstream performance, (ii) a reinforcement learning approach that learns merge policies through quality-aware rewards with convergence guarantees, and (iii) an adaptive parameter learning mechanism via Gumbel-Softmax relaxation for end-to-end optimization. Our experimental evaluation demonstrates consistent improvements: genomics (6.7 percentage point F1 gain in variant calling over BPE), finance (30% Sharpe ratio improvement). At foundation scale, we tokenize a pretraining corpus comprising 1.7 trillion base-pairs and achieve state-of-the-art pathogen detection (94.53 MCC) while reducing token count by 15%. We unlock noisy real-world corpora, spanning petabases of genomic sequences and terabytes of financial time series, for foundation model training with zero inference overhead.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [3] [An Interpretable Vision Transformer as a Fingerprint-Based Diagnostic Aid for Kabuki and Wiedemann-Steiner Syndromes](https://arxiv.org/abs/2602.06282)
*Marilyn Lionts,Arnhildur Tomasdottir,Viktor I. Agustsson,Yuankai Huo,Hans T. Bjornsson,Lotta M. Ellingsen*

Main category: cs.CV

TL;DR: 基于视觉Transformer的深度学习模型利用指纹图像区分Kabuki综合征、Wiedemann-Steiner综合征和健康对照，为罕见遗传病提供非侵入性AI诊断工具


<details>
  <summary>Details</summary>
Motivation: Kabuki综合征和Wiedemann-Steiner综合征是临床表现重叠的罕见发育障碍，由于遗传检测可及性和专业知识的限制，许多患者未能得到诊断。尽管皮纹异常是多种遗传综合征的已知特征，但在分子检测时代仍未被充分利用作为诊断信号。

Method: 开发基于视觉Transformer的深度学习模型，利用指纹图像进行三类二元分类：健康对照vs.KS、健康对照vs.WSS、KS vs.WSS。使用注意力可视化技术识别对模型预测最关键的指纹区域，增强可解释性。

Result: 模型在三项分类任务中表现良好：健康对照vs.KS的AUC为0.80，健康对照vs.WSS的AUC为0.73，KS vs.WSS的AUC为0.85。相应的F1分数分别为0.71、0.72和0.83。注意力可视化揭示了与综合征相关的特异性指纹特征。

Conclusion: 研究证实了综合征特异性指纹特征的存在，展示了基于指纹的AI工具作为非侵入性、可解释且易于获取的诊断辅助手段的可行性，有望用于早期诊断未确诊的遗传综合征。

Abstract: Kabuki syndrome (KS) and Wiedemann-Steiner syndrome (WSS) are rare but distinct developmental disorders that share overlapping clinical features, including neurodevelopmental delay, growth restriction, and persistent fetal fingertip pads. While genetic testing remains the diagnostic gold standard, many individuals with KS or WSS remain undiagnosed due to barriers in access to both genetic testing and expertise. Dermatoglyphic anomalies, despite being established hallmarks of several genetic syndromes, remain an underutilized diagnostic signal in the era of molecular testing. This study presents a vision transformer-based deep learning model that leverages fingerprint images to distinguish individuals with KS and WSS from unaffected controls and from one another. We evaluate model performance across three binary classification tasks. Across the three classification tasks, the model achieved AUC scores of 0.80 (control vs. KS), 0.73 (control vs. WSS), and 0.85 (KS vs. WSS), with corresponding F1 scores of 0.71, 0.72, and 0.83, respectively. Beyond classification, we apply attention-based visualizations to identify fingerprint regions most salient to model predictions, enhancing interpretability. Together, these findings suggest the presence of syndrome-specific fingerprint features, demonstrating the feasibility of a fingerprint-based artificial intelligence (AI) tool as a noninvasive, interpretable, and accessible future diagnostic aid for the early diagnosis of underdiagnosed genetic syndromes.

</details>
