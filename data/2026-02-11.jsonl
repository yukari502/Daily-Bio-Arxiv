{"id": "2602.09036", "pdf": "https://arxiv.org/pdf/2602.09036", "abs": "https://arxiv.org/abs/2602.09036", "authors": ["Maria De La Luz Lomboy Toledo", "Daniel Onah"], "title": "Predicting Gene Disease Associations in Type 2 Diabetes Using Machine Learning on Single-Cell RNA-Seq Data", "categories": ["q-bio.GN", "cs.LG"], "comment": "11 pages, 7 figures. Preprint", "summary": "Diabetes is a chronic metabolic disorder characterized by elevated blood glucose levels due to impaired insulin production or function. Two main forms are recognized: type 1 diabetes (T1D), which involves autoimmune destruction of insulin-producing \\b{eta}-cells, and type 2 diabetes (T2D), which arises from insulin resistance and progressive \\b{eta}-cell dysfunction. Understanding the molecular mechanisms underlying these diseases is essential for the development of improved therapeutic strategies, particularly those targeting \\b{eta}-cell dysfunction. To investigate these mechanisms in a controlled and biologically interpretable setting, mouse models have played a central role in diabetes research. Owing to their genetic and physiological similarity to humans, together with the ability to precisely manipulate their genome, mice enable detailed investigation of disease progression and gene function. In particular, mouse models have provided critical insights into \\b{eta}-cell development, cellular heterogeneity, and functional failure under diabetic conditions. Building on these experimental advances, this study applies machine learning methods to single-cell transcriptomic data from mouse pancreatic islets. Specifically, we evaluate two supervised approaches identified in the literature; Extra Trees Classifier (ETC) and Partial Least Squares Discriminant Analysis (PLS-DA), to assess their ability to identify T2D-associated gene expression signatures at single-cell resolution. Model performance is evaluated using standard classification metrics, with an emphasis on interpretability and biological relevance"}
{"id": "2602.09063", "pdf": "https://arxiv.org/pdf/2602.09063", "abs": "https://arxiv.org/abs/2602.09063", "authors": ["Kenny Workman", "Zhen Yang", "Harihara Muralidharan", "Aidan Abdulali", "Hannah Le"], "title": "scBench: Evaluating AI Agents on Single-Cell RNA-seq Analysis", "categories": ["q-bio.GN", "cs.AI"], "comment": null, "summary": "As single-cell RNA sequencing datasets grow in adoption, scale, and complexity, data analysis remains a bottleneck for many research groups. Although frontier AI agents have improved dramatically at software engineering and general data analysis, it remains unclear whether they can extract biological insight from messy, real-world single-cell datasets. We introduce scBench, a benchmark of 394 verifiable problems derived from practical scRNA-seq workflows spanning six sequencing platforms and seven task categories. Each problem provides a snapshot of experimental data immediately prior to an analysis step and a deterministic grader that evaluates recovery of a key biological result. Benchmark data on eight frontier models shows that accuracy ranges from 29-53%, with strong model-task and model-platform interactions. Platform choice affects accuracy as much as model choice, with 40+ percentage point drops on less-documented technologies. scBench complements SpatialBench to cover the two dominant single-cell modalities, serving both as a measurement tool and a diagnostic lens for developing agents that can analyze real scRNA-seq datasets faithfully and reproducibly."}
{"id": "2602.09067", "pdf": "https://arxiv.org/pdf/2602.09067", "abs": "https://arxiv.org/abs/2602.09067", "authors": ["Yue Pei", "Xuebin Chi", "Yu Kang"], "title": "AntigenLM: Structure-Aware DNA Language Modeling for Influenza", "categories": ["q-bio.GN", "cs.AI"], "comment": "Accepted by ICLR 2026", "summary": "Language models have advanced sequence analysis, yet DNA foundation models often lag behind task-specific methods for unclear reasons. We present AntigenLM, a generative DNA language model pretrained on influenza genomes with intact, aligned functional units. This structure-aware pretraining enables AntigenLM to capture evolutionary constraints and generalize across tasks. Fine-tuned on time-series hemagglutinin (HA) and neuraminidase (NA) sequences, AntigenLM accurately forecasts future antigenic variants across regions and subtypes, including those unseen during training, outperforming phylogenetic and evolution-based models. It also achieves near-perfect subtype classification. Ablation studies show that disrupting genomic structure through fragmentation or shuffling severely degrades performance, revealing the importance of preserving functional-unit integrity in DNA language modeling. AntigenLM thus provides both a powerful framework for antigen evolution prediction and a general principle for building biologically grounded DNA foundation models."}
{"id": "2602.09649", "pdf": "https://arxiv.org/pdf/2602.09649", "abs": "https://arxiv.org/abs/2602.09649", "authors": ["Ben Jeffery", "Yan Wong", "Kevin Thornton", "Georgia Tsambos", "Gertjan Bisschop", "Yun Deng", "E. Castedo Ellerman", "Thomas B. Forest", "Halley Fritze", "Daniel Goldstein", "Gregor Gorjanc", "Graham Gower", "Simon Gravel", "Jeremy Guez", "Benjamin C. Haller", "Andrew D. Kern", "Lloyd Kirk", "Hanbin Lee", "Brieuc Lehmann", "Hossameldin Loay", "Matthew M. Osmond", "Duncan S. Palmer", "Nathaniel S. Pope", "Aaron P. Ragsdale", "Duncan Robertson", "Murillo F. Rodrigues", "Hugo van Kemenade", "Clemens L. Weiß", "Anthony Wilder Wohns", "Shing H. Zhan", "Brian C. Zhang", "Marianne Aspbury", "Nikolas A. Baya", "Saurabh Belsare", "Arjun Biddanda", "Francisco Campuzano Jiménez", "Ariella Gladstein", "Bing Guo", "Savita Karthikeyan", "Warren W. Kretzschmar", "Inés Rebollo", "Kumar Saunack", "Ruhollah Shemirani", "Alexis Simon", "Chris Smith", "Jeet Sukumaran", "Jonathan Terhorst", "Per Unneberg", "Ao Zhang", "Peter Ralph", "Jerome Kelleher"], "title": "Population-scale Ancestral Recombination Graphs with tskit 1.0", "categories": ["q-bio.PE", "q-bio.GN"], "comment": null, "summary": "Ancestral recombination graphs (ARGs) are an increasingly important component of population and statistical genetics. The tskit library has become key infrastructure for the field, providing an expressive and general representation of ARGs together with a suite of efficient fundamental operations. In this note, we announce tskit version 1.0, describe its underlying rationale, and document its stability guarantees. These guarantees provide a foundation for durable computational artefacts and support long-term reproducibility of code and analyses."}
{"id": "2602.09116", "pdf": "https://arxiv.org/pdf/2602.09116", "abs": "https://arxiv.org/abs/2602.09116", "authors": ["Daniele Caligiore"], "title": "Importance inversion transfer identifies shared principles for cross-domain learning", "categories": ["cs.LG", "physics.soc-ph", "q-bio.QM"], "comment": null, "summary": "The capacity to transfer knowledge across scientific domains relies on shared organizational principles. However, existing transfer-learning methodologies often fail to bridge radically heterogeneous systems, particularly under severe data scarcity or stochastic noise. This study formalizes Explainable Cross-Domain Transfer Learning (X-CDTL), a framework unifying network science and explainable artificial intelligence to identify structural invariants that generalize across biological, linguistic, molecular, and social networks. By introducing the Importance Inversion Transfer (IIT) mechanism, the framework prioritizes domain-invariant structural anchors over idiosyncratic, highly discriminative features. In anomaly detection tasks, models guided by these principles achieve significant performance gains - exhibiting a 56\\% relative improvement in decision stability under extreme noise - over traditional baselines. These results provide evidence for a shared organizational signature across heterogeneous domains, establishing a principled paradigm for cross-disciplinary knowledge propagation. By shifting from opaque latent representations to explicit structural laws, this work advances machine learning as a robust engine for scientific discovery."}
{"id": "2602.09424", "pdf": "https://arxiv.org/pdf/2602.09424", "abs": "https://arxiv.org/abs/2602.09424", "authors": ["Prin Phunyaphibarn", "Minhyuk Sung"], "title": "Reward-Guided Discrete Diffusion via Clean-Sample Markov Chain for Molecule and Biological Sequence Design", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Discrete diffusion models have recently emerged as a powerful class of generative models for chemistry and biology data. In these fields, the goal is to generate various samples with high rewards (e.g., drug-likeness in molecules), making reward-based guidance crucial. Most existing methods are based on guiding the diffusion model using intermediate rewards but tend to underperform since intermediate rewards are noisy due to the non-smooth nature of reward functions used in scientific domains. To address this, we propose Clean-Sample Markov Chain (CSMC) Sampler, a method that performs effective test-time reward-guided sampling for discrete diffusion models, enabling local search without relying on intermediate rewards. CSMC constructs a Markov chain of clean samples using the Metropolis-Hastings algorithm such that its stationary distribution is the target distribution. We design a proposal distribution by sequentially applying the forward and backward diffusion processes, making the acceptance probability tractable. Experiments on molecule and biological sequence generation with various reward functions demonstrate that our method consistently outperforms prior approaches that rely on intermediate rewards."}
{"id": "2602.09793", "pdf": "https://arxiv.org/pdf/2602.09793", "abs": "https://arxiv.org/abs/2602.09793", "authors": ["Jesper Strøm", "Casper Skjærbæk", "Natasha Becker Bertelsen", "Steffen Torpe Simonsen", "Niels Okkels", "David Bertram", "Sinah Röttgen", "Konstantin Kufer", "Kaare B. Mikkelsen", "Marit Otto", "Poul Jørgen Jennum", "Per Borghammer", "Michael Sommerauer", "Preben Kidmose"], "title": "Fully-automated sleep staging: multicenter validation of a generalizable deep neural network for Parkinson's disease and isolated REM sleep behavior disorder", "categories": ["cs.LG", "q-bio.QM"], "comment": "21 pages excluding supplementary, 9 figures", "summary": "Isolated REM sleep behavior disorder (iRBD) is a key prodromal marker of Parkinson's disease (PD), and video-polysomnography (vPSG) remains the diagnostic gold standard. However, manual sleep staging is particularly challenging in neurodegenerative diseases due to EEG abnormalities and fragmented sleep, making PSG assessments a bottleneck for deploying new RBD screening technologies at scale. We adapted U-Sleep, a deep neural network, for generalizable sleep staging in PD and iRBD. A pretrained U-Sleep model, based on a large publicly available, multisite non-neurodegenerative dataset (PUB; 19,236 PSGs across 12 sites), was fine-tuned on research datasets from two centers (Lundbeck Foundation Parkinson's Disease Research Center (PACE) and the Cologne-Bonn Cohort (CBC); 112 PD, 138 iRBD, 89 age-matched controls. The resulting model was evaluated on an independent dataset from the Danish Center for Sleep Medicine (DCSM; 81 PD, 36 iRBD, 87 sleep-clinic controls). A subset of PSGs with low agreement between the human rater and the model (\\k{appa} < 0.6) was re-scored by a second blinded human rater to identify sources of disagreement. Finally, we applied confidence-based thresholds to optimize REM sleep staging. The pretrained model achieved mean \\k{appa} = 0.81 in PUB, but \\k{appa} = 0.66 when applied directly to PACE/CBC. By fine-tuning the model, we developed a generalized model with \\k{appa} = 0.74 on PACE/CBC (p < 0.001 vs. the pretrained model). In DCSM, mean and median \\k{appa} increased from 0.60 to 0.64 (p < 0.001) and 0.64 to 0.69 (p < 0.001), respectively. In the interrater study, PSGs with low agreement between the model and the initial scorer showed similarly low agreement between human scorers. Applying a confidence threshold increased the proportion of correctly identified REM sleep epochs from 85% to 95.5%, while preserving sufficient (> 5 min) REM sleep for 95% of subjects."}
