{"id": "2602.10152", "pdf": "https://arxiv.org/pdf/2602.10152", "abs": "https://arxiv.org/abs/2602.10152", "authors": ["Zahra Khodagholi", "Niloofar Yousefi"], "title": "Validating Interpretability in siRNA Efficacy Prediction: A Perturbation-Based, Dataset-Aware Protocol", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "Saliency maps are increasingly used as \\emph{design guidance} in siRNA efficacy prediction, yet attribution methods are rarely validated before motivating sequence edits. We introduce a \\textbf{pre-synthesis gate}: a protocol for \\emph{counterfactual sensitivity faithfulness} that tests whether mutating high-saliency positions changes model output more than composition-matched controls. Cross-dataset transfer reveals two failure modes that would otherwise go undetected: \\emph{faithful-but-wrong} (saliency valid, predictions fail) and \\emph{inverted saliency} (top-saliency edits less impactful than random). Strikingly, models trained on mRNA-level assays collapse on a luciferase reporter dataset, demonstrating that protocol shifts can silently invalidate deployment. Across four benchmarks, 19/20 fold instances pass; the single failure shows inverted saliency. A biology-informed regularizer (BioPrior) strengthens saliency faithfulness with modest, dataset-dependent predictive trade-offs. Our results establish saliency validation as essential pre-deployment practice for explanation-guided therapeutic design. Code is available at https://github.com/shadi97kh/BioPrior.", "AI": {"tldr": "\u63d0\u51fa\"\u9884\u5408\u6210\u95e8\"\u534f\u8bae\u9a8c\u8bc1siRNA\u9884\u6d4b\u6a21\u578b\u4e2d\u663e\u8457\u6027\u56fe\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u4e24\u79cd\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u5f00\u53d1\u751f\u7269\u5b66\u5148\u9a8c\u6b63\u5219\u5316\u5668\u63d0\u5347\u663e\u8457\u6027\u5fe0\u5b9e\u5ea6", "motivation": "\u663e\u8457\u6027\u56fe\u5728siRNA\u6548\u529b\u9884\u6d4b\u4e2d\u4f5c\u4e3a\u8bbe\u8ba1\u6307\u5bfc\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5f88\u5c11\u5728\u6307\u5bfc\u5e8f\u5217\u7f16\u8f91\u524d\u9a8c\u8bc1\u5176\u5f52\u56e0\u65b9\u6cd5\u7684\u53ef\u9760\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u65e0\u6548\u7684\u8bbe\u8ba1\u51b3\u7b56", "method": "\u5f15\u5165\"\u9884\u5408\u6210\u95e8\"\u534f\u8bae\u8fdb\u884c\u53cd\u4e8b\u5b9e\u654f\u611f\u6027\u5fe0\u5b9e\u5ea6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u7a81\u53d8\u9ad8\u663e\u8457\u6027\u4f4d\u7f6e\u5e76\u4e0e\u7ec4\u6210\u5339\u914d\u7684\u5bf9\u7167\u6bd4\u8f83\u6a21\u578b\u8f93\u51fa\u53d8\u5316\uff1b\u5f00\u53d1\u751f\u7269\u5b66\u5148\u9a8c\u6b63\u5219\u5316\u5668(BioPrior)\u589e\u5f3a\u663e\u8457\u6027\u5fe0\u5b9e\u5ea6", "result": "\u8de8\u6570\u636e\u96c6\u8f6c\u79fb\u63ed\u793a\u4e24\u79cd\u5931\u8d25\u6a21\u5f0f\uff1a\u5fe0\u5b9e\u4f46\u9519\u8bef\uff08\u663e\u8457\u6027\u6709\u6548\u4f46\u9884\u6d4b\u5931\u8d25\uff09\u548c\u53cd\u8f6c\u663e\u8457\u6027\uff08\u9ad8\u663e\u8457\u6027\u7f16\u8f91\u5f71\u54cd\u5c0f\u4e8e\u968f\u673a\u7f16\u8f91\uff09\uff1b\u5728mRNA\u6c34\u5e73\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u8367\u5149\u7d20\u9176\u62a5\u544a\u6570\u636e\u96c6\u4e0a\u5d29\u6e83\uff1b\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d19/20\u901a\u8fc7\uff0c\u552f\u4e00\u5931\u8d25\u6848\u4f8b\u663e\u793a\u53cd\u8f6c\u663e\u8457\u6027\uff1bBioPrior\u80fd\u589e\u5f3a\u663e\u8457\u6027\u5fe0\u5b9e\u5ea6\u4f46\u5e26\u6765\u6570\u636e\u96c6\u4f9d\u8d56\u7684\u9884\u6d4b\u6743\u8861", "conclusion": "\u663e\u8457\u6027\u9a8c\u8bc1\u662f\u89e3\u91ca\u5f15\u5bfc\u6cbb\u7597\u8bbe\u8ba1\u90e8\u7f72\u524d\u7684\u91cd\u8981\u5b9e\u8df5\uff0c\u9884\u5408\u6210\u95e8\u534f\u8bae\u80fd\u68c0\u6d4b\u663e\u8457\u6027\u56fe\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u907f\u514d\u65e0\u6548\u7684\u8bbe\u8ba1\u6307\u5bfc"}}
{"id": "2602.10156", "pdf": "https://arxiv.org/pdf/2602.10156", "abs": "https://arxiv.org/abs/2602.10156", "authors": ["Boyang Fu", "George Dasoulas", "Sameer Gabbita", "Xiang Lin", "Shanghua Gao", "Xiaorui Su", "Soumya Ghosh", "Marinka Zitnik"], "title": "STRAND: Sequence-Conditioned Transport for Single-Cell Perturbations", "categories": ["q-bio.GN", "cs.LG", "q-bio.CB"], "comment": "8 pages for main draft, 6 main figures", "summary": "Predicting how genetic perturbations change cellular state is a core problem for building controllable models of gene regulation. Perturbations targeting the same gene can produce different transcriptional responses depending on their genomic locus, including different transcription start sites and regulatory elements. Gene-level perturbation models collapse these distinct interventions into the same representation.\n  We introduce STRAND, a generative model that predicts single-cell transcriptional responses by conditioning on regulatory DNA sequence. STRAND represents a perturbation by encoding the sequence at its genomic locus and uses this representation to parameterize a conditional transport process from control to perturbed cell states. Representing perturbations by sequence, rather than by a fixed set of gene identifiers, supports zero-shot inference at loci not seen during training and expands inference-time genomic coverage from ~1.5% for gene-level single-cell foundation models to ~95% of the genome.\n  We evaluate STRAND on CRISPR perturbation datasets in K562, Jurkat, and RPE1 cells. STRAND improves discrimination scores by up to 33% in low-sample regimes, achieves the best average rank on unseen gene perturbation benchmarks, and improves transfer to novel cell lines by up to 0.14 in Pearson correlation. Ablations isolate the gains to sequence conditioning and transport, and case studies show that STRAND resolves functionally alternative transcription start sites missed by gene-level models.", "AI": {"tldr": "STRAND\u662f\u4e00\u4e2a\u57fa\u4e8eDNA\u5e8f\u5217\u7684\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u7f16\u7801\u57fa\u56e0\u7ec4\u4f4d\u70b9\u5e8f\u5217\u6765\u9884\u6d4b\u5355\u7ec6\u80de\u8f6c\u5f55\u54cd\u5e94\uff0c\u652f\u6301\u96f6\u6837\u672c\u63a8\u7406\u5e76\u663e\u8457\u6269\u5c55\u57fa\u56e0\u7ec4\u8986\u76d6\u8303\u56f4\u3002", "motivation": "\u73b0\u6709\u57fa\u56e0\u6c34\u5e73\u6270\u52a8\u6a21\u578b\u5c06\u9488\u5bf9\u540c\u4e00\u57fa\u56e0\u7684\u4e0d\u540c\u57fa\u56e0\u7ec4\u4f4d\u70b9\u5e72\u9884\uff08\u5982\u4e0d\u540c\u8f6c\u5f55\u8d77\u59cb\u4f4d\u70b9\u548c\u8c03\u63a7\u5143\u4ef6\uff09\u5408\u5e76\u4e3a\u76f8\u540c\u8868\u793a\uff0c\u65e0\u6cd5\u533a\u5206\u8fd9\u4e9b\u5dee\u5f02\uff0c\u9650\u5236\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "STRAND\u901a\u8fc7\u7f16\u7801\u6270\u52a8\u4f4d\u70b9\u7684\u8c03\u63a7DNA\u5e8f\u5217\u6765\u8868\u793a\u6270\u52a8\uff0c\u4f7f\u7528\u8be5\u8868\u793a\u53c2\u6570\u5316\u4ece\u5bf9\u7167\u5230\u6270\u52a8\u7ec6\u80de\u72b6\u6001\u7684\u6761\u4ef6\u4f20\u8f93\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u57fa\u4e8e\u5e8f\u5217\u800c\u975e\u56fa\u5b9a\u57fa\u56e0\u6807\u8bc6\u7684\u9884\u6d4b\u3002", "result": "\u5728K562\u3001Jurkat\u548cRPE1\u7ec6\u80de\u7684CRISPR\u6270\u52a8\u6570\u636e\u96c6\u4e0a\uff0cSTRAND\u5728\u4f4e\u6837\u672c\u6761\u4ef6\u4e0b\u63d0\u5347\u5224\u522b\u5206\u6570\u8fbe33%\uff0c\u5728\u672a\u89c1\u57fa\u56e0\u6270\u52a8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6392\u540d\u6700\u4f73\uff0c\u8de8\u7ec6\u80de\u7cfb\u8f6c\u79fb\u6027\u80fd\u63d0\u53470.14\u76ae\u5c14\u900a\u76f8\u5173\u6027\u3002", "conclusion": "STRAND\u901a\u8fc7\u5e8f\u5217\u6761\u4ef6\u5316\u548c\u4f20\u8f93\u8fc7\u7a0b\u663e\u8457\u63d0\u5347\u6270\u52a8\u9884\u6d4b\u6027\u80fd\uff0c\u80fd\u591f\u89e3\u6790\u57fa\u56e0\u6c34\u5e73\u6a21\u578b\u9057\u6f0f\u7684\u529f\u80fd\u6027\u66ff\u4ee3\u8f6c\u5f55\u8d77\u59cb\u4f4d\u70b9\uff0c\u5c06\u63a8\u7406\u65f6\u57fa\u56e0\u7ec4\u8986\u76d6\u4ece~1.5%\u6269\u5c55\u5230~95%\u3002"}}
{"id": "2602.10163", "pdf": "https://arxiv.org/pdf/2602.10163", "abs": "https://arxiv.org/abs/2602.10163", "authors": ["Edward Wijaya"], "title": "Beyond SMILES: Evaluating Agentic Systems for Drug Discovery", "categories": ["q-bio.QM", "cs.AI"], "comment": "46 pages, 8 figures, 15 tables", "summary": "Agentic systems for drug discovery have demonstrated autonomous synthesis planning, literature mining, and molecular design. We ask how well they generalize. Evaluating six frameworks against 15 task classes drawn from peptide therapeutics, in vivo pharmacology, and resource-constrained settings, we find five capability gaps: no support for protein language models or peptide-specific prediction, no bridges between in vivo and in silico data, reliance on LLM inference with no pathway to ML training or reinforcement learning, assumptions tied to large-pharma resources, and single-objective optimization that ignores safety-efficacy-stability trade-offs. A paired knowledge-probing experiment suggests the bottleneck is architectural rather than epistemic: four frontier LLMs reason about peptides at levels comparable to small molecules, yet no framework exposes this capability. We propose design requirements and a capability matrix for next-generation frameworks that function as computational partners under realistic constraints.", "AI": {"tldr": "\u8bc4\u4f306\u4e2a\u836f\u7269\u53d1\u73b0\u667a\u80fd\u4f53\u7cfb\u7edf\u572815\u4e2a\u4efb\u52a1\u7c7b\u522b\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b05\u4e2a\u80fd\u529b\u5dee\u8ddd\uff0c\u63d0\u51fa\u4e0b\u4e00\u4ee3\u6846\u67b6\u8bbe\u8ba1\u9700\u6c42", "motivation": "\u836f\u7269\u53d1\u73b0\u667a\u80fd\u4f53\u7cfb\u7edf\u5df2\u5c55\u793a\u81ea\u4e3b\u5408\u6210\u89c4\u5212\u3001\u6587\u732e\u6316\u6398\u548c\u5206\u5b50\u8bbe\u8ba1\u80fd\u529b\uff0c\u4f46\u9700\u8981\u8bc4\u4f30\u5176\u6cdb\u5316\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u80bd\u7597\u6cd5\u3001\u4f53\u5185\u836f\u7406\u5b66\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u7b49\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528\u8868\u73b0", "method": "\u8bc4\u4f306\u4e2a\u6846\u67b6\u572815\u4e2a\u4efb\u52a1\u7c7b\u522b\u4e2d\u7684\u8868\u73b0\uff0c\u5305\u62ec\u80bd\u7597\u6cd5\u3001\u4f53\u5185\u836f\u7406\u5b66\u548c\u8d44\u6e90\u53d7\u9650\u8bbe\u7f6e\uff1b\u8fdb\u884c\u914d\u5bf9\u77e5\u8bc6\u63a2\u6d4b\u5b9e\u9a8c\uff0c\u6d4b\u8bd54\u4e2a\u524d\u6cbfLLM\u5bf9\u80bd\u7684\u7406\u89e3\u80fd\u529b", "result": "\u53d1\u73b05\u4e2a\u5173\u952e\u80fd\u529b\u5dee\u8ddd\uff1a\u4e0d\u652f\u6301\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u6216\u80bd\u7279\u5f02\u6027\u9884\u6d4b\u3001\u7f3a\u4e4f\u4f53\u5185\u4e0e\u8ba1\u7b97\u673a\u6570\u636e\u6865\u6881\u3001\u4f9d\u8d56LLM\u63a8\u7406\u800c\u65e0ML\u8bad\u7ec3\u6216\u5f3a\u5316\u5b66\u4e60\u8def\u5f84\u3001\u5047\u8bbe\u4f9d\u8d56\u5927\u578b\u5236\u836f\u8d44\u6e90\u3001\u5355\u76ee\u6807\u4f18\u5316\u5ffd\u7565\u5b89\u5168-\u7597\u6548-\u7a33\u5b9a\u6027\u6743\u8861\uff1b\u77e5\u8bc6\u63a2\u6d4b\u5b9e\u9a8c\u663e\u793a\u74f6\u9888\u662f\u67b6\u6784\u800c\u975e\u8ba4\u77e5\u95ee\u9898", "conclusion": "\u63d0\u51fa\u4e0b\u4e00\u4ee3\u6846\u67b6\u7684\u8bbe\u8ba1\u9700\u6c42\u548c\u80fd\u529b\u77e9\u9635\uff0c\u4f7f\u5176\u80fd\u5728\u73b0\u5b9e\u7ea6\u675f\u4e0b\u4f5c\u4e3a\u8ba1\u7b97\u4f19\u4f34\u53d1\u6325\u4f5c\u7528\uff0c\u9700\u8981\u89e3\u51b3\u5f53\u524d\u67b6\u6784\u9650\u5236\u4ee5\u5145\u5206\u5229\u7528LLM\u7684\u80bd\u7406\u89e3\u80fd\u529b"}}
{"id": "2602.10168", "pdf": "https://arxiv.org/pdf/2602.10168", "abs": "https://arxiv.org/abs/2602.10168", "authors": ["Ethan Bandasack", "Vincent Bouget", "Apolline Bruley", "Yannis Cattan", "Charlotte Claye", "Matthew Corney", "Julien Duquesne", "Karim El Kanbi", "Aziz Fouch\u00e9", "Pierre Marschall", "Francesco Strozzi"], "title": "EVA: Towards a universal model of the immune system", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "The effective application of foundation models to translational research in immune-mediated diseases requires multimodal patient-level representations that can capture complex phenotypes emerging from multicellular interactions. Yet most current biological foundation models focus only on single-cell resolution and are evaluated on technical metrics often disconnected from actual drug development tasks and challenges. Here, we introduce EVA, the first cross-species, multimodal foundation model of immunology and inflammation, a therapeutic area where shared pathogenic mechanisms create unique opportunities for transfer learning. EVA harmonizes transcriptomics data across species, platforms, and resolutions, and integrates histology data to produce rich, unified patient representations. We establish clear scaling laws, demonstrating that increasing model size and compute translates to improvements in both pretraining and downstream tasks performance. We introduce a comprehensive evaluation suite of 39 tasks spanning the drug development pipeline: zero-shot target efficacy and gene function prediction for discovery, cross-species or cross-diseases molecular perturbations for preclinical development, and patient stratification with treatment response prediction or disease activity prediction for clinical trials applications. We benchmark EVA against several state-of-the-art biological foundation models and baselines on these tasks, and demonstrate state-of-the-art results on each task category. Using mechanistic interpretability, we further identify biological meaningful features, revealing intertwined representations across species and technologies. We release an open version of EVA for transcriptomics to accelerate research on immune-mediated diseases.", "AI": {"tldr": "EVA\u662f\u9996\u4e2a\u8de8\u7269\u79cd\u3001\u591a\u6a21\u6001\u7684\u514d\u75ab\u5b66\u4e0e\u708e\u75c7\u57fa\u7840\u6a21\u578b\uff0c\u6574\u5408\u8f6c\u5f55\u7ec4\u5b66\u548c\u75c5\u7406\u5b66\u6570\u636e\uff0c\u5728\u836f\u7269\u7814\u53d1\u5168\u6d41\u7a0b\u768439\u4e2a\u4efb\u52a1\u4e0a\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u751f\u7269\u57fa\u7840\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u5355\u7ec6\u80de\u5206\u8fa8\u7387\uff0c\u4e14\u8bc4\u4f30\u6307\u6807\u4e0e\u836f\u7269\u7814\u53d1\u5b9e\u9645\u4efb\u52a1\u8131\u8282\u3002\u514d\u75ab\u4ecb\u5bfc\u75be\u75c5\u4e2d\u5171\u4eab\u7684\u81f4\u75c5\u673a\u5236\u4e3a\u8fc1\u79fb\u5b66\u4e60\u63d0\u4f9b\u4e86\u72ec\u7279\u673a\u4f1a\uff0c\u9700\u8981\u80fd\u591f\u6355\u6349\u591a\u7ec6\u80de\u76f8\u4e92\u4f5c\u7528\u590d\u6742\u8868\u578b\u7684\u591a\u6a21\u6001\u60a3\u8005\u8868\u5f81\u3002", "method": "EVA\u6574\u5408\u8de8\u7269\u79cd\u3001\u5e73\u53f0\u548c\u5206\u8fa8\u7387\u7684\u8f6c\u5f55\u7ec4\u5b66\u6570\u636e\uff0c\u7ed3\u5408\u75c5\u7406\u5b66\u6570\u636e\u751f\u6210\u7edf\u4e00\u60a3\u8005\u8868\u5f81\u3002\u5efa\u7acb\u4e86\u6e05\u6670\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u8bc1\u660e\u589e\u52a0\u6a21\u578b\u89c4\u6a21\u548c\u8ba1\u7b97\u8d44\u6e90\u80fd\u63d0\u5347\u9884\u8bad\u7ec3\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002\u91c7\u7528\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u8bc6\u522b\u751f\u7269\u5b66\u6709\u610f\u4e49\u7684\u7279\u5f81\u3002", "result": "\u5728\u6db5\u76d6\u836f\u7269\u7814\u53d1\u7ba1\u7ebf\u768439\u4e2a\u4efb\u52a1\u8bc4\u4f30\u5957\u4ef6\u4e2d\uff0cEVA\u5728\u96f6\u9776\u70b9\u7597\u6548\u9884\u6d4b\u3001\u57fa\u56e0\u529f\u80fd\u9884\u6d4b\u3001\u8de8\u7269\u79cd\u5206\u5b50\u6270\u52a8\u3001\u60a3\u8005\u5206\u5c42\u3001\u6cbb\u7597\u53cd\u5e94\u9884\u6d4b\u7b49\u6240\u6709\u4efb\u52a1\u7c7b\u522b\u4e0a\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002\u53d1\u73b0\u4e86\u8de8\u7269\u79cd\u548c\u6280\u672f\u7684\u4ea4\u7ec7\u8868\u5f81\u6a21\u5f0f\u3002", "conclusion": "EVA\u4f5c\u4e3a\u9996\u4e2a\u8de8\u7269\u79cd\u591a\u6a21\u6001\u514d\u75ab\u5b66\u57fa\u7840\u6a21\u578b\uff0c\u4e3a\u514d\u75ab\u4ecb\u5bfc\u75be\u75c5\u7684\u8f6c\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u5f3a\u5927\u5de5\u5177\u3002\u901a\u8fc7\u5f00\u653e\u8f6c\u5f55\u7ec4\u5b66\u7248\u672c\uff0c\u65e8\u5728\u52a0\u901f\u8be5\u9886\u57df\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2602.10303", "pdf": "https://arxiv.org/pdf/2602.10303", "abs": "https://arxiv.org/abs/2602.10303", "authors": ["Haoling Wang", "Lang Zeng", "Tao Sun", "Youngjoo Cho", "Ying Ding"], "title": "ICODEN: Ordinary Differential Equation Neural Networks for Interval-Censored Data", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "comment": null, "summary": "Predicting time-to-event outcomes when event times are interval censored is challenging because the exact event time is unobserved. Many existing survival analysis approaches for interval-censored data rely on strong model assumptions or cannot handle high-dimensional predictors. We develop ICODEN, an ordinary differential equation-based neural network for interval-censored data that models the hazard function through deep neural networks and obtains the cumulative hazard by solving an ordinary differential equation. ICODEN does not require the proportional hazards assumption or a prespecified parametric form for the hazard function, thereby permitting flexible survival modeling. Across simulation settings with proportional or non-proportional hazards and both linear and nonlinear covariate effects, ICODEN consistently achieves satisfactory predictive accuracy and remains stable as the number of predictors increases. Applications to data from multiple phases of the Alzheimer's Disease Neuroimaging Initiative (ADNI) and to two Age-Related Eye Disease Studies (AREDS and AREDS2) for age-related macular degeneration (AMD) demonstrate ICODEN's robust prediction performance. In both applications, predicting time-to-AD or time-to-late AMD, ICODEN effectively uses hundreds to more than 1,000 SNPs and supports data-driven subgroup identification with differential progression risk profiles. These results establish ICODEN as a practical assumption-lean tool for prediction with interval-censored survival data in high-dimensional biomedical settings.", "AI": {"tldr": "ICODeN\uff1a\u4e00\u79cd\u57fa\u4e8e\u5e38\u5fae\u5206\u65b9\u7a0b\u7684\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u533a\u95f4\u5220\u5931\u751f\u5b58\u6570\u636e\uff0c\u65e0\u9700\u6bd4\u4f8b\u98ce\u9669\u5047\u8bbe\u6216\u53c2\u6570\u5316\u98ce\u9669\u51fd\u6570\u5f62\u5f0f\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u9884\u6d4b\u53d8\u91cf\u573a\u666f\u3002", "motivation": "\u533a\u95f4\u5220\u5931\u751f\u5b58\u6570\u636e\u4e2d\u4e8b\u4ef6\u53d1\u751f\u65f6\u95f4\u65e0\u6cd5\u7cbe\u786e\u89c2\u6d4b\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u5f3a\u6a21\u578b\u5047\u8bbe\uff08\u5982\u6bd4\u4f8b\u98ce\u9669\uff09\uff0c\u8981\u4e48\u65e0\u6cd5\u5904\u7406\u9ad8\u7ef4\u9884\u6d4b\u53d8\u91cf\uff0c\u9650\u5236\u4e86\u5728\u751f\u7269\u533b\u5b66\u9ad8\u7ef4\u6570\u636e\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5f00\u53d1ICODeN\u6a21\u578b\uff0c\u901a\u8fc7\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5efa\u6a21\u98ce\u9669\u51fd\u6570\uff0c\u901a\u8fc7\u6c42\u89e3\u5e38\u5fae\u5206\u65b9\u7a0b\u83b7\u5f97\u7d2f\u79ef\u98ce\u9669\u51fd\u6570\u3002\u8be5\u65b9\u6cd5\u4e0d\u8981\u6c42\u6bd4\u4f8b\u98ce\u9669\u5047\u8bbe\uff0c\u4e5f\u4e0d\u9884\u8bbe\u98ce\u9669\u51fd\u6570\u7684\u53c2\u6570\u5f62\u5f0f\uff0c\u652f\u6301\u7075\u6d3b\u751f\u5b58\u5efa\u6a21\u3002", "result": "\u5728\u6a21\u62df\u7814\u7a76\u4e2d\uff0c\u65e0\u8bba\u6bd4\u4f8b\u98ce\u9669\u6216\u975e\u6bd4\u4f8b\u98ce\u9669\u3001\u7ebf\u6027\u6216\u975e\u7ebf\u6027\u534f\u53d8\u91cf\u6548\u5e94\uff0cICODeN\u5747\u4fdd\u6301\u826f\u597d\u9884\u6d4b\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u3002\u5728ADNI\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u6570\u636e\u548cAREDS/AREDS2\u5e74\u9f84\u76f8\u5173\u6027\u9ec4\u6591\u53d8\u6027\u6570\u636e\u5e94\u7528\u4e2d\uff0cICODeN\u80fd\u6709\u6548\u5229\u7528\u6570\u767e\u81f3\u4e0a\u5343\u4e2aSNPs\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u652f\u6301\u6570\u636e\u9a71\u52a8\u7684\u4e9a\u7ec4\u8bc6\u522b\u3002", "conclusion": "ICODeN\u662f\u4e00\u4e2a\u5b9e\u7528\u7684\u5047\u8bbe\u5bbd\u677e\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u751f\u7269\u533b\u5b66\u73af\u5883\u4e2d\u533a\u95f4\u5220\u5931\u751f\u5b58\u6570\u636e\u7684\u9884\u6d4b\u5206\u6790\uff0c\u4e3a\u590d\u6742\u751f\u5b58\u6570\u636e\u5efa\u6a21\u63d0\u4f9b\u4e86\u7075\u6d3b\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
