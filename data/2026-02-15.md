<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 2]
- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [How Well Do Large-Scale Chemical Language Models Transfer to Downstream Tasks?](https://arxiv.org/abs/2602.11618)
*Tatsuya Sagawa,Ryosuke Kojima*

Main category: cs.LG

TL;DR: 化学语言模型（CLMs）的预训练损失随训练资源增加而降低，但下游分子性质预测任务的性能提升有限，预训练指标与下游性能之间存在差距。


<details>
  <summary>Details</summary>
Motivation: 验证化学领域中"增加训练资源（模型大小、数据集大小、训练计算量）能同时改善预训练损失和下游任务性能"这一常见假设是否成立。

Method: 通过缩放训练资源预训练CLMs，测量在多样化分子性质预测任务上的迁移性能，分析Hessian和损失景观等替代指标，并通过参数空间可视化分析任务依赖的失败模式。

Result: 预训练损失随训练资源增加而持续降低，但下游任务性能改善有限；基于Hessian或损失景观的替代指标也无法有效估计CLMs的下游性能；在某些条件下，下游性能会饱和甚至下降，尽管预训练指标持续改善。

Conclusion: 预训练评估与下游性能之间存在差距，需要开发能够明确考虑下游任务特性的模型选择和评估策略。

Abstract: Chemical Language Models (CLMs) pre-trained on large scale molecular data are widely used for molecular property prediction. However, the common belief that increasing training resources such as model size, dataset size, and training compute improves both pretraining loss and downstream task performance has not been systematically validated in the chemical domain. In this work, we evaluate this assumption by pretraining CLMs while scaling training resources and measuring transfer performance across diverse molecular property prediction (MPP) tasks. We find that while pretraining loss consistently decreases with increased training resources, downstream task performance shows limited improvement. Moreover, alternative metrics based on the Hessian or loss landscape also fail to estimate downstream performance in CLMs. We further identify conditions under which downstream performance saturates or degrades despite continued improvements in pretraining metrics, and analyze the underlying task dependent failure modes through parameter space visualizations. These results expose a gap between pretraining based evaluation and downstream performance, and emphasize the need for model selection and evaluation strategies that explicitly account for downstream task characteristics.

</details>


### [2] [Protein Circuit Tracing via Cross-layer Transcoders](https://arxiv.org/abs/2602.12026)
*Darin Tsui,Kunal Talreja,Daniel Saeedi,Amirali Aghazadeh*

Main category: cs.LG

TL;DR: ProtoMech是一个用于发现蛋白质语言模型中计算电路的框架，通过跨层转码器学习稀疏潜在表示，能恢复82-89%的原始性能，识别出仅使用<1%潜在空间的压缩电路，并可用于蛋白质设计。


<details>
  <summary>Details</summary>
Motivation: 蛋白质语言模型已成为预测蛋白质结构和功能的有力工具，但其背后的计算机制仍不明确。现有的可解释性方法独立处理每一层，无法捕捉跨层计算，限制了近似完整模型的能力。

Method: 引入ProtoMech框架，使用跨层转码器学习稀疏潜在表示，共同捕捉模型在所有层的完整计算电路。应用于ESM2蛋白质语言模型。

Result: 在蛋白质家族分类和功能预测任务中恢复82-89%的原始性能；识别出仅使用<1%潜在空间的压缩电路，保留高达79%的模型准确率；揭示与结构和功能基序的对应关系；在蛋白质设计中，超过70%的情况下优于基线方法。

Conclusion: ProtoMech为蛋白质电路追踪提供了一个原则性框架，能够发现蛋白质语言模型中的计算电路，揭示其与生物学功能的联系，并应用于蛋白质设计。

Abstract: Protein language models (pLMs) have emerged as powerful predictors of protein structure and function. However, the computational circuits underlying their predictions remain poorly understood. Recent mechanistic interpretability methods decompose pLM representations into interpretable features, but they treat each layer independently and thus fail to capture cross-layer computation, limiting their ability to approximate the full model. We introduce ProtoMech, a framework for discovering computational circuits in pLMs using cross-layer transcoders that learn sparse latent representations jointly across layers to capture the model's full computational circuitry. Applied to the pLM ESM2, ProtoMech recovers 82-89% of the original performance on protein family classification and function prediction tasks. ProtoMech then identifies compressed circuits that use <1% of the latent space while retaining up to 79% of model accuracy, revealing correspondence with structural and functional motifs, including binding, signaling, and stability. Steering along these circuits enables high-fitness protein design, surpassing baseline methods in more than 70% of cases. These results establish ProtoMech as a principled framework for protein circuit tracing.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [3] [scPilot: Large Language Model Reasoning Toward Automated Single-Cell Analysis and Discovery](https://arxiv.org/abs/2602.11609)
*Yiming Gao,Zhen Wang,Jefferson Chen,Mark Antkowiak,Mengzhou Hu,JungHo Kong,Dexter Pratt,Jieyuan Liu,Enze Ma,Zhiting Hu,Eric P. Xing*

Main category: cs.AI

TL;DR: scPilot是首个实现组学原生推理的系统框架，让大语言模型能够直接检查单细胞RNA-seq数据和使用生物信息学工具，通过逐步推理解决单细胞分析问题。


<details>
  <summary>Details</summary>
Motivation: 当前单细胞分析需要专业生物信息学知识，缺乏透明度和可解释性。scPilot旨在让大语言模型直接基于原始组学数据进行推理，实现可审计、可解释的单细胞分析。

Method: 将核心单细胞分析（细胞类型注释、发育轨迹重建、转录因子靶向）转化为逐步推理问题，让LLM在自然语言对话中直接检查单细胞数据和工具，支持迭代推理和证据修订。

Result: 实验显示：迭代组学原生推理将细胞类型注释平均准确率提升11%；Gemini-2.5-Pro将轨迹图编辑距离减少30%；生成透明推理轨迹解释标记基因模糊性和调控逻辑。

Conclusion: scPilot通过将LLM锚定在原始组学数据中，实现了可审计、可解释且具有诊断信息的单细胞分析，为生物医学研究提供了新的分析范式。

Abstract: We present scPilot, the first systematic framework to practice omics-native reasoning: a large language model (LLM) converses in natural language while directly inspecting single-cell RNA-seq data and on-demand bioinformatics tools. scPilot converts core single-cell analyses, i.e., cell-type annotation, developmental-trajectory reconstruction, and transcription-factor targeting, into step-by-step reasoning problems that the model must solve, justify, and, when needed, revise with new evidence.
  To measure progress, we release scBench, a suite of 9 expertly curated datasets and graders that faithfully evaluate the omics-native reasoning capability of scPilot w.r.t various LLMs. Experiments with o1 show that iterative omics-native reasoning lifts average accuracy by 11% for cell-type annotation and Gemini-2.5-Pro cuts trajectory graph-edit distance by 30% versus one-shot prompting, while generating transparent reasoning traces explain marker gene ambiguity and regulatory logic. By grounding LLMs in raw omics data, scPilot enables auditable, interpretable, and diagnostically informative single-cell analyses.
  Code, data, and package are available at https://github.com/maitrix-org/scPilot

</details>
