{"id": "2602.20198", "pdf": "https://arxiv.org/pdf/2602.20198", "abs": "https://arxiv.org/abs/2602.20198", "authors": ["Soumik Deb Niloy", "Md. Fahmid-Ul-Alam Juboraj", "Swakkhar Shatabda"], "title": "KEMP-PIP: A Feature-Fusion Based Approach for Pro-inflammatory Peptide Prediction", "categories": ["q-bio.QM", "cs.LG"], "comment": "11 pages, 4 figures, 6 tables; includes web server and GitHub implementation", "summary": "Pro-inflammatory peptides (PIPs) play critical roles in immune signaling and inflammation but are difficult to identify experimentally due to costly and time-consuming assays. To address this challenge, we present KEMP-PIP, a hybrid machine learning framework that integrates deep protein embeddings with handcrafted descriptors for robust PIP prediction. Our approach combines contextual embeddings from pretrained ESM protein language models with multi-scale k-mer frequencies, physicochemical descriptors, and modlAMP sequence features. Feature pruning and class-weighted logistic regression manage high dimensionality and class imbalance, while ensemble averaging with an optimized decision threshold enhances the sensitivity--specificity balance. Through systematic ablation studies, we demonstrate that integrating complementary feature sets consistently improves predictive performance. On the standard benchmark dataset, KEMP-PIP achieves an MCC of 0.505, accuracy of 0.752, and AUC of 0.762, outperforming ProIn-fuse, MultiFeatVotPIP, and StackPIP. Relative to StackPIP, these results represent improvements of 9.5% in MCC and 4.8% in both accuracy and AUC. The KEMP-PIP web server is freely available at https://nilsparrow1920-kemp-pip.hf.space/ and the full implementation at https://github.com/S18-Niloy/KEMP-PIP.", "AI": {"tldr": "KEMP-PIP\u662f\u4e00\u4e2a\u6df7\u5408\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u6df1\u5ea6\u86cb\u767d\u8d28\u5d4c\u5165\u548c\u624b\u5de5\u7279\u5f81\u6765\u9884\u6d4b\u4fc3\u708e\u80bd\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4fc3\u708e\u80bd\u5728\u514d\u75ab\u4fe1\u53f7\u4f20\u5bfc\u548c\u708e\u75c7\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u5b9e\u9a8c\u9274\u5b9a\u6210\u672c\u9ad8\u3001\u8017\u65f6\u957f\uff0c\u9700\u8981\u5f00\u53d1\u8ba1\u7b97\u9884\u6d4b\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u6574\u5408\u9884\u8bad\u7ec3ESM\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5d4c\u5165\u4e0e\u591a\u5c3a\u5ea6k-mer\u9891\u7387\u3001\u7269\u7406\u5316\u5b66\u63cf\u8ff0\u7b26\u548cmodlAMP\u5e8f\u5217\u7279\u5f81\uff0c\u901a\u8fc7\u7279\u5f81\u526a\u679d\u3001\u7c7b\u522b\u52a0\u6743\u903b\u8f91\u56de\u5f52\u5904\u7406\u9ad8\u7ef4\u5ea6\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u4f7f\u7528\u96c6\u6210\u5e73\u5747\u548c\u4f18\u5316\u51b3\u7b56\u9608\u503c\u5e73\u8861\u654f\u611f\u6027\u548c\u7279\u5f02\u6027\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cKEMP-PIP\u8fbe\u5230MCC 0.505\u3001\u51c6\u786e\u73870.752\u3001AUC 0.762\uff0c\u4f18\u4e8eProIn-fuse\u3001MultiFeatVotPIP\u548cStackPIP\uff0c\u76f8\u6bd4StackPIP\u5728MCC\u4e0a\u63d0\u53479.5%\uff0c\u51c6\u786e\u7387\u548cAUC\u5747\u63d0\u53474.8%\u3002", "conclusion": "KEMP-PIP\u901a\u8fc7\u6574\u5408\u4e92\u8865\u7279\u5f81\u96c6\u663e\u8457\u63d0\u9ad8\u4e86\u4fc3\u708e\u80bd\u9884\u6d4b\u6027\u80fd\uff0c\u63d0\u4f9b\u4e86\u514d\u8d39\u53ef\u7528\u7684\u7f51\u7edc\u670d\u52a1\u5668\u548c\u5f00\u6e90\u5b9e\u73b0\uff0c\u4e3a\u514d\u75ab\u80bd\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.20209", "pdf": "https://arxiv.org/pdf/2602.20209", "abs": "https://arxiv.org/abs/2602.20209", "authors": ["Shaorong Chen", "Jingbo Zhou", "Jun Xia"], "title": "Regressor-guided Diffusion Model for De Novo Peptide Sequencing with Explicit Mass Control", "categories": ["q-bio.QM", "cs.LG"], "comment": null, "summary": "The discovery of novel proteins relies on sensitive protein identification, for which de novo peptide sequencing (DNPS) from mass spectra is a crucial approach. While deep learning has advanced DNPS, existing models inadequately enforce the fundamental mass consistency constraint, that a predicted peptide's mass must match the experimental measured precursor mass. Previous DNPS methods often treat this critical information as a simple input feature or use it in post-processing, leading to numerous implausible predictions that do not adhere to this fundamental physical property. To address this limitation, we introduce DiffuNovo, a novel regressor-guided diffusion model for de novo peptide sequencing that provides explicit peptide-level mass control. Our approach integrates the mass constraint at two critical stages: during training, a novel peptide-level mass loss guides model optimization, while at inference, regressor-based guidance from gradient-based updates in the latent space steers the generation to compel the predicted peptide adheres to the mass constraint. Comprehensive evaluations on established benchmarks demonstrate that DiffuNovo surpasses state-of-the-art methods in DNPS accuracy. Additionally, as the first DNPS model to employ a diffusion model as its core backbone, DiffuNovo leverages the powerful controllability of diffusion architecture and achieves a significant reduction in mass error, thereby producing much more physically plausible peptides. These innovations represent a substantial advancement toward robust and broadly applicable DNPS. The source code is available in the supplementary material.", "AI": {"tldr": "DiffuNovo\uff1a\u4e00\u79cd\u57fa\u4e8e\u56de\u5f52\u5668\u5f15\u5bfc\u6269\u6563\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u80bd\u6bb5\u8d28\u91cf\u63a7\u5236\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u5f3a\u5236\u5b9e\u65bd\u8d28\u91cf\u4e00\u81f4\u6027\u7ea6\u675f\uff0c\u663e\u8457\u63d0\u9ad8\u4ece\u5934\u80bd\u6bb5\u6d4b\u5e8f\u7684\u51c6\u786e\u6027\u548c\u7269\u7406\u5408\u7406\u6027\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u4ece\u5934\u80bd\u6bb5\u6d4b\u5e8f\u4e2d\u672a\u80fd\u5145\u5206\u5f3a\u5236\u6267\u884c\u57fa\u672c\u8d28\u91cf\u4e00\u81f4\u6027\u7ea6\u675f\uff08\u9884\u6d4b\u80bd\u6bb5\u8d28\u91cf\u5fc5\u987b\u4e0e\u5b9e\u9a8c\u6d4b\u91cf\u7684\u524d\u4f53\u8d28\u91cf\u5339\u914d\uff09\uff0c\u5bfc\u81f4\u5927\u91cf\u4e0d\u7b26\u5408\u7269\u7406\u6027\u8d28\u7684\u4e0d\u53ef\u4fe1\u9884\u6d4b\u3002", "method": "\u63d0\u51faDiffuNovo\u56de\u5f52\u5668\u5f15\u5bfc\u6269\u6563\u6a21\u578b\uff0c\u5728\u8bad\u7ec3\u9636\u6bb5\u4f7f\u7528\u65b0\u9896\u7684\u80bd\u6bb5\u7ea7\u8d28\u91cf\u635f\u5931\u6307\u5bfc\u6a21\u578b\u4f18\u5316\uff0c\u5728\u63a8\u7406\u9636\u6bb5\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u56de\u5f52\u5668\u5f15\u5bfc\uff0c\u5f3a\u5236\u9884\u6d4b\u80bd\u6bb5\u7b26\u5408\u8d28\u91cf\u7ea6\u675f\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDiffuNovo\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8d28\u91cf\u8bef\u5dee\uff0c\u4ea7\u751f\u4e86\u66f4\u7b26\u5408\u7269\u7406\u5b9e\u9645\u7684\u80bd\u6bb5\u9884\u6d4b\u3002", "conclusion": "DiffuNovo\u901a\u8fc7\u5c06\u8d28\u91cf\u7ea6\u675f\u6574\u5408\u5230\u6269\u6563\u6a21\u578b\u6846\u67b6\u4e2d\uff0c\u5b9e\u73b0\u4e86\u5bf9\u4ece\u5934\u80bd\u6bb5\u6d4b\u5e8f\u7684\u663e\u5f0f\u63a7\u5236\uff0c\u4ee3\u8868\u4e86\u8be5\u9886\u57df\u5411\u66f4\u7a33\u5065\u548c\u5e7f\u6cdb\u5e94\u7528\u7684\u5b9e\u8d28\u6027\u8fdb\u5c55\u3002"}}
{"id": "2602.20495", "pdf": "https://arxiv.org/pdf/2602.20495", "abs": "https://arxiv.org/abs/2602.20495", "authors": ["Shun Wang", "Wenrui Hao"], "title": "Unveiling Scaling Laws of Parameter Identifiability and Uncertainty Quantification in Data-Driven Biological Modeling", "categories": ["q-bio.QM"], "comment": "45 pages, 5figures", "summary": "Integrating high-dimensional biological data into data-driven mechanistic modeling requires rigorous practical identifiability to ensure interpretability and generalizability. However, coordinate identifiability analysis often suffers from numerical instabilities near singular local minimizers. We present a computational framework that uncovers fundamental scaling laws governing practical identifiability through asymptotic analysis. By synthesizing Fisher information with perturbed Hessian matrices, we establish a hierarchical approach to quantify coordinate identifiability and inform uncertainty quantification within non-identifiable subspaces across different orders. Supported by rigorous mathematical analysis and validated on synthetic and real-world data, our framework was applied to HIV-host dynamics and spatiotemporal amyloid-beta propagation. These applications demonstrate the framework's efficiency in elucidating critical mechanisms underlying HIV diagnostics and Alzheimer's disease progression. In the era of large-scale mechanistic digital twins, our framework provides the scaling laws for data-driven modeling in terms of both parameter identifiability and uncertainty, ensuring that data-driven inferences are grounded in verifiable biological reality.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\uff0c\u901a\u8fc7\u6e10\u8fd1\u5206\u6790\u63ed\u793a\u63a7\u5236\u5b9e\u9645\u53ef\u8bc6\u522b\u6027\u7684\u57fa\u672c\u5c3a\u5ea6\u5b9a\u5f8b\uff0c\u5e94\u7528\u4e8eHIV-\u5bbf\u4e3b\u52a8\u529b\u5b66\u548c\u6dc0\u7c89\u6837\u86cb\u767d\u03b2\u4f20\u64ad\uff0c\u4e3a\u5927\u89c4\u6a21\u673a\u5236\u6570\u5b57\u5b6a\u751f\u63d0\u4f9b\u53c2\u6570\u53ef\u8bc6\u522b\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u5c3a\u5ea6\u5b9a\u5f8b\u3002", "motivation": "\u5c06\u9ad8\u7ef4\u751f\u7269\u6570\u636e\u6574\u5408\u5230\u6570\u636e\u9a71\u52a8\u7684\u673a\u5236\u5efa\u6a21\u4e2d\u9700\u8981\u4e25\u683c\u7684\u5b9e\u9645\u53ef\u8bc6\u522b\u6027\uff0c\u4ee5\u786e\u4fdd\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u6027\u3002\u7136\u800c\uff0c\u5750\u6807\u53ef\u8bc6\u522b\u6027\u5206\u6790\u7ecf\u5e38\u5728\u5947\u5f02\u5c40\u90e8\u6781\u5c0f\u503c\u9644\u8fd1\u906d\u53d7\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\u3002", "method": "\u901a\u8fc7\u6e10\u8fd1\u5206\u6790\u63ed\u793a\u5b9e\u9645\u53ef\u8bc6\u522b\u6027\u7684\u5c3a\u5ea6\u5b9a\u5f8b\uff0c\u7efc\u5408Fisher\u4fe1\u606f\u4e0e\u6270\u52a8Hessian\u77e9\u9635\uff0c\u5efa\u7acb\u5206\u5c42\u65b9\u6cd5\u6765\u91cf\u5316\u5750\u6807\u53ef\u8bc6\u522b\u6027\uff0c\u5e76\u5728\u4e0d\u540c\u9636\u6b21\u4e0a\u4e3a\u975e\u53ef\u8bc6\u522b\u5b50\u7a7a\u95f4\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u8be5\u6846\u67b6\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u5f97\u5230\u9a8c\u8bc1\uff0c\u5e94\u7528\u4e8eHIV-\u5bbf\u4e3b\u52a8\u529b\u5b66\u548c\u65f6\u7a7a\u6dc0\u7c89\u6837\u86cb\u767d\u03b2\u4f20\u64ad\uff0c\u6709\u6548\u9610\u660e\u4e86HIV\u8bca\u65ad\u548c\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u8fdb\u5c55\u7684\u5173\u952e\u673a\u5236\u3002", "conclusion": "\u5728\u5927\u89c4\u6a21\u673a\u5236\u6570\u5b57\u5b6a\u751f\u65f6\u4ee3\uff0c\u8be5\u6846\u67b6\u4e3a\u6570\u636e\u9a71\u52a8\u5efa\u6a21\u63d0\u4f9b\u4e86\u53c2\u6570\u53ef\u8bc6\u522b\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u5c3a\u5ea6\u5b9a\u5f8b\uff0c\u786e\u4fdd\u6570\u636e\u9a71\u52a8\u7684\u63a8\u65ad\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u7684\u751f\u7269\u73b0\u5b9e\u3002"}}
{"id": "2602.18889", "pdf": "https://arxiv.org/pdf/2602.18889", "abs": "https://arxiv.org/abs/2602.18889", "authors": ["Haochen Yang", "Vadim Lebovici", "Andreas Tarcevski", "Liliana Tchernev", "Saulius Zuklys", "Georg A. Holl\u00e4nder", "Helen M. Byrne", "Heather A. Harrington"], "title": "Topological shape transform for thymus structures", "categories": ["math.AT", "q-bio.QM"], "comment": "41 pages, 13 figures", "summary": "The Euler characteristic transform (ECT) is an emerging and powerful framework within topological data analysis for quantifying the geometry of shape. The applicability of ECT has been limited due to its sensitivity to noisy data. Here, we introduce SampEuler, a novel ECT-based shape descriptor designed to achieve enhanced robustness to perturbations. We provide a theoretical analysis establishing the stability of SampEuler and validate these properties empirically through pairwise similarity analyses on a benchmark dataset and showcase it on a thymus dataset. The thymus is a primary lymphoid organ that is essential for the maturation and selection of self-tolerant T cells, and within the thymus, thymic epithelial cells are organized in complex three-dimensional architectures, yet the principles governing their formation, functional organization, and remodeling during age-related involution remain poorly understood. Addressing these questions requires robust and informative shape descriptors capable of capturing subtle architectural changes across developmental stages. We develop and apply SampEuler to a newly generated two-dimensional imaging dataset of mouse thymi spanning multiple age groups, where SampEuler outperforms both persistent homology--based methods and deep learning models in detecting subtle, localized morphological differences associated with aging. To facilitate interpretation, we develop a vectorization and visualization framework for SampEuler, which preserves rich morphological information and enables identification of structural features that distinguish thymi across age groups. Collectively, our results demonstrate that SampEuler provides a robust and interpretable approach for quantifying thymic architecture and reveals age-dependent structural changes that offer new insights into thymic organization and involution.", "AI": {"tldr": "\u63d0\u51faSampEuler\uff0c\u4e00\u79cd\u57fa\u4e8e\u6b27\u62c9\u7279\u5f81\u53d8\u6362\u7684\u65b0\u578b\u5f62\u72b6\u63cf\u8ff0\u7b26\uff0c\u5177\u6709\u66f4\u5f3a\u7684\u6297\u566a\u6027\uff0c\u5e94\u7528\u4e8e\u80f8\u817a\u8870\u8001\u7814\u7a76\uff0c\u4f18\u4e8e\u6301\u4e45\u540c\u8c03\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u6b27\u62c9\u7279\u5f81\u53d8\u6362\uff08ECT\uff09\u5728\u62d3\u6251\u6570\u636e\u5206\u6790\u4e2d\u91cf\u5316\u51e0\u4f55\u5f62\u72b6\uff0c\u4f46\u5bf9\u566a\u58f0\u654f\u611f\u9650\u5236\u4e86\u5176\u5e94\u7528\u3002\u80f8\u817a\u4f5c\u4e3a\u91cd\u8981\u6dcb\u5df4\u5668\u5b98\uff0c\u5176\u4e09\u7ef4\u7ed3\u6784\u590d\u6742\uff0c\u5e74\u9f84\u76f8\u5173\u9000\u5316\u673a\u5236\u4e0d\u660e\uff0c\u9700\u8981\u80fd\u6355\u6349\u7ec6\u5fae\u7ed3\u6784\u53d8\u5316\u7684\u9c81\u68d2\u5f62\u72b6\u63cf\u8ff0\u7b26\u3002", "method": "\u63d0\u51faSampEuler\uff0c\u4e00\u79cd\u57fa\u4e8eECT\u7684\u65b0\u578b\u5f62\u72b6\u63cf\u8ff0\u7b26\uff0c\u5177\u6709\u7406\u8bba\u7a33\u5b9a\u6027\u5206\u6790\u3002\u5f00\u53d1\u5411\u91cf\u5316\u548c\u53ef\u89c6\u5316\u6846\u67b6\uff0c\u5e94\u7528\u4e8e\u5c0f\u9f20\u80f8\u817a\u4e8c\u7ef4\u6210\u50cf\u6570\u636e\u96c6\uff0c\u8de8\u8d8a\u591a\u4e2a\u5e74\u9f84\u7ec4\u3002", "result": "SampEuler\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u7a33\u5b9a\u6027\uff0c\u5728\u80f8\u817a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u6301\u4e45\u540c\u8c03\u65b9\u6cd5\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u80fd\u68c0\u6d4b\u4e0e\u8870\u8001\u76f8\u5173\u7684\u7ec6\u5fae\u5c40\u90e8\u5f62\u6001\u5dee\u5f02\u3002\u53ef\u89c6\u5316\u6846\u67b6\u80fd\u8bc6\u522b\u533a\u5206\u4e0d\u540c\u5e74\u9f84\u7ec4\u7684\u7ed3\u6784\u7279\u5f81\u3002", "conclusion": "SampEuler\u63d0\u4f9b\u4e86\u4e00\u79cd\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u7684\u80f8\u817a\u7ed3\u6784\u91cf\u5316\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u5e74\u9f84\u4f9d\u8d56\u7684\u7ed3\u6784\u53d8\u5316\uff0c\u4e3a\u80f8\u817a\u7ec4\u7ec7\u548c\u9000\u5316\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2602.20218", "pdf": "https://arxiv.org/pdf/2602.20218", "abs": "https://arxiv.org/abs/2602.20218", "authors": ["Marco \u00d6chsner", "Lena Kaiser", "Robert Stahl", "Nathalie L. Albert", "Thomas Liebig", "Robert Forbrig", "Jonas Reis"], "title": "Targeted T2-FLAIR Dropout Training Improves Robustness of nnU-Net Glioblastoma Segmentation to Missing T2-FLAIR", "categories": ["eess.IV", "q-bio.QM"], "comment": null, "summary": "Purpose: To determine whether targeted T2 fluid-attenuated inversion recovery (T2-FLAIR) dropout training improves glioblastoma MRI tumor segmentation robustness to missing T2-FLAIR without degrading performance when T2-FLAIR is available. Materials and Methods: This retrospective multi-dataset study developed nnU-Net models on BraTS 2021 (n=848) and externally tested them on UPenn-GBM glioblastoma MRI (n=403; 2006-2018; age 18-89 years; 60% male). Models were trained with no dropout or targeted T2-FLAIR dropout (probability rate r=0.35 or 0.50) by replacing only the T2-FLAIR channel with zeros. Inference used T2-FLAIR-present and T2-FLAIR-absent scenarios (T2-FLAIR set to zero). The primary endpoint was Dice similarity coefficient (DSC); secondary endpoints were 95th percentile Hausdorff distance and Bland-Altman whole-tumor volume bias. Equivalence was assessed with two one-sided tests using +/-1.5 DSC percentage points, and noninferiority versus HD-GLIO used a -1.5-point margin. Results: With T2-FLAIR present, median overall DSC was 94.8% (interquartile range, 90.0%-97.1%) with dropout and 95.0% (interquartile range, 90.3%-97.1%) without dropout (equivalence supported, p<0.001). With T2-FLAIR absent, median overall DSC improved from 81.0% (interquartile range, 75.1%-86.4%) without dropout to 93.4% (interquartile range, 89.1%-96.2%) with dropout (r=0.35); edema DSC improved from 14.0% to 87.0%, edema 95th percentile Hausdorff distance improved from 22.44 mm to 2.45 mm, and whole-tumor volume bias improved from -45.6 mL to 0.83 mL. Dropout was noninferior to HD-GLIO under T2-FLAIR-present (all p<0.001). Conclusion: Targeted T2-FLAIR dropout preserved segmentation performance when T2-FLAIR was available and reduced segmentation error and whole-tumor volume bias when T2-FLAIR was absent.", "AI": {"tldr": "\u9488\u5bf9T2-FLAIR\u5e8f\u5217\u7f3a\u5931\u60c5\u51b5\uff0c\u901a\u8fc7\u6709\u9488\u5bf9\u6027\u7684T2-FLAIR dropout\u8bad\u7ec3\uff0c\u53ef\u5728T2-FLAIR\u53ef\u7528\u65f6\u4fdd\u6301\u5206\u5272\u6027\u80fd\uff0c\u5728T2-FLAIR\u7f3a\u5931\u65f6\u663e\u8457\u63d0\u5347\u5206\u5272\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3\u4e34\u5e8aMRI\u626b\u63cf\u4e2dT2-FLAIR\u5e8f\u5217\u53ef\u80fd\u7f3a\u5931\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u5206\u5272\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u907f\u514d\u56e0\u5e8f\u5217\u7f3a\u5931\u5bfc\u81f4\u7684\u5206\u5272\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u4f7f\u7528nnU-Net\u6a21\u578b\uff0c\u5728BraTS 2021\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u91c7\u7528\u6709\u9488\u5bf9\u6027\u7684T2-FLAIR dropout\u7b56\u7565\uff08\u6982\u7387\u7387r=0.35\u62160.50\uff09\uff0c\u5728\u8bad\u7ec3\u65f6\u968f\u673a\u5c06T2-FLAIR\u901a\u9053\u7f6e\u96f6\u3002\u5728UPenn-GBM\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5916\u90e8\u6d4b\u8bd5\uff0c\u8bc4\u4f30T2-FLAIR\u5b58\u5728\u548c\u7f3a\u5931\u4e24\u79cd\u573a\u666f\u4e0b\u7684\u5206\u5272\u6027\u80fd\u3002", "result": "\u5f53T2-FLAIR\u5b58\u5728\u65f6\uff0cdropout\u6a21\u578b\u4e0e\u65e0dropout\u6a21\u578b\u6027\u80fd\u76f8\u5f53\uff08\u4e2d\u4f4dDSC 94.8% vs 95.0%\uff09\u3002\u5f53T2-FLAIR\u7f3a\u5931\u65f6\uff0cdropout\u6a21\u578b\u6027\u80fd\u663e\u8457\u63d0\u5347\uff1a\u4e2d\u4f4dDSC\u4ece81.0%\u63d0\u5347\u81f393.4%\uff0c\u6c34\u80bfDSC\u4ece14.0%\u63d0\u5347\u81f387.0%\uff0c\u6c34\u80bfHausdorff\u8ddd\u79bb\u4ece22.44mm\u6539\u5584\u81f32.45mm\uff0c\u5168\u80bf\u7624\u4f53\u79ef\u504f\u5dee\u4ece-45.6mL\u6539\u5584\u81f30.83mL\u3002", "conclusion": "\u6709\u9488\u5bf9\u6027\u7684T2-FLAIR dropout\u8bad\u7ec3\u7b56\u7565\u65e2\u80fd\u4fdd\u6301T2-FLAIR\u53ef\u7528\u65f6\u7684\u5206\u5272\u6027\u80fd\uff0c\u53c8\u80fd\u663e\u8457\u63d0\u5347T2-FLAIR\u7f3a\u5931\u65f6\u7684\u5206\u5272\u9c81\u68d2\u6027\uff0c\u51cf\u5c11\u5206\u5272\u8bef\u5dee\u548c\u4f53\u79ef\u504f\u5dee\uff0c\u5177\u6709\u4e34\u5e8a\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.20289", "pdf": "https://arxiv.org/pdf/2602.20289", "abs": "https://arxiv.org/abs/2602.20289", "authors": ["Zien Ma", "S. M. Shermer", "Oktay Karaku\u015f", "Frank C. Langbein"], "title": "The Sim-to-Real Gap in MRS Quantification: A Systematic Deep Learning Validation for GABA", "categories": ["eess.SP", "cs.LG", "q-bio.QM"], "comment": "37 pages, 10 figures, 12 tables", "summary": "Magnetic resonance spectroscopy (MRS) is used to quantify metabolites in vivo and estimate biomarkers for conditions ranging from neurological disorders to cancers. Quantifying low-concentration metabolites such as GABA ($\u03b3$-aminobutyric acid) is challenging due to low signal-to-noise ratio (SNR) and spectral overlap. We investigate and validate deep learning for quantifying complex, low-SNR, overlapping signals from MEGA-PRESS spectra, devise a convolutional neural network (CNN) and a Y-shaped autoencoder (YAE), and select the best models via Bayesian optimisation on 10,000 simulated spectra from slice-profile-aware MEGA-PRESS simulations. The selected models are trained on 100,000 simulated spectra. We validate their performance on 144 spectra from 112 experimental phantoms containing five metabolites of interest (GABA, Glu, Gln, NAA, Cr) with known ground truth concentrations across solution and gel series acquired at 3 T under varied bandwidths and implementations. These models are further assessed against the widely used LCModel quantification tool. On simulations, both models achieve near-perfect agreement (small MAEs; regression slopes $\\approx 1.00$, $R^2 \\approx 1.00$). On experimental phantom data, errors initially increased substantially. However, modelling variable linewidths in the training data significantly reduced this gap. The best augmented deep learning models achieved a mean MAE for GABA over all phantom spectra of 0.151 (YAE) and 0.160 (FCNN) in max-normalised relative concentrations, outperforming the conventional baseline LCModel (0.220). A sim-to-real gap remains, but physics-informed data augmentation substantially reduced it. Phantom ground truth is needed to judge whether a method will perform reliably on real data.", "AI": {"tldr": "\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\uff08CNN\u548cYAE\uff09\u91cf\u5316MEGA-PRESS MRS\u4e2d\u4f4e\u6d53\u5ea6\u4ee3\u8c22\u7269\uff08\u5982GABA\uff09\uff0c\u901a\u8fc7\u6a21\u62df\u6570\u636e\u8bad\u7ec3\u548c\u7269\u7406\u589e\u5f3a\uff0c\u5728\u5b9e\u9a8c\u4f53\u6a21\u6570\u636e\u4e0a\u4f18\u4e8e\u4f20\u7edfLCModel\u65b9\u6cd5\u3002", "motivation": "\u78c1\u5171\u632f\u6ce2\u8c31\uff08MRS\uff09\u7528\u4e8e\u4f53\u5185\u4ee3\u8c22\u7269\u5b9a\u91cf\uff0c\u4f46\u4f4e\u6d53\u5ea6\u4ee3\u8c22\u7269\u5982GABA\u7531\u4e8e\u4fe1\u566a\u6bd4\u4f4e\u548c\u8c31\u7ebf\u91cd\u53e0\u800c\u96be\u4ee5\u51c6\u786e\u91cf\u5316\u3002\u9700\u8981\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "1) \u5f00\u53d1\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u548cY\u5f62\u81ea\u7f16\u7801\u5668\uff08YAE\uff09\uff1b2) \u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u572810,000\u4e2a\u6a21\u62df\u8c31\u4e2d\u9009\u62e9\u6700\u4f73\u6a21\u578b\uff1b3) \u5728100,000\u4e2a\u6a21\u62df\u8c31\u4e0a\u8bad\u7ec3\uff1b4) \u901a\u8fc7\u7269\u7406\u589e\u5f3a\uff08\u5982\u53ef\u53d8\u7ebf\u5bbd\uff09\u51cf\u5c11\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\uff1b5) \u5728144\u4e2a\u5b9e\u9a8c\u4f53\u6a21\u8c31\u4e0a\u9a8c\u8bc1\uff0c\u5e76\u4e0eLCModel\u6bd4\u8f83\u3002", "result": "1) \u6a21\u62df\u6570\u636e\u4e0a\u8868\u73b0\u8fd1\u4e4e\u5b8c\u7f8e\uff08MAE\u5c0f\uff0c\u56de\u5f52\u659c\u7387\u22481.00\uff0cR\u00b2\u22481.00\uff09\uff1b2) \u5b9e\u9a8c\u4f53\u6a21\u6570\u636e\u4e0a\uff0c\u589e\u5f3a\u540e\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bGABA\u5e73\u5747MAE\u4e3a0.151\uff08YAE\uff09\u548c0.160\uff08FCNN\uff09\uff0c\u4f18\u4e8eLCModel\uff080.220\uff09\uff1b3) \u7269\u7406\u589e\u5f3a\u663e\u8457\u51cf\u5c11\u4e86\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u7ed3\u5408\u7269\u7406\u589e\u5f3a\u6570\u636e\u53ef\u4ee5\u6709\u6548\u91cf\u5316MRS\u4e2d\u7684\u4f4e\u6d53\u5ea6\u4ee3\u8c22\u7269\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002\u4f46\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\u4ecd\u7136\u5b58\u5728\uff0c\u9700\u8981\u4f53\u6a21\u771f\u5b9e\u6570\u636e\u6765\u8bc4\u4f30\u65b9\u6cd5\u5728\u5b9e\u9645\u6570\u636e\u4e0a\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2602.20344", "pdf": "https://arxiv.org/pdf/2602.20344", "abs": "https://arxiv.org/abs/2602.20344", "authors": ["Jiele Wu", "Haozhe Ma", "Zhihan Guo", "Thanh Vinh Vo", "Tze Yun Leong"], "title": "Hierarchical Molecular Representation Learning via Fragment-Based Self-Supervised Embedding Prediction", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": "15 pages (8 pages main text),8 figures", "summary": "Graph self-supervised learning (GSSL) has demonstrated strong potential for generating expressive graph embeddings without the need for human annotations, making it particularly valuable in domains with high labeling costs such as molecular graph analysis. However, existing GSSL methods mostly focus on node- or edge-level information, often ignoring chemically relevant substructures which strongly influence molecular properties. In this work, we propose Graph Semantic Predictive Network (GraSPNet), a hierarchical self-supervised framework that explicitly models both atomic-level and fragment-level semantics. GraSPNet decomposes molecular graphs into chemically meaningful fragments without predefined vocabularies and learns node- and fragment-level representations through multi-level message passing with masked semantic prediction at both levels. This hierarchical semantic supervision enables GraSPNet to learn multi-resolution structural information that is both expressive and transferable. Extensive experiments on multiple molecular property prediction benchmarks demonstrate that GraSPNet learns chemically meaningful representations and consistently outperforms state-of-the-art GSSL methods in transfer learning settings.", "AI": {"tldr": "GraSPNet\u662f\u4e00\u4e2a\u5206\u5c42\u81ea\u76d1\u7763\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u539f\u5b50\u7ea7\u548c\u7247\u6bb5\u7ea7\u8bed\u4e49\u6765\u5b66\u4e60\u5206\u5b50\u56fe\u7684\u591a\u5206\u8fa8\u7387\u8868\u793a\uff0c\u5728\u5206\u5b50\u6027\u8d28\u9884\u6d4b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5927\u591a\u5173\u6ce8\u8282\u70b9\u6216\u8fb9\u7ea7\u4fe1\u606f\uff0c\u5ffd\u7565\u4e86\u5316\u5b66\u76f8\u5173\u7684\u5b50\u7ed3\u6784\uff0c\u800c\u8fd9\u4e9b\u5b50\u7ed3\u6784\u5bf9\u5206\u5b50\u6027\u8d28\u6709\u91cd\u8981\u5f71\u54cd\u3002\u5728\u6807\u6ce8\u6210\u672c\u9ad8\u7684\u5206\u5b50\u56fe\u5206\u6790\u9886\u57df\uff0c\u9700\u8981\u80fd\u591f\u6355\u83b7\u5316\u5b66\u76f8\u5173\u5b50\u7ed3\u6784\u7684\u81ea\u76d1\u7763\u65b9\u6cd5\u3002", "method": "GraSPNet\u5c06\u5206\u5b50\u56fe\u5206\u89e3\u4e3a\u5316\u5b66\u6709\u610f\u4e49\u7684\u7247\u6bb5\uff08\u65e0\u9700\u9884\u5b9a\u4e49\u8bcd\u6c47\u8868\uff09\uff0c\u901a\u8fc7\u591a\u7ea7\u6d88\u606f\u4f20\u9012\u5728\u4e24\u4e2a\u5c42\u6b21\u4e0a\u8fdb\u884c\u63a9\u7801\u8bed\u4e49\u9884\u6d4b\uff0c\u5b66\u4e60\u8282\u70b9\u7ea7\u548c\u7247\u6bb5\u7ea7\u8868\u793a\u3002\u8fd9\u79cd\u5206\u5c42\u8bed\u4e49\u76d1\u7763\u4f7f\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u591a\u5206\u8fa8\u7387\u7ed3\u6784\u4fe1\u606f\u3002", "result": "\u5728\u591a\u4e2a\u5206\u5b50\u6027\u8d28\u9884\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGraSPNet\u5b66\u4e60\u4e86\u5316\u5b66\u6709\u610f\u4e49\u7684\u8868\u793a\uff0c\u5e76\u5728\u8fc1\u79fb\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u56fe\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "GraSPNet\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u539f\u5b50\u7ea7\u548c\u7247\u6bb5\u7ea7\u8bed\u4e49\uff0c\u80fd\u591f\u5b66\u4e60\u8868\u8fbe\u6027\u5f3a\u4e14\u53ef\u8fc1\u79fb\u7684\u591a\u5206\u8fa8\u7387\u7ed3\u6784\u4fe1\u606f\uff0c\u4e3a\u5206\u5b50\u56fe\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5206\u5c42\u81ea\u76d1\u7763\u6846\u67b6\u3002"}}
