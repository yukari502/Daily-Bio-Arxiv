<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 2]
- [q-bio.QM](#q-bio.QM) [Total: 3]
- [cs.LG](#cs.LG) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [physics.bio-ph](#physics.bio-ph) [Total: 1]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [CrossLLM-Mamba: Multimodal State Space Fusion of LLMs for RNA Interaction Prediction](https://arxiv.org/abs/2602.22236)
*Rabeya Tus Sadia,Qiang Ye,Qiang Cheng*

Main category: q-bio.GN

TL;DR: CrossLLM-Mamba：基于状态空间对齐的RNA相互作用预测新框架，利用双向Mamba编码器实现模态间深度交互，在多个RNA相互作用任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于BioLLM的RNA相互作用预测方法采用静态融合策略，无法捕捉分子结合的动态、上下文依赖特性，需要更有效的多模态交互建模方法。

Method: 将相互作用预测重新定义为状态空间对齐问题，使用双向Mamba编码器通过隐藏状态传播实现模态特定嵌入间的深度"对话"，将相互作用建模为动态序列转换而非静态特征重叠。框架保持线性计算复杂度，并引入高斯噪声注入和Focal Loss增强对困难负样本的鲁棒性。

Result: 在RNA-蛋白质、RNA-小分子、RNA-RNA三类相互作用预测任务上均取得SOTA性能。在RPI1460基准测试中MCC达到0.892，比之前最佳方法提升5.2%。在结合亲和力预测任务中，核糖开关和重复RNA亚型的Pearson相关系数超过0.95。

Conclusion: 状态空间建模是多模态生物相互作用预测的强大范式，CrossLLM-Mamba框架通过动态序列转换建模显著提升了RNA相关相互作用的预测准确性。

Abstract: Accurate prediction of RNA-associated interactions is essential for understanding cellular regulation and advancing drug discovery. While Biological Large Language Models (BioLLMs) such as ESM-2 and RiNALMo provide powerful sequence representations, existing methods rely on static fusion strategies that fail to capture the dynamic, context-dependent nature of molecular binding. We introduce CrossLLM-Mamba, a novel framework that reformulates interaction prediction as a state-space alignment problem. By leveraging bidirectional Mamba encoders, our approach enables deep ``crosstalk'' between modality-specific embeddings through hidden state propagation, modeling interactions as dynamic sequence transitions rather than static feature overlaps. The framework maintains linear computational complexity, making it scalable to high-dimensional BioLLM embeddings. We further incorporate Gaussian noise injection and Focal Loss to enhance robustness against hard-negative samples. Comprehensive experiments across three interaction categories, RNA-protein, RNA-small molecule, and RNA-RNA demonstrate that CrossLLM-Mamba achieves state-of-the-art performance. On the RPI1460 benchmark, our model attains an MCC of 0.892, surpassing the previous best by 5.2\%. For binding affinity prediction, we achieve Pearson correlations exceeding 0.95 on riboswitch and repeat RNA subtypes. These results establish state-space modeling as a powerful paradigm for multi-modal biological interaction prediction.

</details>


### [2] [Multi-Dimensional Spectral Geometry of Biological Knowledge in Single-Cell Transformer Representations](https://arxiv.org/abs/2602.22247)
*Ihor Kendiukhov*

Main category: q-bio.GN

TL;DR: scGPT单细胞基础模型学习到的基因表征具有可解释的几何结构，形成生物坐标系统而非不透明特征空间，揭示了模型内部对细胞组织的结构化理解。


<details>
  <summary>Details</summary>
Motivation: 单细胞基础模型如scGPT学习高维基因表征，但这些表征编码了哪些生物学知识尚不清楚。需要系统解码scGPT内部表征的几何结构，理解模型如何组织和表示生物学信息。

Method: 通过63次自动化假设筛选（测试183个假设），系统解码scGPT内部表征的几何结构。分析模型的谱轴、转换器层、正交轴等，研究基因在表征空间中的组织方式。

Result: 1. 主要谱轴按亚细胞定位分离基因（分泌蛋白与胞质蛋白两极）；2. 中间转换器层瞬时编码线粒体和ER区室，序列反映细胞分泌途径；3. 正交轴编码蛋白质-蛋白质相互作用网络，与实验测量强度高度相关；4. 六维谱子空间能区分转录因子与靶基因；5. 细胞类型标记基因高保真聚类；6. 残差流几何编码与注意力模式互补的生物结构。

Conclusion: 生物学转换器学习了一个可解释的细胞组织内部模型，这对调控网络推断、药物靶点优先排序和模型审计具有重要意义。模型内部表征形成了结构化的生物坐标系统而非不透明特征空间。

Abstract: Single-cell foundation models such as scGPT learn high-dimensional gene representations, but what biological knowledge these representations encode remains unclear. We systematically decode the geometric structure of scGPT internal representations through 63 iterations of automated hypothesis screening (183 hypotheses tested), revealing that the model organizes genes into a structured biological coordinate system rather than an opaque feature space.
  The dominant spectral axis separates genes by subcellular localization, with secreted proteins at one pole and cytosolic proteins at the other. Intermediate transformer layers transiently encode mitochondrial and ER compartments in a sequence that mirrors the cellular secretory pathway. Orthogonal axes encode protein-protein interaction networks with graded fidelity to experimentally measured interaction strength (Spearman rho = 1.000 across n = 5 STRING confidence quintiles, p = 0.017).
  In a compact six-dimensional spectral subspace, the model distinguishes transcription factors from their target genes (AUROC = 0.744, all 12 layers significant). Early layers preserve which specific genes regulate which targets, while deeper layers compress this into a coarser regulator versus regulated distinction. Repression edges are geometrically more prominent than activation edges, and B-cell master regulators BATF and BACH2 show convergence toward the B-cell identity anchor PAX5 across transformer depth. Cell-type marker genes cluster with high fidelity (AUROC = 0.851). Residual-stream geometry encodes biological structure complementary to attention patterns. These results indicate that biological transformers learn an interpretable internal model of cellular organization, with implications for regulatory network inference, drug target prioritization, and model auditing.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [3] [Unsupervised Denoising of Diffusion-Weighted Images with Bias and Variance Corrected Noise Modeling](https://arxiv.org/abs/2602.22235)
*Jine Xie,Zhicheng Zhang,Yunwei Chen,Yanqiu Feng,Xinyuan Zhang*

Main category: q-bio.QM

TL;DR: 提出两种基于Rician统计的噪声校正训练目标，用于扩散MRI去噪，有效减少系统偏差和异方差噪声，提升低信噪比条件下的图像质量和扩散指标可靠性。


<details>
  <summary>Details</summary>
Motivation: 扩散MRI在临床和神经科学研究中至关重要，但其固有的低信噪比（尤其是在高扩散加权下）会显著降低图像质量并影响下游分析。现有的自监督和无监督去噪方法大多未明确考虑dMRI幅度数据中常见的非高斯噪声特性，可能导致系统偏差和异方差方差，特别是在低信噪比条件下。

Method: 提出了两种噪声校正训练目标，明确建模Rician统计特性：一种基于一阶矩去除均值偏差，另一种基于二阶矩校正平方信号偏差。两种损失函数都包含自适应权重以考虑方差异质性，可在不改变网络架构的情况下使用。这些目标在图像特定的无监督深度图像先验框架中实现。

Result: 在模拟和体内dMRI上的综合实验表明，提出的损失函数有效减少了Rician偏差并抑制了噪声波动，相比最先进的去噪基线方法，获得了更高的图像质量和更可靠的扩散指标。

Conclusion: 这些结果强调了偏差和方差感知的噪声建模对于低信噪比条件下稳健的dMRI分析的重要性。提出的方法为dMRI去噪提供了一种更准确的统计建模方案。

Abstract: Diffusion magnetic resonance imaging (dMRI) plays a vital role in both clinical diagnostics and neuroscience research. However, its inherently low signal-to-noise ratio (SNR), especially under high diffusion weighting, significantly degrades image quality and impairs downstream analysis. Recent self-supervised and unsupervised denoising methods offer a practical solution by enhancing image quality without requiring clean references. However, most of these methods do not explicitly account for the non-Gaussian noise characteristics commonly present in dMRI magnitude data during the supervised learning process, potentially leading to systematic bias and heteroscedastic variance, particularly under low-SNR conditions. To overcome this limitation, we introduce noise-corrected training objectives that explicitly model Rician statistics. Specifically, we propose two alternative loss functions: one derived from the first-order moment to remove mean bias, and another from the second-order moment to correct squared-signal bias. Both losses include adaptive weighting to account for variance heterogeneity and can be used without changing the network architecture. These objectives are instantiated in an image-specific, unsupervised Deep Image Prior (DIP) framework. Comprehensive experiments on simulated and in-vivo dMRI show that the proposed losses effectively reduce Rician bias and suppress noise fluctuations, yielding higher image quality and more reliable diffusion metrics than state-of-the-art denoising baselines. These results underscore the importance of bias- and variance-aware noise modeling for robust dMRI analysis under low-SNR conditions.

</details>


### [4] [What Topological and Geometric Structure Do Biological Foundation Models Learn? Evidence from 141 Hypotheses](https://arxiv.org/abs/2602.22289)
*Ihor Kendiukhov*

Main category: q-bio.QM

TL;DR: 研究发现scGPT和Geneformer等生物基础模型在处理单细胞基因表达数据时，其内部表示形成了具有生物学意义的几何拓扑结构，这些结构在不同模型间共享但基因级对应关系不明确，且信号主要集中在免疫组织中。


<details>
  <summary>Details</summary>
Motivation: 探究生物基础模型处理单细胞基因表达数据时，其内部表示形成的几何拓扑结构是否具有生物学意义，还是仅仅是训练产物，以及对这些结论的置信度如何。

Method: 采用自主大规模假设筛选方法：AI驱动的执行者-头脑风暴者循环，提出、测试和精炼了141个几何拓扑假设，涵盖持久同调、流形距离、跨模型对齐、社区结构和有向拓扑等，所有实验都包含明确的零假设控制和不相交基因池分割。

Result: 1. 模型学习到了真实的几何结构：基因嵌入邻域表现出非平凡拓扑结构，持久同调在12个transformer层中有11层在弱域中显著(p<0.05)，在其他两个域中12/12显著；流形感知度量在识别调控基因对方面优于欧几里得距离；图社区划分追踪已知的转录因子靶标关系。
2. 结构在不同独立训练模型间共享：scGPT和Geneformer的CCA对齐产生0.80的典型相关性和72%的基因检索准确率，但19种测试方法中无一能可靠恢复基因级对应关系。
3. 结构比最初看起来更局部化：在所有零假设家族中应用严格控制后，稳健信号集中在免疫组织中，而肺和外部肺信号显著减弱。

Conclusion: 生物基础模型确实学习到了具有生物学意义的几何拓扑结构，这些结构在不同模型间共享但基因级对应关系不明确，且信号分布具有组织特异性，主要集中在免疫组织中。

Abstract: When biological foundation models such as scGPT and Geneformer process single-cell gene expression, what geometric and topological structure forms in their internal representations? Is that structure biologically meaningful or a training artifact, and how confident should we be in such claims? We address these questions through autonomous large-scale hypothesis screening: an AI-driven executor-brainstormer loop that proposed, tested, and refined 141 geometric and topological hypotheses across 52 iterations, covering persistent homology, manifold distances, cross-model alignment, community structure, and directed topology, all with explicit null controls and disjoint gene-pool splits.
  Three principal findings emerge. First, the models learn genuine geometric structure. Gene embedding neighborhoods exhibit non-trivial topology, with persistent homology significant in 11 of 12 transformer layers at p < 0.05 in the weakest domain and 12 of 12 in the other two. A multi-level distance hierarchy shows that manifold-aware metrics outperform Euclidean distance for identifying regulatory gene pairs, and graph community partitions track known transcription factor target relationships. Second, this structure is shared across independently trained models. CCA alignment between scGPT and Geneformer yields canonical correlation of 0.80 and gene retrieval accuracy of 72 percent, yet none of 19 tested methods reliably recover gene-level correspondences. The models agree on the global shape of gene space but not on precise gene placement. Third, the structure is more localized than it first appears. Under stringent null controls applied across all null families, robust signal concentrates in immune tissue, while lung and external lung signals weaken substantially.

</details>


### [5] [An Active Learning Framework for Data-Efficient, Human-in-the-Loop Enzyme Function Prediction](https://arxiv.org/abs/2602.23269)
*Ashley Babjac,Adrienne Hoarfrost*

Main category: q-bio.QM

TL;DR: HATTER框架通过人机协同主动学习策略，在减少计算成本和数据需求的情况下，实现与标准监督训练相当的酶功能预测性能。


<details>
  <summary>Details</summary>
Motivation: 环境蛋白质序列呈指数增长，而实验验证的功能数据积累缓慢，这种不匹配限制了通用蛋白质功能预测的发展。主动学习通过选择最具信息量的蛋白质进行实验注释，有望加速生物功能预测，但其潜力尚未充分探索。

Method: 提出HATTER（人机协同自适应可转移酶表征工具包）框架，整合多种主动学习策略与人机协同实验注释，用于高效微调功能预测模型。比较主动学习训练与标准监督训练在生物酶功能预测中的表现。

Result: 主动学习在多种蛋白质序列评估数据集上达到与标准训练相当的性能，同时需要更少的模型更新、处理更少的数据，并显著降低计算成本。基于点的不确定性采样方法（如熵或边缘采样）表现与更复杂的获取函数相当或更好。

Conclusion: 人机协同主动学习能有效加速酶发现，为自适应、可扩展、专家指导的蛋白质功能预测提供了一个灵活平台。序列多样性和模型架构设计比复杂的获取函数更重要。

Abstract: Generalizable protein function prediction is increasingly constrained by the growing mismatch between exponentially expanding sequences of environmental proteins and the comparatively slow accumulation of experimentally verified functional data. Active learning offers a promising path forward for accelerating biological function prediction, by selecting the most informative proteins to experimentally annotate for data-efficient training, yet its potential remains largely unexplored. We introduce HATTER (Human-in-the-loop Adaptive Toolkit for Transferable Enzyme Representations), a modular framework that integrates multiple active learning strategies with human-in-the-loop experimental annotation to efficiently fine tune function prediction models. We compare active learning training to standard supervised training for biological enzyme function prediction, demonstrating that active learning achieves performance comparable to standard training across diverse protein sequence evaluation datasets while requiring fewer model updates, processing less data, and substantially reducing computational cost. Interestingly, point-based uncertainty sampling methods like entropy or margin sampling perform as well or better than more complex acquisition functions such as bayesian sampling or BALD, highlighting the relative importance of sequence diversity in training datasets and model architecture design. These results demonstrate that human-in-the-loop active learning can efficiently accelerate enzyme discovery, providing a flexible platform for adaptive, scalable, and expert-guided protein function prediction.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [Forecasting Antimicrobial Resistance Trends Using Machine Learning on WHO GLASS Surveillance Data: A Retrieval-Augmented Generation Approach for Policy Decision Support](https://arxiv.org/abs/2602.22673)
*Md Tanvir Hasan Turja*

Main category: cs.LG

TL;DR: 开发了一个两组件框架，用于预测抗菌素耐药性趋势并提供基于证据的政策决策支持，XGBoost模型表现最佳，并实现了结合WHO政策文档的RAG系统。


<details>
  <summary>Details</summary>
Motivation: 抗菌素耐药性（AMR）是全球性危机，预计到205年每年导致1000万人死亡。虽然WHO GLASS系统提供了标准化监测数据，但很少有研究应用机器学习来预测人口层面的耐药趋势。需要开发预测模型和政策决策支持工具来应对这一危机。

Method: 提出了一个两组件框架：1）使用六种模型（朴素模型、线性回归、岭回归、XGBoost、LightGBM、LSTM）对WHO GLASS的5,909个观测值进行AMR趋势预测基准测试；2）实现检索增强生成（RAG）管道，结合ChromaDB向量存储的WHO政策文档和本地部署的Phi-3 Mini语言模型。

Result: XGBoost表现最佳，测试MAE为7.07%，R平方为0.854，比朴素基线提高了83.1%。特征重要性分析显示前一年耐药率是最重要的预测因子（50.5%重要性）。区域MAE从欧洲区域的4.16%到东南亚区域的10.14%不等。RAG系统能够生成有来源引用、幻觉受限的政策答案。

Conclusion: 该研究展示了机器学习在预测AMR趋势方面的有效性，XGBoost是最佳模型。结合RAG的政策决策支持系统为公共卫生决策者提供了基于证据的工具。代码和数据已开源，有助于进一步研究和应用。

Abstract: Antimicrobial resistance (AMR) is a growing global crisis projected to cause 10 million deaths per year by 2050. While the WHO Global Antimicrobial Resistance and Use Surveillance System (GLASS) provides standardized surveillance data across 44 countries, few studies have applied machine learning to forecast population-level resistance trends from this data. This paper presents a two-component framework for AMR trend forecasting and evidence-grounded policy decision support. We benchmark six models -- Naive, Linear Regression, Ridge Regression, XGBoost, LightGBM, and LSTM -- on 5,909 WHO GLASS observations across six WHO regions (2021-2023). XGBoost achieved the best performance with a test MAE of 7.07% and R-squared of 0.854, outperforming the naive baseline by 83.1%. Feature importance analysis identified the prior-year resistance rate as the dominant predictor (50.5% importance), while regional MAE ranged from 4.16% (European Region) to 10.14% (South-East Asia Region). We additionally implemented a Retrieval-Augmented Generation (RAG) pipeline combining a ChromaDB vector store of WHO policy documents with a locally deployed Phi-3 Mini language model, producing source-attributed, hallucination-constrained policy answers. Code and data are available at https://github.com/TanvirTurja

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [7] [CryoNet.Refine: A One-step Diffusion Model for Rapid Refinement of Structural Models with Cryo-EM Density Map Restraints](https://arxiv.org/abs/2602.22263)
*Fuyao Huang,Xiaozhu Yu,Kui Xu,Qiangfeng Cliff Zhang*

Main category: q-bio.BM

TL;DR: CryoNet.Refine：基于深度学习的一步扩散模型，用于自动化加速冷冻电镜结构精修，显著提升模型-密度图相关性和几何质量


<details>
  <summary>Details</summary>
Motivation: 传统冷冻电镜结构精修方法（如Phenix.real_space_refine和Rosetta）计算成本高、需要大量人工调整，成为研究瓶颈，需要更高效自动化的解决方案

Method: 采用端到端深度学习框架，使用一步扩散模型，结合密度感知损失函数和稳健的立体化学约束，快速优化结构以适应实验数据

Result: 与Phenix.real_space_refine相比，CryoNet.Refine在模型-密度图相关性和整体几何质量指标上均取得显著改进

Conclusion: CryoNet.Refine提供了一个可扩展、自动化且强大的替代方案，有望成为下一代冷冻电镜结构精修的重要工具

Abstract: High-resolution structure determination by cryo-electron microscopy (cryo-EM) requires the accurate fitting of an atomic model into an experimental density map. Traditional refinement pipelines such as Phenix.real_space_refine and Rosetta are computationally expensive, demand extensive manual tuning, and present a significant bottleneck for researchers. We present CryoNet.Refine, an end-to-end deep learning framework that automates and accelerates molecular structure refinement. Our approach utilizes a one-step diffusion model that integrates a density-aware loss function with robust stereochemical restraints, enabling rapid optimization of a structure against experimental data. CryoNet.Refine provides a unified and versatile solution capable of refining protein complexes as well as DNA/RNA-protein complexes. In benchmarks against Phenix.real_space_refine, CryoNet.Refine consistently achieves substantial improvements in both model-map correlation and overall geometric quality metrics. By offering a scalable, automated, and powerful alternative, CryoNet.Refine aims to serve as an essential tool for next-generation cryo-EM structure refinement. Web server: https://cryonet.ai/refine; Source code: https://github.com/kuixu/cryonet.refine.

</details>


<div id='physics.bio-ph'></div>

# physics.bio-ph [[Back]](#toc)

### [8] [Discrete turn strategies emerge in information-limited navigation](https://arxiv.org/abs/2602.23324)
*Jose M. Betancourt,Matthew P. Leighton,Thierry Emonet,Benjamin B. Machta,Michael C. Abbott*

Main category: physics.bio-ph

TL;DR: 研究生物在感官梯度中导航的最佳策略选择，发现突然转向比渐进转向更有效，并观察到不同信息量下最优策略的转变。


<details>
  <summary>Details</summary>
Motivation: 探索生物在感官梯度导航中选择不同行为策略（如反转方向、特定角度转向）的驱动因素，旨在理解如何用给定单位时间内的感官信息最大化上梯度速度。

Method: 通过理论框架分析不同行为策略的性能，比较运行-翻滚、方向反转、角度转向等策略，考察信息量变化对最优策略选择的影响。

Result: 发现无方向信息时，突然转向策略优于渐进转向；观察到策略转变：信息量增加时从方向反转到完全重定向翻滚；在复杂重定向策略中，离散转向角度最优，且最优策略使用的角度数量随条件变化。

Conclusion: 生物在感官梯度导航中的策略选择受可用信息量影响，突然转向和离散角度转向在特定条件下最优，这解释了自然界中观察到的不同行为策略的适应性优势。

Abstract: Navigation up a sensory gradient is one of the simplest behaviours, and the simplest strategy is run and tumble. But some organisms use other strategies, such as reversing direction or turning by some angle. Here we ask what drives the choice of strategy, which we frame as maximising up-gradient speed using a given amount of sensory information per unit time. We find that, without directional information on which way to turn, behavioural strategies which make sudden turns perform better than gradual steering. We see various transitions where a different strategy becomes optimal, such as a switch from reversing direction to fully re-orienting tumbles as more information becomes available. And, among more complex re-orientation strategies, we show that discrete turn angles are best, and see transitions in how many such angles the optimal strategy employs.

</details>
