<div id=toc></div>

# Table of Contents

- [q-bio.GN](#q-bio.GN) [Total: 2]
- [q-bio.QM](#q-bio.QM) [Total: 3]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [physics.bio-ph](#physics.bio-ph) [Total: 1]


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [1] [CrossLLM-Mamba: Multimodal State Space Fusion of LLMs for RNA Interaction Prediction](https://arxiv.org/abs/2602.22236)
*Rabeya Tus Sadia,Qiang Ye,Qiang Cheng*

Main category: q-bio.GN

TL;DR: CrossLLM-Mamba：基于状态空间对齐的RNA相互作用预测框架，利用双向Mamba编码器实现模态间深度"对话"，在多个RNA相互作用任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于BioLLM的方法采用静态融合策略，无法捕捉分子结合的动态、上下文依赖特性，需要更有效的多模态交互建模方法。

Method: 将相互作用预测重新定义为状态空间对齐问题，使用双向Mamba编码器通过隐藏状态传播实现模态特定嵌入间的深度"对话"，将相互作用建模为动态序列转换而非静态特征重叠。采用高斯噪声注入和Focal Loss增强对困难负样本的鲁棒性。

Result: 在RNA-蛋白质、RNA-小分子、RNA-RNA三类相互作用预测中均达到最先进性能。RPI1460基准测试MCC达0.892，比之前最佳提升5.2%。结合亲和力预测在核糖开关和重复RNA亚型上Pearson相关系数超过0.95。

Conclusion: 状态空间建模是多模态生物相互作用预测的强大范式，CrossLLM-Mamba框架通过动态序列转换建模显著提升了预测准确性。

Abstract: Accurate prediction of RNA-associated interactions is essential for understanding cellular regulation and advancing drug discovery. While Biological Large Language Models (BioLLMs) such as ESM-2 and RiNALMo provide powerful sequence representations, existing methods rely on static fusion strategies that fail to capture the dynamic, context-dependent nature of molecular binding. We introduce CrossLLM-Mamba, a novel framework that reformulates interaction prediction as a state-space alignment problem. By leveraging bidirectional Mamba encoders, our approach enables deep ``crosstalk'' between modality-specific embeddings through hidden state propagation, modeling interactions as dynamic sequence transitions rather than static feature overlaps. The framework maintains linear computational complexity, making it scalable to high-dimensional BioLLM embeddings. We further incorporate Gaussian noise injection and Focal Loss to enhance robustness against hard-negative samples. Comprehensive experiments across three interaction categories, RNA-protein, RNA-small molecule, and RNA-RNA demonstrate that CrossLLM-Mamba achieves state-of-the-art performance. On the RPI1460 benchmark, our model attains an MCC of 0.892, surpassing the previous best by 5.2\%. For binding affinity prediction, we achieve Pearson correlations exceeding 0.95 on riboswitch and repeat RNA subtypes. These results establish state-space modeling as a powerful paradigm for multi-modal biological interaction prediction.

</details>


### [2] [Multi-Dimensional Spectral Geometry of Biological Knowledge in Single-Cell Transformer Representations](https://arxiv.org/abs/2602.22247)
*Ihor Kendiukhov*

Main category: q-bio.GN

TL;DR: scGPT单细胞基础模型学习到的基因表示具有可解释的生物学结构，形成生物坐标系统而非不透明特征空间


<details>
  <summary>Details</summary>
Motivation: 单细胞基础模型如scGPT学习高维基因表示，但这些表示编码了哪些生物学知识尚不清楚，需要系统解码其内部表示的几何结构

Method: 通过63次自动化假设筛选（测试183个假设），系统解码scGPT内部表示的几何结构，分析其光谱轴和变换器层

Result: 模型将基因组织成结构化生物坐标系统：主要光谱轴按亚细胞定位分离基因；中间层编码线粒体和ER区室；正交轴编码蛋白质相互作用网络；六维子空间区分转录因子与靶基因；细胞类型标记基因高保真聚类

Conclusion: 生物变换器学习可解释的细胞组织内部模型，对调控网络推断、药物靶点优先排序和模型审计具有重要意义

Abstract: Single-cell foundation models such as scGPT learn high-dimensional gene representations, but what biological knowledge these representations encode remains unclear. We systematically decode the geometric structure of scGPT internal representations through 63 iterations of automated hypothesis screening (183 hypotheses tested), revealing that the model organizes genes into a structured biological coordinate system rather than an opaque feature space.
  The dominant spectral axis separates genes by subcellular localization, with secreted proteins at one pole and cytosolic proteins at the other. Intermediate transformer layers transiently encode mitochondrial and ER compartments in a sequence that mirrors the cellular secretory pathway. Orthogonal axes encode protein-protein interaction networks with graded fidelity to experimentally measured interaction strength (Spearman rho = 1.000 across n = 5 STRING confidence quintiles, p = 0.017).
  In a compact six-dimensional spectral subspace, the model distinguishes transcription factors from their target genes (AUROC = 0.744, all 12 layers significant). Early layers preserve which specific genes regulate which targets, while deeper layers compress this into a coarser regulator versus regulated distinction. Repression edges are geometrically more prominent than activation edges, and B-cell master regulators BATF and BACH2 show convergence toward the B-cell identity anchor PAX5 across transformer depth. Cell-type marker genes cluster with high fidelity (AUROC = 0.851). Residual-stream geometry encodes biological structure complementary to attention patterns. These results indicate that biological transformers learn an interpretable internal model of cellular organization, with implications for regulatory network inference, drug target prioritization, and model auditing.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [3] [Unsupervised Denoising of Diffusion-Weighted Images with Bias and Variance Corrected Noise Modeling](https://arxiv.org/abs/2602.22235)
*Jine Xie,Zhicheng Zhang,Yunwei Chen,Yanqiu Feng,Xinyuan Zhang*

Main category: q-bio.QM

TL;DR: 提出针对dMRI中Rician噪声的校正训练目标，通过一阶和二阶矩损失函数消除偏差，在DIP框架中实现无监督去噪，提升低信噪比条件下的图像质量和扩散指标可靠性。


<details>
  <summary>Details</summary>
Motivation: dMRI在临床和神经科学研究中至关重要，但其低信噪比（尤其在强扩散权重下）会降低图像质量并影响后续分析。现有的自监督和无监督去噪方法大多未考虑dMRI幅度数据中常见的非高斯（Rician）噪声特性，这可能导致系统性偏差和异方差性，特别是在低信噪比条件下。

Method: 提出两种基于Rician统计的噪声校正训练目标：1）基于一阶矩的损失函数以消除均值偏差；2）基于二阶矩的损失函数以校正平方信号偏差。两种损失都包含自适应权重以处理方差异质性，可在不改变网络架构的情况下使用。这些目标在图像特定的无监督Deep Image Prior（DIP）框架中实现。

Result: 在模拟和体内dMRI上的综合实验表明，所提出的损失函数能有效减少Rician偏差并抑制噪声波动，相比最先进的去噪基线方法，能产生更高的图像质量和更可靠的扩散指标。

Conclusion: 研究结果强调了偏差和方差感知的噪声建模对于低信噪比条件下稳健dMRI分析的重要性。提出的方法通过显式建模Rician统计特性，为dMRI去噪提供了更准确的解决方案。

Abstract: Diffusion magnetic resonance imaging (dMRI) plays a vital role in both clinical diagnostics and neuroscience research. However, its inherently low signal-to-noise ratio (SNR), especially under high diffusion weighting, significantly degrades image quality and impairs downstream analysis. Recent self-supervised and unsupervised denoising methods offer a practical solution by enhancing image quality without requiring clean references. However, most of these methods do not explicitly account for the non-Gaussian noise characteristics commonly present in dMRI magnitude data during the supervised learning process, potentially leading to systematic bias and heteroscedastic variance, particularly under low-SNR conditions. To overcome this limitation, we introduce noise-corrected training objectives that explicitly model Rician statistics. Specifically, we propose two alternative loss functions: one derived from the first-order moment to remove mean bias, and another from the second-order moment to correct squared-signal bias. Both losses include adaptive weighting to account for variance heterogeneity and can be used without changing the network architecture. These objectives are instantiated in an image-specific, unsupervised Deep Image Prior (DIP) framework. Comprehensive experiments on simulated and in-vivo dMRI show that the proposed losses effectively reduce Rician bias and suppress noise fluctuations, yielding higher image quality and more reliable diffusion metrics than state-of-the-art denoising baselines. These results underscore the importance of bias- and variance-aware noise modeling for robust dMRI analysis under low-SNR conditions.

</details>


### [4] [What Topological and Geometric Structure Do Biological Foundation Models Learn? Evidence from 141 Hypotheses](https://arxiv.org/abs/2602.22289)
*Ihor Kendiukhov*

Main category: q-bio.QM

TL;DR: 论文通过AI驱动的假设筛选方法，发现scGPT和Geneformer等生物基础模型在单细胞基因表达处理中学习到了真实的几何拓扑结构，这些结构在不同模型间共享但基因级对应关系不精确，且信号主要集中于免疫组织。


<details>
  <summary>Details</summary>
Motivation: 研究生物基础模型（如scGPT和Geneformer）在处理单细胞基因表达时，其内部表示形成的几何拓扑结构是否具有生物学意义而非训练伪影，以及如何评估这些发现的可靠性。

Method: 采用自主大规模假设筛选方法：AI驱动的执行者-头脑风暴者循环，提出、测试和精炼了141个几何拓扑假设，涵盖持久同调、流形距离、跨模型对齐、社区结构和有向拓扑，所有实验都包含明确的零控制和不相交基因池分割。

Result: 1. 模型学习到真实的几何结构：基因嵌入邻域展现非平凡拓扑，持久同调在12个transformer层中有11层显著；流形感知度量在识别调控基因对上优于欧氏距离；图社区划分追踪已知转录因子-靶标关系。
2. 结构在不同独立训练模型间共享：scGPT和Geneformer的CCA对齐达到0.80典型相关和72%基因检索准确率，但19种方法均无法可靠恢复基因级对应关系。
3. 结构比最初表现更局部化：在严格零控制下，稳健信号集中在免疫组织，肺和外部肺信号显著减弱。

Conclusion: 生物基础模型确实学习到了具有生物学意义的几何拓扑结构，这些结构在不同模型间共享但存在基因级差异，且信号具有组织特异性（主要集中于免疫组织）。研究强调了在评估此类发现时严格零控制和跨模型验证的重要性。

Abstract: When biological foundation models such as scGPT and Geneformer process single-cell gene expression, what geometric and topological structure forms in their internal representations? Is that structure biologically meaningful or a training artifact, and how confident should we be in such claims? We address these questions through autonomous large-scale hypothesis screening: an AI-driven executor-brainstormer loop that proposed, tested, and refined 141 geometric and topological hypotheses across 52 iterations, covering persistent homology, manifold distances, cross-model alignment, community structure, and directed topology, all with explicit null controls and disjoint gene-pool splits.
  Three principal findings emerge. First, the models learn genuine geometric structure. Gene embedding neighborhoods exhibit non-trivial topology, with persistent homology significant in 11 of 12 transformer layers at p < 0.05 in the weakest domain and 12 of 12 in the other two. A multi-level distance hierarchy shows that manifold-aware metrics outperform Euclidean distance for identifying regulatory gene pairs, and graph community partitions track known transcription factor target relationships. Second, this structure is shared across independently trained models. CCA alignment between scGPT and Geneformer yields canonical correlation of 0.80 and gene retrieval accuracy of 72 percent, yet none of 19 tested methods reliably recover gene-level correspondences. The models agree on the global shape of gene space but not on precise gene placement. Third, the structure is more localized than it first appears. Under stringent null controls applied across all null families, robust signal concentrates in immune tissue, while lung and external lung signals weaken substantially.

</details>


### [5] [An Active Learning Framework for Data-Efficient, Human-in-the-Loop Enzyme Function Prediction](https://arxiv.org/abs/2602.23269)
*Ashley Babjac,Adrienne Hoarfrost*

Main category: q-bio.QM

TL;DR: HATTER框架通过人机协同主动学习，在酶功能预测中实现与标准监督学习相当的性能，同时大幅减少数据需求和计算成本。


<details>
  <summary>Details</summary>
Motivation: 环境蛋白质序列呈指数增长，而实验验证的功能数据积累缓慢，这限制了蛋白质功能预测的泛化能力。主动学习通过选择信息量最大的蛋白质进行实验注释，有望加速生物功能预测，但其潜力尚未充分探索。

Method: 提出HATTER框架，整合多种主动学习策略与人机协同实验注释，用于高效微调功能预测模型。比较主动学习训练与标准监督训练在生物酶功能预测中的表现。

Result: 主动学习在不同蛋白质序列评估数据集上达到与标准训练相当的性能，同时需要更少的模型更新、处理更少的数据，并显著降低计算成本。基于不确定性的采样方法（如熵或边界采样）表现与更复杂的获取函数相当甚至更好。

Conclusion: 人机协同主动学习能够有效加速酶发现，为自适应、可扩展且专家指导的蛋白质功能预测提供了一个灵活平台。

Abstract: Generalizable protein function prediction is increasingly constrained by the growing mismatch between exponentially expanding sequences of environmental proteins and the comparatively slow accumulation of experimentally verified functional data. Active learning offers a promising path forward for accelerating biological function prediction, by selecting the most informative proteins to experimentally annotate for data-efficient training, yet its potential remains largely unexplored. We introduce HATTER (Human-in-the-loop Adaptive Toolkit for Transferable Enzyme Representations), a modular framework that integrates multiple active learning strategies with human-in-the-loop experimental annotation to efficiently fine tune function prediction models. We compare active learning training to standard supervised training for biological enzyme function prediction, demonstrating that active learning achieves performance comparable to standard training across diverse protein sequence evaluation datasets while requiring fewer model updates, processing less data, and substantially reducing computational cost. Interestingly, point-based uncertainty sampling methods like entropy or margin sampling perform as well or better than more complex acquisition functions such as bayesian sampling or BALD, highlighting the relative importance of sequence diversity in training datasets and model architecture design. These results demonstrate that human-in-the-loop active learning can efficiently accelerate enzyme discovery, providing a flexible platform for adaptive, scalable, and expert-guided protein function prediction.

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [6] [CryoNet.Refine: A One-step Diffusion Model for Rapid Refinement of Structural Models with Cryo-EM Density Map Restraints](https://arxiv.org/abs/2602.22263)
*Fuyao Huang,Xiaozhu Yu,Kui Xu,Qiangfeng Cliff Zhang*

Main category: q-bio.BM

TL;DR: CryoNet.Refine是一个端到端的深度学习框架，用于自动化加速冷冻电镜结构精修，通过扩散模型和密度感知损失函数，在保持立体化学约束的同时快速优化结构。


<details>
  <summary>Details</summary>
Motivation: 传统冷冻电镜结构精修方法（如Phenix.real_space_refine和Rosetta）计算成本高、需要大量手动调整，成为研究瓶颈，需要更高效自动化的解决方案。

Method: 采用端到端深度学习框架，使用一步扩散模型，结合密度感知损失函数和稳健的立体化学约束，能够快速优化结构以适应实验数据。

Result: 在基准测试中，与Phenix.real_space_refine相比，CryoNet.Refine在模型-密度图相关性和整体几何质量指标上均取得显著改进。

Conclusion: CryoNet.Refine提供了一个可扩展、自动化且功能强大的替代方案，旨在成为下一代冷冻电镜结构精修的重要工具。

Abstract: High-resolution structure determination by cryo-electron microscopy (cryo-EM) requires the accurate fitting of an atomic model into an experimental density map. Traditional refinement pipelines such as Phenix.real_space_refine and Rosetta are computationally expensive, demand extensive manual tuning, and present a significant bottleneck for researchers. We present CryoNet.Refine, an end-to-end deep learning framework that automates and accelerates molecular structure refinement. Our approach utilizes a one-step diffusion model that integrates a density-aware loss function with robust stereochemical restraints, enabling rapid optimization of a structure against experimental data. CryoNet.Refine provides a unified and versatile solution capable of refining protein complexes as well as DNA/RNA-protein complexes. In benchmarks against Phenix.real_space_refine, CryoNet.Refine consistently achieves substantial improvements in both model-map correlation and overall geometric quality metrics. By offering a scalable, automated, and powerful alternative, CryoNet.Refine aims to serve as an essential tool for next-generation cryo-EM structure refinement. Web server: https://cryonet.ai/refine; Source code: https://github.com/kuixu/cryonet.refine.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [7] [Forecasting Antimicrobial Resistance Trends Using Machine Learning on WHO GLASS Surveillance Data: A Retrieval-Augmented Generation Approach for Policy Decision Support](https://arxiv.org/abs/2602.22673)
*Md Tanvir Hasan Turja*

Main category: cs.LG

TL;DR: 开发了一个两组件框架，用于预测抗菌素耐药性趋势并提供基于证据的政策决策支持，XGBoost模型在WHO GLASS数据上表现最佳，同时结合RAG管道生成有来源依据的政策建议。


<details>
  <summary>Details</summary>
Motivation: 抗菌素耐药性（AMR）是全球性危机，预计到205年每年导致1000万人死亡。虽然WHO GLASS系统提供了标准化监测数据，但很少有研究应用机器学习从这些数据中预测群体层面的耐药趋势。

Method: 提出了一个两组件框架：1）对6个模型（Naive、线性回归、岭回归、XGBoost、LightGBM、LSTM）在5,909个WHO GLASS观测值上进行基准测试；2）实现检索增强生成（RAG）管道，结合ChromaDB向量存储的WHO政策文档和本地部署的Phi-3 Mini语言模型。

Result: XGBoost表现最佳，测试MAE为7.07%，R平方为0.854，比朴素基线提高83.1%。特征重要性分析显示前一年耐药率是最重要的预测因子（50.5%重要性）。区域MAE从欧洲区的4.16%到东南亚区的10.14%不等。RAG管道能够生成有来源依据、减少幻觉的政策答案。

Conclusion: 该框架成功预测了AMR趋势并提供了基于证据的政策决策支持，为全球AMR监测和干预提供了实用的机器学习工具。

Abstract: Antimicrobial resistance (AMR) is a growing global crisis projected to cause 10 million deaths per year by 2050. While the WHO Global Antimicrobial Resistance and Use Surveillance System (GLASS) provides standardized surveillance data across 44 countries, few studies have applied machine learning to forecast population-level resistance trends from this data. This paper presents a two-component framework for AMR trend forecasting and evidence-grounded policy decision support. We benchmark six models -- Naive, Linear Regression, Ridge Regression, XGBoost, LightGBM, and LSTM -- on 5,909 WHO GLASS observations across six WHO regions (2021-2023). XGBoost achieved the best performance with a test MAE of 7.07% and R-squared of 0.854, outperforming the naive baseline by 83.1%. Feature importance analysis identified the prior-year resistance rate as the dominant predictor (50.5% importance), while regional MAE ranged from 4.16% (European Region) to 10.14% (South-East Asia Region). We additionally implemented a Retrieval-Augmented Generation (RAG) pipeline combining a ChromaDB vector store of WHO policy documents with a locally deployed Phi-3 Mini language model, producing source-attributed, hallucination-constrained policy answers. Code and data are available at https://github.com/TanvirTurja

</details>


<div id='physics.bio-ph'></div>

# physics.bio-ph [[Back]](#toc)

### [8] [Discrete turn strategies emerge in information-limited navigation](https://arxiv.org/abs/2602.23324)
*Jose M. Betancourt,Matthew P. Leighton,Thierry Emonet,Benjamin B. Machta,Michael C. Abbott*

Main category: physics.bio-ph

TL;DR: 研究探索了生物在感知梯度中导航的最佳行为策略，发现基于可用信息量，突然转向比渐进转向更有效，并观察到策略转变的多个临界点。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解生物在感知梯度导航中为何选择不同行为策略（如反转方向、特定角度转向等），并将其框架化为在单位时间内使用给定感官信息量的前提下最大化上梯度速度的问题。

Method: 通过理论分析，比较不同行为策略在最大化上梯度速度方面的性能，考察策略随可用信息量变化的转变，特别关注突然转向与渐进转向、方向反转与完全重定向翻滚等策略的比较。

Result: 研究发现：1) 在没有方向信息指示转向方向时，突然转向策略优于渐进转向；2) 随着信息量增加，观察到策略转变，如从方向反转到完全重定向翻滚；3) 在更复杂的重定向策略中，离散转向角度最优，且最优策略使用的离散角度数量随条件变化而转变。

Conclusion: 生物在感知梯度导航中的行为策略选择受到可用感官信息量的驱动，最优策略会随信息条件变化而发生转变，离散转向角度策略在复杂重定向中表现最佳。

Abstract: Navigation up a sensory gradient is one of the simplest behaviours, and the simplest strategy is run and tumble. But some organisms use other strategies, such as reversing direction or turning by some angle. Here we ask what drives the choice of strategy, which we frame as maximising up-gradient speed using a given amount of sensory information per unit time. We find that, without directional information on which way to turn, behavioural strategies which make sudden turns perform better than gradual steering. We see various transitions where a different strategy becomes optimal, such as a switch from reversing direction to fully re-orienting tumbles as more information becomes available. And, among more complex re-orientation strategies, we show that discrete turn angles are best, and see transitions in how many such angles the optimal strategy employs.

</details>
