{
  "q-bio.NC": [
    {
      "id": "2506.03214",
      "tldr": "提出了一种多语言、多被试和多模态的联合解码框架，通过预训练多语言模型统一语义空间，提升了脑机接口的解码性能和语言公平性。",
      "motivation": "当前脑机接口的解码方法局限于单语言、单被试和单模态，限制了其临床应用和泛化能力。",
      "result": "在159名参与者的非侵入性脑记录上验证，表现出强大的跨语言、跨被试和多模态泛化能力，并提升了少数语言的解码性能。",
      "conclusion": "该框架为脑解码提供了新范式，拓宽了脑机接口的应用范围，并促进了语言公平性。"
    }
  ],
  "stat.ML": [
    {
      "id": "2505.21777",
      "tldr": "论文将扩散模型与Hopfield网络的联想记忆机制类比，探讨了在小数据和大数据情况下扩散模型的记忆与泛化行为，并预测和验证了虚假状态的存在。",
      "motivation": "研究扩散模型在联想记忆框架下的行为，特别是记忆与泛化现象，以及虚假状态的出现。",
      "result": "在小数据时，扩散模型表现出强记忆行为；在大数据时，出现新的吸引子状态，虚假状态在过渡边界出现。",
      "conclusion": "研究为扩散模型的记忆-泛化现象提供了新视角，并理论预测和实证验证了虚假状态的存在。"
    },
    {
      "id": "2505.21777",
      "tldr": "论文将扩散模型与Hopfield网络的联想记忆特性类比，探讨了其在训练和生成阶段的行为，揭示了虚假状态的存在及其与记忆-泛化现象的关系。",
      "motivation": "研究扩散模型在联想记忆框架下的行为，特别是训练数据量对记忆编码和检索的影响，以及虚假状态的出现。",
      "result": "在小数据量下，扩散模型表现出强记忆性；在大数据量下，出现新的吸引子状态和虚假状态。",
      "conclusion": "研究为扩散模型的记忆-泛化现象提供了新视角，并理论预测和实证验证了虚假状态的存在。"
    }
  ]
}